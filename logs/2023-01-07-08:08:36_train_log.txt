2023-01-07 08:08:44,034 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:08:44,035 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,072 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -0.5199394226074219
2023-01-07 08:08:44,072 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,073 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 9408
2023-01-07 08:08:44,073 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,073 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,073 > [DEBUG] 0 :: scheduled task in conv1._dp_wrapped_module.flat_param_0 :: 0, FW, [AR, [[1, torch.Size([128]) 0 0], [4, torch.Size([36864]) 24374 24374]]]
2023-01-07 08:08:44,073 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,939 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:44,939 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,939 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:08:44,939 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,940 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,940 > [DEBUG] 0 :: scheduled task in bn1._dp_wrapped_module.flat_param_0 :: 1, FW, [AR, [[2, torch.Size([4096]) 0 0], [4, torch.Size([36864]) 29806 29806]]]
2023-01-07 08:08:44,940 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,942 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 24.324832916259766
2023-01-07 08:08:44,942 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,942 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:08:44,942 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,942 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,942 > [DEBUG] 0 :: scheduled task in layer1.0.conv1._dp_wrapped_module.flat_param_0 :: 2, FW, [AR, [[4, torch.Size([36864]) 29895 29895]]]
2023-01-07 08:08:44,942 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,943 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:44,943 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,944 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:08:44,944 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,944 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,944 > [DEBUG] 0 :: scheduled task in layer1.0.bn1._dp_wrapped_module.flat_param_0 :: 3, FW, [AR, [[4, torch.Size([36864]) 34135 34135]]]
2023-01-07 08:08:44,944 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,945 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 7.929748058319092
2023-01-07 08:08:44,945 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,946 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:08:44,946 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,946 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,946 > [DEBUG] 0 :: scheduled task in layer1.0.conv2._dp_wrapped_module.flat_param_0 :: 4, FW, [AR, [[5, torch.Size([128]) 0 0], [6, torch.Size([16384]) 0 0], [18, torch.Size([36864]) 16953 16953]]]
2023-01-07 08:08:44,946 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,983 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:44,983 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,984 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:08:44,984 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,984 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,984 > [DEBUG] 0 :: scheduled task in layer1.0.bn2._dp_wrapped_module.flat_param_0 :: 5, FW, [AR, [[18, torch.Size([36864]) 19948 19948]]]
2023-01-07 08:08:44,984 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,985 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: -4.6837615966796875
2023-01-07 08:08:44,985 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,986 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:08:44,986 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,986 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,986 > [DEBUG] 0 :: scheduled task in layer1.0.conv3._dp_wrapped_module.flat_param_0 :: 6, FW, [AR, [[7, torch.Size([512]) 0 0], [10, torch.Size([16384]) 5999 5999]]]
2023-01-07 08:08:44,986 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,987 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:44,987 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,988 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:44,988 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,988 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,988 > [DEBUG] 0 :: scheduled task in layer1.0.bn3._dp_wrapped_module.flat_param_0 :: 7, FW, [AR, [[12, torch.Size([36864]) 4826 4826]]]
2023-01-07 08:08:44,988 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,989 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -3.2458581924438477
2023-01-07 08:08:44,989 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,989 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:08:44,989 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,989 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,989 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.0._dp_wrapped_module.flat_param_0 :: 8, FW, [AR, [[12, torch.Size([36864]) 9052 9052]]]
2023-01-07 08:08:44,989 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,990 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:44,990 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,991 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:44,991 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,991 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,991 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.1._dp_wrapped_module.flat_param_0 :: 9, FW, [AR, [[12, torch.Size([36864]) 13245 13245]]]
2023-01-07 08:08:44,991 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,992 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 15.818506240844727
2023-01-07 08:08:44,992 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,992 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:08:44,993 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,993 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,993 > [DEBUG] 0 :: scheduled task in layer1.1.conv1._dp_wrapped_module.flat_param_0 :: 10, FW, [AR, [[11, torch.Size([128]) 0 0], [12, torch.Size([36864]) 15961 15961]]]
2023-01-07 08:08:44,993 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,994 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:44,994 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,994 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:08:44,994 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,994 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,994 > [DEBUG] 0 :: scheduled task in layer1.1.bn1._dp_wrapped_module.flat_param_0 :: 11, FW, [AR, [[12, torch.Size([36864]) 35400 35400], [24, torch.Size([147456]) 133638 133638]]]
2023-01-07 08:08:44,994 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,995 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 9.770098686218262
2023-01-07 08:08:44,996 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,996 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:08:44,996 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,996 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,996 > [DEBUG] 0 :: scheduled task in layer1.1.conv2._dp_wrapped_module.flat_param_0 :: 12, FW, [AR, [[13, torch.Size([128]) 0 0], [14, torch.Size([16384]) 5438 5438]]]
2023-01-07 08:08:44,996 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,997 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:44,997 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,997 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:08:44,998 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,998 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:44,998 > [DEBUG] 0 :: scheduled task in layer1.1.bn2._dp_wrapped_module.flat_param_0 :: 13, FW, [AR, [[18, torch.Size([36864]) 22600 22600]]]
2023-01-07 08:08:44,998 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,999 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 11.862354278564453
2023-01-07 08:08:44,999 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:44,999 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:08:44,999 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:44,999 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,000 > [DEBUG] 0 :: scheduled task in layer1.1.conv3._dp_wrapped_module.flat_param_0 :: 14, FW, [AR, [[16, torch.Size([16384]) 8376 8376]]]
2023-01-07 08:08:45,000 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,001 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,001 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,001 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,001 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,001 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,001 > [DEBUG] 0 :: scheduled task in layer1.1.bn3._dp_wrapped_module.flat_param_0 :: 15, FW, [AR, [[16, torch.Size([16384]) 15379 15379], [18, torch.Size([36864]) 26760 26760]]]
2023-01-07 08:08:45,001 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,002 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 1.681412696838379
2023-01-07 08:08:45,002 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,003 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:08:45,003 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,003 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,003 > [DEBUG] 0 :: scheduled task in layer1.2.conv1._dp_wrapped_module.flat_param_0 :: 16, FW, [AR, [[18, torch.Size([36864]) 29950 29950]]]
2023-01-07 08:08:45,003 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,004 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:45,004 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,004 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:08:45,004 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,004 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,004 > [DEBUG] 0 :: scheduled task in layer1.2.bn1._dp_wrapped_module.flat_param_0 :: 17, FW, [AR, [[18, torch.Size([36864]) 34171 34171]]]
2023-01-07 08:08:45,005 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,006 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 13.247636795043945
2023-01-07 08:08:45,006 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,006 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:08:45,006 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,006 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,006 > [DEBUG] 0 :: scheduled task in layer1.2.conv2._dp_wrapped_module.flat_param_0 :: 18, FW, [AR, [[19, torch.Size([128]) 0 0], [20, torch.Size([16384]) 0 0], [22, torch.Size([32768]) 14465 14465]]]
2023-01-07 08:08:45,006 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,007 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:45,007 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,008 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:08:45,008 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,008 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,008 > [DEBUG] 0 :: scheduled task in layer1.2.bn2._dp_wrapped_module.flat_param_0 :: 19, FW, [AR, [[24, torch.Size([147456]) 134884 134884]]]
2023-01-07 08:08:45,008 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,009 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 0.36771655082702637
2023-01-07 08:08:45,009 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,010 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:08:45,010 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,010 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,010 > [DEBUG] 0 :: scheduled task in layer1.2.conv3._dp_wrapped_module.flat_param_0 :: 20, FW, [AR, [[22, torch.Size([32768]) 24699 24699]]]
2023-01-07 08:08:45,010 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,011 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,011 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,011 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,011 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,011 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,011 > [DEBUG] 0 :: scheduled task in layer1.2.bn3._dp_wrapped_module.flat_param_0 :: 21, FW, [AR, [[24, torch.Size([147456]) 137525 137525]]]
2023-01-07 08:08:45,011 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,012 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: -11.583595275878906
2023-01-07 08:08:45,013 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,013 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 32768
2023-01-07 08:08:45,013 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,013 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,013 > [DEBUG] 0 :: scheduled task in layer2.0.conv1._dp_wrapped_module.flat_param_0 :: 22, FW, [AR, [[24, torch.Size([147456]) 140496 140496]]]
2023-01-07 08:08:45,013 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,014 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,014 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,015 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,015 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,015 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,015 > [DEBUG] 0 :: scheduled task in layer2.0.bn1._dp_wrapped_module.flat_param_0 :: 23, FW, [AR, [[24, torch.Size([147456]) 144875 144875]]]
2023-01-07 08:08:45,015 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,016 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 8.155218124389648
2023-01-07 08:08:45,016 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,017 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:08:45,017 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,017 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,017 > [DEBUG] 0 :: scheduled task in layer2.0.conv2._dp_wrapped_module.flat_param_0 :: 24, FW, [AR, [[25, torch.Size([256]) 0 0], [26, torch.Size([65536]) 55354 55354]]]
2023-01-07 08:08:45,017 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,018 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,018 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,018 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,018 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,018 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,019 > [DEBUG] 0 :: scheduled task in layer2.0.bn2._dp_wrapped_module.flat_param_0 :: 25, FW, [AR, [[26, torch.Size([65536]) 62932 62932]]]
2023-01-07 08:08:45,019 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,020 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 15.936713218688965
2023-01-07 08:08:45,020 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,020 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:08:45,020 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,020 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,020 > [DEBUG] 0 :: scheduled task in layer2.0.conv3._dp_wrapped_module.flat_param_0 :: 26, FW, [AR, [[27, torch.Size([1024]) 0 0], [28, torch.Size([131072]) 121409 121409]]]
2023-01-07 08:08:45,020 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,021 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,021 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,022 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,022 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,022 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,022 > [DEBUG] 0 :: scheduled task in layer2.0.bn3._dp_wrapped_module.flat_param_0 :: 27, FW, [AR, [[28, torch.Size([131072]) 128101 128101]]]
2023-01-07 08:08:45,022 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,023 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -7.7740325927734375
2023-01-07 08:08:45,023 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,023 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 08:08:45,023 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,024 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,024 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.0._dp_wrapped_module.flat_param_0 :: 28, FW, [AR, [[30, torch.Size([65536]) 58518 58518]]]
2023-01-07 08:08:45,024 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,025 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,025 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,025 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,025 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,025 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,025 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.1._dp_wrapped_module.flat_param_0 :: 29, FW, [AR, [[30, torch.Size([65536]) 62926 62926]]]
2023-01-07 08:08:45,026 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,027 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 7.860844612121582
2023-01-07 08:08:45,027 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,027 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:08:45,027 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,027 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,027 > [DEBUG] 0 :: scheduled task in layer2.1.conv1._dp_wrapped_module.flat_param_0 :: 30, FW, [AR, [[31, torch.Size([256]) 0 0], [32, torch.Size([147456]) 137276 137276]]]
2023-01-07 08:08:45,027 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,028 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,028 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,029 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,029 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,029 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,029 > [DEBUG] 0 :: scheduled task in layer2.1.bn1._dp_wrapped_module.flat_param_0 :: 31, FW, [AR, [[32, torch.Size([147456]) 144843 144843]]]
2023-01-07 08:08:45,029 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,030 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -14.456551551818848
2023-01-07 08:08:45,030 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,031 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:08:45,031 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,031 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,031 > [DEBUG] 0 :: scheduled task in layer2.1.conv2._dp_wrapped_module.flat_param_0 :: 32, FW, [AR, [[33, torch.Size([256]) 0 0], [34, torch.Size([65536]) 55010 55010]]]
2023-01-07 08:08:45,031 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,032 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,032 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,032 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,032 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,032 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,033 > [DEBUG] 0 :: scheduled task in layer2.1.bn2._dp_wrapped_module.flat_param_0 :: 33, FW, [AR, [[34, torch.Size([65536]) 62519 62519]]]
2023-01-07 08:08:45,033 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,034 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -11.198725700378418
2023-01-07 08:08:45,034 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,034 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:08:45,034 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,034 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,034 > [DEBUG] 0 :: scheduled task in layer2.1.conv3._dp_wrapped_module.flat_param_0 :: 34, FW, [AR, [[36, torch.Size([65536]) 58337 58337]]]
2023-01-07 08:08:45,034 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,035 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,035 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,036 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,036 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,036 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,036 > [DEBUG] 0 :: scheduled task in layer2.1.bn3._dp_wrapped_module.flat_param_0 :: 35, FW, [AR, [[36, torch.Size([65536]) 62837 62837]]]
2023-01-07 08:08:45,036 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,037 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -35.33835220336914
2023-01-07 08:08:45,037 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,038 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:08:45,038 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,038 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,038 > [DEBUG] 0 :: scheduled task in layer2.2.conv1._dp_wrapped_module.flat_param_0 :: 36, FW, [AR, [[37, torch.Size([256]) 0 0], [38, torch.Size([147456]) 136838 136838]]]
2023-01-07 08:08:45,038 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,039 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,039 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,039 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,039 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,039 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,039 > [DEBUG] 0 :: scheduled task in layer2.2.bn1._dp_wrapped_module.flat_param_0 :: 37, FW, [AR, [[38, torch.Size([147456]) 144611 144611]]]
2023-01-07 08:08:45,039 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,040 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 10.06299877166748
2023-01-07 08:08:45,041 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,041 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:08:45,041 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,041 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,041 > [DEBUG] 0 :: scheduled task in layer2.2.conv2._dp_wrapped_module.flat_param_0 :: 38, FW, [AR, [[39, torch.Size([256]) 0 0], [40, torch.Size([65536]) 54391 54391]]]
2023-01-07 08:08:45,041 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,042 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,042 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,042 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,043 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,043 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,043 > [DEBUG] 0 :: scheduled task in layer2.2.bn2._dp_wrapped_module.flat_param_0 :: 39, FW, [AR, [[40, torch.Size([65536]) 62211 62211]]]
2023-01-07 08:08:45,043 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,044 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -5.881447792053223
2023-01-07 08:08:45,044 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,044 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:08:45,044 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,044 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,044 > [DEBUG] 0 :: scheduled task in layer2.2.conv3._dp_wrapped_module.flat_param_0 :: 40, FW, [AR, [[41, torch.Size([1024]) 0 0], [42, torch.Size([65536]) 58457 58457]]]
2023-01-07 08:08:45,044 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,045 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,046 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,046 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,046 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,046 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,046 > [DEBUG] 0 :: scheduled task in layer2.2.bn3._dp_wrapped_module.flat_param_0 :: 41, FW, [AR, [[42, torch.Size([65536]) 62434 62434]]]
2023-01-07 08:08:45,046 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,047 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 51.715721130371094
2023-01-07 08:08:45,047 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,048 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:08:45,048 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,048 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,048 > [DEBUG] 0 :: scheduled task in layer2.3.conv1._dp_wrapped_module.flat_param_0 :: 42, FW, [AR, [[43, torch.Size([256]) 0 0], [44, torch.Size([147456]) 136250 136250]]]
2023-01-07 08:08:45,048 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,049 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,049 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,049 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,049 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,049 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,049 > [DEBUG] 0 :: scheduled task in layer2.3.bn1._dp_wrapped_module.flat_param_0 :: 43, FW, [AR, [[44, torch.Size([147456]) 144343 144343]]]
2023-01-07 08:08:45,049 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,051 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 12.392324447631836
2023-01-07 08:08:45,051 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,051 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:08:45,051 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,051 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,051 > [DEBUG] 0 :: scheduled task in layer2.3.conv2._dp_wrapped_module.flat_param_0 :: 44, FW, [AR, [[45, torch.Size([256]) 0 0], [46, torch.Size([65536]) 53786 53786]]]
2023-01-07 08:08:45,051 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,052 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,052 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,053 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:08:45,053 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,053 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,053 > [DEBUG] 0 :: scheduled task in layer2.3.bn2._dp_wrapped_module.flat_param_0 :: 45, FW, [AR, [[46, torch.Size([65536]) 62012 62012]]]
2023-01-07 08:08:45,053 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,054 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 1.4828391075134277
2023-01-07 08:08:45,054 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,054 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:08:45,054 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,054 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,055 > [DEBUG] 0 :: scheduled task in layer2.3.conv3._dp_wrapped_module.flat_param_0 :: 46, FW, [AR, [[47, torch.Size([1024]) 0 0], [48, torch.Size([131072]) 123183 123183]]]
2023-01-07 08:08:45,055 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,056 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,056 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,056 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,056 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,056 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,056 > [DEBUG] 0 :: scheduled task in layer2.3.bn3._dp_wrapped_module.flat_param_0 :: 47, FW, [AR, [[48, torch.Size([131072]) 127567 127567]]]
2023-01-07 08:08:45,056 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,057 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: -8.193731307983398
2023-01-07 08:08:45,058 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,058 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 08:08:45,058 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,058 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,058 > [DEBUG] 0 :: scheduled task in layer3.0.conv1._dp_wrapped_module.flat_param_0 :: 48, FW, [AR, [[49, torch.Size([512]) 0 0], [50, torch.Size([589824]) 577505 577505]]]
2023-01-07 08:08:45,058 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,059 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,059 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,060 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,060 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,060 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,060 > [DEBUG] 0 :: scheduled task in layer3.0.bn1._dp_wrapped_module.flat_param_0 :: 49, FW, [AR, [[50, torch.Size([589824]) 586102 586102]]]
2023-01-07 08:08:45,060 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,061 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: 13.779520034790039
2023-01-07 08:08:45,061 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,061 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:08:45,061 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,062 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,062 > [DEBUG] 0 :: scheduled task in layer3.0.conv2._dp_wrapped_module.flat_param_0 :: 50, FW, [AR, [[52, torch.Size([262144]) 248915 248915]]]
2023-01-07 08:08:45,062 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,063 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,063 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,063 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,063 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,063 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,063 > [DEBUG] 0 :: scheduled task in layer3.0.bn2._dp_wrapped_module.flat_param_0 :: 51, FW, [AR, [[52, torch.Size([262144]) 258136 258136]]]
2023-01-07 08:08:45,063 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,064 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -22.520231246948242
2023-01-07 08:08:45,065 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,065 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,065 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,065 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,065 > [DEBUG] 0 :: scheduled task in layer3.0.conv3._dp_wrapped_module.flat_param_0 :: 52, FW, [AR, [[54, torch.Size([524288]) 514056 514056]]]
2023-01-07 08:08:45,065 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,066 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:08:45,066 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,067 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:08:45,067 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,067 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,067 > [DEBUG] 0 :: scheduled task in layer3.0.bn3._dp_wrapped_module.flat_param_0 :: 53, FW, [AR, [[54, torch.Size([524288]) 520083 520083]]]
2023-01-07 08:08:45,067 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,068 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -18.634197235107422
2023-01-07 08:08:45,068 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,068 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 08:08:45,068 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,068 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,068 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.0._dp_wrapped_module.flat_param_0 :: 54, FW, [AR, [[56, torch.Size([262144]) 251612 251612]]]
2023-01-07 08:08:45,068 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,069 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:08:45,070 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,070 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:08:45,070 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,070 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,070 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.1._dp_wrapped_module.flat_param_0 :: 55, FW, [AR, [[56, torch.Size([262144]) 258055 258055]]]
2023-01-07 08:08:45,070 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,071 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 32.724674224853516
2023-01-07 08:08:45,071 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,072 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,072 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,072 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,072 > [DEBUG] 0 :: scheduled task in layer3.1.conv1._dp_wrapped_module.flat_param_0 :: 56, FW, [AR, [[57, torch.Size([512]) 0 0], [58, torch.Size([589824]) 575870 575870]]]
2023-01-07 08:08:45,072 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,073 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,073 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,073 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,073 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,073 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,073 > [DEBUG] 0 :: scheduled task in layer3.1.bn1._dp_wrapped_module.flat_param_0 :: 57, FW, [AR, [[58, torch.Size([589824]) 585646 585646]]]
2023-01-07 08:08:45,074 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,075 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -24.185583114624023
2023-01-07 08:08:45,075 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,075 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:08:45,075 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,075 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,075 > [DEBUG] 0 :: scheduled task in layer3.1.conv2._dp_wrapped_module.flat_param_0 :: 58, FW, [AR, [[60, torch.Size([262144]) 250298 250298]]]
2023-01-07 08:08:45,075 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,076 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,077 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,077 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,077 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,077 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,077 > [DEBUG] 0 :: scheduled task in layer3.1.bn2._dp_wrapped_module.flat_param_0 :: 59, FW, [AR, [[60, torch.Size([262144]) 257996 257996]]]
2023-01-07 08:08:45,077 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,078 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -42.3776969909668
2023-01-07 08:08:45,078 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,079 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,079 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,079 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,079 > [DEBUG] 0 :: scheduled task in layer3.1.conv3._dp_wrapped_module.flat_param_0 :: 60, FW, [AR, [[62, torch.Size([262144]) 251486 251486]]]
2023-01-07 08:08:45,079 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,080 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:08:45,080 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,080 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:08:45,080 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,080 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,080 > [DEBUG] 0 :: scheduled task in layer3.1.bn3._dp_wrapped_module.flat_param_0 :: 61, FW, [AR, [[62, torch.Size([262144]) 257960 257960]]]
2023-01-07 08:08:45,080 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,082 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 64.7243881225586
2023-01-07 08:08:45,082 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,082 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,082 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,082 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,082 > [DEBUG] 0 :: scheduled task in layer3.2.conv1._dp_wrapped_module.flat_param_0 :: 62, FW, [AR, [[64, torch.Size([589824]) 578797 578797]]]
2023-01-07 08:08:45,082 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,083 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,083 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,084 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,084 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,084 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,084 > [DEBUG] 0 :: scheduled task in layer3.2.bn1._dp_wrapped_module.flat_param_0 :: 63, FW, [AR, [[64, torch.Size([589824]) 585633 585633]]]
2023-01-07 08:08:45,084 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,085 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 7.2132487297058105
2023-01-07 08:08:45,085 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,085 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:08:45,086 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,086 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,086 > [DEBUG] 0 :: scheduled task in layer3.2.conv2._dp_wrapped_module.flat_param_0 :: 64, FW, [AR, [[66, torch.Size([262144]) 250265 250265]]]
2023-01-07 08:08:45,086 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,087 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,087 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,087 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,087 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,087 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,087 > [DEBUG] 0 :: scheduled task in layer3.2.bn2._dp_wrapped_module.flat_param_0 :: 65, FW, [AR, [[66, torch.Size([262144]) 257992 257992]]]
2023-01-07 08:08:45,087 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,088 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -7.5133466720581055
2023-01-07 08:08:45,088 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,089 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,089 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,089 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,089 > [DEBUG] 0 :: scheduled task in layer3.2.conv3._dp_wrapped_module.flat_param_0 :: 66, FW, [AR, [[68, torch.Size([262144]) 251489 251489]]]
2023-01-07 08:08:45,089 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,090 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:08:45,090 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,090 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:08:45,090 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,090 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,090 > [DEBUG] 0 :: scheduled task in layer3.2.bn3._dp_wrapped_module.flat_param_0 :: 67, FW, [AR, [[68, torch.Size([262144]) 257975 257975]]]
2023-01-07 08:08:45,091 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,092 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: -73.61570739746094
2023-01-07 08:08:45,092 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,092 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,092 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,092 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,092 > [DEBUG] 0 :: scheduled task in layer3.3.conv1._dp_wrapped_module.flat_param_0 :: 68, FW, [AR, [[70, torch.Size([589824]) 578834 578834]]]
2023-01-07 08:08:45,092 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,093 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,093 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,094 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,094 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,094 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,094 > [DEBUG] 0 :: scheduled task in layer3.3.bn1._dp_wrapped_module.flat_param_0 :: 69, FW, [AR, [[70, torch.Size([589824]) 585643 585643]]]
2023-01-07 08:08:45,094 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,095 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 4.203762054443359
2023-01-07 08:08:45,095 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,096 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:08:45,096 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,096 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,096 > [DEBUG] 0 :: scheduled task in layer3.3.conv2._dp_wrapped_module.flat_param_0 :: 70, FW, [AR, [[72, torch.Size([262144]) 250221 250221]]]
2023-01-07 08:08:45,096 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,097 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,097 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,097 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,097 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,097 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,097 > [DEBUG] 0 :: scheduled task in layer3.3.bn2._dp_wrapped_module.flat_param_0 :: 71, FW, [AR, [[72, torch.Size([262144]) 257983 257983]]]
2023-01-07 08:08:45,097 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,098 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -11.194499969482422
2023-01-07 08:08:45,099 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,099 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,099 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,099 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,099 > [DEBUG] 0 :: scheduled task in layer3.3.conv3._dp_wrapped_module.flat_param_0 :: 72, FW, [AR, [[74, torch.Size([262144]) 251508 251508]]]
2023-01-07 08:08:45,099 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,100 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:08:45,100 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,100 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:08:45,100 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,101 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,101 > [DEBUG] 0 :: scheduled task in layer3.3.bn3._dp_wrapped_module.flat_param_0 :: 73, FW, [AR, [[74, torch.Size([262144]) 257957 257957]]]
2023-01-07 08:08:45,101 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,102 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 46.961524963378906
2023-01-07 08:08:45,102 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,102 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,102 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,102 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,102 > [DEBUG] 0 :: scheduled task in layer3.4.conv1._dp_wrapped_module.flat_param_0 :: 74, FW, [AR, [[76, torch.Size([589824]) 578817 578817]]]
2023-01-07 08:08:45,102 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,103 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,103 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,104 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,104 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,104 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,104 > [DEBUG] 0 :: scheduled task in layer3.4.bn1._dp_wrapped_module.flat_param_0 :: 75, FW, [AR, [[76, torch.Size([589824]) 585626 585626]]]
2023-01-07 08:08:45,104 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,105 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 69.10386657714844
2023-01-07 08:08:45,105 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,106 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:08:45,106 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,106 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,106 > [DEBUG] 0 :: scheduled task in layer3.4.conv2._dp_wrapped_module.flat_param_0 :: 76, FW, [AR, [[78, torch.Size([262144]) 250146 250146]]]
2023-01-07 08:08:45,106 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,107 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,107 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,107 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,107 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,107 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,107 > [DEBUG] 0 :: scheduled task in layer3.4.bn2._dp_wrapped_module.flat_param_0 :: 77, FW, [AR, [[78, torch.Size([262144]) 258090 258090]]]
2023-01-07 08:08:45,107 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,108 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: 8.155654907226562
2023-01-07 08:08:45,109 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,109 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,109 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,109 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,109 > [DEBUG] 0 :: scheduled task in layer3.4.conv3._dp_wrapped_module.flat_param_0 :: 78, FW, [AR, [[80, torch.Size([262144]) 252751 252751]]]
2023-01-07 08:08:45,109 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,110 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:08:45,110 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,110 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:08:45,111 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,111 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,111 > [DEBUG] 0 :: scheduled task in layer3.4.bn3._dp_wrapped_module.flat_param_0 :: 79, FW, [AR, [[80, torch.Size([262144]) 258004 258004]]]
2023-01-07 08:08:45,111 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,112 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: 51.074806213378906
2023-01-07 08:08:45,112 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,112 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,112 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,112 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,112 > [DEBUG] 0 :: scheduled task in layer3.5.conv1._dp_wrapped_module.flat_param_0 :: 80, FW, [AR, [[82, torch.Size([589824]) 579303 579303]]]
2023-01-07 08:08:45,113 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,113 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,114 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,114 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,114 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,114 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,114 > [DEBUG] 0 :: scheduled task in layer3.5.bn1._dp_wrapped_module.flat_param_0 :: 81, FW, [AR, [[82, torch.Size([589824]) 585666 585666]]]
2023-01-07 08:08:45,114 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,115 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: 13.907087326049805
2023-01-07 08:08:45,115 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,116 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:08:45,116 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,116 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,116 > [DEBUG] 0 :: scheduled task in layer3.5.conv2._dp_wrapped_module.flat_param_0 :: 82, FW, [AR, [[84, torch.Size([262144]) 249049 249049]]]
2023-01-07 08:08:45,116 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,117 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,117 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,117 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:08:45,117 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,117 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,117 > [DEBUG] 0 :: scheduled task in layer3.5.bn2._dp_wrapped_module.flat_param_0 :: 83, FW, [AR, [[84, torch.Size([262144]) 258029 258029]]]
2023-01-07 08:08:45,117 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,118 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -4.035181999206543
2023-01-07 08:08:45,119 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,119 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:08:45,119 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,119 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,119 > [DEBUG] 0 :: scheduled task in layer3.5.conv3._dp_wrapped_module.flat_param_0 :: 84, FW, [AR, [[86, torch.Size([524288]) 513996 513996]]]
2023-01-07 08:08:45,119 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,120 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:08:45,120 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,120 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:08:45,120 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,121 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,121 > [DEBUG] 0 :: scheduled task in layer3.5.bn3._dp_wrapped_module.flat_param_0 :: 85, FW, [AR, [[86, torch.Size([524288]) 520257 520257]]]
2023-01-07 08:08:45,121 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,122 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: 92.53986358642578
2023-01-07 08:08:45,122 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,122 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 08:08:45,122 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,122 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,122 > [DEBUG] 0 :: scheduled task in layer4.0.conv1._dp_wrapped_module.flat_param_0 :: 86, FW, [AR, [[88, torch.Size([2359296]) 2348986 2348986]]]
2023-01-07 08:08:45,123 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,124 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,124 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,124 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,124 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,124 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,124 > [DEBUG] 0 :: scheduled task in layer4.0.bn1._dp_wrapped_module.flat_param_0 :: 87, FW, [AR, [[88, torch.Size([2359296]) 2355264 2355264]]]
2023-01-07 08:08:45,124 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,125 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -25.77981948852539
2023-01-07 08:08:45,125 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,126 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:08:45,126 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,126 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,126 > [DEBUG] 0 :: scheduled task in layer4.0.conv2._dp_wrapped_module.flat_param_0 :: 88, FW, [AR, [[90, torch.Size([1048576]) 1038739 1038739]]]
2023-01-07 08:08:45,126 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,127 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,127 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,127 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,128 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,128 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,128 > [DEBUG] 0 :: scheduled task in layer4.0.bn2._dp_wrapped_module.flat_param_0 :: 89, FW, [AR, [[90, torch.Size([1048576]) 1044678 1044678]]]
2023-01-07 08:08:45,128 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,129 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 8.454111099243164
2023-01-07 08:08:45,129 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,129 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:08:45,129 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,129 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,129 > [DEBUG] 0 :: scheduled task in layer4.0.conv3._dp_wrapped_module.flat_param_0 :: 90, FW, [AR, [[92, torch.Size([2097152]) 2086529 2086529]]]
2023-01-07 08:08:45,130 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,130 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:08:45,131 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,131 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:08:45,131 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,131 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,131 > [DEBUG] 0 :: scheduled task in layer4.0.bn3._dp_wrapped_module.flat_param_0 :: 91, FW, [AR, [[92, torch.Size([2097152]) 2093335 2093335]]]
2023-01-07 08:08:45,131 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,132 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 16.471223831176758
2023-01-07 08:08:45,132 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,132 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2097152
2023-01-07 08:08:45,132 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,132 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,133 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.0._dp_wrapped_module.flat_param_0 :: 92, FW, [AR, [[94, torch.Size([1048576]) 1039183 1039183]]]
2023-01-07 08:08:45,133 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,134 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:08:45,134 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,134 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:08:45,134 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,134 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,134 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.1._dp_wrapped_module.flat_param_0 :: 93, FW, [AR, [[94, torch.Size([1048576]) 1044932 1044932]]]
2023-01-07 08:08:45,134 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,135 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -5.653153419494629
2023-01-07 08:08:45,135 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,136 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:08:45,136 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,136 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,136 > [DEBUG] 0 :: scheduled task in layer4.1.conv1._dp_wrapped_module.flat_param_0 :: 94, FW, [AR, [[96, torch.Size([2359296]) 2350332 2350332]]]
2023-01-07 08:08:45,136 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,137 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,137 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,137 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,138 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,138 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,138 > [DEBUG] 0 :: scheduled task in layer4.1.bn1._dp_wrapped_module.flat_param_0 :: 95, FW, [AR, [[96, torch.Size([2359296]) 2355789 2355789]]]
2023-01-07 08:08:45,138 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,139 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 19.831912994384766
2023-01-07 08:08:45,139 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,139 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:08:45,139 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,139 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,139 > [DEBUG] 0 :: scheduled task in layer4.1.conv2._dp_wrapped_module.flat_param_0 :: 96, FW, [AR, [[98, torch.Size([1048576]) 1038824 1038824]]]
2023-01-07 08:08:45,140 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,141 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,141 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,141 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,141 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,141 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,141 > [DEBUG] 0 :: scheduled task in layer4.1.bn2._dp_wrapped_module.flat_param_0 :: 97, FW, [AR, [[98, torch.Size([1048576]) 1045258 1045258]]]
2023-01-07 08:08:45,141 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,142 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -20.00731086730957
2023-01-07 08:08:45,142 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,143 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:08:45,143 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,143 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,143 > [DEBUG] 0 :: scheduled task in layer4.1.conv3._dp_wrapped_module.flat_param_0 :: 98, FW, [AR, [[100, torch.Size([1048576]) 1041045 1041045]]]
2023-01-07 08:08:45,143 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,144 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:08:45,144 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,144 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:08:45,144 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,144 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,145 > [DEBUG] 0 :: scheduled task in layer4.1.bn3._dp_wrapped_module.flat_param_0 :: 99, FW, [AR, [[100, torch.Size([1048576]) 1045245 1045245]]]
2023-01-07 08:08:45,145 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,146 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -78.32325744628906
2023-01-07 08:08:45,146 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,146 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:08:45,146 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,146 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,146 > [DEBUG] 0 :: scheduled task in layer4.2.conv1._dp_wrapped_module.flat_param_0 :: 100, FW, [AR, [[102, torch.Size([2359296]) 2351012 2351012]]]
2023-01-07 08:08:45,146 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,147 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,147 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,148 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,148 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,148 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,148 > [DEBUG] 0 :: scheduled task in layer4.2.bn1._dp_wrapped_module.flat_param_0 :: 101, FW, [AR, [[102, torch.Size([2359296]) 2356170 2356170]]]
2023-01-07 08:08:45,148 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,149 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 19.43707275390625
2023-01-07 08:08:45,149 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,150 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:08:45,150 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,150 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,150 > [DEBUG] 0 :: scheduled task in layer4.2.conv2._dp_wrapped_module.flat_param_0 :: 102, FW, [AR, [[104, torch.Size([1048576]) 1040523 1040523]]]
2023-01-07 08:08:45,150 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,151 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,151 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,151 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:08:45,151 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,151 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,151 > [DEBUG] 0 :: scheduled task in layer4.2.bn2._dp_wrapped_module.flat_param_0 :: 103, FW, [AR, [[104, torch.Size([1048576]) 1045407 1045407]]]
2023-01-07 08:08:45,151 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,152 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: -26.429080963134766
2023-01-07 08:08:45,153 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,153 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:08:45,153 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,153 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,153 > [DEBUG] 0 :: scheduled task in layer4.2.conv3._dp_wrapped_module.flat_param_0 :: 104, FW, [AR, [[106, torch.Size([2049000]) 2039302 2039302]]]
2023-01-07 08:08:45,153 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,154 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:08:45,154 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,154 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:08:45,154 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,154 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,154 > [DEBUG] 0 :: scheduled task in layer4.2.bn3._dp_wrapped_module.flat_param_0 :: 105, FW, [AR, [[106, torch.Size([2049000]) 2045884 2045884]]]
2023-01-07 08:08:45,155 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,156 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: 11.498095512390137
2023-01-07 08:08:45,156 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:45,157 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2049000
2023-01-07 08:08:45,157 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,157 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:08:45,157 > [DEBUG] 0 :: scheduled task in fc._dp_wrapped_module.flat_param_0 :: No scheduled
2023-01-07 08:08:45,158 > [DEBUG] 0 :: 7.651744842529297
2023-01-07 08:08:45,163 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,163 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,164 > [DEBUG] 0 :: before allreduce fusion buffer :: -370.73321533203125
2023-01-07 08:08:45,167 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,168 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,168 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,168 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,168 > [DEBUG] 0 :: before allreduce fusion buffer :: -349.224853515625
2023-01-07 08:08:45,178 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,178 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,178 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.060251299291849136
2023-01-07 08:08:45,179 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,179 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,179 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,180 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,180 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.7303838729858398
2023-01-07 08:08:45,182 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,182 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,183 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.1655614972114563
2023-01-07 08:08:45,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,183 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,184 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,184 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,184 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6481711864471436
2023-01-07 08:08:45,186 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,186 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,186 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.055031806230545044
2023-01-07 08:08:45,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,187 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,187 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.21432441473007202
2023-01-07 08:08:45,190 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,190 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,190 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.15107682347297668
2023-01-07 08:08:45,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,191 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,192 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.063173532485962
2023-01-07 08:08:45,193 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,193 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,194 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.17839065194129944
2023-01-07 08:08:45,195 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,195 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,195 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,195 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,195 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5912033319473267
2023-01-07 08:08:45,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,197 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,197 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0758211612701416
2023-01-07 08:08:45,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,198 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,198 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.311143159866333
2023-01-07 08:08:45,200 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,200 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,201 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.237412929534912
2023-01-07 08:08:45,201 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,201 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,202 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.07567428797483444
2023-01-07 08:08:45,204 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,204 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,204 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.1448424607515335
2023-01-07 08:08:45,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,205 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,205 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4570919275283813
2023-01-07 08:08:45,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,208 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,208 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.22552189230918884
2023-01-07 08:08:45,209 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,209 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,209 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,209 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,209 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8508042693138123
2023-01-07 08:08:45,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,211 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,211 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7446194291114807
2023-01-07 08:08:45,212 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,212 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,213 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,213 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,213 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.2230467796325684
2023-01-07 08:08:45,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,215 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,215 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2976362705230713
2023-01-07 08:08:45,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,216 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,216 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,216 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8951007723808289
2023-01-07 08:08:45,219 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,219 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,219 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0931594371795654
2023-01-07 08:08:45,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,220 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,220 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.110190749168396
2023-01-07 08:08:45,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,222 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,222 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.18562519550323486
2023-01-07 08:08:45,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,223 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,224 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,224 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,224 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.24560049176216125
2023-01-07 08:08:45,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,226 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,226 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.14596882462501526
2023-01-07 08:08:45,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,227 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,227 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9637110233306885
2023-01-07 08:08:45,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,229 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,229 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0918524265289307
2023-01-07 08:08:45,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,230 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,230 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,230 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.153430938720703
2023-01-07 08:08:45,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,232 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,232 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.17089638113975525
2023-01-07 08:08:45,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,233 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,234 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4532772302627563
2023-01-07 08:08:45,235 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,236 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,236 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3964540362358093
2023-01-07 08:08:45,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,237 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,237 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,237 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.15738090872764587
2023-01-07 08:08:45,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,239 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,239 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9322414398193359
2023-01-07 08:08:45,240 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,240 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,240 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,240 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,241 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.07775014638900757
2023-01-07 08:08:45,242 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,242 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,242 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.6778645515441895
2023-01-07 08:08:45,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,243 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,244 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,244 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,244 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2693527936935425
2023-01-07 08:08:45,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,246 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,246 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.1396106332540512
2023-01-07 08:08:45,247 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,247 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,247 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,247 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,247 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0980472564697266
2023-01-07 08:08:45,249 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,249 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,249 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.153984546661377
2023-01-07 08:08:45,250 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,250 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,251 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,251 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,251 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.082671880722046
2023-01-07 08:08:45,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,253 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,253 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.385371208190918
2023-01-07 08:08:45,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,254 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,254 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.509183168411255
2023-01-07 08:08:45,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,256 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,256 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.004075527191162
2023-01-07 08:08:45,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,257 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,257 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,258 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6508688926696777
2023-01-07 08:08:45,259 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,259 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,260 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.680074691772461
2023-01-07 08:08:45,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,261 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,261 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.395435333251953
2023-01-07 08:08:45,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,262 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,262 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.5756101608276367
2023-01-07 08:08:45,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,263 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,264 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.251884937286377
2023-01-07 08:08:45,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,266 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,266 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.7563438415527344
2023-01-07 08:08:45,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,267 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,267 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,268 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.52023458480835
2023-01-07 08:08:45,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,269 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,270 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.61859130859375
2023-01-07 08:08:45,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,271 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,271 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,271 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.231490135192871
2023-01-07 08:08:45,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,273 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,273 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.2742931842803955
2023-01-07 08:08:45,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,275 > [DEBUG] 0 :: before allreduce fusion buffer :: 29.396472930908203
2023-01-07 08:08:45,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,276 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,277 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.221039772033691
2023-01-07 08:08:45,277 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,277 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,278 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.8941476345062256
2023-01-07 08:08:45,279 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,279 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,279 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.5411264896392822
2023-01-07 08:08:45,280 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,280 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,281 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7319042682647705
2023-01-07 08:08:45,282 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,282 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,282 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.954535961151123
2023-01-07 08:08:45,283 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,283 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,283 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.231334686279297
2023-01-07 08:08:45,285 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,285 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.3794174194335938
2023-01-07 08:08:45,286 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,286 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,287 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.489851951599121
2023-01-07 08:08:45,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,288 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,288 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.1315749883651733
2023-01-07 08:08:45,289 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,289 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,289 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5708348751068115
2023-01-07 08:08:45,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,290 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,291 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.680784225463867
2023-01-07 08:08:45,292 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,292 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,292 > [DEBUG] 0 :: before allreduce fusion buffer :: 37.162635803222656
2023-01-07 08:08:45,293 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,293 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,293 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.6869235038757324
2023-01-07 08:08:45,294 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,294 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,295 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.484424114227295
2023-01-07 08:08:45,296 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,297 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,297 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.517470359802246
2023-01-07 08:08:45,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.435304641723633
2023-01-07 08:08:45,299 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,299 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,299 > [DEBUG] 0 :: before allreduce fusion buffer :: -19.10543441772461
2023-01-07 08:08:45,300 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,300 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,301 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.587329864501953
2023-01-07 08:08:45,302 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,302 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,302 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.327701091766357
2023-01-07 08:08:45,303 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,303 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,303 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,303 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,303 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.963932037353516
2023-01-07 08:08:45,306 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,306 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,306 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.002756595611572
2023-01-07 08:08:45,307 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,307 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,307 > [DEBUG] 0 :: before allreduce fusion buffer :: 21.168853759765625
2023-01-07 08:08:45,308 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,308 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,309 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.908612251281738
2023-01-07 08:08:45,309 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,309 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,310 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.21208381652832
2023-01-07 08:08:45,311 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,311 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,312 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.513164520263672
2023-01-07 08:08:45,313 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,313 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,313 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,313 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,313 > [DEBUG] 0 :: before allreduce fusion buffer :: 35.017799377441406
2023-01-07 08:08:45,315 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,315 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,315 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.2420449256896973
2023-01-07 08:08:45,316 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,316 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,316 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,316 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,317 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,317 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,317 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.43288803100586
2023-01-07 08:08:45,319 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,319 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,319 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.771617889404297
2023-01-07 08:08:45,320 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,320 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,321 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.251313209533691
2023-01-07 08:08:45,322 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,322 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,323 > [DEBUG] 0 :: before allreduce fusion buffer :: -29.841690063476562
2023-01-07 08:08:45,325 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,325 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,325 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,325 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 51.30345916748047
2023-01-07 08:08:45,327 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,327 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,328 > [DEBUG] 0 :: before allreduce fusion buffer :: 38.43608093261719
2023-01-07 08:08:45,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,329 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,329 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,329 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,329 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.577939987182617
2023-01-07 08:08:45,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,331 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,331 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.378484725952148
2023-01-07 08:08:45,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,332 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.813033103942871
2023-01-07 08:08:45,334 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,334 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,334 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.873414993286133
2023-01-07 08:08:45,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,335 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,335 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.983224868774414
2023-01-07 08:08:45,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,337 > [DEBUG] 0 :: before allreduce fusion buffer :: -50.48796081542969
2023-01-07 08:08:45,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,337 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,338 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,338 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,338 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,338 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,338 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,338 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,338 > [DEBUG] 0 :: before allreduce fusion buffer :: 21.381729125976562
2023-01-07 08:08:45,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,340 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.834808349609375
2023-01-07 08:08:45,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,341 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,342 > [DEBUG] 0 :: before allreduce fusion buffer :: -79.92922973632812
2023-01-07 08:08:45,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,343 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.23211669921875
2023-01-07 08:08:45,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,344 > [DEBUG] 0 :: before allreduce fusion buffer :: 91.76631164550781
2023-01-07 08:08:45,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,346 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,346 > [DEBUG] 0 :: before allreduce fusion buffer :: 31.349700927734375
2023-01-07 08:08:45,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,347 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,348 > [DEBUG] 0 :: before allreduce fusion buffer :: -173.36700439453125
2023-01-07 08:08:45,350 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,350 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,350 > [DEBUG] 0 :: before allreduce fusion buffer :: 129.3391571044922
2023-01-07 08:08:45,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,351 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.717747688293457
2023-01-07 08:08:45,353 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:08:45,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,354 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,359 > [DEBUG] 0 :: before allreduce fusion buffer :: 1208.820068359375
2023-01-07 08:08:45,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.280660629272461
2023-01-07 08:08:45,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,364 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.047070503234863
2023-01-07 08:08:45,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,365 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,365 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,366 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.851743698120117
2023-01-07 08:08:45,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,367 > [DEBUG] 0 :: before allreduce fusion buffer :: 716.6947021484375
2023-01-07 08:08:45,368 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -0.5199394226074219
2023-01-07 08:08:45,368 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,368 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,368 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,368 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:08:45,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,368 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 29.177135467529297
2023-01-07 08:08:45,370 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:45,370 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,370 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,370 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,370 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 24.324832916259766
2023-01-07 08:08:45,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,370 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,371 > [DEBUG] 0 :: before allreduce fusion buffer :: -18.091964721679688
2023-01-07 08:08:45,372 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 24.324832916259766
2023-01-07 08:08:45,372 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,372 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,373 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,373 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 7.929748058319092
2023-01-07 08:08:45,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,373 > [DEBUG] 0 :: before allreduce fusion buffer :: -206.92547607421875
2023-01-07 08:08:45,374 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.39999389648438
2023-01-07 08:08:45,374 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,374 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,374 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,374 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 7.929748058319092
2023-01-07 08:08:45,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,374 > [DEBUG] 0 :: before allreduce fusion buffer :: -145.88168334960938
2023-01-07 08:08:45,376 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 7.929748058319092
2023-01-07 08:08:45,376 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,376 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,376 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,376 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:08:45,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,376 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,377 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,377 > [DEBUG] 0 :: before allreduce fusion buffer :: -84.53761291503906
2023-01-07 08:08:45,379 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:45,379 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,379 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,379 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,379 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.247636795043945
2023-01-07 08:08:45,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,379 > [DEBUG] 0 :: before allreduce fusion buffer :: -30.097675323486328
2023-01-07 08:08:45,380 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: -4.6837615966796875
2023-01-07 08:08:45,381 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,381 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,381 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,381 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:08:45,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,381 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,381 > [DEBUG] 0 :: before allreduce fusion buffer :: 50.1472282409668
2023-01-07 08:08:45,383 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,383 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,383 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,383 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,383 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 9.770098686218262
2023-01-07 08:08:45,383 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,383 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 121.94656372070312
2023-01-07 08:08:45,385 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 35.35430145263672
2023-01-07 08:08:45,385 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,385 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,385 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,385 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 9.770098686218262
2023-01-07 08:08:45,385 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,385 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,385 > [DEBUG] 0 :: before allreduce fusion buffer :: -61.860626220703125
2023-01-07 08:08:45,386 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 259.5999755859375
2023-01-07 08:08:45,386 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,386 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,386 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,386 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 9.770098686218262
2023-01-07 08:08:45,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,387 > [DEBUG] 0 :: before allreduce fusion buffer :: -86.52940368652344
2023-01-07 08:08:45,388 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 15.818506240844727
2023-01-07 08:08:45,388 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,388 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,388 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,388 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:08:45,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,388 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,389 > [DEBUG] 0 :: before allreduce fusion buffer :: -140.78628540039062
2023-01-07 08:08:45,390 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:45,390 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,390 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,390 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,390 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 9.770098686218262
2023-01-07 08:08:45,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,391 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.80902099609375
2023-01-07 08:08:45,392 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 9.770098686218262
2023-01-07 08:08:45,392 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,392 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,392 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,392 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:08:45,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,392 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,393 > [DEBUG] 0 :: before allreduce fusion buffer :: -69.11443328857422
2023-01-07 08:08:45,395 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:45,395 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,395 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,395 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,395 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.247636795043945
2023-01-07 08:08:45,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,395 > [DEBUG] 0 :: before allreduce fusion buffer :: 101.4487075805664
2023-01-07 08:08:45,396 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 11.862354278564453
2023-01-07 08:08:45,396 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,396 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,396 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,396 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 1.681412696838379
2023-01-07 08:08:45,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 54.474056243896484
2023-01-07 08:08:45,398 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 253.99990844726562
2023-01-07 08:08:45,398 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,398 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,398 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,398 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 1.681412696838379
2023-01-07 08:08:45,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,398 > [DEBUG] 0 :: before allreduce fusion buffer :: 11.610313415527344
2023-01-07 08:08:45,400 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 1.681412696838379
2023-01-07 08:08:45,400 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,400 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,400 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,400 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.247636795043945
2023-01-07 08:08:45,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,401 > [DEBUG] 0 :: before allreduce fusion buffer :: 23.211843490600586
2023-01-07 08:08:45,401 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 64.59998321533203
2023-01-07 08:08:45,401 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,402 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,402 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,402 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.247636795043945
2023-01-07 08:08:45,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,402 > [DEBUG] 0 :: before allreduce fusion buffer :: 50.115509033203125
2023-01-07 08:08:45,404 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 13.247636795043945
2023-01-07 08:08:45,404 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,404 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,404 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,404 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:08:45,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,404 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,404 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,405 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.791156768798828
2023-01-07 08:08:45,406 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:08:45,406 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,406 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,407 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,407 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 8.155218124389648
2023-01-07 08:08:45,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,407 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.6874170303344727
2023-01-07 08:08:45,408 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 0.36771655082702637
2023-01-07 08:08:45,408 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,408 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,408 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,408 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: -11.583595275878906
2023-01-07 08:08:45,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,409 > [DEBUG] 0 :: before allreduce fusion buffer :: 27.119943618774414
2023-01-07 08:08:45,410 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 249.5999755859375
2023-01-07 08:08:45,410 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,410 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,410 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,410 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 8.155218124389648
2023-01-07 08:08:45,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,410 > [DEBUG] 0 :: before allreduce fusion buffer :: 50.170413970947266
2023-01-07 08:08:45,412 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: -11.583595275878906
2023-01-07 08:08:45,412 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,412 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,412 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,412 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 8.155218124389648
2023-01-07 08:08:45,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,412 > [DEBUG] 0 :: before allreduce fusion buffer :: 25.981327056884766
2023-01-07 08:08:45,413 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 127.00001525878906
2023-01-07 08:08:45,413 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,413 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,413 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,413 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 8.155218124389648
2023-01-07 08:08:45,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,414 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.35687255859375
2023-01-07 08:08:45,416 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 8.155218124389648
2023-01-07 08:08:45,416 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,416 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,416 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,416 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:08:45,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,416 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,417 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6103546619415283
2023-01-07 08:08:45,418 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,418 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,418 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,418 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,418 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 15.936713218688965
2023-01-07 08:08:45,418 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,419 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.528585433959961
2023-01-07 08:08:45,420 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 15.936713218688965
2023-01-07 08:08:45,420 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,420 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,421 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,421 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:08:45,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,421 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,421 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,421 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.274154663085938
2023-01-07 08:08:45,422 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,422 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,423 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,423 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,423 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -7.7740325927734375
2023-01-07 08:08:45,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,423 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.35160493850708
2023-01-07 08:08:45,424 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -7.7740325927734375
2023-01-07 08:08:45,424 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,424 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,424 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,424 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 7.860844612121582
2023-01-07 08:08:45,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,425 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.609050750732422
2023-01-07 08:08:45,426 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 521.8001098632812
2023-01-07 08:08:45,426 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,426 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,426 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,426 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 7.860844612121582
2023-01-07 08:08:45,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,426 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.472606897354126
2023-01-07 08:08:45,428 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 7.860844612121582
2023-01-07 08:08:45,428 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,428 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,428 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,428 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:08:45,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,428 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,428 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.907965660095215
2023-01-07 08:08:45,430 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,430 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,430 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,430 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,430 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: -14.456551551818848
2023-01-07 08:08:45,430 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,431 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,431 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.667938232421875
2023-01-07 08:08:45,432 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -14.456551551818848
2023-01-07 08:08:45,432 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,432 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,432 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,433 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:08:45,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,433 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,433 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.691303253173828
2023-01-07 08:08:45,434 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,434 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,434 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,434 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,435 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: -11.198725700378418
2023-01-07 08:08:45,435 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,435 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,435 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.907980442047119
2023-01-07 08:08:45,436 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -11.198725700378418
2023-01-07 08:08:45,436 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,436 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,436 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,437 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -35.33835220336914
2023-01-07 08:08:45,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,437 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,437 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.1089861392974854
2023-01-07 08:08:45,438 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 516.3994140625
2023-01-07 08:08:45,438 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,438 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,438 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,438 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -35.33835220336914
2023-01-07 08:08:45,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,438 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.311853408813477
2023-01-07 08:08:45,440 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -35.33835220336914
2023-01-07 08:08:45,440 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,440 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,440 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,440 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:08:45,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,440 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,440 > [DEBUG] 0 :: before allreduce fusion buffer :: -29.1033878326416
2023-01-07 08:08:45,442 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,442 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,442 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,442 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,442 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 10.06299877166748
2023-01-07 08:08:45,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,442 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,442 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.827415466308594
2023-01-07 08:08:45,444 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 10.06299877166748
2023-01-07 08:08:45,444 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,444 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,444 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,444 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:08:45,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,444 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,445 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.555671691894531
2023-01-07 08:08:45,446 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,446 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,446 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,446 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,446 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -5.881447792053223
2023-01-07 08:08:45,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,446 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.774862766265869
2023-01-07 08:08:45,448 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -5.881447792053223
2023-01-07 08:08:45,448 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,448 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,448 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,448 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:08:45,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,448 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,449 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.481395721435547
2023-01-07 08:08:45,450 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,450 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,450 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,450 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,450 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: 51.715721130371094
2023-01-07 08:08:45,450 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,450 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.511526107788086
2023-01-07 08:08:45,452 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 51.715721130371094
2023-01-07 08:08:45,452 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,452 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,452 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,452 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:08:45,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,452 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,453 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.116194486618042
2023-01-07 08:08:45,454 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,454 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,454 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,454 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,454 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: 12.392324447631836
2023-01-07 08:08:45,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,455 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.725623607635498
2023-01-07 08:08:45,456 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 12.392324447631836
2023-01-07 08:08:45,456 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,456 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,456 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,456 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:08:45,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,456 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,457 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.026973724365234
2023-01-07 08:08:45,458 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:08:45,458 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,458 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,458 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,458 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 1.4828391075134277
2023-01-07 08:08:45,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,459 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.018151044845581
2023-01-07 08:08:45,460 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 1.4828391075134277
2023-01-07 08:08:45,460 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,460 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,460 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,460 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:08:45,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,460 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,461 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.878540992736816
2023-01-07 08:08:45,462 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:08:45,462 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,462 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,462 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,462 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: -8.193731307983398
2023-01-07 08:08:45,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5091489553451538
2023-01-07 08:08:45,464 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: -8.193731307983398
2023-01-07 08:08:45,465 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,465 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,465 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,465 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:08:45,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,465 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,465 > [DEBUG] 0 :: before allreduce fusion buffer :: 25.996389389038086
2023-01-07 08:08:45,467 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,467 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,467 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,467 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,467 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: 13.779520034790039
2023-01-07 08:08:45,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,467 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.14967918395996
2023-01-07 08:08:45,469 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: 13.779520034790039
2023-01-07 08:08:45,469 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,469 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,469 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,469 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -22.520231246948242
2023-01-07 08:08:45,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,469 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.539388656616211
2023-01-07 08:08:45,470 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 261.60003662109375
2023-01-07 08:08:45,470 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,470 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,470 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,471 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -22.520231246948242
2023-01-07 08:08:45,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,471 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0857388973236084
2023-01-07 08:08:45,472 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -22.520231246948242
2023-01-07 08:08:45,472 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,473 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,473 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,473 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -18.634197235107422
2023-01-07 08:08:45,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,473 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.0697238445281982
2023-01-07 08:08:45,474 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1042.7935791015625
2023-01-07 08:08:45,474 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,474 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,474 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,474 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -18.634197235107422
2023-01-07 08:08:45,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,474 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.22513775527477264
2023-01-07 08:08:45,476 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -18.634197235107422
2023-01-07 08:08:45,476 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,476 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,476 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,476 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 32.724674224853516
2023-01-07 08:08:45,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,476 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7889482975006104
2023-01-07 08:08:45,477 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1051.409912109375
2023-01-07 08:08:45,477 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,477 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,477 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,477 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 32.724674224853516
2023-01-07 08:08:45,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,478 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.934645891189575
2023-01-07 08:08:45,479 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 32.724674224853516
2023-01-07 08:08:45,479 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,479 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,480 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,480 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:08:45,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,480 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:08:45,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,480 > [DEBUG] 0 :: before allreduce fusion buffer :: 17.114994049072266
2023-01-07 08:08:45,481 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:08:45,481 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,482 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,482 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,482 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -24.185583114624023
2023-01-07 08:08:45,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,482 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.978448867797852
2023-01-07 08:08:45,483 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -24.185583114624023
2023-01-07 08:08:45,483 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,484 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,484 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,484 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -42.3776969909668
2023-01-07 08:08:45,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,484 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2139655351638794
2023-01-07 08:08:45,485 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 254.79696655273438
2023-01-07 08:08:45,485 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,485 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,485 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,485 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -42.3776969909668
2023-01-07 08:08:45,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,485 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6145458221435547
2023-01-07 08:08:45,487 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -42.3776969909668
2023-01-07 08:08:45,487 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,487 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,487 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,487 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 64.7243881225586
2023-01-07 08:08:45,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,488 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.8785619735717773
2023-01-07 08:08:45,488 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1007.3977661132812
2023-01-07 08:08:45,488 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,488 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,489 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,489 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 64.7243881225586
2023-01-07 08:08:45,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,489 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.225067138671875
2023-01-07 08:08:45,491 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 64.7243881225586
2023-01-07 08:08:45,491 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,491 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,491 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,491 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 7.2132487297058105
2023-01-07 08:08:45,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,491 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.64292573928833
2023-01-07 08:08:45,492 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 255.59649658203125
2023-01-07 08:08:45,492 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,492 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,492 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,492 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 7.2132487297058105
2023-01-07 08:08:45,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,493 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9469870328903198
2023-01-07 08:08:45,494 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 7.2132487297058105
2023-01-07 08:08:45,494 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,494 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,494 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,494 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -7.5133466720581055
2023-01-07 08:08:45,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,495 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.8953332901000977
2023-01-07 08:08:45,496 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 252.0006561279297
2023-01-07 08:08:45,496 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,496 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,496 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,496 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -7.5133466720581055
2023-01-07 08:08:45,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,496 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9121949672698975
2023-01-07 08:08:45,498 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -7.5133466720581055
2023-01-07 08:08:45,498 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,498 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,498 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,498 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -73.61570739746094
2023-01-07 08:08:45,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,498 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.288744568824768
2023-01-07 08:08:45,499 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1105.80126953125
2023-01-07 08:08:45,499 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,499 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,499 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,499 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -73.61570739746094
2023-01-07 08:08:45,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,500 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9458836317062378
2023-01-07 08:08:45,502 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: -73.61570739746094
2023-01-07 08:08:45,502 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,502 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,502 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,502 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 4.203762054443359
2023-01-07 08:08:45,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,502 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8359599113464355
2023-01-07 08:08:45,503 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 301.9991455078125
2023-01-07 08:08:45,503 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,503 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,503 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,503 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 4.203762054443359
2023-01-07 08:08:45,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,504 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.7691513299942017
2023-01-07 08:08:45,505 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 4.203762054443359
2023-01-07 08:08:45,505 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,505 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,505 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,505 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -11.194499969482422
2023-01-07 08:08:45,506 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,506 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,506 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6548993587493896
2023-01-07 08:08:45,507 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 301.7998046875
2023-01-07 08:08:45,507 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,507 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,507 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,507 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -11.194499969482422
2023-01-07 08:08:45,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,507 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8012356758117676
2023-01-07 08:08:45,509 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -11.194499969482422
2023-01-07 08:08:45,509 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,509 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,509 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,509 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 46.961524963378906
2023-01-07 08:08:45,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,509 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5757980346679688
2023-01-07 08:08:45,510 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1100.3944091796875
2023-01-07 08:08:45,510 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,510 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,510 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,511 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 46.961524963378906
2023-01-07 08:08:45,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,511 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,511 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3347160518169403
2023-01-07 08:08:45,512 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 46.961524963378906
2023-01-07 08:08:45,513 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,513 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,513 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,513 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 69.10386657714844
2023-01-07 08:08:45,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,513 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.850479602813721
2023-01-07 08:08:45,514 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 302.5997314453125
2023-01-07 08:08:45,514 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,514 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,514 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,514 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 69.10386657714844
2023-01-07 08:08:45,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,514 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4500420093536377
2023-01-07 08:08:45,516 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 69.10386657714844
2023-01-07 08:08:45,516 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,516 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,516 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,516 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: 8.155654907226562
2023-01-07 08:08:45,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,516 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.184211254119873
2023-01-07 08:08:45,517 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 303.19970703125
2023-01-07 08:08:45,517 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,517 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,517 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,518 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: 8.155654907226562
2023-01-07 08:08:45,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,518 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.8371667861938477
2023-01-07 08:08:45,519 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: 8.155654907226562
2023-01-07 08:08:45,520 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,520 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,520 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,520 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: 51.074806213378906
2023-01-07 08:08:45,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,520 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8192133903503418
2023-01-07 08:08:45,521 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1082.996337890625
2023-01-07 08:08:45,521 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,521 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,521 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,521 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: 51.074806213378906
2023-01-07 08:08:45,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,521 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.9589900970458984
2023-01-07 08:08:45,523 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: 51.074806213378906
2023-01-07 08:08:45,523 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,523 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,523 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,523 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: 13.907087326049805
2023-01-07 08:08:45,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,524 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.07715415954589844
2023-01-07 08:08:45,525 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 303.9996337890625
2023-01-07 08:08:45,525 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,525 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,525 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,525 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: 13.907087326049805
2023-01-07 08:08:45,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,525 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8973153829574585
2023-01-07 08:08:45,527 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: 13.907087326049805
2023-01-07 08:08:45,527 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,527 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,527 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,527 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -4.035181999206543
2023-01-07 08:08:45,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,527 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4658993184566498
2023-01-07 08:08:45,528 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 304.9989318847656
2023-01-07 08:08:45,528 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,528 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,528 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,528 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -4.035181999206543
2023-01-07 08:08:45,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,529 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3465951681137085
2023-01-07 08:08:45,530 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -4.035181999206543
2023-01-07 08:08:45,530 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,530 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,530 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,531 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: 92.53986358642578
2023-01-07 08:08:45,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,531 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5570313930511475
2023-01-07 08:08:45,532 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1093.000732421875
2023-01-07 08:08:45,532 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,532 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,532 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,532 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: 92.53986358642578
2023-01-07 08:08:45,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,532 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.015324905514717102
2023-01-07 08:08:45,534 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: 92.53986358642578
2023-01-07 08:08:45,534 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,534 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,534 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,534 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -25.77981948852539
2023-01-07 08:08:45,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,534 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6600960493087769
2023-01-07 08:08:45,535 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 594.8016967773438
2023-01-07 08:08:45,535 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,535 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,535 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,536 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -25.77981948852539
2023-01-07 08:08:45,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,536 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5314425826072693
2023-01-07 08:08:45,538 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -25.77981948852539
2023-01-07 08:08:45,538 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,538 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,538 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,538 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 8.454111099243164
2023-01-07 08:08:45,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,538 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3808183968067169
2023-01-07 08:08:45,539 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 594.2003173828125
2023-01-07 08:08:45,539 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,539 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,539 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,539 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 8.454111099243164
2023-01-07 08:08:45,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,540 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.42760905623435974
2023-01-07 08:08:45,541 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 8.454111099243164
2023-01-07 08:08:45,541 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,541 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,541 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,541 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 16.471223831176758
2023-01-07 08:08:45,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,542 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5661219358444214
2023-01-07 08:08:45,542 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2110.000244140625
2023-01-07 08:08:45,543 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,543 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,543 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,543 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 16.471223831176758
2023-01-07 08:08:45,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,543 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.32255464792251587
2023-01-07 08:08:45,545 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 16.471223831176758
2023-01-07 08:08:45,545 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,545 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,545 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,545 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -5.653153419494629
2023-01-07 08:08:45,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,545 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,545 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7974189519882202
2023-01-07 08:08:45,546 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2160.835205078125
2023-01-07 08:08:45,546 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,546 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,546 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,546 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -5.653153419494629
2023-01-07 08:08:45,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5294609069824219
2023-01-07 08:08:45,548 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -5.653153419494629
2023-01-07 08:08:45,548 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,548 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,548 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,548 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 19.831912994384766
2023-01-07 08:08:45,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,549 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5762250423431396
2023-01-07 08:08:45,549 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 596.7992553710938
2023-01-07 08:08:45,549 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,549 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,550 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,550 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 19.831912994384766
2023-01-07 08:08:45,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,550 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.10054454207420349
2023-01-07 08:08:45,552 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 19.831912994384766
2023-01-07 08:08:45,552 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,552 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,552 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,552 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -20.00731086730957
2023-01-07 08:08:45,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,552 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5356895327568054
2023-01-07 08:08:45,553 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 596.6007080078125
2023-01-07 08:08:45,553 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,553 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,553 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,553 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -20.00731086730957
2023-01-07 08:08:45,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,554 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.41497358679771423
2023-01-07 08:08:45,555 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -20.00731086730957
2023-01-07 08:08:45,556 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,556 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,556 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,556 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -78.32325744628906
2023-01-07 08:08:45,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,556 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.03264318406581879
2023-01-07 08:08:45,557 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2055.55224609375
2023-01-07 08:08:45,557 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,557 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,557 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,557 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -78.32325744628906
2023-01-07 08:08:45,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,557 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.02477302774786949
2023-01-07 08:08:45,559 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -78.32325744628906
2023-01-07 08:08:45,559 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,559 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,559 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,559 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 19.43707275390625
2023-01-07 08:08:45,559 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,559 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,560 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.08305124938488007
2023-01-07 08:08:45,560 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 597.80224609375
2023-01-07 08:08:45,560 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,560 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,561 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,561 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 19.43707275390625
2023-01-07 08:08:45,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,561 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.22061562538146973
2023-01-07 08:08:45,563 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 19.43707275390625
2023-01-07 08:08:45,563 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,563 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,563 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,563 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -26.429080963134766
2023-01-07 08:08:45,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,563 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,563 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.116879403591156
2023-01-07 08:08:45,564 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 597.9994506835938
2023-01-07 08:08:45,564 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,564 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,564 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,564 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -26.429080963134766
2023-01-07 08:08:45,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,565 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.06420014798641205
2023-01-07 08:08:45,566 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: -26.429080963134766
2023-01-07 08:08:45,566 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,566 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,567 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: 11.498095512390137
2023-01-07 08:08:45,567 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,567 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,567 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.224303245544434
2023-01-07 08:08:45,568 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2449.999267578125
2023-01-07 08:08:45,568 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,568 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,568 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: 11.498095512390137
2023-01-07 08:08:45,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2426563501358032
2023-01-07 08:08:45,570 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: 11.498095512390137
2023-01-07 08:08:45,570 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:45,570 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:45,570 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:45,571 > [DEBUG] 0 :: 7.358820915222168
2023-01-07 08:08:45,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,575 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,576 > [DEBUG] 0 :: before allreduce fusion buffer :: -584.1958618164062
2023-01-07 08:08:45,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,578 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,579 > [DEBUG] 0 :: before allreduce fusion buffer :: -584.592041015625
2023-01-07 08:08:45,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,581 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,581 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.41465377807617
2023-01-07 08:08:45,582 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,582 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,583 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,583 > [DEBUG] 0 :: before allreduce fusion buffer :: -313.7305908203125
2023-01-07 08:08:45,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,585 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,585 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.36612319946289
2023-01-07 08:08:45,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,586 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,586 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,586 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,586 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0840280055999756
2023-01-07 08:08:45,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,588 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,588 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,588 > [DEBUG] 0 :: before allreduce fusion buffer :: -27.350730895996094
2023-01-07 08:08:45,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,589 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,590 > [DEBUG] 0 :: before allreduce fusion buffer :: -49.13896179199219
2023-01-07 08:08:45,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,591 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,592 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.53460693359375
2023-01-07 08:08:45,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,593 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,593 > [DEBUG] 0 :: before allreduce fusion buffer :: -60.26033020019531
2023-01-07 08:08:45,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,595 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,595 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.63389587402344
2023-01-07 08:08:45,596 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,596 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,596 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,596 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,596 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,596 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.490894079208374
2023-01-07 08:08:45,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,598 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,598 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.46543884277344
2023-01-07 08:08:45,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,599 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,599 > [DEBUG] 0 :: before allreduce fusion buffer :: -61.19931411743164
2023-01-07 08:08:45,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,601 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,601 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.572265625
2023-01-07 08:08:45,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,602 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,603 > [DEBUG] 0 :: before allreduce fusion buffer :: -18.159507751464844
2023-01-07 08:08:45,604 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,604 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,604 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,605 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.20634841918945
2023-01-07 08:08:45,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,606 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,606 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,606 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.35767364501953
2023-01-07 08:08:45,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,608 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,608 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.723609924316406
2023-01-07 08:08:45,609 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,609 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,609 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,609 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,609 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,609 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.2549638748168945
2023-01-07 08:08:45,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,611 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,611 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,611 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.086524963378906
2023-01-07 08:08:45,612 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,613 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,613 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.05684658885002136
2023-01-07 08:08:45,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,615 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,615 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.54966735839844
2023-01-07 08:08:45,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,616 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,616 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.876321792602539
2023-01-07 08:08:45,618 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,618 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,618 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,618 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.07160949707031
2023-01-07 08:08:45,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,619 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,619 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.550737380981445
2023-01-07 08:08:45,621 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,621 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,621 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,621 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.528377532958984
2023-01-07 08:08:45,622 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,622 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,622 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,622 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,622 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,623 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6379787921905518
2023-01-07 08:08:45,624 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,624 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,624 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,624 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.86320877075195
2023-01-07 08:08:45,625 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,625 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,625 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,625 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,626 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.141609191894531
2023-01-07 08:08:45,737 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,737 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,737 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,737 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.255306243896484
2023-01-07 08:08:45,738 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,738 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,738 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,738 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,738 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,739 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.570229530334473
2023-01-07 08:08:45,921 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,921 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,921 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,922 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.832176208496094
2023-01-07 08:08:45,922 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,923 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,923 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:45,923 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:45,923 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:45,923 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.09505623579025269
2023-01-07 08:08:46,221 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,222 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,222 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.988807678222656
2023-01-07 08:08:46,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,223 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,223 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,223 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,224 > [DEBUG] 0 :: before allreduce fusion buffer :: -59.888587951660156
2023-01-07 08:08:46,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,226 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,226 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.644287109375
2023-01-07 08:08:46,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,227 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,227 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.73103141784668
2023-01-07 08:08:46,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,229 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,229 > [DEBUG] 0 :: before allreduce fusion buffer :: -2585.506591796875
2023-01-07 08:08:46,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,230 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,230 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,230 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,230 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.1720094680786133
2023-01-07 08:08:46,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,232 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,232 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,232 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.28806573152542114
2023-01-07 08:08:46,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,233 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,234 > [DEBUG] 0 :: before allreduce fusion buffer :: 10947.26953125
2023-01-07 08:08:46,235 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,235 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,235 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,235 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.743574857711792
2023-01-07 08:08:46,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,236 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,237 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,237 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.6832470893859863
2023-01-07 08:08:46,238 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,238 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,238 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,238 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.31845760345459
2023-01-07 08:08:46,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,239 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,240 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,240 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,240 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,240 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.39545440673828
2023-01-07 08:08:46,242 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,242 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,242 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,242 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9975614547729492
2023-01-07 08:08:46,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,243 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,243 > [DEBUG] 0 :: before allreduce fusion buffer :: 2802841.0
2023-01-07 08:08:46,245 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,245 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,245 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,245 > [DEBUG] 0 :: before allreduce fusion buffer :: 5607338.0
2023-01-07 08:08:46,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,246 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,246 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.48305606842041
2023-01-07 08:08:46,247 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,247 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,247 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,247 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.92937970161438
2023-01-07 08:08:46,248 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,248 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,248 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,249 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,249 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,249 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.991855144500732
2023-01-07 08:08:46,250 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,250 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,250 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,251 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0415360927581787
2023-01-07 08:08:46,251 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,251 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,252 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,252 > [DEBUG] 0 :: before allreduce fusion buffer :: 358868032.0
2023-01-07 08:08:46,253 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,253 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,253 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,254 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.33113884925842285
2023-01-07 08:08:46,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,255 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,255 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,255 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,255 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,255 > [DEBUG] 0 :: before allreduce fusion buffer :: -1435712.375
2023-01-07 08:08:46,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,256 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,257 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,257 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.559675216674805
2023-01-07 08:08:46,258 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,258 > [DEBUG] 0 :: before allreduce fusion buffer :: 28.7231502532959
2023-01-07 08:08:46,259 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,259 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,259 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,259 > [DEBUG] 0 :: before allreduce fusion buffer :: -23.31500244140625
2023-01-07 08:08:46,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,260 > [DEBUG] 0 :: before allreduce fusion buffer :: -30.016448974609375
2023-01-07 08:08:46,261 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,261 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,262 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,262 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.403121948242188
2023-01-07 08:08:46,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,263 > [DEBUG] 0 :: before allreduce fusion buffer :: 24.40041732788086
2023-01-07 08:08:46,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,264 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,264 > [DEBUG] 0 :: before allreduce fusion buffer :: 83.2435302734375
2023-01-07 08:08:46,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,265 > [DEBUG] 0 :: before allreduce fusion buffer :: -513369152.0
2023-01-07 08:08:46,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,266 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,267 > [DEBUG] 0 :: before allreduce fusion buffer :: 156.70867919921875
2023-01-07 08:08:46,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,268 > [DEBUG] 0 :: before allreduce fusion buffer :: -193.3660430908203
2023-01-07 08:08:46,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,269 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,269 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,269 > [DEBUG] 0 :: before allreduce fusion buffer :: 30.665424346923828
2023-01-07 08:08:46,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,270 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,270 > [DEBUG] 0 :: before allreduce fusion buffer :: -180.0345458984375
2023-01-07 08:08:46,271 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,271 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,272 > [DEBUG] 0 :: before allreduce fusion buffer :: -114.42146301269531
2023-01-07 08:08:46,272 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,272 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,273 > [DEBUG] 0 :: before allreduce fusion buffer :: 4759847.5
2023-01-07 08:08:46,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,274 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,274 > [DEBUG] 0 :: before allreduce fusion buffer :: -3423.2568359375
2023-01-07 08:08:46,275 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,275 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,275 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,275 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,275 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,276 > [DEBUG] 0 :: before allreduce fusion buffer :: -3365.869140625
2023-01-07 08:08:46,277 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,277 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,277 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,277 > [DEBUG] 0 :: before allreduce fusion buffer :: -864.080078125
2023-01-07 08:08:46,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,278 > [DEBUG] 0 :: before allreduce fusion buffer :: -1881.1697998046875
2023-01-07 08:08:46,279 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,280 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,280 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,280 > [DEBUG] 0 :: before allreduce fusion buffer :: 5936.2548828125
2023-01-07 08:08:46,281 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,281 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,281 > [DEBUG] 0 :: before allreduce fusion buffer :: -8526.013671875
2023-01-07 08:08:46,282 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,282 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,282 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,282 > [DEBUG] 0 :: before allreduce fusion buffer :: 4139.24462890625
2023-01-07 08:08:46,283 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,283 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,283 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,283 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,283 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,284 > [DEBUG] 0 :: before allreduce fusion buffer :: 13754.3623046875
2023-01-07 08:08:46,285 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,285 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,285 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 326.89404296875
2023-01-07 08:08:46,286 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,286 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,286 > [DEBUG] 0 :: before allreduce fusion buffer :: -61545.2890625
2023-01-07 08:08:46,287 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,288 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,288 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,288 > [DEBUG] 0 :: before allreduce fusion buffer :: -8704.21484375
2023-01-07 08:08:46,289 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,289 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,289 > [DEBUG] 0 :: before allreduce fusion buffer :: -13394.1923828125
2023-01-07 08:08:46,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,290 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,290 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,290 > [DEBUG] 0 :: before allreduce fusion buffer :: 35143.46875
2023-01-07 08:08:46,291 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,291 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,291 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,291 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,291 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,292 > [DEBUG] 0 :: before allreduce fusion buffer :: 74312.5625
2023-01-07 08:08:46,293 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,293 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,294 > [DEBUG] 0 :: before allreduce fusion buffer :: -18042.533203125
2023-01-07 08:08:46,294 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,295 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,295 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,295 > [DEBUG] 0 :: before allreduce fusion buffer :: -28716.34765625
2023-01-07 08:08:46,297 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,297 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,297 > [DEBUG] 0 :: before allreduce fusion buffer :: -18528.5546875
2023-01-07 08:08:46,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 39429.9375
2023-01-07 08:08:46,299 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,299 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,299 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,299 > [DEBUG] 0 :: before allreduce fusion buffer :: 74704.5078125
2023-01-07 08:08:46,300 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,300 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,301 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,301 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,301 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,301 > [DEBUG] 0 :: before allreduce fusion buffer :: -655422.0
2023-01-07 08:08:46,302 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,302 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,303 > [DEBUG] 0 :: before allreduce fusion buffer :: 34608.203125
2023-01-07 08:08:46,303 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,303 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,304 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,304 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,304 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,304 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,304 > [DEBUG] 0 :: before allreduce fusion buffer :: -1167823.625
2023-01-07 08:08:46,305 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,305 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,306 > [DEBUG] 0 :: before allreduce fusion buffer :: -82972.59375
2023-01-07 08:08:46,306 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,306 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,307 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,307 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,307 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,307 > [DEBUG] 0 :: before allreduce fusion buffer :: -62250708.0
2023-01-07 08:08:46,308 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,308 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,308 > [DEBUG] 0 :: before allreduce fusion buffer :: 123980.625
2023-01-07 08:08:46,309 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,310 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,310 > [DEBUG] 0 :: before allreduce fusion buffer :: 969776.75
2023-01-07 08:08:46,311 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,311 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,311 > [DEBUG] 0 :: before allreduce fusion buffer :: 302462.75
2023-01-07 08:08:46,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,312 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,312 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,313 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,313 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,313 > [DEBUG] 0 :: before allreduce fusion buffer :: -248169.375
2023-01-07 08:08:46,314 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,314 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,315 > [DEBUG] 0 :: before allreduce fusion buffer :: -21659.44140625
2023-01-07 08:08:46,315 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,315 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,316 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,316 > [DEBUG] 0 :: before allreduce fusion buffer :: 1812443.0
2023-01-07 08:08:46,317 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,317 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,317 > [DEBUG] 0 :: before allreduce fusion buffer :: 5235995.0
2023-01-07 08:08:46,318 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,318 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,318 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,318 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,318 > [DEBUG] 0 :: before allreduce fusion buffer :: 21981972480.0
2023-01-07 08:08:46,320 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,320 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,320 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,320 > [DEBUG] 0 :: before allreduce fusion buffer :: -3787921.5
2023-01-07 08:08:46,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,321 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,321 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,321 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,321 > [DEBUG] 0 :: before allreduce fusion buffer :: 10641568.0
2023-01-07 08:08:46,323 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,323 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,323 > [DEBUG] 0 :: before allreduce fusion buffer :: -503201.3125
2023-01-07 08:08:46,324 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,324 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,324 > [DEBUG] 0 :: before allreduce fusion buffer :: -8490216.0
2023-01-07 08:08:46,329 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:08:46,329 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,329 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,330 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,331 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,331 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,334 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,334 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,334 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,334 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,334 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,337 > [DEBUG] 0 :: before allreduce fusion buffer :: 43814290980864.0
2023-01-07 08:08:46,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,341 > [DEBUG] 0 :: before allreduce fusion buffer :: 5612588100485120.0
2023-01-07 08:08:46,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,343 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.835379275556454e+16
2023-01-07 08:08:46,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,344 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.214865484428083e+17
2023-01-07 08:08:46,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,345 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,345 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.771784015275622e+16
2023-01-07 08:08:46,345 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -33.56787872314453
2023-01-07 08:08:46,345 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,346 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,346 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,346 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 65.99998474121094
2023-01-07 08:08:46,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,346 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,346 > [DEBUG] 0 :: before allreduce fusion buffer :: -4730620.0
2023-01-07 08:08:46,347 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 65.99998474121094
2023-01-07 08:08:46,348 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,348 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,348 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,348 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 31.124814987182617
2023-01-07 08:08:46,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,348 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,348 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.864270692949688e+17
2023-01-07 08:08:46,350 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 31.124814987182617
2023-01-07 08:08:46,350 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,350 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,350 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,350 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 89.31981658935547
2023-01-07 08:08:46,350 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,350 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,350 > [DEBUG] 0 :: before allreduce fusion buffer :: -10312209.0
2023-01-07 08:08:46,351 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.39999389648438
2023-01-07 08:08:46,351 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,351 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,351 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,351 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 89.31981658935547
2023-01-07 08:08:46,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,352 > [DEBUG] 0 :: before allreduce fusion buffer :: -4512527.0
2023-01-07 08:08:46,353 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 89.31981658935547
2023-01-07 08:08:46,353 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,353 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,353 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,353 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 66.0
2023-01-07 08:08:46,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,353 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,354 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,354 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.623028872100614e+20
2023-01-07 08:08:46,355 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 66.0
2023-01-07 08:08:46,356 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,356 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,356 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,356 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 47.04784393310547
2023-01-07 08:08:46,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 195617.78125
2023-01-07 08:08:46,357 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 30.6688232421875
2023-01-07 08:08:46,357 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,357 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,357 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,357 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 302.3994140625
2023-01-07 08:08:46,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,357 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,358 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0575040770717203e+22
2023-01-07 08:08:46,359 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 302.3994140625
2023-01-07 08:08:46,359 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,359 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,359 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,360 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 102.97187042236328
2023-01-07 08:08:46,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,360 > [DEBUG] 0 :: before allreduce fusion buffer :: -1276837.5
2023-01-07 08:08:46,361 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 68.67936706542969
2023-01-07 08:08:46,361 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,361 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,361 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,361 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 102.97187042236328
2023-01-07 08:08:46,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.3239631300620574e+23
2023-01-07 08:08:46,362 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 259.1535339355469
2023-01-07 08:08:46,362 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,362 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,362 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,362 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 102.97187042236328
2023-01-07 08:08:46,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,363 > [DEBUG] 0 :: before allreduce fusion buffer :: -1031786.75
2023-01-07 08:08:46,364 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 39.78094482421875
2023-01-07 08:08:46,364 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,364 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,364 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,364 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 66.19999694824219
2023-01-07 08:08:46,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,364 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 3929873.25
2023-01-07 08:08:46,366 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 66.19999694824219
2023-01-07 08:08:46,366 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,366 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,366 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,366 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 102.97187042236328
2023-01-07 08:08:46,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,366 > [DEBUG] 0 :: before allreduce fusion buffer :: -698419.9375
2023-01-07 08:08:46,368 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 102.97187042236328
2023-01-07 08:08:46,368 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,368 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,368 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,368 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 66.19999694824219
2023-01-07 08:08:46,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,368 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,369 > [DEBUG] 0 :: before allreduce fusion buffer :: 74757.375
2023-01-07 08:08:46,370 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 66.19999694824219
2023-01-07 08:08:46,370 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,370 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,370 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,370 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 47.04784393310547
2023-01-07 08:08:46,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,371 > [DEBUG] 0 :: before allreduce fusion buffer :: 99784.5
2023-01-07 08:08:46,372 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 4.902883529663086
2023-01-07 08:08:46,372 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,372 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,372 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,372 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 20.903413772583008
2023-01-07 08:08:46,372 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,372 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,372 > [DEBUG] 0 :: before allreduce fusion buffer :: -225730.859375
2023-01-07 08:08:46,373 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 250.13038635253906
2023-01-07 08:08:46,373 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,373 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,373 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,373 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 20.903413772583008
2023-01-07 08:08:46,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,374 > [DEBUG] 0 :: before allreduce fusion buffer :: -9853.111328125
2023-01-07 08:08:46,375 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 20.903413772583008
2023-01-07 08:08:46,375 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,375 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,375 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,376 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 47.04784393310547
2023-01-07 08:08:46,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,376 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,376 > [DEBUG] 0 :: before allreduce fusion buffer :: 281368.6875
2023-01-07 08:08:46,377 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 62.51639938354492
2023-01-07 08:08:46,377 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,377 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,377 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,377 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 47.04784393310547
2023-01-07 08:08:46,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,377 > [DEBUG] 0 :: before allreduce fusion buffer :: -106358.1796875
2023-01-07 08:08:46,378 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 47.04784393310547
2023-01-07 08:08:46,379 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,379 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,379 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,379 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 66.19999694824219
2023-01-07 08:08:46,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,379 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,379 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,379 > [DEBUG] 0 :: before allreduce fusion buffer :: -182649.5625
2023-01-07 08:08:46,381 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 66.19999694824219
2023-01-07 08:08:46,381 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,381 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,381 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,381 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 111.33123779296875
2023-01-07 08:08:46,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,382 > [DEBUG] 0 :: before allreduce fusion buffer :: -29637.6875
2023-01-07 08:08:46,383 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: -9.04720687866211
2023-01-07 08:08:46,383 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,383 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,383 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,383 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 386.01934814453125
2023-01-07 08:08:46,383 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,383 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,383 > [DEBUG] 0 :: before allreduce fusion buffer :: 43437.4453125
2023-01-07 08:08:46,384 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 244.98634338378906
2023-01-07 08:08:46,384 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,385 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,385 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,385 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 111.33123779296875
2023-01-07 08:08:46,385 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,385 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,385 > [DEBUG] 0 :: before allreduce fusion buffer :: -38869.515625
2023-01-07 08:08:46,386 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 386.01934814453125
2023-01-07 08:08:46,386 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,386 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,386 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,386 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 111.33123779296875
2023-01-07 08:08:46,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,387 > [DEBUG] 0 :: before allreduce fusion buffer :: 175864.21875
2023-01-07 08:08:46,387 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 126.70236206054688
2023-01-07 08:08:46,387 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,388 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,388 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,388 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 111.33123779296875
2023-01-07 08:08:46,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,388 > [DEBUG] 0 :: before allreduce fusion buffer :: -22857.234375
2023-01-07 08:08:46,389 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 111.33123779296875
2023-01-07 08:08:46,389 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,389 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,389 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,390 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:46,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,390 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,390 > [DEBUG] 0 :: before allreduce fusion buffer :: 8004.849609375
2023-01-07 08:08:46,391 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:46,391 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,391 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,391 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,392 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 426.4547119140625
2023-01-07 08:08:46,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,392 > [DEBUG] 0 :: before allreduce fusion buffer :: -1366.86669921875
2023-01-07 08:08:46,393 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 426.4547119140625
2023-01-07 08:08:46,393 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,393 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,393 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,393 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 504.7999572753906
2023-01-07 08:08:46,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,394 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,394 > [DEBUG] 0 :: before allreduce fusion buffer :: 10915.16015625
2023-01-07 08:08:46,395 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 504.7999572753906
2023-01-07 08:08:46,395 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,395 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,395 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,395 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -4.934715270996094
2023-01-07 08:08:46,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,396 > [DEBUG] 0 :: before allreduce fusion buffer :: 13761.830078125
2023-01-07 08:08:46,397 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -4.934715270996094
2023-01-07 08:08:46,397 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,397 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,397 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,397 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -91.1648178100586
2023-01-07 08:08:46,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 8810.94921875
2023-01-07 08:08:46,398 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 521.948974609375
2023-01-07 08:08:46,398 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,398 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,398 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,399 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -91.1648178100586
2023-01-07 08:08:46,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,399 > [DEBUG] 0 :: before allreduce fusion buffer :: -4379.845703125
2023-01-07 08:08:46,400 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -91.1648178100586
2023-01-07 08:08:46,400 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,400 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,400 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,400 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:46,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,401 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,401 > [DEBUG] 0 :: before allreduce fusion buffer :: 28381.03515625
2023-01-07 08:08:46,402 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:46,402 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,402 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,402 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,402 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: -106.76310729980469
2023-01-07 08:08:46,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,403 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,403 > [DEBUG] 0 :: before allreduce fusion buffer :: 2094.74072265625
2023-01-07 08:08:46,404 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -106.76310729980469
2023-01-07 08:08:46,404 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,404 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,404 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,404 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:46,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,405 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,405 > [DEBUG] 0 :: before allreduce fusion buffer :: -1588.54296875
2023-01-07 08:08:46,406 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:46,406 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,406 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,406 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,406 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 66.03190612792969
2023-01-07 08:08:46,406 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,406 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,407 > [DEBUG] 0 :: before allreduce fusion buffer :: -1959.5404052734375
2023-01-07 08:08:46,408 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 66.03190612792969
2023-01-07 08:08:46,408 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,408 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,408 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,408 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -120.90240478515625
2023-01-07 08:08:46,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,409 > [DEBUG] 0 :: before allreduce fusion buffer :: 665.1920166015625
2023-01-07 08:08:46,409 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 519.34716796875
2023-01-07 08:08:46,409 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,409 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,409 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,410 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -120.90240478515625
2023-01-07 08:08:46,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,410 > [DEBUG] 0 :: before allreduce fusion buffer :: -134.8220977783203
2023-01-07 08:08:46,411 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -120.90240478515625
2023-01-07 08:08:46,411 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,411 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,411 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,412 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:46,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,412 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,412 > [DEBUG] 0 :: before allreduce fusion buffer :: -120.21107482910156
2023-01-07 08:08:46,413 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:46,413 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,413 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,413 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,414 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 244.4005584716797
2023-01-07 08:08:46,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,414 > [DEBUG] 0 :: before allreduce fusion buffer :: -352.8021545410156
2023-01-07 08:08:46,415 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 244.4005584716797
2023-01-07 08:08:46,415 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,415 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,415 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,415 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:46,415 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,415 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,416 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,416 > [DEBUG] 0 :: before allreduce fusion buffer :: -57.255828857421875
2023-01-07 08:08:46,417 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:46,417 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,417 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,417 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,417 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -61.264137268066406
2023-01-07 08:08:46,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,418 > [DEBUG] 0 :: before allreduce fusion buffer :: 49.50495147705078
2023-01-07 08:08:46,419 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -61.264137268066406
2023-01-07 08:08:46,419 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,419 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,419 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,419 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 505.0
2023-01-07 08:08:46,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,420 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,420 > [DEBUG] 0 :: before allreduce fusion buffer :: 245.14903259277344
2023-01-07 08:08:46,421 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 505.0
2023-01-07 08:08:46,421 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,421 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,421 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,421 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: 165.2937469482422
2023-01-07 08:08:46,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,421 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,422 > [DEBUG] 0 :: before allreduce fusion buffer :: 225.62994384765625
2023-01-07 08:08:46,423 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 165.2937469482422
2023-01-07 08:08:46,423 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,423 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,423 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,423 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:46,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,423 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,424 > [DEBUG] 0 :: before allreduce fusion buffer :: -87.58158111572266
2023-01-07 08:08:46,425 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:46,425 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,425 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,425 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,425 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -54.6978759765625
2023-01-07 08:08:46,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,425 > [DEBUG] 0 :: before allreduce fusion buffer :: -75.31574249267578
2023-01-07 08:08:46,427 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -54.6978759765625
2023-01-07 08:08:46,427 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,427 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,427 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,427 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:46,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,428 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,428 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0519046783447266
2023-01-07 08:08:46,429 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:46,429 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,429 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,429 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,429 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: -100.38951873779297
2023-01-07 08:08:46,430 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,430 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,430 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4157297611236572
2023-01-07 08:08:46,431 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -100.38951873779297
2023-01-07 08:08:46,431 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,431 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,431 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,431 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 505.0
2023-01-07 08:08:46,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,431 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,432 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,432 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,432 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.687210083007812
2023-01-07 08:08:46,433 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 505.0
2023-01-07 08:08:46,433 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,433 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,433 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,433 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: -15.874872207641602
2023-01-07 08:08:46,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,434 > [DEBUG] 0 :: before allreduce fusion buffer :: 19.087299346923828
2023-01-07 08:08:46,435 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: -15.874872207641602
2023-01-07 08:08:46,435 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,435 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,435 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,435 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 255.8000030517578
2023-01-07 08:08:46,435 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,435 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,435 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,436 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,436 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,436 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.866016387939453
2023-01-07 08:08:46,437 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 255.8000030517578
2023-01-07 08:08:46,437 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,437 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,437 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,437 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -24317.546875
2023-01-07 08:08:46,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,437 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,438 > [DEBUG] 0 :: before allreduce fusion buffer :: 13.787239074707031
2023-01-07 08:08:46,439 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -24317.546875
2023-01-07 08:08:46,439 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,439 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,439 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,439 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -530.74169921875
2023-01-07 08:08:46,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,440 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,440 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 256.9863586425781
2023-01-07 08:08:46,440 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,440 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,440 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,441 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -530.74169921875
2023-01-07 08:08:46,441 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,441 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,441 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,443 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -530.74169921875
2023-01-07 08:08:46,444 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,444 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,444 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,444 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1516.7818603515625
2023-01-07 08:08:46,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,444 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,445 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1045.026123046875
2023-01-07 08:08:46,445 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,445 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,445 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,446 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1516.7818603515625
2023-01-07 08:08:46,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,446 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,447 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -1516.7818603515625
2023-01-07 08:08:46,447 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,447 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,447 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,447 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1067.925048828125
2023-01-07 08:08:46,447 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,447 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,448 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,448 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1053.642333984375
2023-01-07 08:08:46,448 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,449 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,449 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,449 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1067.925048828125
2023-01-07 08:08:46,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,450 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1067.925048828125
2023-01-07 08:08:46,450 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,450 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,451 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,451 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 248.60061645507812
2023-01-07 08:08:46,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,451 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:08:46,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,451 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,452 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 248.60061645507812
2023-01-07 08:08:46,452 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,453 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,453 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,453 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -2401.14599609375
2023-01-07 08:08:46,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,453 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,454 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -2401.14599609375
2023-01-07 08:08:46,454 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,454 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,454 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,455 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -458.8734130859375
2023-01-07 08:08:46,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,455 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,456 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 250.18331909179688
2023-01-07 08:08:46,456 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,456 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,456 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,456 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -458.8734130859375
2023-01-07 08:08:46,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,458 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -458.8734130859375
2023-01-07 08:08:46,458 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,458 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,458 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,458 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 202.35226440429688
2023-01-07 08:08:46,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,458 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,459 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1009.779052734375
2023-01-07 08:08:46,459 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,459 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,459 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,459 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 202.35226440429688
2023-01-07 08:08:46,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,460 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,461 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 202.35226440429688
2023-01-07 08:08:46,461 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,461 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,461 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,461 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 319.07861328125
2023-01-07 08:08:46,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,462 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,462 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 250.98284912109375
2023-01-07 08:08:46,463 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,463 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,463 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,463 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 319.07861328125
2023-01-07 08:08:46,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,464 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 319.07861328125
2023-01-07 08:08:46,464 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,465 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,465 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,465 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -163.30230712890625
2023-01-07 08:08:46,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,465 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,466 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 247.3870086669922
2023-01-07 08:08:46,466 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,466 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,466 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,466 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -163.30230712890625
2023-01-07 08:08:46,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,466 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,468 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -163.30230712890625
2023-01-07 08:08:46,468 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,468 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,468 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,468 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 305.5634765625
2023-01-07 08:08:46,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,469 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1103.7176513671875
2023-01-07 08:08:46,469 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,469 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,469 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,469 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 305.5634765625
2023-01-07 08:08:46,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,470 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,471 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 305.5634765625
2023-01-07 08:08:46,471 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,471 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,471 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,471 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 446.3744201660156
2023-01-07 08:08:46,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,472 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,473 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 297.385498046875
2023-01-07 08:08:46,473 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,473 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,473 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,473 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 446.3744201660156
2023-01-07 08:08:46,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,473 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,474 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 446.3744201660156
2023-01-07 08:08:46,475 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,475 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,475 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,475 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 72.70564270019531
2023-01-07 08:08:46,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,475 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,476 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 297.6326904296875
2023-01-07 08:08:46,476 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,476 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,476 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,476 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 72.70564270019531
2023-01-07 08:08:46,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,476 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,478 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 72.70564270019531
2023-01-07 08:08:46,478 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,478 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,478 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,478 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 50.807952880859375
2023-01-07 08:08:46,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,478 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,479 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1087.297607421875
2023-01-07 08:08:46,479 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,479 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,479 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,480 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 50.807952880859375
2023-01-07 08:08:46,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,480 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,481 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 50.807952880859375
2023-01-07 08:08:46,481 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,481 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,481 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,481 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 233.51821899414062
2023-01-07 08:08:46,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,482 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,483 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 296.9463806152344
2023-01-07 08:08:46,483 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,483 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,483 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,483 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 233.51821899414062
2023-01-07 08:08:46,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,483 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,485 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 233.51821899414062
2023-01-07 08:08:46,485 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,485 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,485 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,485 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3039.64697265625
2023-01-07 08:08:46,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,485 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,486 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 298.1405944824219
2023-01-07 08:08:46,486 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,486 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,486 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,486 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3039.64697265625
2023-01-07 08:08:46,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,487 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,488 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -3039.64697265625
2023-01-07 08:08:46,488 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,488 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,488 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,488 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -21015.724609375
2023-01-07 08:08:46,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,489 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,489 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1069.010986328125
2023-01-07 08:08:46,489 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,489 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,489 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,490 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -21015.724609375
2023-01-07 08:08:46,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,490 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,491 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -21015.724609375
2023-01-07 08:08:46,491 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,491 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,491 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,492 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -8839.833984375
2023-01-07 08:08:46,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,492 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,493 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 299.2393493652344
2023-01-07 08:08:46,493 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,493 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,493 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,493 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -8839.833984375
2023-01-07 08:08:46,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,493 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,495 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -8839.833984375
2023-01-07 08:08:46,495 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,495 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,495 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,495 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23628.99609375
2023-01-07 08:08:46,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,495 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,496 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 299.9436950683594
2023-01-07 08:08:46,496 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,496 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,496 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,496 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23628.99609375
2023-01-07 08:08:46,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,497 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,498 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -23628.99609375
2023-01-07 08:08:46,498 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,498 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,498 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,498 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50149.640625
2023-01-07 08:08:46,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,499 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,499 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1082.48876953125
2023-01-07 08:08:46,499 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,499 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,499 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,500 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50149.640625
2023-01-07 08:08:46,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,500 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,501 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -50149.640625
2023-01-07 08:08:46,501 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,501 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,501 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,502 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -42793.6875
2023-01-07 08:08:46,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,502 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,503 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 590.7883911132812
2023-01-07 08:08:46,503 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,503 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,503 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,503 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -42793.6875
2023-01-07 08:08:46,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,503 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,505 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -42793.6875
2023-01-07 08:08:46,505 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,505 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,505 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,505 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 55.53363800048828
2023-01-07 08:08:46,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,505 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,506 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 594.0867919921875
2023-01-07 08:08:46,506 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,506 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,506 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,507 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 55.53363800048828
2023-01-07 08:08:46,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,507 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,508 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 55.53363800048828
2023-01-07 08:08:46,508 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,508 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,508 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,509 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -122963.609375
2023-01-07 08:08:46,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,509 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,510 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2102.86083984375
2023-01-07 08:08:46,510 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,510 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,510 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,510 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -122963.609375
2023-01-07 08:08:46,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,510 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,511 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -122963.609375
2023-01-07 08:08:46,511 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,512 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,512 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,512 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26806.1875
2023-01-07 08:08:46,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,512 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,513 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2149.3984375
2023-01-07 08:08:46,513 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,513 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,513 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,513 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26806.1875
2023-01-07 08:08:46,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,513 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,515 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -26806.1875
2023-01-07 08:08:46,515 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,515 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,515 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,515 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 279.4430847167969
2023-01-07 08:08:46,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,515 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,516 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 595.0272216796875
2023-01-07 08:08:46,516 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,516 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,516 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,516 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 279.4430847167969
2023-01-07 08:08:46,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,517 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,518 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 279.4430847167969
2023-01-07 08:08:46,518 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,518 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,518 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,518 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -33994.81640625
2023-01-07 08:08:46,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,519 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,520 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 597.9412841796875
2023-01-07 08:08:46,520 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,520 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,520 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,520 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -33994.81640625
2023-01-07 08:08:46,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,520 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,522 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -33994.81640625
2023-01-07 08:08:46,522 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,522 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,522 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,522 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102861.265625
2023-01-07 08:08:46,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,522 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,523 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.00439453125
2023-01-07 08:08:46,523 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,523 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,523 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,523 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102861.265625
2023-01-07 08:08:46,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,524 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,525 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -102861.265625
2023-01-07 08:08:46,525 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,525 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,525 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,525 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -12838.1982421875
2023-01-07 08:08:46,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,526 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,526 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 599.7402954101562
2023-01-07 08:08:46,526 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,526 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,526 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,527 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -12838.1982421875
2023-01-07 08:08:46,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,527 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,528 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -12838.1982421875
2023-01-07 08:08:46,528 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,528 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,528 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,529 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 593.8854370117188
2023-01-07 08:08:46,529 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,529 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,530 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 599.3426513671875
2023-01-07 08:08:46,530 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,530 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,530 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,530 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 593.8854370117188
2023-01-07 08:08:46,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,530 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,532 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 593.8854370117188
2023-01-07 08:08:46,532 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,532 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,532 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,532 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -148924.03125
2023-01-07 08:08:46,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,532 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,533 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2443.63232421875
2023-01-07 08:08:46,533 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,533 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,533 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,533 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -148924.03125
2023-01-07 08:08:46,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,534 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:46,535 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -148924.03125
2023-01-07 08:08:46,535 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:46,535 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:46,535 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:46,536 > [DEBUG] 0 :: 18.164936065673828
2023-01-07 08:08:46,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,538 > [DEBUG] 0 :: before allreduce fusion buffer :: -44345.3203125
2023-01-07 08:08:46,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,540 > [DEBUG] 0 :: before allreduce fusion buffer :: -238929.25
2023-01-07 08:08:46,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,542 > [DEBUG] 0 :: before allreduce fusion buffer :: 307645.53125
2023-01-07 08:08:46,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,543 > [DEBUG] 0 :: before allreduce fusion buffer :: -467445.25
2023-01-07 08:08:46,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,545 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,545 > [DEBUG] 0 :: before allreduce fusion buffer :: 74306.875
2023-01-07 08:08:46,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,546 > [DEBUG] 0 :: before allreduce fusion buffer :: -535011.75
2023-01-07 08:08:46,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 3529968.25
2023-01-07 08:08:46,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,549 > [DEBUG] 0 :: before allreduce fusion buffer :: -11485586.0
2023-01-07 08:08:46,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,551 > [DEBUG] 0 :: before allreduce fusion buffer :: -11932378.0
2023-01-07 08:08:46,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,552 > [DEBUG] 0 :: before allreduce fusion buffer :: -24263632.0
2023-01-07 08:08:46,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,554 > [DEBUG] 0 :: before allreduce fusion buffer :: -25054836.0
2023-01-07 08:08:46,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,556 > [DEBUG] 0 :: before allreduce fusion buffer :: -25738266.0
2023-01-07 08:08:46,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,557 > [DEBUG] 0 :: before allreduce fusion buffer :: -92212232.0
2023-01-07 08:08:46,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,559 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,559 > [DEBUG] 0 :: before allreduce fusion buffer :: -121350048.0
2023-01-07 08:08:46,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,561 > [DEBUG] 0 :: before allreduce fusion buffer :: -399636288.0
2023-01-07 08:08:46,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,562 > [DEBUG] 0 :: before allreduce fusion buffer :: -448013696.0
2023-01-07 08:08:46,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,563 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,564 > [DEBUG] 0 :: before allreduce fusion buffer :: -251278624.0
2023-01-07 08:08:46,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,565 > [DEBUG] 0 :: before allreduce fusion buffer :: -300217472.0
2023-01-07 08:08:46,567 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,567 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,567 > [DEBUG] 0 :: before allreduce fusion buffer :: 566796736.0
2023-01-07 08:08:46,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 1177774464.0
2023-01-07 08:08:46,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,570 > [DEBUG] 0 :: before allreduce fusion buffer :: 1059450176.0
2023-01-07 08:08:46,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,571 > [DEBUG] 0 :: before allreduce fusion buffer :: 2201896192.0
2023-01-07 08:08:46,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,573 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,573 > [DEBUG] 0 :: before allreduce fusion buffer :: 2270583296.0
2023-01-07 08:08:46,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,574 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,575 > [DEBUG] 0 :: before allreduce fusion buffer :: 2215228672.0
2023-01-07 08:08:46,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,576 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,577 > [DEBUG] 0 :: before allreduce fusion buffer :: 3315630592.0
2023-01-07 08:08:46,577 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,577 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,578 > [DEBUG] 0 :: before allreduce fusion buffer :: 7700818944.0
2023-01-07 08:08:46,579 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,579 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,580 > [DEBUG] 0 :: before allreduce fusion buffer :: 13628405760.0
2023-01-07 08:08:46,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,581 > [DEBUG] 0 :: before allreduce fusion buffer :: 18043031552.0
2023-01-07 08:08:46,582 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,582 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,583 > [DEBUG] 0 :: before allreduce fusion buffer :: 28307783680.0
2023-01-07 08:08:46,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,584 > [DEBUG] 0 :: before allreduce fusion buffer :: 57399173120.0
2023-01-07 08:08:46,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,586 > [DEBUG] 0 :: before allreduce fusion buffer :: 65642151936.0
2023-01-07 08:08:46,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,587 > [DEBUG] 0 :: before allreduce fusion buffer :: 180312342528.0
2023-01-07 08:08:46,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,589 > [DEBUG] 0 :: before allreduce fusion buffer :: 374731046912.0
2023-01-07 08:08:46,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,590 > [DEBUG] 0 :: before allreduce fusion buffer :: 352209240064.0
2023-01-07 08:08:46,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,592 > [DEBUG] 0 :: before allreduce fusion buffer :: -3172343.5
2023-01-07 08:08:46,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,593 > [DEBUG] 0 :: before allreduce fusion buffer :: 269716896.0
2023-01-07 08:08:46,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,595 > [DEBUG] 0 :: before allreduce fusion buffer :: 315107616.0
2023-01-07 08:08:46,596 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,596 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,596 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,596 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,596 > [DEBUG] 0 :: before allreduce fusion buffer :: 283459200.0
2023-01-07 08:08:46,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,598 > [DEBUG] 0 :: before allreduce fusion buffer :: 629229248.0
2023-01-07 08:08:46,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,599 > [DEBUG] 0 :: before allreduce fusion buffer :: 282282592.0
2023-01-07 08:08:46,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,601 > [DEBUG] 0 :: before allreduce fusion buffer :: 1410979840.0
2023-01-07 08:08:46,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,602 > [DEBUG] 0 :: before allreduce fusion buffer :: 2463634432.0
2023-01-07 08:08:46,604 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,604 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,604 > [DEBUG] 0 :: before allreduce fusion buffer :: 5649594368.0
2023-01-07 08:08:46,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,605 > [DEBUG] 0 :: before allreduce fusion buffer :: 8786769920.0
2023-01-07 08:08:46,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,607 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,607 > [DEBUG] 0 :: before allreduce fusion buffer :: 22593376256.0
2023-01-07 08:08:46,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,608 > [DEBUG] 0 :: before allreduce fusion buffer :: -105638656.0
2023-01-07 08:08:46,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,610 > [DEBUG] 0 :: before allreduce fusion buffer :: 45174579200.0
2023-01-07 08:08:46,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,611 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,612 > [DEBUG] 0 :: before allreduce fusion buffer :: 65162584064.0
2023-01-07 08:08:46,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,613 > [DEBUG] 0 :: before allreduce fusion buffer :: 172142100480.0
2023-01-07 08:08:46,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,615 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,615 > [DEBUG] 0 :: before allreduce fusion buffer :: 335854895104.0
2023-01-07 08:08:46,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,616 > [DEBUG] 0 :: before allreduce fusion buffer :: 671542673408.0
2023-01-07 08:08:46,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,617 > [DEBUG] 0 :: before allreduce fusion buffer :: 312695776.0
2023-01-07 08:08:46,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,619 > [DEBUG] 0 :: before allreduce fusion buffer :: 2788219158528.0
2023-01-07 08:08:46,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,620 > [DEBUG] 0 :: before allreduce fusion buffer :: 830554112.0
2023-01-07 08:08:46,622 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,622 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,622 > [DEBUG] 0 :: before allreduce fusion buffer :: 10957692600320.0
2023-01-07 08:08:46,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,623 > [DEBUG] 0 :: before allreduce fusion buffer :: 16532457390080.0
2023-01-07 08:08:46,731 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,731 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,731 > [DEBUG] 0 :: before allreduce fusion buffer :: 43836634038272.0
2023-01-07 08:08:46,732 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,732 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,732 > [DEBUG] 0 :: before allreduce fusion buffer :: 87650912436224.0
2023-01-07 08:08:46,734 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,734 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,734 > [DEBUG] 0 :: before allreduce fusion buffer :: 175297026588672.0
2023-01-07 08:08:46,735 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,735 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,735 > [DEBUG] 0 :: before allreduce fusion buffer :: 350599019233280.0
2023-01-07 08:08:46,736 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,736 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,736 > [DEBUG] 0 :: before allreduce fusion buffer :: 331611874787328.0
2023-01-07 08:08:46,737 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,737 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,738 > [DEBUG] 0 :: before allreduce fusion buffer :: 701560896094208.0
2023-01-07 08:08:46,739 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,739 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,739 > [DEBUG] 0 :: before allreduce fusion buffer :: 1403172123836416.0
2023-01-07 08:08:46,740 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,740 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,740 > [DEBUG] 0 :: before allreduce fusion buffer :: 2806294050242560.0
2023-01-07 08:08:46,741 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,741 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,741 > [DEBUG] 0 :: before allreduce fusion buffer :: 5612585953001472.0
2023-01-07 08:08:46,742 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,742 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,742 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0972924181741568e+16
2023-01-07 08:08:46,743 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,744 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,744 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.958843530398925e+16
2023-01-07 08:08:46,914 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,914 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,915 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.917689208281498e+16
2023-01-07 08:08:46,916 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,916 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,916 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.835378416562995e+16
2023-01-07 08:08:46,917 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,917 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,917 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.567075683312599e+17
2023-01-07 08:08:46,918 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,918 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,919 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6074327422140416e+17
2023-01-07 08:08:46,920 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,920 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,920 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:46,920 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:46,920 > [DEBUG] 0 :: before allreduce fusion buffer :: 5162.08349609375
2023-01-07 08:08:47,098 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,098 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,098 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6074327422140416e+17
2023-01-07 08:08:47,099 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,099 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,100 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.214865484428083e+17
2023-01-07 08:08:47,101 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,101 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,101 > [DEBUG] 0 :: before allreduce fusion buffer :: -381992.25
2023-01-07 08:08:47,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,214 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.592044014804664e+17
2023-01-07 08:08:47,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,215 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,216 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.022659794003558e+17
2023-01-07 08:08:47,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,218 > [DEBUG] 0 :: before allreduce fusion buffer :: -1791031.75
2023-01-07 08:08:47,219 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,219 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,220 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.407821185168179e+17
2023-01-07 08:08:47,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,221 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.223935982216728e+19
2023-01-07 08:08:47,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,222 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2679913063286047e+18
2023-01-07 08:08:47,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,223 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,223 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.5359826126572093e+18
2023-01-07 08:08:47,224 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,224 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,225 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.5359826126572093e+18
2023-01-07 08:08:47,225 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,225 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,226 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.0269384688370975e+18
2023-01-07 08:08:47,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,228 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.0908120704246916e+21
2023-01-07 08:08:47,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.181624140849383e+21
2023-01-07 08:08:47,231 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,231 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,231 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,232 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,232 > [DEBUG] 0 :: before allreduce fusion buffer :: 1195530185080832.0
2023-01-07 08:08:47,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,233 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.311277389526367
2023-01-07 08:08:47,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,235 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,235 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,235 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.155463247515058e+22
2023-01-07 08:08:47,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,236 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7891819477081299
2023-01-07 08:08:47,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,237 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,238 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,238 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,238 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5207912307259694e+24
2023-01-07 08:08:47,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,239 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,240 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.717025756835938
2023-01-07 08:08:47,240 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,240 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,241 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,241 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,241 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.7023869573524166e+25
2023-01-07 08:08:47,242 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,242 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,242 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.650261402130127
2023-01-07 08:08:47,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,243 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0430407524108887
2023-01-07 08:08:47,245 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,245 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,245 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.711939811706543
2023-01-07 08:08:47,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,246 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,246 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,247 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,247 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,247 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,247 > [DEBUG] 0 :: before allreduce fusion buffer :: 24.643003463745117
2023-01-07 08:08:47,248 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,248 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,249 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.00929832458496
2023-01-07 08:08:47,250 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,250 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,250 > [DEBUG] 0 :: before allreduce fusion buffer :: 88.19763946533203
2023-01-07 08:08:47,251 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,251 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,251 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.92899227142334
2023-01-07 08:08:47,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,252 > [DEBUG] 0 :: before allreduce fusion buffer :: -1395826790236160.0
2023-01-07 08:08:47,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,254 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.437376976013184
2023-01-07 08:08:47,255 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,255 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,255 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,255 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,255 > [DEBUG] 0 :: before allreduce fusion buffer :: 13899.669921875
2023-01-07 08:08:47,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,257 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,257 > [DEBUG] 0 :: before allreduce fusion buffer :: -72.80033874511719
2023-01-07 08:08:47,258 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,258 > [DEBUG] 0 :: before allreduce fusion buffer :: 88.87283325195312
2023-01-07 08:08:47,260 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:08:47,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,261 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,261 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,261 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,261 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,261 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,267 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,267 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,268 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,268 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,268 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,269 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,269 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,270 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,270 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,271 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.323112154843159e+19
2023-01-07 08:08:47,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,273 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,273 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,273 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,273 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,275 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.284243971199205e+19
2023-01-07 08:08:47,275 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,275 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,276 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,276 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,276 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,276 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9276444344122343e+20
2023-01-07 08:08:47,277 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,277 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,277 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,277 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,277 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,277 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,277 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9588523350818816e+16
2023-01-07 08:08:47,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,278 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9588523350818816e+16
2023-01-07 08:08:47,279 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -33.262062072753906
2023-01-07 08:08:47,279 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,279 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,279 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,279 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 63.916404724121094
2023-01-07 08:08:47,279 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,279 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,280 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,280 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,280 > [DEBUG] 0 :: before allreduce fusion buffer :: 75.30744171142578
2023-01-07 08:08:47,281 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 63.916404724121094
2023-01-07 08:08:47,281 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,281 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,281 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,281 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 15.05252742767334
2023-01-07 08:08:47,281 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,281 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,281 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,282 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,282 > [DEBUG] 0 :: before allreduce fusion buffer :: -403634814976.0
2023-01-07 08:08:47,283 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 15.05252742767334
2023-01-07 08:08:47,283 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,283 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,283 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,284 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 150.35235595703125
2023-01-07 08:08:47,284 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,284 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,284 > [DEBUG] 0 :: before allreduce fusion buffer :: -83.70747375488281
2023-01-07 08:08:47,285 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.39999389648438
2023-01-07 08:08:47,285 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,285 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,285 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,285 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 150.35235595703125
2023-01-07 08:08:47,285 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,285 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.212625503540039
2023-01-07 08:08:47,286 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 150.35235595703125
2023-01-07 08:08:47,287 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,287 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,287 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,287 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 67.3567123413086
2023-01-07 08:08:47,287 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,287 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,287 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,287 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,287 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,287 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,287 > [DEBUG] 0 :: before allreduce fusion buffer :: 67.96212768554688
2023-01-07 08:08:47,289 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 67.3567123413086
2023-01-07 08:08:47,289 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,289 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,289 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,289 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 33.63416290283203
2023-01-07 08:08:47,289 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,289 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,290 > [DEBUG] 0 :: before allreduce fusion buffer :: -22.824172973632812
2023-01-07 08:08:47,290 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 62.237060546875
2023-01-07 08:08:47,291 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,291 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,291 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,291 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 297.7857971191406
2023-01-07 08:08:47,291 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,291 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,291 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,291 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,291 > [DEBUG] 0 :: before allreduce fusion buffer :: -57.6997184753418
2023-01-07 08:08:47,293 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 297.7857971191406
2023-01-07 08:08:47,293 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,293 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,293 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,293 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 49.19612121582031
2023-01-07 08:08:47,293 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,293 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,293 > [DEBUG] 0 :: before allreduce fusion buffer :: -64.86494445800781
2023-01-07 08:08:47,294 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 68.67936706542969
2023-01-07 08:08:47,294 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,294 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,294 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,294 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 49.19612121582031
2023-01-07 08:08:47,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,295 > [DEBUG] 0 :: before allreduce fusion buffer :: 21.08121109008789
2023-01-07 08:08:47,296 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 259.1535339355469
2023-01-07 08:08:47,296 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,296 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,296 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,296 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 49.19612121582031
2023-01-07 08:08:47,296 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,296 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,296 > [DEBUG] 0 :: before allreduce fusion buffer :: 22.256916046142578
2023-01-07 08:08:47,297 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 50.360557556152344
2023-01-07 08:08:47,297 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,297 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,297 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,297 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 64.11641693115234
2023-01-07 08:08:47,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,298 > [DEBUG] 0 :: before allreduce fusion buffer :: -153.699951171875
2023-01-07 08:08:47,299 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.11641693115234
2023-01-07 08:08:47,299 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,299 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,299 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,299 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 49.19612121582031
2023-01-07 08:08:47,299 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,299 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,300 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,300 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,300 > [DEBUG] 0 :: before allreduce fusion buffer :: 893.7327880859375
2023-01-07 08:08:47,301 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 49.19612121582031
2023-01-07 08:08:47,301 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,301 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,301 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,301 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 64.11641693115234
2023-01-07 08:08:47,301 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,302 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,302 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,302 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,302 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.402645111083984
2023-01-07 08:08:47,303 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.11641693115234
2023-01-07 08:08:47,303 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,303 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,304 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,304 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 33.63416290283203
2023-01-07 08:08:47,304 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,304 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,304 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.569227695465088
2023-01-07 08:08:47,305 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 27.65496826171875
2023-01-07 08:08:47,305 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,305 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,305 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,305 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 36.382667541503906
2023-01-07 08:08:47,305 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,305 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,306 > [DEBUG] 0 :: before allreduce fusion buffer :: -877.4281005859375
2023-01-07 08:08:47,306 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 250.13038635253906
2023-01-07 08:08:47,306 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,306 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,306 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,307 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 36.382667541503906
2023-01-07 08:08:47,307 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,307 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,307 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,307 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,307 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.1008817495998464e+16
2023-01-07 08:08:47,308 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 36.382667541503906
2023-01-07 08:08:47,309 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,309 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,309 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,309 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 33.63416290283203
2023-01-07 08:08:47,309 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,309 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,309 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.0179357528686523
2023-01-07 08:08:47,310 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 62.51639938354492
2023-01-07 08:08:47,310 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,310 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,310 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,310 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 33.63416290283203
2023-01-07 08:08:47,310 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,310 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.26921081542969
2023-01-07 08:08:47,312 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 33.63416290283203
2023-01-07 08:08:47,312 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,312 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,312 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,312 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 64.11641693115234
2023-01-07 08:08:47,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,313 > [DEBUG] 0 :: before allreduce fusion buffer :: -95661.5625
2023-01-07 08:08:47,314 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.11641693115234
2023-01-07 08:08:47,314 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,314 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,314 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,314 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -29.13949966430664
2023-01-07 08:08:47,315 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,315 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,315 > [DEBUG] 0 :: before allreduce fusion buffer :: -75012.875
2023-01-07 08:08:47,316 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 25.1119327545166
2023-01-07 08:08:47,316 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,316 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,316 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,316 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 432.150146484375
2023-01-07 08:08:47,316 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,316 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,316 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,317 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 244.98634338378906
2023-01-07 08:08:47,318 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,318 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,318 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,318 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -29.13949966430664
2023-01-07 08:08:47,318 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,318 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,318 > [DEBUG] 0 :: before allreduce fusion buffer :: 43506376.0
2023-01-07 08:08:47,319 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 432.150146484375
2023-01-07 08:08:47,319 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,319 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,319 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,319 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -29.13949966430664
2023-01-07 08:08:47,319 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,319 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,320 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,320 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 126.70236206054688
2023-01-07 08:08:47,321 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,321 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,321 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,321 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -29.13949966430664
2023-01-07 08:08:47,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,321 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,321 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,322 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: -29.13949966430664
2023-01-07 08:08:47,322 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,322 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,323 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,323 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 130.3953094482422
2023-01-07 08:08:47,323 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,323 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,323 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,323 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,323 > [DEBUG] 0 :: before allreduce fusion buffer :: -458451904.0
2023-01-07 08:08:47,324 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 130.3953094482422
2023-01-07 08:08:47,324 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,324 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,324 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,325 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 515.171630859375
2023-01-07 08:08:47,325 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,325 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,326 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 515.171630859375
2023-01-07 08:08:47,326 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,326 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,326 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,326 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 504.279052734375
2023-01-07 08:08:47,327 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,327 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,327 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,327 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,327 > [DEBUG] 0 :: before allreduce fusion buffer :: -658549120.0
2023-01-07 08:08:47,328 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 504.279052734375
2023-01-07 08:08:47,328 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,328 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,328 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,328 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 22.15100860595703
2023-01-07 08:08:47,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,328 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,329 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,330 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 22.15100860595703
2023-01-07 08:08:47,330 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,330 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,330 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,330 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -49.87247848510742
2023-01-07 08:08:47,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,330 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,331 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 521.948974609375
2023-01-07 08:08:47,331 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,331 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,331 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,331 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -49.87247848510742
2023-01-07 08:08:47,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,333 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -49.87247848510742
2023-01-07 08:08:47,333 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,333 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,333 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,333 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 131.00611877441406
2023-01-07 08:08:47,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,334 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,334 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,334 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,335 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 131.00611877441406
2023-01-07 08:08:47,335 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,335 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,335 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,335 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: -322.5728454589844
2023-01-07 08:08:47,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,336 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,337 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -322.5728454589844
2023-01-07 08:08:47,337 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,337 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,337 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,337 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 129.531982421875
2023-01-07 08:08:47,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,338 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,339 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 129.531982421875
2023-01-07 08:08:47,339 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,339 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,339 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,339 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 159.119873046875
2023-01-07 08:08:47,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,339 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,341 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 159.119873046875
2023-01-07 08:08:47,341 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,341 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,341 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,341 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -100.44815063476562
2023-01-07 08:08:47,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,341 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,342 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 521.6258544921875
2023-01-07 08:08:47,342 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,342 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,342 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,342 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -100.44815063476562
2023-01-07 08:08:47,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,343 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,344 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -100.44815063476562
2023-01-07 08:08:47,344 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,344 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,344 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,344 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 131.00611877441406
2023-01-07 08:08:47,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,345 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,345 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,346 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 131.00611877441406
2023-01-07 08:08:47,346 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,346 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,346 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,346 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 377.36566162109375
2023-01-07 08:08:47,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,347 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,348 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 377.36566162109375
2023-01-07 08:08:47,348 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,348 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,348 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,348 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:47,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,349 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,350 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:47,350 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,350 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,350 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,350 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -70.19705200195312
2023-01-07 08:08:47,350 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,350 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,350 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,352 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -70.19705200195312
2023-01-07 08:08:47,352 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,352 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,352 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,352 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 505.0
2023-01-07 08:08:47,352 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,352 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,352 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,354 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 505.0
2023-01-07 08:08:47,354 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,354 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,354 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,354 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: 202.25961303710938
2023-01-07 08:08:47,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,354 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,356 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 202.25961303710938
2023-01-07 08:08:47,356 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,356 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,356 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,356 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:47,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,358 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:47,358 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,358 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,358 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,358 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -186.89923095703125
2023-01-07 08:08:47,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,358 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,360 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -186.89923095703125
2023-01-07 08:08:47,360 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,360 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,360 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,360 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:47,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,362 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:47,362 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,362 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,362 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,362 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: -70.66160583496094
2023-01-07 08:08:47,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,364 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -70.66160583496094
2023-01-07 08:08:47,364 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,364 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,364 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,364 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 500.3067626953125
2023-01-07 08:08:47,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,366 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 500.3067626953125
2023-01-07 08:08:47,366 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,366 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,366 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,366 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: -111.39768981933594
2023-01-07 08:08:47,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,366 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,368 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: -111.39768981933594
2023-01-07 08:08:47,368 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,368 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,368 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,368 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 255.66600036621094
2023-01-07 08:08:47,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,370 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 255.66600036621094
2023-01-07 08:08:47,370 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,370 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,370 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,370 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -37410.37890625
2023-01-07 08:08:47,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,372 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -37410.37890625
2023-01-07 08:08:47,372 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,372 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,372 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,372 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -469.4188232421875
2023-01-07 08:08:47,372 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,372 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,372 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,373 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 253.44960021972656
2023-01-07 08:08:47,373 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,373 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,373 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,373 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -469.4188232421875
2023-01-07 08:08:47,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,374 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,375 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -469.4188232421875
2023-01-07 08:08:47,375 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,375 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,375 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,375 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -2647.904296875
2023-01-07 08:08:47,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,376 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,376 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1046.3050537109375
2023-01-07 08:08:47,376 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,376 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,377 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,377 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -2647.904296875
2023-01-07 08:08:47,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,377 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,378 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -2647.904296875
2023-01-07 08:08:47,378 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,378 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,378 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,378 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1729.4075927734375
2023-01-07 08:08:47,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,378 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,379 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,380 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1053.9227294921875
2023-01-07 08:08:47,380 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,380 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,380 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,380 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1729.4075927734375
2023-01-07 08:08:47,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,380 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,381 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1729.4075927734375
2023-01-07 08:08:47,382 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,382 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,382 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,382 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 251.84320068359375
2023-01-07 08:08:47,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,382 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,383 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 251.84320068359375
2023-01-07 08:08:47,384 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,384 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,384 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,384 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -4018.2216796875
2023-01-07 08:08:47,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,385 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -4018.2216796875
2023-01-07 08:08:47,385 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,385 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,386 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,386 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -798.6490478515625
2023-01-07 08:08:47,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,386 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,387 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 246.7408447265625
2023-01-07 08:08:47,387 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,387 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,387 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,387 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -798.6490478515625
2023-01-07 08:08:47,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,387 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,389 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -798.6490478515625
2023-01-07 08:08:47,389 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,389 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,389 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,389 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 51.183197021484375
2023-01-07 08:08:47,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,389 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,390 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1011.6197509765625
2023-01-07 08:08:47,390 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,390 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,390 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,390 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 51.183197021484375
2023-01-07 08:08:47,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,391 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,392 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 51.183197021484375
2023-01-07 08:08:47,392 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,392 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,392 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,392 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 527.2438354492188
2023-01-07 08:08:47,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,393 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 247.62005615234375
2023-01-07 08:08:47,394 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,394 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,394 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,394 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 527.2438354492188
2023-01-07 08:08:47,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,394 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,395 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 527.2438354492188
2023-01-07 08:08:47,395 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,395 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,396 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,396 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -216.25807189941406
2023-01-07 08:08:47,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,396 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,397 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 243.99697875976562
2023-01-07 08:08:47,397 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,397 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,397 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,397 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -216.25807189941406
2023-01-07 08:08:47,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,399 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -216.25807189941406
2023-01-07 08:08:47,399 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,399 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,399 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,399 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 347.9730529785156
2023-01-07 08:08:47,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,400 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1103.31787109375
2023-01-07 08:08:47,400 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,400 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,400 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,400 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 347.9730529785156
2023-01-07 08:08:47,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,401 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,402 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 347.9730529785156
2023-01-07 08:08:47,402 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,402 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,402 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,402 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 69.14004516601562
2023-01-07 08:08:47,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,403 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,403 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 293.81915283203125
2023-01-07 08:08:47,404 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,404 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,404 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,404 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 69.14004516601562
2023-01-07 08:08:47,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,404 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,405 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 69.14004516601562
2023-01-07 08:08:47,405 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,405 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,406 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,406 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 74.16289520263672
2023-01-07 08:08:47,406 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,406 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,406 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,407 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 294.36614990234375
2023-01-07 08:08:47,407 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,407 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,407 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,407 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 74.16289520263672
2023-01-07 08:08:47,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,409 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 74.16289520263672
2023-01-07 08:08:47,409 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,409 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,409 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,409 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -80.66668701171875
2023-01-07 08:08:47,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,409 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,410 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1076.5146484375
2023-01-07 08:08:47,410 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,410 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,410 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,410 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -80.66668701171875
2023-01-07 08:08:47,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,411 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,412 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -80.66668701171875
2023-01-07 08:08:47,412 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,412 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,412 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,412 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 241.7735137939453
2023-01-07 08:08:47,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,413 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,413 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 292.6849365234375
2023-01-07 08:08:47,413 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,414 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,414 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,414 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 241.7735137939453
2023-01-07 08:08:47,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,415 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 241.7735137939453
2023-01-07 08:08:47,415 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,415 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,416 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,416 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -5144.5009765625
2023-01-07 08:08:47,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,416 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,417 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 294.33819580078125
2023-01-07 08:08:47,417 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,417 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,417 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,417 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -5144.5009765625
2023-01-07 08:08:47,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,417 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,419 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -5144.5009765625
2023-01-07 08:08:47,419 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,419 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,419 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,419 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -35220.8984375
2023-01-07 08:08:47,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,419 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,420 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1058.06103515625
2023-01-07 08:08:47,420 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,420 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,420 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,420 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -35220.8984375
2023-01-07 08:08:47,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,421 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,421 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,422 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -35220.8984375
2023-01-07 08:08:47,422 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,422 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,422 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,422 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -14874.6484375
2023-01-07 08:08:47,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,423 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,424 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 295.62322998046875
2023-01-07 08:08:47,424 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,424 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,424 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,424 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -14874.6484375
2023-01-07 08:08:47,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,424 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,424 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,425 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -14874.6484375
2023-01-07 08:08:47,426 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,426 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,426 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,426 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -39563.6484375
2023-01-07 08:08:47,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,426 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,427 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 296.06036376953125
2023-01-07 08:08:47,427 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,427 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,427 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,427 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -39563.6484375
2023-01-07 08:08:47,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,427 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,429 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -39563.6484375
2023-01-07 08:08:47,429 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,429 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,429 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,429 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -83906.703125
2023-01-07 08:08:47,429 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,429 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,429 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,430 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1075.33544921875
2023-01-07 08:08:47,430 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,430 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,430 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,430 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -83906.703125
2023-01-07 08:08:47,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,431 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,431 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,432 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -83906.703125
2023-01-07 08:08:47,432 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,432 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,432 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,432 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -71536.8203125
2023-01-07 08:08:47,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,433 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,434 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 587.691650390625
2023-01-07 08:08:47,434 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,434 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,434 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,434 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -71536.8203125
2023-01-07 08:08:47,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,434 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,434 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,436 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -71536.8203125
2023-01-07 08:08:47,436 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,436 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,436 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,436 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 118.94886779785156
2023-01-07 08:08:47,436 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,436 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,436 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,438 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 593.3306884765625
2023-01-07 08:08:47,438 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,438 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,438 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,439 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 118.94886779785156
2023-01-07 08:08:47,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,439 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,441 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 118.94886779785156
2023-01-07 08:08:47,441 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,441 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,441 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,441 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -205359.828125
2023-01-07 08:08:47,441 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,441 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,441 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,442 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2088.2919921875
2023-01-07 08:08:47,442 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,442 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,442 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,442 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -205359.828125
2023-01-07 08:08:47,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,443 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,444 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -205359.828125
2023-01-07 08:08:47,444 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,444 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,444 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,444 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -44837.11328125
2023-01-07 08:08:47,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,445 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,445 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2138.2744140625
2023-01-07 08:08:47,445 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,445 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,445 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,446 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -44837.11328125
2023-01-07 08:08:47,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,446 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,447 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -44837.11328125
2023-01-07 08:08:47,447 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,447 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,448 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,448 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 369.85638427734375
2023-01-07 08:08:47,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,448 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,449 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 593.476318359375
2023-01-07 08:08:47,449 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,449 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,449 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,449 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 369.85638427734375
2023-01-07 08:08:47,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,451 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 369.85638427734375
2023-01-07 08:08:47,451 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,451 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,451 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,451 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -56813.234375
2023-01-07 08:08:47,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,451 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,452 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 598.9775390625
2023-01-07 08:08:47,452 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,452 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,452 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,452 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -56813.234375
2023-01-07 08:08:47,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,453 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,454 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -56813.234375
2023-01-07 08:08:47,454 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,454 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,454 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,454 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -171824.375
2023-01-07 08:08:47,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,455 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,456 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2040.7109375
2023-01-07 08:08:47,456 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,456 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,456 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,456 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -171824.375
2023-01-07 08:08:47,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,458 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -171824.375
2023-01-07 08:08:47,458 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,458 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,458 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,458 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -21447.509765625
2023-01-07 08:08:47,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,458 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,459 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 601.2415771484375
2023-01-07 08:08:47,459 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,459 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,459 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,459 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -21447.509765625
2023-01-07 08:08:47,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,460 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,461 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -21447.509765625
2023-01-07 08:08:47,461 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,461 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,461 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,461 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 693.5899658203125
2023-01-07 08:08:47,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,462 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,462 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 600.3807373046875
2023-01-07 08:08:47,462 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,462 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,463 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,463 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 693.5899658203125
2023-01-07 08:08:47,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,464 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 693.5899658203125
2023-01-07 08:08:47,464 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,464 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,464 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,465 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -249365.5
2023-01-07 08:08:47,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,465 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,466 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2433.814697265625
2023-01-07 08:08:47,466 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,466 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,466 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,466 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -249365.5
2023-01-07 08:08:47,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,466 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:47,468 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -249365.5
2023-01-07 08:08:47,468 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:47,468 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:47,468 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:47,469 > [DEBUG] 0 :: 57.08721160888672
2023-01-07 08:08:47,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,471 > [DEBUG] 0 :: before allreduce fusion buffer :: -5156253990912.0
2023-01-07 08:08:47,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,475 > [DEBUG] 0 :: before allreduce fusion buffer :: -154.99342346191406
2023-01-07 08:08:47,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,479 > [DEBUG] 0 :: before allreduce fusion buffer :: -76.60658264160156
2023-01-07 08:08:47,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,481 > [DEBUG] 0 :: before allreduce fusion buffer :: -699614.5
2023-01-07 08:08:47,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,482 > [DEBUG] 0 :: before allreduce fusion buffer :: -10258211667968.0
2023-01-07 08:08:47,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,484 > [DEBUG] 0 :: before allreduce fusion buffer :: -20516423335936.0
2023-01-07 08:08:47,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,486 > [DEBUG] 0 :: before allreduce fusion buffer :: -20516423335936.0
2023-01-07 08:08:47,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,487 > [DEBUG] 0 :: before allreduce fusion buffer :: -129.9696502685547
2023-01-07 08:08:47,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,489 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.556588649749756
2023-01-07 08:08:47,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,490 > [DEBUG] 0 :: before allreduce fusion buffer :: -41032846671872.0
2023-01-07 08:08:47,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,492 > [DEBUG] 0 :: before allreduce fusion buffer :: -41032846671872.0
2023-01-07 08:08:47,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,493 > [DEBUG] 0 :: before allreduce fusion buffer :: -82065693343744.0
2023-01-07 08:08:47,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,495 > [DEBUG] 0 :: before allreduce fusion buffer :: -164131386687488.0
2023-01-07 08:08:47,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,496 > [DEBUG] 0 :: before allreduce fusion buffer :: -1691888.625
2023-01-07 08:08:47,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,498 > [DEBUG] 0 :: before allreduce fusion buffer :: -328262773374976.0
2023-01-07 08:08:47,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,499 > [DEBUG] 0 :: before allreduce fusion buffer :: -1299.042236328125
2023-01-07 08:08:47,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,501 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.253463745117188
2023-01-07 08:08:47,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,502 > [DEBUG] 0 :: before allreduce fusion buffer :: -656525546749952.0
2023-01-07 08:08:47,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,504 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,504 > [DEBUG] 0 :: before allreduce fusion buffer :: -1313051093499904.0
2023-01-07 08:08:47,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,506 > [DEBUG] 0 :: before allreduce fusion buffer :: -2626102186999808.0
2023-01-07 08:08:47,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,507 > [DEBUG] 0 :: before allreduce fusion buffer :: -5252204373999616.0
2023-01-07 08:08:47,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,509 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0504408747999232e+16
2023-01-07 08:08:47,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,511 > [DEBUG] 0 :: before allreduce fusion buffer :: -682.5263671875
2023-01-07 08:08:47,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,511 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,512 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0504408747999232e+16
2023-01-07 08:08:47,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,514 > [DEBUG] 0 :: before allreduce fusion buffer :: -1080.414794921875
2023-01-07 08:08:47,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,515 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.1074163275923456e+16
2023-01-07 08:08:47,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,517 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.214832655184691e+16
2023-01-07 08:08:47,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,518 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.429665310369382e+16
2023-01-07 08:08:47,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,520 > [DEBUG] 0 :: before allreduce fusion buffer :: -59057.08984375
2023-01-07 08:08:47,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,522 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.6859330620738765e+17
2023-01-07 08:08:47,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,523 > [DEBUG] 0 :: before allreduce fusion buffer :: 40629.15625
2023-01-07 08:08:47,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,525 > [DEBUG] 0 :: before allreduce fusion buffer :: -29501.357421875
2023-01-07 08:08:47,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,526 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.6859330620738765e+17
2023-01-07 08:08:47,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,528 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.371866124147753e+17
2023-01-07 08:08:47,529 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,529 > [DEBUG] 0 :: before allreduce fusion buffer :: -40679.3125
2023-01-07 08:08:47,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,531 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.743732248295506e+17
2023-01-07 08:08:47,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,533 > [DEBUG] 0 :: before allreduce fusion buffer :: -152946.0
2023-01-07 08:08:47,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,534 > [DEBUG] 0 :: before allreduce fusion buffer :: -125205.046875
2023-01-07 08:08:47,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,535 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,536 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.743732248295506e+17
2023-01-07 08:08:47,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,537 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3529287170132541e+18
2023-01-07 08:08:47,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,539 > [DEBUG] 0 :: before allreduce fusion buffer :: -833762.5
2023-01-07 08:08:47,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,540 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3529287170132541e+18
2023-01-07 08:08:47,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,542 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4479420781135559
2023-01-07 08:08:47,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,543 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3529287170132541e+18
2023-01-07 08:08:47,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,545 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,545 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.7058574340265083e+18
2023-01-07 08:08:47,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,546 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.7058574340265083e+18
2023-01-07 08:08:47,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,548 > [DEBUG] 0 :: before allreduce fusion buffer :: -40060164.0
2023-01-07 08:08:47,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,549 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.411714868053017e+18
2023-01-07 08:08:47,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,551 > [DEBUG] 0 :: before allreduce fusion buffer :: -1112513408.0
2023-01-07 08:08:47,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,552 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.411714868053017e+18
2023-01-07 08:08:47,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,554 > [DEBUG] 0 :: before allreduce fusion buffer :: -2082819968.0
2023-01-07 08:08:47,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,555 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0823429736106033e+19
2023-01-07 08:08:47,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,557 > [DEBUG] 0 :: before allreduce fusion buffer :: 4794676224.0
2023-01-07 08:08:47,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,558 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0823429736106033e+19
2023-01-07 08:08:47,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,560 > [DEBUG] 0 :: before allreduce fusion buffer :: 13615765504.0
2023-01-07 08:08:47,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,561 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0823429736106033e+19
2023-01-07 08:08:47,721 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,721 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,721 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.12037579715251923
2023-01-07 08:08:47,722 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,722 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,723 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.312277891268477e+18
2023-01-07 08:08:47,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,724 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.6701741218566895
2023-01-07 08:08:47,725 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,725 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,725 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4624555782536954e+19
2023-01-07 08:08:47,726 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,726 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,726 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.5820672512054443
2023-01-07 08:08:47,727 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,727 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,728 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4624555782536954e+19
2023-01-07 08:08:47,729 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,729 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,729 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7537059783935547
2023-01-07 08:08:47,730 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,730 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,730 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.9249111565073908e+19
2023-01-07 08:08:47,731 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,731 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,731 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.222363471984863
2023-01-07 08:08:47,732 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,732 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,732 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.8498223130147815e+19
2023-01-07 08:08:47,733 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,734 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,734 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.28538966178894043
2023-01-07 08:08:47,904 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,904 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,904 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.1699644626029563e+20
2023-01-07 08:08:47,905 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,905 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,905 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.378172367811203
2023-01-07 08:08:47,906 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,906 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,906 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.1699644626029563e+20
2023-01-07 08:08:47,908 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,908 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,908 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0085948705673218
2023-01-07 08:08:47,909 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,909 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,909 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:47,909 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:47,909 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.3399289252059126e+20
2023-01-07 08:08:48,087 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,087 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,087 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.08286213874816895
2023-01-07 08:08:48,089 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,089 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,089 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.679857850411825e+20
2023-01-07 08:08:48,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,090 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6589430570602417
2023-01-07 08:08:48,203 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,203 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,204 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.35971570082365e+20
2023-01-07 08:08:48,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,205 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6588349342346191
2023-01-07 08:08:48,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,206 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8779526309175026e+21
2023-01-07 08:08:48,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,208 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.36930978298187256
2023-01-07 08:08:48,209 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,209 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,209 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.87194314016473e+21
2023-01-07 08:08:48,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,210 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.41455078125
2023-01-07 08:08:48,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,211 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,212 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.74388628032946e+21
2023-01-07 08:08:48,213 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,213 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,213 > [DEBUG] 0 :: before allreduce fusion buffer :: 72539619328.0
2023-01-07 08:08:48,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,214 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.735340137086571e+21
2023-01-07 08:08:48,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,216 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,216 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.021912097930908
2023-01-07 08:08:48,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,217 > [DEBUG] 0 :: before allreduce fusion buffer :: -37430372.0
2023-01-07 08:08:48,219 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,219 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,219 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.08775141835212708
2023-01-07 08:08:48,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,220 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,221 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,221 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,222 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.5941152572631836
2023-01-07 08:08:48,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,223 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,223 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.625779151916504
2023-01-07 08:08:48,224 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,224 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,225 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.975340723991394
2023-01-07 08:08:48,225 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,225 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,226 > [DEBUG] 0 :: before allreduce fusion buffer :: 31194313916416.0
2023-01-07 08:08:48,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,228 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2044506072998047
2023-01-07 08:08:48,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,228 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 307.138916015625
2023-01-07 08:08:48,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,230 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,230 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.840626239776611
2023-01-07 08:08:48,231 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,231 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,231 > [DEBUG] 0 :: before allreduce fusion buffer :: -27419.6171875
2023-01-07 08:08:48,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,232 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,233 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.50569725036621
2023-01-07 08:08:48,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,235 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5971488725204992e+16
2023-01-07 08:08:48,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,236 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.7968368530273438
2023-01-07 08:08:48,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,237 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,238 > [DEBUG] 0 :: before allreduce fusion buffer :: -88.13961029052734
2023-01-07 08:08:48,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,239 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,239 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.5031628608703613
2023-01-07 08:08:48,240 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,240 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,240 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,240 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,240 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.1108763920655974e+17
2023-01-07 08:08:48,242 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,242 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,242 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.156780242919922
2023-01-07 08:08:48,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,243 > [DEBUG] 0 :: before allreduce fusion buffer :: -5292.712890625
2023-01-07 08:08:48,245 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,245 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,245 > [DEBUG] 0 :: before allreduce fusion buffer :: -65.98855590820312
2023-01-07 08:08:48,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,246 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,246 > [DEBUG] 0 :: before allreduce fusion buffer :: 51.98869705200195
2023-01-07 08:08:48,251 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:08:48,251 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,251 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,251 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,251 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,253 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,253 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,253 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,253 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,253 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,253 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,255 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,255 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,255 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,255 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,255 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,256 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,256 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,256 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,257 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,257 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,258 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,258 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,259 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,259 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,259 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,259 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,259 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,259 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,259 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,259 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,260 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.121350204203497e+24
2023-01-07 08:08:48,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,264 > [DEBUG] 0 :: before allreduce fusion buffer :: 202.791015625
2023-01-07 08:08:48,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,266 > [DEBUG] 0 :: before allreduce fusion buffer :: 214.93885803222656
2023-01-07 08:08:48,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,267 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,267 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.0872629324024696e+20
2023-01-07 08:08:48,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,267 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,268 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.767121838345458e+20
2023-01-07 08:08:48,268 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -29.67986297607422
2023-01-07 08:08:48,268 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,269 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,269 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,269 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 62.305789947509766
2023-01-07 08:08:48,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,269 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,269 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,269 > [DEBUG] 0 :: before allreduce fusion buffer :: 47.51806640625
2023-01-07 08:08:48,270 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 62.305789947509766
2023-01-07 08:08:48,270 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,270 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,270 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,271 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: -5.120885372161865
2023-01-07 08:08:48,271 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,271 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,271 > [DEBUG] 0 :: before allreduce fusion buffer :: -112.89726257324219
2023-01-07 08:08:48,273 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -5.120885372161865
2023-01-07 08:08:48,273 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,273 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,273 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,273 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 192.32455444335938
2023-01-07 08:08:48,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,273 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,273 > [DEBUG] 0 :: before allreduce fusion buffer :: -71.8099594116211
2023-01-07 08:08:48,274 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.39999389648438
2023-01-07 08:08:48,274 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,274 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,274 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,274 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 192.32455444335938
2023-01-07 08:08:48,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,275 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.104618072509766
2023-01-07 08:08:48,277 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 192.32455444335938
2023-01-07 08:08:48,277 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,277 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,277 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,277 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 68.57344055175781
2023-01-07 08:08:48,277 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,278 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.661895751953125
2023-01-07 08:08:48,280 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 68.57344055175781
2023-01-07 08:08:48,280 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,280 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,280 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,280 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.331598281860352
2023-01-07 08:08:48,280 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,280 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,280 > [DEBUG] 0 :: before allreduce fusion buffer :: -43.926307678222656
2023-01-07 08:08:48,281 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 86.29620361328125
2023-01-07 08:08:48,281 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,281 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,281 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,282 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 294.21942138671875
2023-01-07 08:08:48,282 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,282 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,282 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,282 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,282 > [DEBUG] 0 :: before allreduce fusion buffer :: -125.76148986816406
2023-01-07 08:08:48,284 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 294.21942138671875
2023-01-07 08:08:48,284 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,284 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,284 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,284 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.3705005645751953
2023-01-07 08:08:48,284 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,284 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,284 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.119335174560547
2023-01-07 08:08:48,285 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 105.51136016845703
2023-01-07 08:08:48,285 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,285 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,285 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,285 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.3705005645751953
2023-01-07 08:08:48,285 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,285 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,286 > [DEBUG] 0 :: before allreduce fusion buffer :: -145040.875
2023-01-07 08:08:48,286 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 258.8083801269531
2023-01-07 08:08:48,286 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,287 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,287 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,287 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.3705005645751953
2023-01-07 08:08:48,287 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,287 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,287 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.9934587478637695
2023-01-07 08:08:48,288 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 66.26497650146484
2023-01-07 08:08:48,288 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,288 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,288 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,288 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 62.50579833984375
2023-01-07 08:08:48,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,288 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,289 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,289 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,289 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.338966369628906
2023-01-07 08:08:48,290 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 62.50579833984375
2023-01-07 08:08:48,290 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,290 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,290 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,290 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.3705005645751953
2023-01-07 08:08:48,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,290 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,290 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,291 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.997753143310547
2023-01-07 08:08:48,292 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: -3.3705005645751953
2023-01-07 08:08:48,292 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,292 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,292 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,292 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 62.50579833984375
2023-01-07 08:08:48,292 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,292 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,292 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,293 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,293 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5047450065612793
2023-01-07 08:08:48,294 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 62.50579833984375
2023-01-07 08:08:48,294 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,294 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,294 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,294 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.331598281860352
2023-01-07 08:08:48,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,295 > [DEBUG] 0 :: before allreduce fusion buffer :: 17.916595458984375
2023-01-07 08:08:48,296 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 45.779239654541016
2023-01-07 08:08:48,296 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,296 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,296 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,296 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 48.564605712890625
2023-01-07 08:08:48,296 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,296 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,296 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.002098083496094
2023-01-07 08:08:48,297 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 247.13922119140625
2023-01-07 08:08:48,297 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,297 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,297 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,297 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 48.564605712890625
2023-01-07 08:08:48,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 48.278018951416016
2023-01-07 08:08:48,299 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 48.564605712890625
2023-01-07 08:08:48,299 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,299 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,299 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,300 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.331598281860352
2023-01-07 08:08:48,300 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,300 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,300 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3434767723083496
2023-01-07 08:08:48,301 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 60.905784606933594
2023-01-07 08:08:48,301 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,301 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,301 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,301 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.331598281860352
2023-01-07 08:08:48,301 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,301 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,301 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.179605722427368
2023-01-07 08:08:48,303 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 13.331598281860352
2023-01-07 08:08:48,303 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,303 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,303 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,303 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 62.50579833984375
2023-01-07 08:08:48,303 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,303 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,303 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,303 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,303 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,303 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,303 > [DEBUG] 0 :: before allreduce fusion buffer :: -148154592.0
2023-01-07 08:08:48,305 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 62.50579833984375
2023-01-07 08:08:48,305 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,305 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,305 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,305 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -27.298595428466797
2023-01-07 08:08:48,305 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,305 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,306 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,307 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 56.283470153808594
2023-01-07 08:08:48,307 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,307 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,307 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,307 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 488.4967346191406
2023-01-07 08:08:48,307 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,307 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,307 > [DEBUG] 0 :: before allreduce fusion buffer :: -1186107392.0
2023-01-07 08:08:48,308 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 241.4199676513672
2023-01-07 08:08:48,308 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,308 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,308 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,309 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -27.298595428466797
2023-01-07 08:08:48,309 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,309 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,309 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,310 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 488.4967346191406
2023-01-07 08:08:48,310 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,310 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,310 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,310 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -27.298595428466797
2023-01-07 08:08:48,310 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,311 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,311 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 126.4722671508789
2023-01-07 08:08:48,311 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,311 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,311 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,312 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -27.298595428466797
2023-01-07 08:08:48,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,312 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,313 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: -27.298595428466797
2023-01-07 08:08:48,313 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,313 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,313 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,313 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 130.85548400878906
2023-01-07 08:08:48,314 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,314 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,314 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,314 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,314 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,315 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 130.85548400878906
2023-01-07 08:08:48,315 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,315 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,315 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,315 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 588.934326171875
2023-01-07 08:08:48,316 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,316 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,316 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,317 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 588.934326171875
2023-01-07 08:08:48,317 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,317 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,317 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,317 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 503.87640380859375
2023-01-07 08:08:48,317 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,317 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,318 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,318 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,318 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,319 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 503.87640380859375
2023-01-07 08:08:48,319 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,319 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,319 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,319 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 6.997344970703125
2023-01-07 08:08:48,319 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,319 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,320 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,321 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 6.997344970703125
2023-01-07 08:08:48,321 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,321 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,321 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,321 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -21.00524139404297
2023-01-07 08:08:48,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,321 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,321 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,322 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 522.0640869140625
2023-01-07 08:08:48,322 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,322 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,322 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,322 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -21.00524139404297
2023-01-07 08:08:48,322 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,322 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,323 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,324 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -21.00524139404297
2023-01-07 08:08:48,324 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,324 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,324 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,324 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 131.94058227539062
2023-01-07 08:08:48,324 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,324 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,324 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,325 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,326 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 131.94058227539062
2023-01-07 08:08:48,326 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,326 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,326 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,326 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: -275.1772766113281
2023-01-07 08:08:48,326 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,326 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,327 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,328 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -275.1772766113281
2023-01-07 08:08:48,328 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,328 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,328 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,328 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 129.3249053955078
2023-01-07 08:08:48,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,328 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,328 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,329 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,330 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 129.3249053955078
2023-01-07 08:08:48,330 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,330 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,330 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,330 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 233.66761779785156
2023-01-07 08:08:48,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,330 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,332 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 233.66761779785156
2023-01-07 08:08:48,332 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,332 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,332 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,332 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -9.932205200195312
2023-01-07 08:08:48,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,333 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 523.492431640625
2023-01-07 08:08:48,333 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,333 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,333 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,333 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -9.932205200195312
2023-01-07 08:08:48,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,334 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,335 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -9.932205200195312
2023-01-07 08:08:48,335 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,335 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,335 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,335 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 131.93841552734375
2023-01-07 08:08:48,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,336 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,337 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 131.93841552734375
2023-01-07 08:08:48,337 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,337 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,337 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,337 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 468.20013427734375
2023-01-07 08:08:48,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,337 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,339 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 468.20013427734375
2023-01-07 08:08:48,339 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,339 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,339 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,339 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:48,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,340 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,341 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:48,341 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,341 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,341 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,341 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -61.93678283691406
2023-01-07 08:08:48,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,341 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,343 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -61.93678283691406
2023-01-07 08:08:48,343 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,343 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,343 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,343 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 505.0
2023-01-07 08:08:48,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,344 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,345 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 505.0
2023-01-07 08:08:48,345 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,345 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,345 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,345 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: 214.922607421875
2023-01-07 08:08:48,345 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,345 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,347 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 214.922607421875
2023-01-07 08:08:48,347 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,347 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,347 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,347 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:48,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,347 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,347 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,347 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,349 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:48,349 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,349 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,349 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,349 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -293.1374816894531
2023-01-07 08:08:48,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,349 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,349 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,351 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -293.1374816894531
2023-01-07 08:08:48,351 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,351 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,351 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,351 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 129.79998779296875
2023-01-07 08:08:48,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,352 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,353 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79998779296875
2023-01-07 08:08:48,353 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,353 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,353 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,353 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 23.13809585571289
2023-01-07 08:08:48,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,354 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,355 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 23.13809585571289
2023-01-07 08:08:48,355 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,355 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,355 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,355 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 496.7940368652344
2023-01-07 08:08:48,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,357 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 496.7940368652344
2023-01-07 08:08:48,357 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,357 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,357 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,357 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: -213.65638732910156
2023-01-07 08:08:48,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,357 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,359 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: -213.65638732910156
2023-01-07 08:08:48,359 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,359 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,359 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,359 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 255.56240844726562
2023-01-07 08:08:48,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,359 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,359 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,361 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 255.56240844726562
2023-01-07 08:08:48,361 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,361 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,361 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,361 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -46677.09375
2023-01-07 08:08:48,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,363 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -46677.09375
2023-01-07 08:08:48,363 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,363 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,363 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,363 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -302.5226135253906
2023-01-07 08:08:48,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,364 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 250.55250549316406
2023-01-07 08:08:48,364 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,364 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,364 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,364 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -302.5226135253906
2023-01-07 08:08:48,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,366 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -302.5226135253906
2023-01-07 08:08:48,366 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,366 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,366 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,366 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -3258.7119140625
2023-01-07 08:08:48,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,367 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,367 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1047.352783203125
2023-01-07 08:08:48,367 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,367 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,368 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,368 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -3258.7119140625
2023-01-07 08:08:48,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,369 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -3258.7119140625
2023-01-07 08:08:48,369 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,369 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,369 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,369 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -2254.301513671875
2023-01-07 08:08:48,369 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,369 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,371 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1054.15234375
2023-01-07 08:08:48,371 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,371 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,371 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,371 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -2254.301513671875
2023-01-07 08:08:48,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,371 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,372 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -2254.301513671875
2023-01-07 08:08:48,373 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,373 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,373 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,373 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 255.61456298828125
2023-01-07 08:08:48,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,373 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,374 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 255.61456298828125
2023-01-07 08:08:48,375 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,375 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,375 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,375 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -5440.6015625
2023-01-07 08:08:48,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,375 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,376 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -5440.6015625
2023-01-07 08:08:48,376 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,376 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,377 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,377 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -1067.1934814453125
2023-01-07 08:08:48,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,377 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,378 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 243.92100524902344
2023-01-07 08:08:48,378 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,378 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,378 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,378 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -1067.1934814453125
2023-01-07 08:08:48,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,378 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,378 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,380 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -1067.1934814453125
2023-01-07 08:08:48,380 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,380 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,380 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,380 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: -134.40447998046875
2023-01-07 08:08:48,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,380 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,381 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1013.12744140625
2023-01-07 08:08:48,381 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,381 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,381 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,381 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: -134.40447998046875
2023-01-07 08:08:48,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,382 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,383 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: -134.40447998046875
2023-01-07 08:08:48,383 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,383 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,383 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,383 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 446.500732421875
2023-01-07 08:08:48,383 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,383 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,384 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 244.86544799804688
2023-01-07 08:08:48,385 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,385 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,385 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,385 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 446.500732421875
2023-01-07 08:08:48,385 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,385 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,385 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,386 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 446.500732421875
2023-01-07 08:08:48,386 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,387 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,387 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,387 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -177.8898468017578
2023-01-07 08:08:48,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,387 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,388 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 241.22006225585938
2023-01-07 08:08:48,388 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,388 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,388 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,388 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -177.8898468017578
2023-01-07 08:08:48,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,388 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,390 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -177.8898468017578
2023-01-07 08:08:48,390 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,390 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,390 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,390 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 307.4449157714844
2023-01-07 08:08:48,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,390 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,391 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1102.990234375
2023-01-07 08:08:48,391 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,391 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,391 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,391 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 307.4449157714844
2023-01-07 08:08:48,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,391 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,392 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,393 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 307.4449157714844
2023-01-07 08:08:48,393 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,393 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,393 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,393 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -181.43809509277344
2023-01-07 08:08:48,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,394 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,394 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 290.8978271484375
2023-01-07 08:08:48,395 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,395 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,395 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,395 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -181.43809509277344
2023-01-07 08:08:48,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,395 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,396 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: -181.43809509277344
2023-01-07 08:08:48,396 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,397 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,397 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,397 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 99.13211059570312
2023-01-07 08:08:48,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,398 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 291.69036865234375
2023-01-07 08:08:48,398 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,398 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,398 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,398 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 99.13211059570312
2023-01-07 08:08:48,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,398 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,400 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 99.13211059570312
2023-01-07 08:08:48,400 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,400 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,400 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,400 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -161.7198486328125
2023-01-07 08:08:48,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,400 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,401 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1067.6820068359375
2023-01-07 08:08:48,401 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,401 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,401 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,401 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -161.7198486328125
2023-01-07 08:08:48,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,402 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,403 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -161.7198486328125
2023-01-07 08:08:48,403 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,403 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,403 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,403 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 268.55364990234375
2023-01-07 08:08:48,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,404 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,405 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 289.1994934082031
2023-01-07 08:08:48,405 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,405 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,405 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,405 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 268.55364990234375
2023-01-07 08:08:48,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,405 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,406 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 268.55364990234375
2023-01-07 08:08:48,407 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,407 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,407 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,407 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -6740.5400390625
2023-01-07 08:08:48,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,408 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 291.2235107421875
2023-01-07 08:08:48,408 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,408 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,408 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,408 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -6740.5400390625
2023-01-07 08:08:48,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,408 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,410 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -6740.5400390625
2023-01-07 08:08:48,410 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,410 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,410 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,410 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -46195.2734375
2023-01-07 08:08:48,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,410 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,411 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1049.0897216796875
2023-01-07 08:08:48,411 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,411 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,411 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,411 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -46195.2734375
2023-01-07 08:08:48,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,412 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,413 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -46195.2734375
2023-01-07 08:08:48,413 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,413 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,413 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,413 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -19531.53515625
2023-01-07 08:08:48,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,415 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 292.661376953125
2023-01-07 08:08:48,415 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,415 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,415 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,415 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -19531.53515625
2023-01-07 08:08:48,415 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,415 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,415 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,417 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -19531.53515625
2023-01-07 08:08:48,417 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,417 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,417 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,417 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -51871.984375
2023-01-07 08:08:48,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,417 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,418 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 292.87847900390625
2023-01-07 08:08:48,418 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,418 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,418 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,418 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -51871.984375
2023-01-07 08:08:48,418 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,418 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,419 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,420 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -51871.984375
2023-01-07 08:08:48,420 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,420 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,420 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,420 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -109995.328125
2023-01-07 08:08:48,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,421 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,421 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1069.476806640625
2023-01-07 08:08:48,421 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,421 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,421 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,422 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -109995.328125
2023-01-07 08:08:48,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,422 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,423 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -109995.328125
2023-01-07 08:08:48,423 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,423 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,423 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,424 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -93749.7578125
2023-01-07 08:08:48,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,424 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,424 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,425 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 585.1549682617188
2023-01-07 08:08:48,425 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,425 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,425 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,425 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -93749.7578125
2023-01-07 08:08:48,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,425 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,427 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -93749.7578125
2023-01-07 08:08:48,427 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,427 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,427 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,427 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 188.0306396484375
2023-01-07 08:08:48,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,427 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,428 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 592.7110595703125
2023-01-07 08:08:48,428 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,428 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,428 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,428 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 188.0306396484375
2023-01-07 08:08:48,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,429 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,429 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,430 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 188.0306396484375
2023-01-07 08:08:48,430 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,430 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,430 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,431 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -269054.0
2023-01-07 08:08:48,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,431 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,431 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,432 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2075.784912109375
2023-01-07 08:08:48,432 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,432 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,432 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,432 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -269054.0
2023-01-07 08:08:48,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,432 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,432 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,433 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -269054.0
2023-01-07 08:08:48,433 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,434 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,434 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,434 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -58781.0390625
2023-01-07 08:08:48,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,434 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,434 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,435 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2130.198486328125
2023-01-07 08:08:48,435 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,435 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,435 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,435 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -58781.0390625
2023-01-07 08:08:48,435 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,435 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,435 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,437 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -58781.0390625
2023-01-07 08:08:48,437 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,437 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,437 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,437 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 439.9178466796875
2023-01-07 08:08:48,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,437 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,437 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,438 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 592.328857421875
2023-01-07 08:08:48,438 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,438 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,438 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,439 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 439.9178466796875
2023-01-07 08:08:48,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,439 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,440 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 439.9178466796875
2023-01-07 08:08:48,440 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,440 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,440 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,440 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -74453.734375
2023-01-07 08:08:48,441 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,441 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,441 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,442 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 599.8251342773438
2023-01-07 08:08:48,442 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,442 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,442 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,442 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -74453.734375
2023-01-07 08:08:48,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,442 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,442 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,444 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -74453.734375
2023-01-07 08:08:48,444 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,444 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,444 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,444 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -225141.1875
2023-01-07 08:08:48,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,444 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,445 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2034.74951171875
2023-01-07 08:08:48,445 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,445 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,445 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,445 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -225141.1875
2023-01-07 08:08:48,445 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,445 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,446 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,447 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -225141.1875
2023-01-07 08:08:48,447 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,447 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,447 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,447 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -28110.16796875
2023-01-07 08:08:48,447 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,447 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,448 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,448 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 602.4776611328125
2023-01-07 08:08:48,448 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,449 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,449 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,449 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -28110.16796875
2023-01-07 08:08:48,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,450 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -28110.16796875
2023-01-07 08:08:48,450 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,450 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,451 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,451 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 778.959716796875
2023-01-07 08:08:48,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,451 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,452 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 601.230224609375
2023-01-07 08:08:48,452 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,452 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,452 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,452 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 778.959716796875
2023-01-07 08:08:48,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,452 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,454 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 778.959716796875
2023-01-07 08:08:48,454 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,454 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,454 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,454 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -327010.625
2023-01-07 08:08:48,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,454 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,455 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2425.906982421875
2023-01-07 08:08:48,455 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,455 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,455 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,455 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -327010.625
2023-01-07 08:08:48,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:48,457 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -327010.625
2023-01-07 08:08:48,457 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:08:48,457 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:08:48,458 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:08:48,458 > [DEBUG] 0 :: 134.76194763183594
2023-01-07 08:08:48,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,462 > [DEBUG] 0 :: before allreduce fusion buffer :: -15842758.0
2023-01-07 08:08:48,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,465 > [DEBUG] 0 :: before allreduce fusion buffer :: -31676094.0
2023-01-07 08:08:48,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,470 > [DEBUG] 0 :: before allreduce fusion buffer :: -26.018714904785156
2023-01-07 08:08:48,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,473 > [DEBUG] 0 :: before allreduce fusion buffer :: -122802888.0
2023-01-07 08:08:48,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,476 > [DEBUG] 0 :: before allreduce fusion buffer :: -18044.884765625
2023-01-07 08:08:48,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,477 > [DEBUG] 0 :: before allreduce fusion buffer :: -18056.6328125
2023-01-07 08:08:48,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,479 > [DEBUG] 0 :: before allreduce fusion buffer :: -36184.9609375
2023-01-07 08:08:48,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,480 > [DEBUG] 0 :: before allreduce fusion buffer :: 57.632972717285156
2023-01-07 08:08:48,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,482 > [DEBUG] 0 :: before allreduce fusion buffer :: -238.94541931152344
2023-01-07 08:08:48,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,484 > [DEBUG] 0 :: before allreduce fusion buffer :: -55958980.0
2023-01-07 08:08:48,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,485 > [DEBUG] 0 :: before allreduce fusion buffer :: -144594.25
2023-01-07 08:08:48,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,487 > [DEBUG] 0 :: before allreduce fusion buffer :: -289525.96875
2023-01-07 08:08:48,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,488 > [DEBUG] 0 :: before allreduce fusion buffer :: -290210.96875
2023-01-07 08:08:48,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,490 > [DEBUG] 0 :: before allreduce fusion buffer :: -116730424.0
2023-01-07 08:08:48,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,492 > [DEBUG] 0 :: before allreduce fusion buffer :: -579555.3125
2023-01-07 08:08:48,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,493 > [DEBUG] 0 :: before allreduce fusion buffer :: 91.99457550048828
2023-01-07 08:08:48,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,495 > [DEBUG] 0 :: before allreduce fusion buffer :: -1758.2166748046875
2023-01-07 08:08:48,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,496 > [DEBUG] 0 :: before allreduce fusion buffer :: -235072384.0
2023-01-07 08:08:48,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,498 > [DEBUG] 0 :: before allreduce fusion buffer :: -2314410.5
2023-01-07 08:08:48,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,499 > [DEBUG] 0 :: before allreduce fusion buffer :: -289.13653564453125
2023-01-07 08:08:48,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,502 > [DEBUG] 0 :: before allreduce fusion buffer :: -4628830.5
2023-01-07 08:08:48,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,503 > [DEBUG] 0 :: before allreduce fusion buffer :: -4629405.5
2023-01-07 08:08:48,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,505 > [DEBUG] 0 :: before allreduce fusion buffer :: 93.01553344726562
2023-01-07 08:08:48,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,507 > [DEBUG] 0 :: before allreduce fusion buffer :: -4632062.0
2023-01-07 08:08:48,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,509 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8864774703979492
2023-01-07 08:08:48,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,510 > [DEBUG] 0 :: before allreduce fusion buffer :: -4631010.0
2023-01-07 08:08:48,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,512 > [DEBUG] 0 :: before allreduce fusion buffer :: -9260289.0
2023-01-07 08:08:48,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,513 > [DEBUG] 0 :: before allreduce fusion buffer :: -18524288.0
2023-01-07 08:08:48,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,515 > [DEBUG] 0 :: before allreduce fusion buffer :: -187.1916046142578
2023-01-07 08:08:48,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,516 > [DEBUG] 0 :: before allreduce fusion buffer :: -37049168.0
2023-01-07 08:08:48,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,518 > [DEBUG] 0 :: before allreduce fusion buffer :: -365.840087890625
2023-01-07 08:08:48,519 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,519 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,519 > [DEBUG] 0 :: before allreduce fusion buffer :: -37044416.0
2023-01-07 08:08:48,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,521 > [DEBUG] 0 :: before allreduce fusion buffer :: -74077296.0
2023-01-07 08:08:48,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,522 > [DEBUG] 0 :: before allreduce fusion buffer :: -148165328.0
2023-01-07 08:08:48,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,524 > [DEBUG] 0 :: before allreduce fusion buffer :: -1703.3433837890625
2023-01-07 08:08:48,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,525 > [DEBUG] 0 :: before allreduce fusion buffer :: -148171984.0
2023-01-07 08:08:48,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,527 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0685774087905884
2023-01-07 08:08:48,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,529 > [DEBUG] 0 :: before allreduce fusion buffer :: -296532320.0
2023-01-07 08:08:48,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,530 > [DEBUG] 0 :: before allreduce fusion buffer :: -593053696.0
2023-01-07 08:08:48,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,532 > [DEBUG] 0 :: before allreduce fusion buffer :: -1186130688.0
2023-01-07 08:08:48,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,533 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6155503988265991
2023-01-07 08:08:48,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,535 > [DEBUG] 0 :: before allreduce fusion buffer :: -1186144256.0
2023-01-07 08:08:48,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,536 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5611369609832764
2023-01-07 08:08:48,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,538 > [DEBUG] 0 :: before allreduce fusion buffer :: -2372210176.0
2023-01-07 08:08:48,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,539 > [DEBUG] 0 :: before allreduce fusion buffer :: -3568989952.0
2023-01-07 08:08:48,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,541 > [DEBUG] 0 :: before allreduce fusion buffer :: -8313485312.0
2023-01-07 08:08:48,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5779870748519897
2023-01-07 08:08:48,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,544 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,544 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,544 > [DEBUG] 0 :: before allreduce fusion buffer :: -8313480192.0
2023-01-07 08:08:48,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.354828119277954
2023-01-07 08:08:48,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,547 > [DEBUG] 0 :: before allreduce fusion buffer :: -16626656256.0
2023-01-07 08:08:48,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 2751.665771484375
2023-01-07 08:08:48,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,550 > [DEBUG] 0 :: before allreduce fusion buffer :: -50680.80859375
2023-01-07 08:08:48,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,551 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.687098979949951
2023-01-07 08:08:48,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,553 > [DEBUG] 0 :: before allreduce fusion buffer :: -33253390336.0
2023-01-07 08:08:48,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,554 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.03715503215789795
2023-01-07 08:08:48,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,556 > [DEBUG] 0 :: before allreduce fusion buffer :: -66507214848.0
2023-01-07 08:08:48,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,712 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.04241520166397095
2023-01-07 08:08:48,712 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,713 > [DEBUG] 0 :: before allreduce fusion buffer :: 1811528.75
2023-01-07 08:08:48,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,714 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.339533805847168
2023-01-07 08:08:48,715 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,715 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,715 > [DEBUG] 0 :: before allreduce fusion buffer :: -280498.34375
2023-01-07 08:08:48,716 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,716 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,717 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.500920295715332
2023-01-07 08:08:48,717 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,718 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,718 > [DEBUG] 0 :: before allreduce fusion buffer :: -1075337.0
2023-01-07 08:08:48,719 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,719 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,719 > [DEBUG] 0 :: before allreduce fusion buffer :: -27.87018585205078
2023-01-07 08:08:48,720 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,720 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,720 > [DEBUG] 0 :: before allreduce fusion buffer :: 2494066.5
2023-01-07 08:08:48,721 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,721 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,722 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.479363441467285
2023-01-07 08:08:48,722 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,722 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,723 > [DEBUG] 0 :: before allreduce fusion buffer :: 203571.5625
2023-01-07 08:08:48,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,724 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.785906195640564
2023-01-07 08:08:48,894 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,894 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,895 > [DEBUG] 0 :: before allreduce fusion buffer :: -336820.5
2023-01-07 08:08:48,896 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,896 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,896 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8593705892562866
2023-01-07 08:08:48,897 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,897 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,897 > [DEBUG] 0 :: before allreduce fusion buffer :: 3827745.0
2023-01-07 08:08:48,898 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,898 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,899 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.1361427307128906
2023-01-07 08:08:48,899 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,900 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,900 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:48,900 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:48,900 > [DEBUG] 0 :: before allreduce fusion buffer :: 1737115.0
2023-01-07 08:08:49,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,078 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,078 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.8560004234313965
2023-01-07 08:08:49,079 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,079 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,080 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.406585693359375
2023-01-07 08:08:49,081 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,081 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,081 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6649730205535889
2023-01-07 08:08:49,194 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,194 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,194 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.794246673583984
2023-01-07 08:08:49,195 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,196 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,196 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.408683776855469
2023-01-07 08:08:49,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,197 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,197 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,197 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.413315773010254
2023-01-07 08:08:49,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,199 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,199 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.14871001243591309
2023-01-07 08:08:49,200 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,200 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,200 > [DEBUG] 0 :: before allreduce fusion buffer :: 13.39293098449707
2023-01-07 08:08:49,201 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,201 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,201 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8347127437591553
2023-01-07 08:08:49,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,202 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.057124614715576
2023-01-07 08:08:49,204 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,204 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,204 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.980205535888672
2023-01-07 08:08:49,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,205 > [DEBUG] 0 :: before allreduce fusion buffer :: 17.758237838745117
2023-01-07 08:08:49,207 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,207 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,207 > [DEBUG] 0 :: before allreduce fusion buffer :: 17.951128005981445
2023-01-07 08:08:49,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,208 > [DEBUG] 0 :: before allreduce fusion buffer :: -433663.6875
2023-01-07 08:08:49,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,210 > [DEBUG] 0 :: before allreduce fusion buffer :: 1684.7459716796875
2023-01-07 08:08:49,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,211 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,211 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:08:49,212 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,212 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,213 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.5221924781799316
2023-01-07 08:08:49,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,214 > [DEBUG] 0 :: before allreduce fusion buffer :: 5435925.5
2023-01-07 08:08:49,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,215 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,216 > [DEBUG] 0 :: before allreduce fusion buffer :: -1062.43701171875
2023-01-07 08:08:49,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,217 > [DEBUG] 0 :: before allreduce fusion buffer :: 107551096.0
2023-01-07 08:08:49,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,219 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.834066390991211
2023-01-07 08:08:49,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,220 > [DEBUG] 0 :: before allreduce fusion buffer :: 26.07984161376953
2023-01-07 08:08:49,221 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,221 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,221 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.581807613372803
2023-01-07 08:08:49,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,222 > [DEBUG] 0 :: before allreduce fusion buffer :: -89.6507797241211
2023-01-07 08:08:49,224 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,224 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,224 > [DEBUG] 0 :: before allreduce fusion buffer :: 4608924160.0
2023-01-07 08:08:49,225 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,225 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,226 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.274459838867188
2023-01-07 08:08:49,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,228 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,228 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.536972999572754
2023-01-07 08:08:49,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 125.94822692871094
2023-01-07 08:08:49,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,230 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,230 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.17238426208496
2023-01-07 08:08:49,231 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,231 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,231 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,231 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,232 > [DEBUG] 0 :: before allreduce fusion buffer :: 711305854976.0
2023-01-07 08:08:49,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,233 > [DEBUG] 0 :: before allreduce fusion buffer :: -32.85968780517578
2023-01-07 08:08:49,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,235 > [DEBUG] 0 :: before allreduce fusion buffer :: -199.14056396484375
2023-01-07 08:08:49,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,236 > [DEBUG] 0 :: before allreduce fusion buffer :: 167.090087890625
2023-01-07 08:08:49,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:08:49,237 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:08:49,237 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.605628967285156
