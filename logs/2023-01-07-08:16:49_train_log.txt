2023-01-07 08:16:55,849 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:16:55,851 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:55,887 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -1.0251891613006592
2023-01-07 08:16:55,888 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:55,888 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 9408
2023-01-07 08:16:55,888 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:55,888 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:55,888 > [DEBUG] 0 :: scheduled task in conv1._dp_wrapped_module.flat_param_0 :: 0, FW, [AR, [[1, torch.Size([128]) 0 0], [4, torch.Size([36864]) 24374 24374]]]
2023-01-07 08:16:55,888 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,779 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:56,779 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,779 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:16:56,779 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,779 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,779 > [DEBUG] 0 :: scheduled task in bn1._dp_wrapped_module.flat_param_0 :: 1, FW, [AR, [[2, torch.Size([4096]) 0 0], [4, torch.Size([36864]) 29806 29806]]]
2023-01-07 08:16:56,780 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,781 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -22.87832260131836
2023-01-07 08:16:56,782 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,782 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:16:56,782 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,782 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,782 > [DEBUG] 0 :: scheduled task in layer1.0.conv1._dp_wrapped_module.flat_param_0 :: 2, FW, [AR, [[4, torch.Size([36864]) 29895 29895]]]
2023-01-07 08:16:56,782 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,783 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:56,783 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,784 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:16:56,784 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,784 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,784 > [DEBUG] 0 :: scheduled task in layer1.0.bn1._dp_wrapped_module.flat_param_0 :: 3, FW, [AR, [[4, torch.Size([36864]) 34135 34135]]]
2023-01-07 08:16:56,784 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,785 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: -7.09437370300293
2023-01-07 08:16:56,785 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,785 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:16:56,785 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,785 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,786 > [DEBUG] 0 :: scheduled task in layer1.0.conv2._dp_wrapped_module.flat_param_0 :: 4, FW, [AR, [[5, torch.Size([128]) 0 0], [6, torch.Size([16384]) 0 0], [18, torch.Size([36864]) 16953 16953]]]
2023-01-07 08:16:56,786 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,822 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:56,822 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,823 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:16:56,823 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,823 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,823 > [DEBUG] 0 :: scheduled task in layer1.0.bn2._dp_wrapped_module.flat_param_0 :: 5, FW, [AR, [[18, torch.Size([36864]) 19948 19948]]]
2023-01-07 08:16:56,823 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,824 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: -3.2959747314453125
2023-01-07 08:16:56,824 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,825 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:16:56,825 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,825 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,825 > [DEBUG] 0 :: scheduled task in layer1.0.conv3._dp_wrapped_module.flat_param_0 :: 6, FW, [AR, [[7, torch.Size([512]) 0 0], [10, torch.Size([16384]) 5999 5999]]]
2023-01-07 08:16:56,825 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,826 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,826 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,826 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,826 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,827 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,827 > [DEBUG] 0 :: scheduled task in layer1.0.bn3._dp_wrapped_module.flat_param_0 :: 7, FW, [AR, [[12, torch.Size([36864]) 4826 4826]]]
2023-01-07 08:16:56,827 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,828 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 0.6738348007202148
2023-01-07 08:16:56,828 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,828 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:16:56,828 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,828 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,828 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.0._dp_wrapped_module.flat_param_0 :: 8, FW, [AR, [[12, torch.Size([36864]) 9052 9052]]]
2023-01-07 08:16:56,828 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,829 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,829 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,830 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,830 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,830 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,830 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.1._dp_wrapped_module.flat_param_0 :: 9, FW, [AR, [[12, torch.Size([36864]) 13245 13245]]]
2023-01-07 08:16:56,830 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,831 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 12.357175827026367
2023-01-07 08:16:56,831 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,831 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:16:56,831 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,831 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,831 > [DEBUG] 0 :: scheduled task in layer1.1.conv1._dp_wrapped_module.flat_param_0 :: 10, FW, [AR, [[11, torch.Size([128]) 0 0], [12, torch.Size([36864]) 15961 15961]]]
2023-01-07 08:16:56,832 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,832 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:56,833 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,833 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:16:56,833 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,833 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,833 > [DEBUG] 0 :: scheduled task in layer1.1.bn1._dp_wrapped_module.flat_param_0 :: 11, FW, [AR, [[12, torch.Size([36864]) 35400 35400], [24, torch.Size([147456]) 133638 133638]]]
2023-01-07 08:16:56,833 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,834 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 2.9115123748779297
2023-01-07 08:16:56,834 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,835 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:16:56,835 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,835 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,835 > [DEBUG] 0 :: scheduled task in layer1.1.conv2._dp_wrapped_module.flat_param_0 :: 12, FW, [AR, [[13, torch.Size([128]) 0 0], [14, torch.Size([16384]) 5438 5438]]]
2023-01-07 08:16:56,835 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,836 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:56,836 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,836 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:16:56,836 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,836 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,836 > [DEBUG] 0 :: scheduled task in layer1.1.bn2._dp_wrapped_module.flat_param_0 :: 13, FW, [AR, [[18, torch.Size([36864]) 22600 22600]]]
2023-01-07 08:16:56,837 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,838 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 9.54641342163086
2023-01-07 08:16:56,838 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,838 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:16:56,838 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,838 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,838 > [DEBUG] 0 :: scheduled task in layer1.1.conv3._dp_wrapped_module.flat_param_0 :: 14, FW, [AR, [[16, torch.Size([16384]) 8376 8376]]]
2023-01-07 08:16:56,838 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,839 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,839 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,840 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,840 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,840 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,840 > [DEBUG] 0 :: scheduled task in layer1.1.bn3._dp_wrapped_module.flat_param_0 :: 15, FW, [AR, [[16, torch.Size([16384]) 15379 15379], [18, torch.Size([36864]) 26760 26760]]]
2023-01-07 08:16:56,840 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,841 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 16.164283752441406
2023-01-07 08:16:56,841 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,841 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:16:56,842 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,842 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,842 > [DEBUG] 0 :: scheduled task in layer1.2.conv1._dp_wrapped_module.flat_param_0 :: 16, FW, [AR, [[18, torch.Size([36864]) 29950 29950]]]
2023-01-07 08:16:56,842 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,843 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:56,843 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,843 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:16:56,843 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,843 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,843 > [DEBUG] 0 :: scheduled task in layer1.2.bn1._dp_wrapped_module.flat_param_0 :: 17, FW, [AR, [[18, torch.Size([36864]) 34171 34171]]]
2023-01-07 08:16:56,843 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,844 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: -8.160484313964844
2023-01-07 08:16:56,844 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,845 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:16:56,845 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,845 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,845 > [DEBUG] 0 :: scheduled task in layer1.2.conv2._dp_wrapped_module.flat_param_0 :: 18, FW, [AR, [[19, torch.Size([128]) 0 0], [20, torch.Size([16384]) 0 0], [22, torch.Size([32768]) 14465 14465]]]
2023-01-07 08:16:56,845 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,846 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:56,846 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,846 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:16:56,846 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,846 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,846 > [DEBUG] 0 :: scheduled task in layer1.2.bn2._dp_wrapped_module.flat_param_0 :: 19, FW, [AR, [[24, torch.Size([147456]) 134884 134884]]]
2023-01-07 08:16:56,847 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,848 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: -3.3462157249450684
2023-01-07 08:16:56,848 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,848 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:16:56,848 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,848 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,848 > [DEBUG] 0 :: scheduled task in layer1.2.conv3._dp_wrapped_module.flat_param_0 :: 20, FW, [AR, [[22, torch.Size([32768]) 24699 24699]]]
2023-01-07 08:16:56,848 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,849 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,849 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,850 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,850 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,850 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,850 > [DEBUG] 0 :: scheduled task in layer1.2.bn3._dp_wrapped_module.flat_param_0 :: 21, FW, [AR, [[24, torch.Size([147456]) 137525 137525]]]
2023-01-07 08:16:56,850 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,851 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 17.942874908447266
2023-01-07 08:16:56,851 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,851 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 32768
2023-01-07 08:16:56,852 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,852 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,852 > [DEBUG] 0 :: scheduled task in layer2.0.conv1._dp_wrapped_module.flat_param_0 :: 22, FW, [AR, [[24, torch.Size([147456]) 140496 140496]]]
2023-01-07 08:16:56,852 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,853 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,853 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,853 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,853 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,853 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,853 > [DEBUG] 0 :: scheduled task in layer2.0.bn1._dp_wrapped_module.flat_param_0 :: 23, FW, [AR, [[24, torch.Size([147456]) 144875 144875]]]
2023-01-07 08:16:56,853 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,855 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 5.741408348083496
2023-01-07 08:16:56,855 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,855 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:16:56,855 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,855 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,855 > [DEBUG] 0 :: scheduled task in layer2.0.conv2._dp_wrapped_module.flat_param_0 :: 24, FW, [AR, [[25, torch.Size([256]) 0 0], [26, torch.Size([65536]) 55354 55354]]]
2023-01-07 08:16:56,855 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,856 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,857 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,857 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,857 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,857 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,857 > [DEBUG] 0 :: scheduled task in layer2.0.bn2._dp_wrapped_module.flat_param_0 :: 25, FW, [AR, [[26, torch.Size([65536]) 62932 62932]]]
2023-01-07 08:16:56,857 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,858 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: -0.20096635818481445
2023-01-07 08:16:56,858 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,859 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:16:56,859 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,859 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,859 > [DEBUG] 0 :: scheduled task in layer2.0.conv3._dp_wrapped_module.flat_param_0 :: 26, FW, [AR, [[27, torch.Size([1024]) 0 0], [28, torch.Size([131072]) 121409 121409]]]
2023-01-07 08:16:56,859 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,860 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,860 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,860 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,860 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,860 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,860 > [DEBUG] 0 :: scheduled task in layer2.0.bn3._dp_wrapped_module.flat_param_0 :: 27, FW, [AR, [[28, torch.Size([131072]) 128101 128101]]]
2023-01-07 08:16:56,860 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,861 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 6.827529430389404
2023-01-07 08:16:56,862 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,862 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 08:16:56,862 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,862 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,862 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.0._dp_wrapped_module.flat_param_0 :: 28, FW, [AR, [[30, torch.Size([65536]) 58518 58518]]]
2023-01-07 08:16:56,862 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,863 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,863 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,864 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,864 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,864 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,864 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.1._dp_wrapped_module.flat_param_0 :: 29, FW, [AR, [[30, torch.Size([65536]) 62926 62926]]]
2023-01-07 08:16:56,864 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,865 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 46.608055114746094
2023-01-07 08:16:56,865 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,865 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:16:56,866 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,866 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,866 > [DEBUG] 0 :: scheduled task in layer2.1.conv1._dp_wrapped_module.flat_param_0 :: 30, FW, [AR, [[31, torch.Size([256]) 0 0], [32, torch.Size([147456]) 137276 137276]]]
2023-01-07 08:16:56,866 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,867 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,867 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,867 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,867 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,867 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,867 > [DEBUG] 0 :: scheduled task in layer2.1.bn1._dp_wrapped_module.flat_param_0 :: 31, FW, [AR, [[32, torch.Size([147456]) 144843 144843]]]
2023-01-07 08:16:56,867 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,868 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 7.697781562805176
2023-01-07 08:16:56,869 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,869 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:16:56,869 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,869 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,869 > [DEBUG] 0 :: scheduled task in layer2.1.conv2._dp_wrapped_module.flat_param_0 :: 32, FW, [AR, [[33, torch.Size([256]) 0 0], [34, torch.Size([65536]) 55010 55010]]]
2023-01-07 08:16:56,869 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,870 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,870 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,871 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,871 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,871 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,871 > [DEBUG] 0 :: scheduled task in layer2.1.bn2._dp_wrapped_module.flat_param_0 :: 33, FW, [AR, [[34, torch.Size([65536]) 62519 62519]]]
2023-01-07 08:16:56,871 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,872 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -11.640456199645996
2023-01-07 08:16:56,872 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,872 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:16:56,872 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,873 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,873 > [DEBUG] 0 :: scheduled task in layer2.1.conv3._dp_wrapped_module.flat_param_0 :: 34, FW, [AR, [[36, torch.Size([65536]) 58337 58337]]]
2023-01-07 08:16:56,873 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,874 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,874 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,874 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,874 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,874 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,874 > [DEBUG] 0 :: scheduled task in layer2.1.bn3._dp_wrapped_module.flat_param_0 :: 35, FW, [AR, [[36, torch.Size([65536]) 62837 62837]]]
2023-01-07 08:16:56,874 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,875 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -34.238990783691406
2023-01-07 08:16:56,876 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,876 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:16:56,876 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,876 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,876 > [DEBUG] 0 :: scheduled task in layer2.2.conv1._dp_wrapped_module.flat_param_0 :: 36, FW, [AR, [[37, torch.Size([256]) 0 0], [38, torch.Size([147456]) 136838 136838]]]
2023-01-07 08:16:56,876 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,877 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,877 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,877 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,877 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,878 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,878 > [DEBUG] 0 :: scheduled task in layer2.2.bn1._dp_wrapped_module.flat_param_0 :: 37, FW, [AR, [[38, torch.Size([147456]) 144611 144611]]]
2023-01-07 08:16:56,878 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,879 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -0.9214951992034912
2023-01-07 08:16:56,879 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,879 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:16:56,879 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,879 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,879 > [DEBUG] 0 :: scheduled task in layer2.2.conv2._dp_wrapped_module.flat_param_0 :: 38, FW, [AR, [[39, torch.Size([256]) 0 0], [40, torch.Size([65536]) 54391 54391]]]
2023-01-07 08:16:56,880 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,880 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,881 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,881 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,881 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,881 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,881 > [DEBUG] 0 :: scheduled task in layer2.2.bn2._dp_wrapped_module.flat_param_0 :: 39, FW, [AR, [[40, torch.Size([65536]) 62211 62211]]]
2023-01-07 08:16:56,881 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,882 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: 1.3654184341430664
2023-01-07 08:16:56,882 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,882 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:16:56,883 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,883 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,883 > [DEBUG] 0 :: scheduled task in layer2.2.conv3._dp_wrapped_module.flat_param_0 :: 40, FW, [AR, [[41, torch.Size([1024]) 0 0], [42, torch.Size([65536]) 58457 58457]]]
2023-01-07 08:16:56,883 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,884 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,884 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,884 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,884 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,884 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,884 > [DEBUG] 0 :: scheduled task in layer2.2.bn3._dp_wrapped_module.flat_param_0 :: 41, FW, [AR, [[42, torch.Size([65536]) 62434 62434]]]
2023-01-07 08:16:56,884 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,885 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -0.0301971435546875
2023-01-07 08:16:56,886 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,886 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:16:56,886 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,886 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,886 > [DEBUG] 0 :: scheduled task in layer2.3.conv1._dp_wrapped_module.flat_param_0 :: 42, FW, [AR, [[43, torch.Size([256]) 0 0], [44, torch.Size([147456]) 136250 136250]]]
2023-01-07 08:16:56,886 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,887 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,887 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,887 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,887 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,888 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,888 > [DEBUG] 0 :: scheduled task in layer2.3.bn1._dp_wrapped_module.flat_param_0 :: 43, FW, [AR, [[44, torch.Size([147456]) 144343 144343]]]
2023-01-07 08:16:56,888 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,889 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 7.608846664428711
2023-01-07 08:16:56,889 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,889 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:16:56,889 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,889 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,889 > [DEBUG] 0 :: scheduled task in layer2.3.conv2._dp_wrapped_module.flat_param_0 :: 44, FW, [AR, [[45, torch.Size([256]) 0 0], [46, torch.Size([65536]) 53786 53786]]]
2023-01-07 08:16:56,890 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,890 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:56,891 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,891 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:16:56,891 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,891 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,891 > [DEBUG] 0 :: scheduled task in layer2.3.bn2._dp_wrapped_module.flat_param_0 :: 45, FW, [AR, [[46, torch.Size([65536]) 62012 62012]]]
2023-01-07 08:16:56,891 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,892 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 0.47893810272216797
2023-01-07 08:16:56,892 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,893 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:16:56,893 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,893 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,893 > [DEBUG] 0 :: scheduled task in layer2.3.conv3._dp_wrapped_module.flat_param_0 :: 46, FW, [AR, [[47, torch.Size([1024]) 0 0], [48, torch.Size([131072]) 123183 123183]]]
2023-01-07 08:16:56,893 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,894 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,894 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,894 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,894 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,894 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,894 > [DEBUG] 0 :: scheduled task in layer2.3.bn3._dp_wrapped_module.flat_param_0 :: 47, FW, [AR, [[48, torch.Size([131072]) 127567 127567]]]
2023-01-07 08:16:56,894 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,896 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 37.91153335571289
2023-01-07 08:16:56,896 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,896 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 08:16:56,896 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,896 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,896 > [DEBUG] 0 :: scheduled task in layer3.0.conv1._dp_wrapped_module.flat_param_0 :: 48, FW, [AR, [[49, torch.Size([512]) 0 0], [50, torch.Size([589824]) 577505 577505]]]
2023-01-07 08:16:56,896 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,897 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,897 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,898 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,898 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,898 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,898 > [DEBUG] 0 :: scheduled task in layer3.0.bn1._dp_wrapped_module.flat_param_0 :: 49, FW, [AR, [[50, torch.Size([589824]) 586102 586102]]]
2023-01-07 08:16:56,898 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,899 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: 14.272685050964355
2023-01-07 08:16:56,899 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,900 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:16:56,900 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,900 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,900 > [DEBUG] 0 :: scheduled task in layer3.0.conv2._dp_wrapped_module.flat_param_0 :: 50, FW, [AR, [[52, torch.Size([262144]) 248915 248915]]]
2023-01-07 08:16:56,900 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,901 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,901 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,901 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,901 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,901 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,901 > [DEBUG] 0 :: scheduled task in layer3.0.bn2._dp_wrapped_module.flat_param_0 :: 51, FW, [AR, [[52, torch.Size([262144]) 258136 258136]]]
2023-01-07 08:16:56,902 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,903 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -26.249996185302734
2023-01-07 08:16:56,903 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,903 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,903 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,903 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,903 > [DEBUG] 0 :: scheduled task in layer3.0.conv3._dp_wrapped_module.flat_param_0 :: 52, FW, [AR, [[54, torch.Size([524288]) 514056 514056]]]
2023-01-07 08:16:56,903 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,904 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:16:56,904 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,905 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:16:56,905 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,905 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,905 > [DEBUG] 0 :: scheduled task in layer3.0.bn3._dp_wrapped_module.flat_param_0 :: 53, FW, [AR, [[54, torch.Size([524288]) 520083 520083]]]
2023-01-07 08:16:56,905 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,906 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -52.69746398925781
2023-01-07 08:16:56,906 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,906 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 08:16:56,906 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,906 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,906 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.0._dp_wrapped_module.flat_param_0 :: 54, FW, [AR, [[56, torch.Size([262144]) 251612 251612]]]
2023-01-07 08:16:56,906 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,907 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:16:56,908 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,908 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:16:56,908 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,908 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,908 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.1._dp_wrapped_module.flat_param_0 :: 55, FW, [AR, [[56, torch.Size([262144]) 258055 258055]]]
2023-01-07 08:16:56,908 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,909 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 11.535799026489258
2023-01-07 08:16:56,909 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,910 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,910 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,910 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,910 > [DEBUG] 0 :: scheduled task in layer3.1.conv1._dp_wrapped_module.flat_param_0 :: 56, FW, [AR, [[57, torch.Size([512]) 0 0], [58, torch.Size([589824]) 575870 575870]]]
2023-01-07 08:16:56,910 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,911 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,911 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,911 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,911 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,911 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,911 > [DEBUG] 0 :: scheduled task in layer3.1.bn1._dp_wrapped_module.flat_param_0 :: 57, FW, [AR, [[58, torch.Size([589824]) 585646 585646]]]
2023-01-07 08:16:56,912 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,913 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -6.955451965332031
2023-01-07 08:16:56,913 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,913 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:16:56,913 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,913 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,913 > [DEBUG] 0 :: scheduled task in layer3.1.conv2._dp_wrapped_module.flat_param_0 :: 58, FW, [AR, [[60, torch.Size([262144]) 250298 250298]]]
2023-01-07 08:16:56,913 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,914 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,915 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,915 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,915 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,915 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,915 > [DEBUG] 0 :: scheduled task in layer3.1.bn2._dp_wrapped_module.flat_param_0 :: 59, FW, [AR, [[60, torch.Size([262144]) 257996 257996]]]
2023-01-07 08:16:56,915 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,916 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: 18.500093460083008
2023-01-07 08:16:56,916 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,917 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,917 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,917 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,917 > [DEBUG] 0 :: scheduled task in layer3.1.conv3._dp_wrapped_module.flat_param_0 :: 60, FW, [AR, [[62, torch.Size([262144]) 251486 251486]]]
2023-01-07 08:16:56,917 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,918 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:16:56,918 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,918 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:16:56,918 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,918 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,918 > [DEBUG] 0 :: scheduled task in layer3.1.bn3._dp_wrapped_module.flat_param_0 :: 61, FW, [AR, [[62, torch.Size([262144]) 257960 257960]]]
2023-01-07 08:16:56,918 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,919 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 19.473270416259766
2023-01-07 08:16:56,920 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,920 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,920 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,920 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,920 > [DEBUG] 0 :: scheduled task in layer3.2.conv1._dp_wrapped_module.flat_param_0 :: 62, FW, [AR, [[64, torch.Size([589824]) 578797 578797]]]
2023-01-07 08:16:56,920 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,921 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,921 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,921 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,921 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,922 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,922 > [DEBUG] 0 :: scheduled task in layer3.2.bn1._dp_wrapped_module.flat_param_0 :: 63, FW, [AR, [[64, torch.Size([589824]) 585633 585633]]]
2023-01-07 08:16:56,922 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,923 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: -52.85980987548828
2023-01-07 08:16:56,923 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,923 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:16:56,923 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,923 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,923 > [DEBUG] 0 :: scheduled task in layer3.2.conv2._dp_wrapped_module.flat_param_0 :: 64, FW, [AR, [[66, torch.Size([262144]) 250265 250265]]]
2023-01-07 08:16:56,924 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,924 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,924 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,925 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,925 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,925 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,925 > [DEBUG] 0 :: scheduled task in layer3.2.bn2._dp_wrapped_module.flat_param_0 :: 65, FW, [AR, [[66, torch.Size([262144]) 257992 257992]]]
2023-01-07 08:16:56,925 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,926 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -0.31838464736938477
2023-01-07 08:16:56,926 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,926 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,927 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,927 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,927 > [DEBUG] 0 :: scheduled task in layer3.2.conv3._dp_wrapped_module.flat_param_0 :: 66, FW, [AR, [[68, torch.Size([262144]) 251489 251489]]]
2023-01-07 08:16:56,927 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,928 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:16:56,928 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,928 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:16:56,928 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,928 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,928 > [DEBUG] 0 :: scheduled task in layer3.2.bn3._dp_wrapped_module.flat_param_0 :: 67, FW, [AR, [[68, torch.Size([262144]) 257975 257975]]]
2023-01-07 08:16:56,928 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,929 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: -12.786895751953125
2023-01-07 08:16:56,929 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,930 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,930 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,930 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,930 > [DEBUG] 0 :: scheduled task in layer3.3.conv1._dp_wrapped_module.flat_param_0 :: 68, FW, [AR, [[70, torch.Size([589824]) 578834 578834]]]
2023-01-07 08:16:56,930 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,931 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,931 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,931 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,931 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,932 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,932 > [DEBUG] 0 :: scheduled task in layer3.3.bn1._dp_wrapped_module.flat_param_0 :: 69, FW, [AR, [[70, torch.Size([589824]) 585643 585643]]]
2023-01-07 08:16:56,932 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,933 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 37.10218048095703
2023-01-07 08:16:56,933 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,933 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:16:56,933 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,933 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,933 > [DEBUG] 0 :: scheduled task in layer3.3.conv2._dp_wrapped_module.flat_param_0 :: 70, FW, [AR, [[72, torch.Size([262144]) 250221 250221]]]
2023-01-07 08:16:56,933 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,934 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,934 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,935 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,935 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,935 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,935 > [DEBUG] 0 :: scheduled task in layer3.3.bn2._dp_wrapped_module.flat_param_0 :: 71, FW, [AR, [[72, torch.Size([262144]) 257983 257983]]]
2023-01-07 08:16:56,935 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,936 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 22.78554916381836
2023-01-07 08:16:56,936 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,937 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,937 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,937 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,937 > [DEBUG] 0 :: scheduled task in layer3.3.conv3._dp_wrapped_module.flat_param_0 :: 72, FW, [AR, [[74, torch.Size([262144]) 251508 251508]]]
2023-01-07 08:16:56,937 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,938 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:16:56,938 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,938 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:16:56,938 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,938 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,938 > [DEBUG] 0 :: scheduled task in layer3.3.bn3._dp_wrapped_module.flat_param_0 :: 73, FW, [AR, [[74, torch.Size([262144]) 257957 257957]]]
2023-01-07 08:16:56,938 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,939 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -34.31098937988281
2023-01-07 08:16:56,939 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,940 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,940 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,940 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,940 > [DEBUG] 0 :: scheduled task in layer3.4.conv1._dp_wrapped_module.flat_param_0 :: 74, FW, [AR, [[76, torch.Size([589824]) 578817 578817]]]
2023-01-07 08:16:56,940 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,941 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,941 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,941 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,941 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,941 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,941 > [DEBUG] 0 :: scheduled task in layer3.4.bn1._dp_wrapped_module.flat_param_0 :: 75, FW, [AR, [[76, torch.Size([589824]) 585626 585626]]]
2023-01-07 08:16:56,942 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,943 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 15.409195899963379
2023-01-07 08:16:56,943 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,943 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:16:56,943 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,943 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,943 > [DEBUG] 0 :: scheduled task in layer3.4.conv2._dp_wrapped_module.flat_param_0 :: 76, FW, [AR, [[78, torch.Size([262144]) 250146 250146]]]
2023-01-07 08:16:56,943 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,944 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,944 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,945 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,945 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,945 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,945 > [DEBUG] 0 :: scheduled task in layer3.4.bn2._dp_wrapped_module.flat_param_0 :: 77, FW, [AR, [[78, torch.Size([262144]) 258090 258090]]]
2023-01-07 08:16:56,945 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,946 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: 35.191200256347656
2023-01-07 08:16:56,946 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,946 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,946 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,946 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,946 > [DEBUG] 0 :: scheduled task in layer3.4.conv3._dp_wrapped_module.flat_param_0 :: 78, FW, [AR, [[80, torch.Size([262144]) 252751 252751]]]
2023-01-07 08:16:56,947 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,947 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:16:56,948 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,948 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:16:56,948 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,948 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,948 > [DEBUG] 0 :: scheduled task in layer3.4.bn3._dp_wrapped_module.flat_param_0 :: 79, FW, [AR, [[80, torch.Size([262144]) 258004 258004]]]
2023-01-07 08:16:56,948 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,949 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: 41.722801208496094
2023-01-07 08:16:56,949 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,950 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,950 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,950 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,950 > [DEBUG] 0 :: scheduled task in layer3.5.conv1._dp_wrapped_module.flat_param_0 :: 80, FW, [AR, [[82, torch.Size([589824]) 579303 579303]]]
2023-01-07 08:16:56,950 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,951 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,951 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,951 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,951 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,951 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,951 > [DEBUG] 0 :: scheduled task in layer3.5.bn1._dp_wrapped_module.flat_param_0 :: 81, FW, [AR, [[82, torch.Size([589824]) 585666 585666]]]
2023-01-07 08:16:56,951 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,953 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -25.505298614501953
2023-01-07 08:16:56,953 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,953 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:16:56,953 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,953 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,953 > [DEBUG] 0 :: scheduled task in layer3.5.conv2._dp_wrapped_module.flat_param_0 :: 82, FW, [AR, [[84, torch.Size([262144]) 249049 249049]]]
2023-01-07 08:16:56,953 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,954 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:56,954 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,954 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:16:56,955 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,955 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,955 > [DEBUG] 0 :: scheduled task in layer3.5.bn2._dp_wrapped_module.flat_param_0 :: 83, FW, [AR, [[84, torch.Size([262144]) 258029 258029]]]
2023-01-07 08:16:56,955 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,956 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: 9.816974639892578
2023-01-07 08:16:56,956 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,956 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:16:56,956 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,956 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,956 > [DEBUG] 0 :: scheduled task in layer3.5.conv3._dp_wrapped_module.flat_param_0 :: 84, FW, [AR, [[86, torch.Size([524288]) 513996 513996]]]
2023-01-07 08:16:56,956 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,957 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:16:56,957 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,958 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:16:56,958 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,958 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,958 > [DEBUG] 0 :: scheduled task in layer3.5.bn3._dp_wrapped_module.flat_param_0 :: 85, FW, [AR, [[86, torch.Size([524288]) 520257 520257]]]
2023-01-07 08:16:56,958 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,959 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -9.676406860351562
2023-01-07 08:16:56,959 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,960 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 08:16:56,960 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,960 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,960 > [DEBUG] 0 :: scheduled task in layer4.0.conv1._dp_wrapped_module.flat_param_0 :: 86, FW, [AR, [[88, torch.Size([2359296]) 2348986 2348986]]]
2023-01-07 08:16:56,960 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,961 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,961 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,961 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,961 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,961 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,961 > [DEBUG] 0 :: scheduled task in layer4.0.bn1._dp_wrapped_module.flat_param_0 :: 87, FW, [AR, [[88, torch.Size([2359296]) 2355264 2355264]]]
2023-01-07 08:16:56,961 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,962 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: 22.204957962036133
2023-01-07 08:16:56,963 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,963 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:16:56,963 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,963 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,963 > [DEBUG] 0 :: scheduled task in layer4.0.conv2._dp_wrapped_module.flat_param_0 :: 88, FW, [AR, [[90, torch.Size([1048576]) 1038739 1038739]]]
2023-01-07 08:16:56,963 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,964 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,964 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,965 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,965 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,965 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,965 > [DEBUG] 0 :: scheduled task in layer4.0.bn2._dp_wrapped_module.flat_param_0 :: 89, FW, [AR, [[90, torch.Size([1048576]) 1044678 1044678]]]
2023-01-07 08:16:56,965 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,966 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -42.1867561340332
2023-01-07 08:16:56,966 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,966 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:16:56,966 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,966 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,966 > [DEBUG] 0 :: scheduled task in layer4.0.conv3._dp_wrapped_module.flat_param_0 :: 90, FW, [AR, [[92, torch.Size([2097152]) 2086529 2086529]]]
2023-01-07 08:16:56,967 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,968 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:16:56,968 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,968 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:16:56,968 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,968 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,968 > [DEBUG] 0 :: scheduled task in layer4.0.bn3._dp_wrapped_module.flat_param_0 :: 91, FW, [AR, [[92, torch.Size([2097152]) 2093335 2093335]]]
2023-01-07 08:16:56,968 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,969 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 16.227272033691406
2023-01-07 08:16:56,969 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,969 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2097152
2023-01-07 08:16:56,969 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,970 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,970 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.0._dp_wrapped_module.flat_param_0 :: 92, FW, [AR, [[94, torch.Size([1048576]) 1039183 1039183]]]
2023-01-07 08:16:56,970 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,971 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:16:56,971 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,971 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:16:56,971 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,971 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,971 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.1._dp_wrapped_module.flat_param_0 :: 93, FW, [AR, [[94, torch.Size([1048576]) 1044932 1044932]]]
2023-01-07 08:16:56,971 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,972 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -13.058965682983398
2023-01-07 08:16:56,972 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,973 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:16:56,973 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,973 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,973 > [DEBUG] 0 :: scheduled task in layer4.1.conv1._dp_wrapped_module.flat_param_0 :: 94, FW, [AR, [[96, torch.Size([2359296]) 2350332 2350332]]]
2023-01-07 08:16:56,973 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,974 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,974 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,974 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,974 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,974 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,975 > [DEBUG] 0 :: scheduled task in layer4.1.bn1._dp_wrapped_module.flat_param_0 :: 95, FW, [AR, [[96, torch.Size([2359296]) 2355789 2355789]]]
2023-01-07 08:16:56,975 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,976 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 28.49540138244629
2023-01-07 08:16:56,976 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,976 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:16:56,976 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,976 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,976 > [DEBUG] 0 :: scheduled task in layer4.1.conv2._dp_wrapped_module.flat_param_0 :: 96, FW, [AR, [[98, torch.Size([1048576]) 1038824 1038824]]]
2023-01-07 08:16:56,976 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,977 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,978 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,978 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,978 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,978 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,978 > [DEBUG] 0 :: scheduled task in layer4.1.bn2._dp_wrapped_module.flat_param_0 :: 97, FW, [AR, [[98, torch.Size([1048576]) 1045258 1045258]]]
2023-01-07 08:16:56,978 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,979 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -24.01067543029785
2023-01-07 08:16:56,979 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,980 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:16:56,980 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,980 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,980 > [DEBUG] 0 :: scheduled task in layer4.1.conv3._dp_wrapped_module.flat_param_0 :: 98, FW, [AR, [[100, torch.Size([1048576]) 1041045 1041045]]]
2023-01-07 08:16:56,980 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,981 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:16:56,981 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,981 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:16:56,981 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,981 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,981 > [DEBUG] 0 :: scheduled task in layer4.1.bn3._dp_wrapped_module.flat_param_0 :: 99, FW, [AR, [[100, torch.Size([1048576]) 1045245 1045245]]]
2023-01-07 08:16:56,981 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,982 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -74.64981842041016
2023-01-07 08:16:56,983 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,983 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:16:56,983 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,983 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,983 > [DEBUG] 0 :: scheduled task in layer4.2.conv1._dp_wrapped_module.flat_param_0 :: 100, FW, [AR, [[102, torch.Size([2359296]) 2351012 2351012]]]
2023-01-07 08:16:56,983 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,984 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,984 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,984 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,984 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,984 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,985 > [DEBUG] 0 :: scheduled task in layer4.2.bn1._dp_wrapped_module.flat_param_0 :: 101, FW, [AR, [[102, torch.Size([2359296]) 2356170 2356170]]]
2023-01-07 08:16:56,985 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,986 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 2.462071418762207
2023-01-07 08:16:56,986 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,986 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:16:56,986 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,986 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,986 > [DEBUG] 0 :: scheduled task in layer4.2.conv2._dp_wrapped_module.flat_param_0 :: 102, FW, [AR, [[104, torch.Size([1048576]) 1040523 1040523]]]
2023-01-07 08:16:56,986 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,987 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:56,987 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,988 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:16:56,988 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,988 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,988 > [DEBUG] 0 :: scheduled task in layer4.2.bn2._dp_wrapped_module.flat_param_0 :: 103, FW, [AR, [[104, torch.Size([1048576]) 1045407 1045407]]]
2023-01-07 08:16:56,988 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,989 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 4.99153470993042
2023-01-07 08:16:56,989 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,989 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:16:56,989 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,990 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,990 > [DEBUG] 0 :: scheduled task in layer4.2.conv3._dp_wrapped_module.flat_param_0 :: 104, FW, [AR, [[106, torch.Size([2049000]) 2039302 2039302]]]
2023-01-07 08:16:56,990 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,990 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:16:56,991 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,991 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:16:56,991 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,991 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,991 > [DEBUG] 0 :: scheduled task in layer4.2.bn3._dp_wrapped_module.flat_param_0 :: 105, FW, [AR, [[106, torch.Size([2049000]) 2045884 2045884]]]
2023-01-07 08:16:56,991 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,993 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: 28.895294189453125
2023-01-07 08:16:56,993 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:56,993 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2049000
2023-01-07 08:16:56,993 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:56,993 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:16:56,993 > [DEBUG] 0 :: scheduled task in fc._dp_wrapped_module.flat_param_0 :: No scheduled
2023-01-07 08:16:56,994 > [DEBUG] 0 :: 7.57951021194458
2023-01-07 08:16:56,999 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,000 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,000 > [DEBUG] 0 :: before allreduce fusion buffer :: -355.8268127441406
2023-01-07 08:16:57,004 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,004 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,004 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,005 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,005 > [DEBUG] 0 :: before allreduce fusion buffer :: -344.6435241699219
2023-01-07 08:16:57,018 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,018 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,018 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.21825027465820312
2023-01-07 08:16:57,019 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,019 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,019 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,019 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,019 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0406112670898438
2023-01-07 08:16:57,022 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,022 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,022 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8194690346717834
2023-01-07 08:16:57,023 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,023 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,023 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,023 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,024 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.150923252105713
2023-01-07 08:16:57,025 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,025 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,026 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5269677042961121
2023-01-07 08:16:57,026 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,027 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,027 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,027 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,027 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6662735939025879
2023-01-07 08:16:57,029 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,029 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,030 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.24962745606899261
2023-01-07 08:16:57,030 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,031 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,031 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,031 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,031 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.442797899246216
2023-01-07 08:16:57,033 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,033 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,033 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6396636962890625
2023-01-07 08:16:57,034 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,034 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,034 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,034 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,034 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6201140284538269
2023-01-07 08:16:57,036 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,036 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,036 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3996770679950714
2023-01-07 08:16:57,037 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,037 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,037 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,037 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,038 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8748635053634644
2023-01-07 08:16:57,039 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,040 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,040 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.2989799976348877
2023-01-07 08:16:57,041 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,041 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,041 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,041 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,041 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9043755531311035
2023-01-07 08:16:57,043 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,043 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,043 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9057511687278748
2023-01-07 08:16:57,044 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,044 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,044 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,044 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,044 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.747926235198975
2023-01-07 08:16:57,046 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,047 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,047 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1323285102844238
2023-01-07 08:16:57,048 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,048 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,048 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,048 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,048 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8311678171157837
2023-01-07 08:16:57,050 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,050 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,050 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2002406120300293
2023-01-07 08:16:57,051 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,052 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,052 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,052 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,052 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.15903985500335693
2023-01-07 08:16:57,054 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,054 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,054 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6482712030410767
2023-01-07 08:16:57,055 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,055 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,056 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,056 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,056 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.128103733062744
2023-01-07 08:16:57,058 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,058 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,059 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5707670450210571
2023-01-07 08:16:57,060 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,060 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,060 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,060 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,060 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.560504913330078
2023-01-07 08:16:57,062 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,062 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,063 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9694894552230835
2023-01-07 08:16:57,064 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,064 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,064 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,064 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,064 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8336108326911926
2023-01-07 08:16:57,066 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,066 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,066 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7626057863235474
2023-01-07 08:16:57,067 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,067 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,067 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,068 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,068 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.9396722316741943
2023-01-07 08:16:57,070 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,070 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,070 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.37986814975738525
2023-01-07 08:16:57,071 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,071 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,071 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,071 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,071 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7533456087112427
2023-01-07 08:16:57,073 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,073 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,073 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.734756350517273
2023-01-07 08:16:57,074 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,074 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,074 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,075 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,075 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.643348693847656
2023-01-07 08:16:57,077 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,077 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,077 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.48486554622650146
2023-01-07 08:16:57,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,078 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,078 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,078 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.112507700920105
2023-01-07 08:16:57,080 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,080 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,081 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.450882911682129
2023-01-07 08:16:57,082 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,082 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,082 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,082 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,082 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8106274604797363
2023-01-07 08:16:57,084 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,084 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,084 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.5187253952026367
2023-01-07 08:16:57,085 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,085 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,085 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,085 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,086 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.06778037548065186
2023-01-07 08:16:57,087 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,087 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,088 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9267486333847046
2023-01-07 08:16:57,089 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,089 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,089 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,089 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,089 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7006207704544067
2023-01-07 08:16:57,091 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,091 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,091 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.345156192779541
2023-01-07 08:16:57,092 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,092 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,093 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,093 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,093 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.741020679473877
2023-01-07 08:16:57,095 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,095 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,095 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.882061004638672
2023-01-07 08:16:57,096 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,096 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,096 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,096 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,097 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.071676254272461
2023-01-07 08:16:57,098 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,098 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,099 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4896966218948364
2023-01-07 08:16:57,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,100 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,100 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.721756935119629
2023-01-07 08:16:57,102 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,102 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,102 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.1921486854553223
2023-01-07 08:16:57,103 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,103 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,104 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.962923049926758
2023-01-07 08:16:57,105 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,105 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,105 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4029935598373413
2023-01-07 08:16:57,106 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,106 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,106 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,106 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,107 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.072210311889648
2023-01-07 08:16:57,109 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,109 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,109 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2940796613693237
2023-01-07 08:16:57,110 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,110 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,110 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,110 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,111 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.084184646606445
2023-01-07 08:16:57,112 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,112 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,113 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.6108736991882324
2023-01-07 08:16:57,114 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,114 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,114 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,114 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,114 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.6848602294921875
2023-01-07 08:16:57,116 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,117 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,117 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.502556800842285
2023-01-07 08:16:57,118 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,118 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,118 > [DEBUG] 0 :: before allreduce fusion buffer :: -18.173547744750977
2023-01-07 08:16:57,120 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,120 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,120 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.09043550491333
2023-01-07 08:16:57,121 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,121 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,121 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.039857864379883
2023-01-07 08:16:57,123 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,123 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,123 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.361903190612793
2023-01-07 08:16:57,124 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,124 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.141795635223389
2023-01-07 08:16:57,126 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,126 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,126 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.248849868774414
2023-01-07 08:16:57,127 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,127 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,127 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.734468460083008
2023-01-07 08:16:57,129 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,129 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,129 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8288877606391907
2023-01-07 08:16:57,131 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,131 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,131 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6458990573883057
2023-01-07 08:16:57,132 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,132 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,133 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0173046588897705
2023-01-07 08:16:57,134 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,134 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,134 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.4464681148529053
2023-01-07 08:16:57,135 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,135 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,135 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9415993690490723
2023-01-07 08:16:57,136 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,136 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,137 > [DEBUG] 0 :: before allreduce fusion buffer :: 65.77417755126953
2023-01-07 08:16:57,138 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,138 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,138 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.421968936920166
2023-01-07 08:16:57,139 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,139 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,140 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,140 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,140 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.812016487121582
2023-01-07 08:16:57,142 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,142 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,142 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.611403703689575
2023-01-07 08:16:57,143 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,143 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,143 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.544402122497559
2023-01-07 08:16:57,145 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,145 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,145 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.364629745483398
2023-01-07 08:16:57,146 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,146 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,146 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.3320159912109375
2023-01-07 08:16:57,147 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,148 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,148 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.68338394165039
2023-01-07 08:16:57,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,149 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,149 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.232950687408447
2023-01-07 08:16:57,151 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,152 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,152 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.624565362930298
2023-01-07 08:16:57,153 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,153 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,153 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.0122625827789307
2023-01-07 08:16:57,154 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,154 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,155 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.912539482116699
2023-01-07 08:16:57,156 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,156 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,156 > [DEBUG] 0 :: before allreduce fusion buffer :: -26.446796417236328
2023-01-07 08:16:57,158 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,158 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,158 > [DEBUG] 0 :: before allreduce fusion buffer :: 17.258420944213867
2023-01-07 08:16:57,159 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,159 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,159 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,159 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,160 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.410321235656738
2023-01-07 08:16:57,162 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,162 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,162 > [DEBUG] 0 :: before allreduce fusion buffer :: -44.841102600097656
2023-01-07 08:16:57,163 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,163 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,163 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,163 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,163 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,163 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,163 > [DEBUG] 0 :: before allreduce fusion buffer :: 65.47138977050781
2023-01-07 08:16:57,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,166 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.196885108947754
2023-01-07 08:16:57,167 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,167 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,167 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.381051063537598
2023-01-07 08:16:57,169 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,169 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,169 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.747955322265625
2023-01-07 08:16:57,171 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,171 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,172 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.64964485168457
2023-01-07 08:16:57,174 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,174 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,174 > [DEBUG] 0 :: before allreduce fusion buffer :: 19.437570571899414
2023-01-07 08:16:57,175 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,175 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,175 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,175 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,175 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.274018287658691
2023-01-07 08:16:57,177 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,177 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,177 > [DEBUG] 0 :: before allreduce fusion buffer :: 22.60089683532715
2023-01-07 08:16:57,178 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,178 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,179 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,179 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,179 > [DEBUG] 0 :: before allreduce fusion buffer :: 71.54560852050781
2023-01-07 08:16:57,180 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,180 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,180 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.042970657348633
2023-01-07 08:16:57,181 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,182 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,182 > [DEBUG] 0 :: before allreduce fusion buffer :: -75.05484771728516
2023-01-07 08:16:57,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,183 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,183 > [DEBUG] 0 :: before allreduce fusion buffer :: 66.04904174804688
2023-01-07 08:16:57,184 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,184 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,185 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,185 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,185 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,185 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.959259033203125
2023-01-07 08:16:57,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,187 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8258645534515381
2023-01-07 08:16:57,188 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,188 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,188 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.01407814025879
2023-01-07 08:16:57,190 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,190 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,190 > [DEBUG] 0 :: before allreduce fusion buffer :: 26.720640182495117
2023-01-07 08:16:57,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,191 > [DEBUG] 0 :: before allreduce fusion buffer :: -83.55218505859375
2023-01-07 08:16:57,193 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,193 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,193 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.828258514404297
2023-01-07 08:16:57,194 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,194 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,194 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,194 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,195 > [DEBUG] 0 :: before allreduce fusion buffer :: 30.970050811767578
2023-01-07 08:16:57,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,197 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,197 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.181203842163086
2023-01-07 08:16:57,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,198 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9400882720947266
2023-01-07 08:16:57,202 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:16:57,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,202 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,203 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,203 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,203 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,203 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,204 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,204 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,204 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,204 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,204 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,207 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,207 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,207 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,207 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,207 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,209 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,209 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,209 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,209 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,209 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,211 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,211 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,211 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,212 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,212 > [DEBUG] 0 :: before allreduce fusion buffer :: 1028.1151123046875
2023-01-07 08:16:57,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,215 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,215 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,215 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,215 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,215 > [DEBUG] 0 :: before allreduce fusion buffer :: -83.14344024658203
2023-01-07 08:16:57,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,216 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,216 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,217 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.642458915710449
2023-01-07 08:16:57,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,218 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.631331443786621
2023-01-07 08:16:57,219 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,219 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,219 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,219 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,219 > [DEBUG] 0 :: before allreduce fusion buffer :: 701.8402099609375
2023-01-07 08:16:57,220 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -1.0251891613006592
2023-01-07 08:16:57,220 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,220 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,220 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,220 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:16:57,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,220 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,221 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.3286256790161133
2023-01-07 08:16:57,222 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:57,222 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,222 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,222 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,222 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: -22.87832260131836
2023-01-07 08:16:57,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,222 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,223 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,223 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.595848083496094
2023-01-07 08:16:57,224 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -22.87832260131836
2023-01-07 08:16:57,224 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,224 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,225 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,225 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -7.09437370300293
2023-01-07 08:16:57,225 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,225 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,225 > [DEBUG] 0 :: before allreduce fusion buffer :: -74.32304382324219
2023-01-07 08:16:57,226 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 61.19999694824219
2023-01-07 08:16:57,226 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,226 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,226 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,226 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -7.09437370300293
2023-01-07 08:16:57,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,226 > [DEBUG] 0 :: before allreduce fusion buffer :: 97.20011901855469
2023-01-07 08:16:57,228 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: -7.09437370300293
2023-01-07 08:16:57,228 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,228 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,228 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,228 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:16:57,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,228 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,228 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,228 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.249938011169434
2023-01-07 08:16:57,230 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:57,230 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,230 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,230 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,230 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.160484313964844
2023-01-07 08:16:57,231 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,231 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,231 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.680768966674805
2023-01-07 08:16:57,232 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: -3.2959747314453125
2023-01-07 08:16:57,232 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,232 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,232 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,232 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:16:57,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,232 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,232 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,232 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.68912410736084
2023-01-07 08:16:57,234 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:57,234 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,234 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,234 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,234 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 2.9115123748779297
2023-01-07 08:16:57,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,235 > [DEBUG] 0 :: before allreduce fusion buffer :: -22.814260482788086
2023-01-07 08:16:57,235 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 23.47233009338379
2023-01-07 08:16:57,235 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,236 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,236 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,236 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 2.9115123748779297
2023-01-07 08:16:57,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,236 > [DEBUG] 0 :: before allreduce fusion buffer :: -75.27287292480469
2023-01-07 08:16:57,237 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 247.4000244140625
2023-01-07 08:16:57,237 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,237 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,237 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,237 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 2.9115123748779297
2023-01-07 08:16:57,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,237 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,237 > [DEBUG] 0 :: before allreduce fusion buffer :: 49.49269104003906
2023-01-07 08:16:57,238 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 12.357175827026367
2023-01-07 08:16:57,238 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,238 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,239 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,239 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:16:57,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,239 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,239 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,239 > [DEBUG] 0 :: before allreduce fusion buffer :: 40.63176345825195
2023-01-07 08:16:57,240 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:57,240 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,240 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,240 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,241 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 2.9115123748779297
2023-01-07 08:16:57,241 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,241 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,241 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,241 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,241 > [DEBUG] 0 :: before allreduce fusion buffer :: 53.44562530517578
2023-01-07 08:16:57,242 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 2.9115123748779297
2023-01-07 08:16:57,242 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,243 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,243 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,243 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:16:57,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,243 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,243 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.608058452606201
2023-01-07 08:16:57,245 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:57,245 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,245 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,245 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,245 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.160484313964844
2023-01-07 08:16:57,245 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,245 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,245 > [DEBUG] 0 :: before allreduce fusion buffer :: -94.19861602783203
2023-01-07 08:16:57,246 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 9.54641342163086
2023-01-07 08:16:57,246 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,246 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,246 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,247 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 16.164283752441406
2023-01-07 08:16:57,247 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,247 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,247 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0920050144195557
2023-01-07 08:16:57,248 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 252.20010375976562
2023-01-07 08:16:57,248 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,248 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,248 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,248 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 16.164283752441406
2023-01-07 08:16:57,248 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,248 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,248 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,248 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,248 > [DEBUG] 0 :: before allreduce fusion buffer :: 39.69108581542969
2023-01-07 08:16:57,250 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 16.164283752441406
2023-01-07 08:16:57,250 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,250 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,250 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,250 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.160484313964844
2023-01-07 08:16:57,250 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,250 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,250 > [DEBUG] 0 :: before allreduce fusion buffer :: -63.24542999267578
2023-01-07 08:16:57,251 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 63.99998474121094
2023-01-07 08:16:57,251 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,251 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,251 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,251 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.160484313964844
2023-01-07 08:16:57,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,252 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.08818435668945
2023-01-07 08:16:57,253 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: -8.160484313964844
2023-01-07 08:16:57,253 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,253 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,253 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,254 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:16:57,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,254 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,254 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,254 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.46221923828125
2023-01-07 08:16:57,256 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:16:57,256 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,256 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,256 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,256 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 5.741408348083496
2023-01-07 08:16:57,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,256 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,256 > [DEBUG] 0 :: before allreduce fusion buffer :: 39.20208740234375
2023-01-07 08:16:57,257 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: -3.3462157249450684
2023-01-07 08:16:57,257 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,257 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,258 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,258 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 17.942874908447266
2023-01-07 08:16:57,258 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,258 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.0306782722473145
2023-01-07 08:16:57,259 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 253.39996337890625
2023-01-07 08:16:57,259 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,259 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,259 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,259 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 5.741408348083496
2023-01-07 08:16:57,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,260 > [DEBUG] 0 :: before allreduce fusion buffer :: 32.72330856323242
2023-01-07 08:16:57,261 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 17.942874908447266
2023-01-07 08:16:57,261 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,261 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,261 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,261 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 5.741408348083496
2023-01-07 08:16:57,261 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,261 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,261 > [DEBUG] 0 :: before allreduce fusion buffer :: -22.03316307067871
2023-01-07 08:16:57,262 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 126.20001220703125
2023-01-07 08:16:57,262 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,262 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,262 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,262 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 5.741408348083496
2023-01-07 08:16:57,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,263 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.530080795288086
2023-01-07 08:16:57,265 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 5.741408348083496
2023-01-07 08:16:57,265 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,265 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,265 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,265 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:16:57,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,265 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,266 > [DEBUG] 0 :: before allreduce fusion buffer :: 25.598831176757812
2023-01-07 08:16:57,267 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:57,267 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,267 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,267 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,267 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: -0.20096635818481445
2023-01-07 08:16:57,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,267 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,267 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.993654251098633
2023-01-07 08:16:57,269 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: -0.20096635818481445
2023-01-07 08:16:57,269 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,269 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,269 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,269 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:16:57,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,269 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,270 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,270 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.356542110443115
2023-01-07 08:16:57,271 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:57,271 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,271 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,271 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,271 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 6.827529430389404
2023-01-07 08:16:57,271 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,272 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.0232834815979
2023-01-07 08:16:57,273 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 6.827529430389404
2023-01-07 08:16:57,273 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,273 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,273 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,273 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 46.608055114746094
2023-01-07 08:16:57,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,273 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,273 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.632608413696289
2023-01-07 08:16:57,274 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 505.9995422363281
2023-01-07 08:16:57,274 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,274 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,274 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,274 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 46.608055114746094
2023-01-07 08:16:57,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,275 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,275 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.876165390014648
2023-01-07 08:16:57,276 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 46.608055114746094
2023-01-07 08:16:57,276 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,276 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,276 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,276 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:16:57,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,276 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,277 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,277 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,277 > [DEBUG] 0 :: before allreduce fusion buffer :: 52.34364318847656
2023-01-07 08:16:57,278 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:57,279 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,279 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,279 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,279 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 7.697781562805176
2023-01-07 08:16:57,279 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,279 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,279 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.51410484313965
2023-01-07 08:16:57,281 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 7.697781562805176
2023-01-07 08:16:57,281 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,281 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,281 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,281 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:16:57,281 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,281 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,281 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,281 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,281 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.0450239181518555
2023-01-07 08:16:57,283 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:57,283 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,283 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,283 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,283 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: -11.640456199645996
2023-01-07 08:16:57,283 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,283 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,283 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.401405334472656
2023-01-07 08:16:57,284 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -11.640456199645996
2023-01-07 08:16:57,284 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,285 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,285 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,285 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -34.238990783691406
2023-01-07 08:16:57,285 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,285 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1584891080856323
2023-01-07 08:16:57,286 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 498.796630859375
2023-01-07 08:16:57,286 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,286 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,286 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,286 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -34.238990783691406
2023-01-07 08:16:57,286 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,286 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,286 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.179361343383789
2023-01-07 08:16:57,288 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -34.238990783691406
2023-01-07 08:16:57,288 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,288 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,288 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,288 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:16:57,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,288 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,288 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,288 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.06217539310455322
2023-01-07 08:16:57,290 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:57,290 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,290 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,290 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,290 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: -0.9214951992034912
2023-01-07 08:16:57,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,290 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,290 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.850507736206055
2023-01-07 08:16:57,292 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -0.9214951992034912
2023-01-07 08:16:57,292 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,292 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,292 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,292 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:16:57,292 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,292 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,292 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,292 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,293 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.300247669219971
2023-01-07 08:16:57,294 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:57,294 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,294 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,294 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,294 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: 1.3654184341430664
2023-01-07 08:16:57,294 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,294 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,294 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.287599563598633
2023-01-07 08:16:57,296 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: 1.3654184341430664
2023-01-07 08:16:57,296 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,296 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,296 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,296 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:16:57,296 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,296 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,296 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,296 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,296 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6074028015136719
2023-01-07 08:16:57,298 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:57,298 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,298 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,298 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,298 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -0.0301971435546875
2023-01-07 08:16:57,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.2530651092529297
2023-01-07 08:16:57,300 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -0.0301971435546875
2023-01-07 08:16:57,300 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,300 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,300 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,300 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:16:57,300 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,300 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,300 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,300 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,300 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.564224243164062
2023-01-07 08:16:57,302 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:57,302 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,302 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,302 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,302 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: 7.608846664428711
2023-01-07 08:16:57,302 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,302 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,302 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.571916580200195
2023-01-07 08:16:57,304 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 7.608846664428711
2023-01-07 08:16:57,304 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,304 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,304 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,304 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:16:57,304 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,304 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,304 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,304 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,304 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.1131558418273926
2023-01-07 08:16:57,306 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:16:57,306 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,306 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,306 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,306 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 0.47893810272216797
2023-01-07 08:16:57,306 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,306 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,306 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.3557024002075195
2023-01-07 08:16:57,308 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 0.47893810272216797
2023-01-07 08:16:57,308 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,308 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,308 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,308 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:16:57,308 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,308 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,308 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,308 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,308 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9569878578186035
2023-01-07 08:16:57,310 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:16:57,310 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,310 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,310 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,310 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 37.91153335571289
2023-01-07 08:16:57,310 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,310 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.8739423751831055
2023-01-07 08:16:57,312 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 37.91153335571289
2023-01-07 08:16:57,312 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,312 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,312 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,312 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:16:57,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,312 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,313 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,313 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.1982421875
2023-01-07 08:16:57,314 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:57,314 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,314 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,314 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,314 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: 14.272685050964355
2023-01-07 08:16:57,314 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,314 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,315 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.12095749378204346
2023-01-07 08:16:57,316 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: 14.272685050964355
2023-01-07 08:16:57,316 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,316 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,316 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,317 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -26.249996185302734
2023-01-07 08:16:57,317 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,317 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,317 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.548167705535889
2023-01-07 08:16:57,318 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 257.59918212890625
2023-01-07 08:16:57,318 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,318 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,318 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,318 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -26.249996185302734
2023-01-07 08:16:57,318 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,318 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,318 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.963384628295898
2023-01-07 08:16:57,320 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -26.249996185302734
2023-01-07 08:16:57,320 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,320 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,320 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,320 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -52.69746398925781
2023-01-07 08:16:57,320 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,320 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,320 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.741016387939453
2023-01-07 08:16:57,321 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1020.396728515625
2023-01-07 08:16:57,321 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,321 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,321 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,321 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -52.69746398925781
2023-01-07 08:16:57,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,322 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,322 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8418926000595093
2023-01-07 08:16:57,323 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -52.69746398925781
2023-01-07 08:16:57,323 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,323 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,323 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,323 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 11.535799026489258
2023-01-07 08:16:57,323 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,323 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,323 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.6382968425750732
2023-01-07 08:16:57,324 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1031.0009765625
2023-01-07 08:16:57,325 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,325 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,325 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,325 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 11.535799026489258
2023-01-07 08:16:57,325 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,325 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.923610210418701
2023-01-07 08:16:57,327 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 11.535799026489258
2023-01-07 08:16:57,327 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,327 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,327 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,327 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:16:57,327 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,327 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:16:57,327 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,327 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,327 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.972079277038574
2023-01-07 08:16:57,329 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:16:57,329 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,329 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,329 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,329 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -6.955451965332031
2023-01-07 08:16:57,329 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,329 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,329 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.1693346500396729
2023-01-07 08:16:57,331 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -6.955451965332031
2023-01-07 08:16:57,331 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,331 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,331 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,331 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: 18.500093460083008
2023-01-07 08:16:57,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,331 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,331 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5907838940620422
2023-01-07 08:16:57,332 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 255.40011596679688
2023-01-07 08:16:57,332 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,332 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,332 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,332 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: 18.500093460083008
2023-01-07 08:16:57,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,333 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0361508131027222
2023-01-07 08:16:57,334 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: 18.500093460083008
2023-01-07 08:16:57,334 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,334 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,334 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,334 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 19.473270416259766
2023-01-07 08:16:57,334 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,334 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,335 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7703992128372192
2023-01-07 08:16:57,335 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1042.183837890625
2023-01-07 08:16:57,336 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,336 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,336 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,336 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 19.473270416259766
2023-01-07 08:16:57,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,336 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9840394258499146
2023-01-07 08:16:57,338 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 19.473270416259766
2023-01-07 08:16:57,338 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,338 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,338 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,338 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -52.85980987548828
2023-01-07 08:16:57,338 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,338 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,338 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.518571853637695
2023-01-07 08:16:57,339 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 259.79974365234375
2023-01-07 08:16:57,339 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,339 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,339 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,339 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -52.85980987548828
2023-01-07 08:16:57,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,340 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.106222629547119
2023-01-07 08:16:57,341 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: -52.85980987548828
2023-01-07 08:16:57,341 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,341 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,341 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,341 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -0.31838464736938477
2023-01-07 08:16:57,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,342 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.44421592354774475
2023-01-07 08:16:57,343 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 255.20030212402344
2023-01-07 08:16:57,343 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,343 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,343 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,343 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -0.31838464736938477
2023-01-07 08:16:57,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,343 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6599620580673218
2023-01-07 08:16:57,345 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -0.31838464736938477
2023-01-07 08:16:57,345 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,345 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,345 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,345 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -12.786895751953125
2023-01-07 08:16:57,345 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,345 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.4517728090286255
2023-01-07 08:16:57,346 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1022.4052124023438
2023-01-07 08:16:57,346 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,346 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,346 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,346 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -12.786895751953125
2023-01-07 08:16:57,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,347 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8021241426467896
2023-01-07 08:16:57,348 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: -12.786895751953125
2023-01-07 08:16:57,348 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,348 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,348 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,349 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 37.10218048095703
2023-01-07 08:16:57,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,349 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,349 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.073653221130371
2023-01-07 08:16:57,350 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 256.1994323730469
2023-01-07 08:16:57,350 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,350 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,350 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,350 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 37.10218048095703
2023-01-07 08:16:57,350 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,350 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,350 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6274411678314209
2023-01-07 08:16:57,352 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 37.10218048095703
2023-01-07 08:16:57,352 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,352 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,352 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,352 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 22.78554916381836
2023-01-07 08:16:57,352 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,352 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9935405254364014
2023-01-07 08:16:57,353 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 253.5992431640625
2023-01-07 08:16:57,353 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,353 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,353 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,354 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 22.78554916381836
2023-01-07 08:16:57,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,354 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.701701283454895
2023-01-07 08:16:57,355 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 22.78554916381836
2023-01-07 08:16:57,355 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,355 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,356 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,356 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -34.31098937988281
2023-01-07 08:16:57,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.8576347827911377
2023-01-07 08:16:57,357 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1018.5894775390625
2023-01-07 08:16:57,357 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,357 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,357 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,357 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -34.31098937988281
2023-01-07 08:16:57,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,357 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6691805124282837
2023-01-07 08:16:57,359 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -34.31098937988281
2023-01-07 08:16:57,359 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,359 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,359 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,359 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 15.409195899963379
2023-01-07 08:16:57,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,359 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,360 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5883510708808899
2023-01-07 08:16:57,360 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 254.59796142578125
2023-01-07 08:16:57,360 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,361 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,361 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,361 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 15.409195899963379
2023-01-07 08:16:57,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,361 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.4966917037963867
2023-01-07 08:16:57,362 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 15.409195899963379
2023-01-07 08:16:57,362 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,362 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,363 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,363 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: 35.191200256347656
2023-01-07 08:16:57,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9191102981567383
2023-01-07 08:16:57,364 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 252.7933349609375
2023-01-07 08:16:57,364 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,364 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,364 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,364 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: 35.191200256347656
2023-01-07 08:16:57,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,364 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.1854238510131836
2023-01-07 08:16:57,366 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: 35.191200256347656
2023-01-07 08:16:57,366 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,366 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,366 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,366 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: 41.722801208496094
2023-01-07 08:16:57,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,367 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4724999666213989
2023-01-07 08:16:57,367 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1029.38330078125
2023-01-07 08:16:57,367 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,367 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,367 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,368 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: 41.722801208496094
2023-01-07 08:16:57,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.8428895473480225
2023-01-07 08:16:57,370 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: 41.722801208496094
2023-01-07 08:16:57,370 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,370 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,370 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,370 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -25.505298614501953
2023-01-07 08:16:57,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,370 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.084460258483887
2023-01-07 08:16:57,371 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 250.802978515625
2023-01-07 08:16:57,371 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,371 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,371 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,371 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -25.505298614501953
2023-01-07 08:16:57,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,372 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.798714816570282
2023-01-07 08:16:57,373 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -25.505298614501953
2023-01-07 08:16:57,373 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,373 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,373 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,373 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: 9.816974639892578
2023-01-07 08:16:57,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,374 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.7822353839874268
2023-01-07 08:16:57,374 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 253.19320678710938
2023-01-07 08:16:57,374 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,374 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,375 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,375 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: 9.816974639892578
2023-01-07 08:16:57,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,375 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2453038990497589
2023-01-07 08:16:57,377 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: 9.816974639892578
2023-01-07 08:16:57,377 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,377 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,377 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,377 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -9.676406860351562
2023-01-07 08:16:57,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,377 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.804262161254883
2023-01-07 08:16:57,378 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1014.5970458984375
2023-01-07 08:16:57,378 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,378 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,378 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,378 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -9.676406860351562
2023-01-07 08:16:57,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,378 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,378 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.5314661264419556
2023-01-07 08:16:57,380 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -9.676406860351562
2023-01-07 08:16:57,380 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,380 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,380 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,380 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: 22.204957962036133
2023-01-07 08:16:57,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,381 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.1610868275165558
2023-01-07 08:16:57,381 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 600.199951171875
2023-01-07 08:16:57,382 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,382 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,382 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,382 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: 22.204957962036133
2023-01-07 08:16:57,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,382 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0250433683395386
2023-01-07 08:16:57,384 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: 22.204957962036133
2023-01-07 08:16:57,384 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,384 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,384 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,384 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -42.1867561340332
2023-01-07 08:16:57,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,384 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.058645449578762054
2023-01-07 08:16:57,385 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 601.2001953125
2023-01-07 08:16:57,385 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,385 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,385 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,386 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -42.1867561340332
2023-01-07 08:16:57,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,386 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.7124598026275635
2023-01-07 08:16:57,387 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -42.1867561340332
2023-01-07 08:16:57,387 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,387 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,387 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,388 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 16.227272033691406
2023-01-07 08:16:57,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,388 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3096002340316772
2023-01-07 08:16:57,389 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2145.01220703125
2023-01-07 08:16:57,389 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,389 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,389 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,389 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 16.227272033691406
2023-01-07 08:16:57,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,389 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8149073123931885
2023-01-07 08:16:57,391 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 16.227272033691406
2023-01-07 08:16:57,391 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,391 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,391 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,391 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -13.058965682983398
2023-01-07 08:16:57,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,391 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,391 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7591224908828735
2023-01-07 08:16:57,392 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2139.197998046875
2023-01-07 08:16:57,392 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,392 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,392 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,392 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -13.058965682983398
2023-01-07 08:16:57,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3647626042366028
2023-01-07 08:16:57,394 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -13.058965682983398
2023-01-07 08:16:57,394 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,394 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,394 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,394 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 28.49540138244629
2023-01-07 08:16:57,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,395 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9503777027130127
2023-01-07 08:16:57,395 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 601.3985595703125
2023-01-07 08:16:57,395 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,395 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,396 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,396 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 28.49540138244629
2023-01-07 08:16:57,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,396 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0061410665512085
2023-01-07 08:16:57,398 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 28.49540138244629
2023-01-07 08:16:57,398 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,398 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,398 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,398 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -24.01067543029785
2023-01-07 08:16:57,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,398 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.015622084960341454
2023-01-07 08:16:57,399 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 600.9989013671875
2023-01-07 08:16:57,399 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,399 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,399 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,399 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -24.01067543029785
2023-01-07 08:16:57,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,400 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7610702514648438
2023-01-07 08:16:57,401 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -24.01067543029785
2023-01-07 08:16:57,401 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,401 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,401 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,401 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -74.64981842041016
2023-01-07 08:16:57,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,402 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.311598539352417
2023-01-07 08:16:57,403 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2140.31640625
2023-01-07 08:16:57,403 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,403 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,403 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,403 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -74.64981842041016
2023-01-07 08:16:57,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,403 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,403 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4185038208961487
2023-01-07 08:16:57,405 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -74.64981842041016
2023-01-07 08:16:57,405 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,405 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,405 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,405 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 2.462071418762207
2023-01-07 08:16:57,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,405 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.290523499250412
2023-01-07 08:16:57,406 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 600.1993408203125
2023-01-07 08:16:57,406 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,406 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,406 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,406 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 2.462071418762207
2023-01-07 08:16:57,406 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,406 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.21742135286331177
2023-01-07 08:16:57,408 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 2.462071418762207
2023-01-07 08:16:57,408 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,408 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,408 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,409 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 4.99153470993042
2023-01-07 08:16:57,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,409 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2658117115497589
2023-01-07 08:16:57,410 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 600.7999267578125
2023-01-07 08:16:57,410 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,410 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,410 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,410 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 4.99153470993042
2023-01-07 08:16:57,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,410 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6198818683624268
2023-01-07 08:16:57,412 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 4.99153470993042
2023-01-07 08:16:57,412 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,412 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,412 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,412 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: 28.895294189453125
2023-01-07 08:16:57,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,413 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.756237030029297
2023-01-07 08:16:57,414 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2452.3974609375
2023-01-07 08:16:57,414 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,414 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,414 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,414 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: 28.895294189453125
2023-01-07 08:16:57,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.540097713470459
2023-01-07 08:16:57,416 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: 28.895294189453125
2023-01-07 08:16:57,416 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:57,416 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:57,416 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:57,417 > [DEBUG] 0 :: 7.414742469787598
2023-01-07 08:16:57,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,420 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,420 > [DEBUG] 0 :: before allreduce fusion buffer :: -582.8477783203125
2023-01-07 08:16:57,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,422 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,422 > [DEBUG] 0 :: before allreduce fusion buffer :: -590.600830078125
2023-01-07 08:16:57,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,425 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,425 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.85093688964844
2023-01-07 08:16:57,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,428 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,428 > [DEBUG] 0 :: before allreduce fusion buffer :: -322.1409912109375
2023-01-07 08:16:57,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,431 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,431 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,431 > [DEBUG] 0 :: before allreduce fusion buffer :: -42.32217025756836
2023-01-07 08:16:57,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,433 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,433 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.117499351501465
2023-01-07 08:16:57,436 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,436 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,436 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,437 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.97410583496094
2023-01-07 08:16:57,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,438 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,439 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.80632781982422
2023-01-07 08:16:57,441 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,441 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,442 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,442 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.527347564697266
2023-01-07 08:16:57,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,444 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,444 > [DEBUG] 0 :: before allreduce fusion buffer :: -72.9736328125
2023-01-07 08:16:57,447 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,447 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,447 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,447 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.055992126464844
2023-01-07 08:16:57,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,449 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.9200994968414307
2023-01-07 08:16:57,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,452 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,453 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.815032958984375
2023-01-07 08:16:57,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,454 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,455 > [DEBUG] 0 :: before allreduce fusion buffer :: -70.14010620117188
2023-01-07 08:16:57,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,458 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,458 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.493492126464844
2023-01-07 08:16:57,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,460 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,460 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9090421199798584
2023-01-07 08:16:57,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,463 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,463 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.59600067138672
2023-01-07 08:16:57,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,465 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,465 > [DEBUG] 0 :: before allreduce fusion buffer :: -53.701133728027344
2023-01-07 08:16:57,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,468 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,469 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.185081481933594
2023-01-07 08:16:57,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,470 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,471 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.215270042419434
2023-01-07 08:16:57,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,474 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,474 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4291071891784668
2023-01-07 08:16:57,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,476 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,477 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.443029880523682
2023-01-07 08:16:57,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,480 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,480 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4341263175010681
2023-01-07 08:16:57,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,482 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,482 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.855449676513672
2023-01-07 08:16:57,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,485 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,485 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2793437242507935
2023-01-07 08:16:57,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,487 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,488 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.356431484222412
2023-01-07 08:16:57,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,490 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,491 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.06170471012592316
2023-01-07 08:16:57,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,492 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,492 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.041017115116119385
2023-01-07 08:16:57,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,494 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,494 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5556427240371704
2023-01-07 08:16:57,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,495 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,495 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.1927170753479004
2023-01-07 08:16:57,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,592 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,592 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.362412691116333
2023-01-07 08:16:57,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,593 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,594 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.1310536861419678
2023-01-07 08:16:57,777 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,777 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,777 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,777 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8843874335289001
2023-01-07 08:16:57,778 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,778 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,778 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:57,778 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:57,778 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:57,779 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.015225887298584
2023-01-07 08:16:58,077 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,077 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,077 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,077 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6778943538665771
2023-01-07 08:16:58,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,078 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,078 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,079 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,080 > [DEBUG] 0 :: before allreduce fusion buffer :: 763.1666259765625
2023-01-07 08:16:58,081 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,081 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,081 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,081 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.2955551147460938
2023-01-07 08:16:58,082 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,082 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,082 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,082 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,083 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,083 > [DEBUG] 0 :: before allreduce fusion buffer :: 6108.3671875
2023-01-07 08:16:58,084 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,084 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,084 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,085 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.6935441493988037
2023-01-07 08:16:58,085 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,085 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,085 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,086 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,086 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,086 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.588069498538971
2023-01-07 08:16:58,087 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,087 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,087 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,088 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.10505425930023193
2023-01-07 08:16:58,088 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,088 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,089 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,089 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,089 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,089 > [DEBUG] 0 :: before allreduce fusion buffer :: 9094.46875
2023-01-07 08:16:58,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,090 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,091 > [DEBUG] 0 :: before allreduce fusion buffer :: -31.268543243408203
2023-01-07 08:16:58,091 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,092 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,092 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,092 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,092 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,092 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.478927612304688
2023-01-07 08:16:58,093 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,093 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,094 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,094 > [DEBUG] 0 :: before allreduce fusion buffer :: 1177992.375
2023-01-07 08:16:58,094 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,095 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,095 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,095 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,095 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,095 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.267266273498535
2023-01-07 08:16:58,097 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,097 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,097 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,097 > [DEBUG] 0 :: before allreduce fusion buffer :: -22.91975975036621
2023-01-07 08:16:58,098 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,098 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,098 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,098 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,098 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,098 > [DEBUG] 0 :: before allreduce fusion buffer :: -166.65634155273438
2023-01-07 08:16:58,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,100 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,100 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.6178321838378906
2023-01-07 08:16:58,101 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,101 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,101 > [DEBUG] 0 :: before allreduce fusion buffer :: 603127552.0
2023-01-07 08:16:58,102 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,102 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,102 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,102 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.0118064880371094
2023-01-07 08:16:58,103 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,103 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,103 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,104 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,104 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,104 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.510046005249023
2023-01-07 08:16:58,105 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,105 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,105 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,105 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5936492085456848
2023-01-07 08:16:58,106 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,106 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,106 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,107 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,107 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,107 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.385746002197266
2023-01-07 08:16:58,108 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,108 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,108 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,109 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6003260016441345
2023-01-07 08:16:58,109 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,109 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,109 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,110 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,110 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,110 > [DEBUG] 0 :: before allreduce fusion buffer :: -14.66910171508789
2023-01-07 08:16:58,111 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,111 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,111 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,112 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.016695261001587
2023-01-07 08:16:58,112 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,112 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,113 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.379602432250977
2023-01-07 08:16:58,114 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,114 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,114 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,114 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.3178138732910156
2023-01-07 08:16:58,115 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,115 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,115 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.89849090576172
2023-01-07 08:16:58,116 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,116 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,116 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,117 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.8329782485961914
2023-01-07 08:16:58,117 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,117 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,118 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.834665298461914
2023-01-07 08:16:58,119 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,119 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,119 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,119 > [DEBUG] 0 :: before allreduce fusion buffer :: 50.59184646606445
2023-01-07 08:16:58,120 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,120 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,120 > [DEBUG] 0 :: before allreduce fusion buffer :: 304.42962646484375
2023-01-07 08:16:58,121 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,121 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,121 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,121 > [DEBUG] 0 :: before allreduce fusion buffer :: 69.08177185058594
2023-01-07 08:16:58,122 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,122 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,122 > [DEBUG] 0 :: before allreduce fusion buffer :: 197.32598876953125
2023-01-07 08:16:58,123 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,124 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,124 > [DEBUG] 0 :: before allreduce fusion buffer :: 104.95746612548828
2023-01-07 08:16:58,125 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,125 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,125 > [DEBUG] 0 :: before allreduce fusion buffer :: 77.9559326171875
2023-01-07 08:16:58,126 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,126 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,126 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,126 > [DEBUG] 0 :: before allreduce fusion buffer :: -628.763427734375
2023-01-07 08:16:58,127 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,127 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,127 > [DEBUG] 0 :: before allreduce fusion buffer :: 299.4601745605469
2023-01-07 08:16:58,129 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,129 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,129 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,129 > [DEBUG] 0 :: before allreduce fusion buffer :: -233.2408905029297
2023-01-07 08:16:58,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,130 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,130 > [DEBUG] 0 :: before allreduce fusion buffer :: 115568.1875
2023-01-07 08:16:58,132 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,132 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,132 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,132 > [DEBUG] 0 :: before allreduce fusion buffer :: -4046.97216796875
2023-01-07 08:16:58,133 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,133 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,133 > [DEBUG] 0 :: before allreduce fusion buffer :: 882.7852783203125
2023-01-07 08:16:58,134 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,134 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,134 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,134 > [DEBUG] 0 :: before allreduce fusion buffer :: -1791.1790771484375
2023-01-07 08:16:58,135 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,135 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,135 > [DEBUG] 0 :: before allreduce fusion buffer :: -8755.880859375
2023-01-07 08:16:58,136 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,137 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,137 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,137 > [DEBUG] 0 :: before allreduce fusion buffer :: -6336.603515625
2023-01-07 08:16:58,138 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,138 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,138 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,138 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,138 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,138 > [DEBUG] 0 :: before allreduce fusion buffer :: -3548.69091796875
2023-01-07 08:16:58,139 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,140 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,140 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,140 > [DEBUG] 0 :: before allreduce fusion buffer :: 6322.68994140625
2023-01-07 08:16:58,141 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,141 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,141 > [DEBUG] 0 :: before allreduce fusion buffer :: 16594.693359375
2023-01-07 08:16:58,142 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,142 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,142 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,142 > [DEBUG] 0 :: before allreduce fusion buffer :: 2059.69482421875
2023-01-07 08:16:58,143 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,143 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,143 > [DEBUG] 0 :: before allreduce fusion buffer :: 12990.8759765625
2023-01-07 08:16:58,144 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,144 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,145 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,145 > [DEBUG] 0 :: before allreduce fusion buffer :: 14319.830078125
2023-01-07 08:16:58,146 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,146 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,146 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,146 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,146 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,146 > [DEBUG] 0 :: before allreduce fusion buffer :: 1091.0283203125
2023-01-07 08:16:58,148 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,148 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,148 > [DEBUG] 0 :: before allreduce fusion buffer :: 49741.0390625
2023-01-07 08:16:58,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,149 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,149 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,149 > [DEBUG] 0 :: before allreduce fusion buffer :: 54456.1484375
2023-01-07 08:16:58,151 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,151 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,151 > [DEBUG] 0 :: before allreduce fusion buffer :: -3551.28857421875
2023-01-07 08:16:58,152 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,152 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,152 > [DEBUG] 0 :: before allreduce fusion buffer :: 2970.7080078125
2023-01-07 08:16:58,153 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,153 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,154 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,154 > [DEBUG] 0 :: before allreduce fusion buffer :: 73178.28125
2023-01-07 08:16:58,155 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,155 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,155 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,155 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,155 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,155 > [DEBUG] 0 :: before allreduce fusion buffer :: -551196.4375
2023-01-07 08:16:58,156 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,156 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,157 > [DEBUG] 0 :: before allreduce fusion buffer :: -1076489.125
2023-01-07 08:16:58,157 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,158 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,158 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,158 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,158 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,158 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,158 > [DEBUG] 0 :: before allreduce fusion buffer :: -8266085.5
2023-01-07 08:16:58,159 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,159 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,160 > [DEBUG] 0 :: before allreduce fusion buffer :: -27540.27734375
2023-01-07 08:16:58,161 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,161 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,161 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,161 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,161 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,161 > [DEBUG] 0 :: before allreduce fusion buffer :: -113397.1015625
2023-01-07 08:16:58,162 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,162 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,162 > [DEBUG] 0 :: before allreduce fusion buffer :: -120022.7578125
2023-01-07 08:16:58,164 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,164 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,164 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,164 > [DEBUG] 0 :: before allreduce fusion buffer :: 1387128.75
2023-01-07 08:16:58,165 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,165 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,165 > [DEBUG] 0 :: before allreduce fusion buffer :: -94183.4140625
2023-01-07 08:16:58,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,166 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,166 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,167 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,167 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,167 > [DEBUG] 0 :: before allreduce fusion buffer :: 353165984.0
2023-01-07 08:16:58,168 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,168 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,168 > [DEBUG] 0 :: before allreduce fusion buffer :: -5608.0341796875
2023-01-07 08:16:58,169 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,169 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,169 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,170 > [DEBUG] 0 :: before allreduce fusion buffer :: 46411.5
2023-01-07 08:16:58,171 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,171 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,171 > [DEBUG] 0 :: before allreduce fusion buffer :: 99218.5625
2023-01-07 08:16:58,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,172 > [DEBUG] 0 :: before allreduce fusion buffer :: -12610112512.0
2023-01-07 08:16:58,174 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,174 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,174 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,174 > [DEBUG] 0 :: before allreduce fusion buffer :: 1019802.5
2023-01-07 08:16:58,175 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,175 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,175 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,175 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,175 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,175 > [DEBUG] 0 :: before allreduce fusion buffer :: -1516762.375
2023-01-07 08:16:58,177 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,177 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,177 > [DEBUG] 0 :: before allreduce fusion buffer :: 1584653.625
2023-01-07 08:16:58,178 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,178 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,178 > [DEBUG] 0 :: before allreduce fusion buffer :: -3621723.0
2023-01-07 08:16:58,182 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:16:58,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,183 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,183 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,183 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,184 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,184 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,184 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,184 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,185 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,185 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,186 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,186 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,186 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,186 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,188 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,188 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,188 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,188 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,189 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,189 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,189 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,189 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,190 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,190 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,190 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,190 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,190 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,192 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,192 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,192 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,192 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,192 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,192 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,192 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,192 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,193 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,193 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,193 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,193 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.8832508447555584e+16
2023-01-07 08:16:58,196 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,196 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,197 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,197 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,197 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,197 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,197 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,199 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,199 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.761795035063386e+18
2023-01-07 08:16:58,200 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,200 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,200 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,200 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,200 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,201 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,201 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,201 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,201 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.979018115912827e+18
2023-01-07 08:16:58,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,202 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.183573383501578e+17
2023-01-07 08:16:58,203 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,203 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,203 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,203 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,203 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.613610513319854e+17
2023-01-07 08:16:58,204 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -7.074149131774902
2023-01-07 08:16:58,204 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,204 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,204 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,204 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 62.00000762939453
2023-01-07 08:16:58,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,205 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,205 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,205 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,205 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3064928225350648e+19
2023-01-07 08:16:58,206 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 62.00000762939453
2023-01-07 08:16:58,206 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,207 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,207 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,207 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: -19.477867126464844
2023-01-07 08:16:58,207 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,207 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,207 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,207 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,207 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,207 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.421937247558776e+19
2023-01-07 08:16:58,209 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -19.477867126464844
2023-01-07 08:16:58,209 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,209 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,209 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,209 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 23.312097549438477
2023-01-07 08:16:58,209 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,209 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,210 > [DEBUG] 0 :: before allreduce fusion buffer :: 7046306.5
2023-01-07 08:16:58,211 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 61.19999694824219
2023-01-07 08:16:58,211 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,211 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,211 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,211 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 23.312097549438477
2023-01-07 08:16:58,211 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,211 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,211 > [DEBUG] 0 :: before allreduce fusion buffer :: 3489732.5
2023-01-07 08:16:58,213 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 23.312097549438477
2023-01-07 08:16:58,213 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,213 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,213 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,213 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 62.0
2023-01-07 08:16:58,213 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,213 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,213 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,213 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,213 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,213 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,213 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,213 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,214 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.50835540639663e+22
2023-01-07 08:16:58,215 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 62.0
2023-01-07 08:16:58,215 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,215 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,215 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,216 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.547089576721191
2023-01-07 08:16:58,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,216 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,216 > [DEBUG] 0 :: before allreduce fusion buffer :: 7873.33984375
2023-01-07 08:16:58,217 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 30.43231773376465
2023-01-07 08:16:58,217 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,217 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,217 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,217 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 253.60000610351562
2023-01-07 08:16:58,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,218 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,218 > [DEBUG] 0 :: before allreduce fusion buffer :: -1238104.25
2023-01-07 08:16:58,220 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 253.60000610351562
2023-01-07 08:16:58,220 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,220 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,220 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,220 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 36.91157531738281
2023-01-07 08:16:58,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,220 > [DEBUG] 0 :: before allreduce fusion buffer :: -59498.8828125
2023-01-07 08:16:58,221 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -38.29423904418945
2023-01-07 08:16:58,221 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,221 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,221 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,221 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 36.91157531738281
2023-01-07 08:16:58,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,222 > [DEBUG] 0 :: before allreduce fusion buffer :: -279788.25
2023-01-07 08:16:58,223 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 246.95352172851562
2023-01-07 08:16:58,223 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,223 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,223 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,223 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 36.91157531738281
2023-01-07 08:16:58,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,223 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,223 > [DEBUG] 0 :: before allreduce fusion buffer :: -907058.0625
2023-01-07 08:16:58,224 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 65.35663604736328
2023-01-07 08:16:58,224 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,225 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,225 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,225 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 62.0
2023-01-07 08:16:58,225 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,225 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,225 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,225 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,225 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,225 > [DEBUG] 0 :: before allreduce fusion buffer :: 188492.0625
2023-01-07 08:16:58,226 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 62.0
2023-01-07 08:16:58,226 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,227 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,227 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,227 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 36.91157531738281
2023-01-07 08:16:58,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,227 > [DEBUG] 0 :: before allreduce fusion buffer :: -22112.75
2023-01-07 08:16:58,229 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 36.91157531738281
2023-01-07 08:16:58,229 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,229 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,229 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,229 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 62.0
2023-01-07 08:16:58,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,229 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,229 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,229 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,230 > [DEBUG] 0 :: before allreduce fusion buffer :: 326296.78125
2023-01-07 08:16:58,231 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 62.0
2023-01-07 08:16:58,231 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,231 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,231 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,231 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.547089576721191
2023-01-07 08:16:58,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,232 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,232 > [DEBUG] 0 :: before allreduce fusion buffer :: -52531.9921875
2023-01-07 08:16:58,233 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 3.7478017807006836
2023-01-07 08:16:58,233 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,233 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,233 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,233 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 33.15912628173828
2023-01-07 08:16:58,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,233 > [DEBUG] 0 :: before allreduce fusion buffer :: 38060.859375
2023-01-07 08:16:58,234 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 249.96768188476562
2023-01-07 08:16:58,234 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,234 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,235 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,235 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 33.15912628173828
2023-01-07 08:16:58,235 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,235 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,235 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,235 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,235 > [DEBUG] 0 :: before allreduce fusion buffer :: 30130.67578125
2023-01-07 08:16:58,237 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 33.15912628173828
2023-01-07 08:16:58,237 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,237 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,237 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,237 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.547089576721191
2023-01-07 08:16:58,237 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,237 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,237 > [DEBUG] 0 :: before allreduce fusion buffer :: -133119.703125
2023-01-07 08:16:58,238 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 67.12535858154297
2023-01-07 08:16:58,238 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,238 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,238 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,238 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -8.547089576721191
2023-01-07 08:16:58,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,239 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,239 > [DEBUG] 0 :: before allreduce fusion buffer :: 86094.90625
2023-01-07 08:16:58,240 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: -8.547089576721191
2023-01-07 08:16:58,240 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,240 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,240 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,240 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 62.400108337402344
2023-01-07 08:16:58,241 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,241 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,241 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,241 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,241 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,241 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,241 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,241 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,241 > [DEBUG] 0 :: before allreduce fusion buffer :: -225297.5
2023-01-07 08:16:58,243 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 62.400108337402344
2023-01-07 08:16:58,243 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,243 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,243 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,243 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 253.69757080078125
2023-01-07 08:16:58,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,244 > [DEBUG] 0 :: before allreduce fusion buffer :: 35101.9140625
2023-01-07 08:16:58,245 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 53.619239807128906
2023-01-07 08:16:58,245 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,245 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,245 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,245 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 352.797607421875
2023-01-07 08:16:58,245 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,245 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,245 > [DEBUG] 0 :: before allreduce fusion buffer :: 9253.7998046875
2023-01-07 08:16:58,246 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 251.7628631591797
2023-01-07 08:16:58,247 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,247 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,247 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,247 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 253.69757080078125
2023-01-07 08:16:58,247 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,247 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,247 > [DEBUG] 0 :: before allreduce fusion buffer :: 42561.8515625
2023-01-07 08:16:58,248 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 352.797607421875
2023-01-07 08:16:58,248 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,248 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,248 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,249 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 253.69757080078125
2023-01-07 08:16:58,249 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,249 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,249 > [DEBUG] 0 :: before allreduce fusion buffer :: 33928.61328125
2023-01-07 08:16:58,250 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 126.49742889404297
2023-01-07 08:16:58,250 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,250 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,250 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,250 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 253.69757080078125
2023-01-07 08:16:58,250 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,250 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,250 > [DEBUG] 0 :: before allreduce fusion buffer :: -40574.359375
2023-01-07 08:16:58,252 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 253.69757080078125
2023-01-07 08:16:58,252 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,252 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,252 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,252 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 127.79998779296875
2023-01-07 08:16:58,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,252 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,253 > [DEBUG] 0 :: before allreduce fusion buffer :: 2221.072998046875
2023-01-07 08:16:58,254 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 127.79998779296875
2023-01-07 08:16:58,254 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,254 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,254 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,254 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 473.8998107910156
2023-01-07 08:16:58,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,254 > [DEBUG] 0 :: before allreduce fusion buffer :: 2444.2880859375
2023-01-07 08:16:58,256 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 473.8998107910156
2023-01-07 08:16:58,256 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,256 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,256 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,256 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 520.2000732421875
2023-01-07 08:16:58,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,256 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,256 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,257 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,257 > [DEBUG] 0 :: before allreduce fusion buffer :: -294.40966796875
2023-01-07 08:16:58,258 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 520.2000732421875
2023-01-07 08:16:58,258 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,258 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,258 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,258 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 9.164617538452148
2023-01-07 08:16:58,258 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,259 > [DEBUG] 0 :: before allreduce fusion buffer :: 802.957275390625
2023-01-07 08:16:58,260 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 9.164617538452148
2023-01-07 08:16:58,260 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,260 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,260 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,260 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 88.6766357421875
2023-01-07 08:16:58,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,260 > [DEBUG] 0 :: before allreduce fusion buffer :: 2961.15380859375
2023-01-07 08:16:58,261 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 508.6784362792969
2023-01-07 08:16:58,261 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,261 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,262 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,262 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 88.6766357421875
2023-01-07 08:16:58,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,262 > [DEBUG] 0 :: before allreduce fusion buffer :: 13515.255859375
2023-01-07 08:16:58,263 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 88.6766357421875
2023-01-07 08:16:58,263 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,264 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,264 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,264 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 127.79999542236328
2023-01-07 08:16:58,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,264 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,264 > [DEBUG] 0 :: before allreduce fusion buffer :: -1489.412353515625
2023-01-07 08:16:58,266 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 127.79999542236328
2023-01-07 08:16:58,266 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,266 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,266 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,266 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 57.6421012878418
2023-01-07 08:16:58,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,266 > [DEBUG] 0 :: before allreduce fusion buffer :: 252.37969970703125
2023-01-07 08:16:58,268 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 57.6421012878418
2023-01-07 08:16:58,268 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,268 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,268 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,268 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 127.79999542236328
2023-01-07 08:16:58,268 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,268 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,268 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,268 > [DEBUG] 0 :: before allreduce fusion buffer :: -1233.779296875
2023-01-07 08:16:58,270 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 127.79999542236328
2023-01-07 08:16:58,270 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,270 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,270 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,270 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: -205.64691162109375
2023-01-07 08:16:58,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,270 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,270 > [DEBUG] 0 :: before allreduce fusion buffer :: -614.9337768554688
2023-01-07 08:16:58,272 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -205.64691162109375
2023-01-07 08:16:58,272 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,272 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,272 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,272 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -100.99715423583984
2023-01-07 08:16:58,272 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,272 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,272 > [DEBUG] 0 :: before allreduce fusion buffer :: 1299.255126953125
2023-01-07 08:16:58,273 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 489.9495849609375
2023-01-07 08:16:58,273 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,273 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,273 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,274 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -100.99715423583984
2023-01-07 08:16:58,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,274 > [DEBUG] 0 :: before allreduce fusion buffer :: -2007.4010009765625
2023-01-07 08:16:58,275 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -100.99715423583984
2023-01-07 08:16:58,275 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,275 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,275 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,276 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 127.79999542236328
2023-01-07 08:16:58,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,276 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,276 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,276 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,276 > [DEBUG] 0 :: before allreduce fusion buffer :: 3323.65966796875
2023-01-07 08:16:58,277 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 127.79999542236328
2023-01-07 08:16:58,277 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,278 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,278 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,278 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: -26.00592613220215
2023-01-07 08:16:58,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,278 > [DEBUG] 0 :: before allreduce fusion buffer :: 1143.9189453125
2023-01-07 08:16:58,279 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -26.00592613220215
2023-01-07 08:16:58,280 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,280 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,280 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,280 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 127.79999542236328
2023-01-07 08:16:58,280 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,280 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,280 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,280 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,280 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,280 > [DEBUG] 0 :: before allreduce fusion buffer :: 134.45660400390625
2023-01-07 08:16:58,282 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 127.79999542236328
2023-01-07 08:16:58,282 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,282 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,282 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,282 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -36.05671691894531
2023-01-07 08:16:58,282 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,282 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,282 > [DEBUG] 0 :: before allreduce fusion buffer :: -260.1894836425781
2023-01-07 08:16:58,284 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -36.05671691894531
2023-01-07 08:16:58,284 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,284 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,284 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,284 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 520.2000122070312
2023-01-07 08:16:58,284 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,284 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,284 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,284 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,284 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 45.33263397216797
2023-01-07 08:16:58,286 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 520.2000122070312
2023-01-07 08:16:58,286 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,286 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,286 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,286 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: 7.664581298828125
2023-01-07 08:16:58,286 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,286 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,286 > [DEBUG] 0 :: before allreduce fusion buffer :: -535.2110595703125
2023-01-07 08:16:58,288 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 7.664581298828125
2023-01-07 08:16:58,288 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,288 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,288 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,288 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 127.79999542236328
2023-01-07 08:16:58,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,288 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,288 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,288 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,289 > [DEBUG] 0 :: before allreduce fusion buffer :: -72.89872741699219
2023-01-07 08:16:58,290 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 127.79999542236328
2023-01-07 08:16:58,290 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,290 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,290 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,290 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: 107.51957702636719
2023-01-07 08:16:58,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,290 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,291 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.26527214050293
2023-01-07 08:16:58,292 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 107.51957702636719
2023-01-07 08:16:58,293 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,293 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,293 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,293 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 129.79983520507812
2023-01-07 08:16:58,293 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,293 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,293 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,293 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,293 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,293 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.826541900634766
2023-01-07 08:16:58,295 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 129.79983520507812
2023-01-07 08:16:58,295 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,295 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,295 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,295 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: -15.496582984924316
2023-01-07 08:16:58,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,295 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9054276943206787
2023-01-07 08:16:58,297 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -15.496582984924316
2023-01-07 08:16:58,297 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,297 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,297 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,297 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 520.2000122070312
2023-01-07 08:16:58,297 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,297 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,297 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,297 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,297 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,297 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.682154655456543
2023-01-07 08:16:58,299 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 520.2000122070312
2023-01-07 08:16:58,299 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,299 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,299 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,299 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 192.05429077148438
2023-01-07 08:16:58,299 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,299 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,299 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.156584739685059
2023-01-07 08:16:58,301 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 192.05429077148438
2023-01-07 08:16:58,301 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,301 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,301 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,301 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 257.3999938964844
2023-01-07 08:16:58,301 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,301 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,301 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,301 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,302 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,302 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.48806619644165
2023-01-07 08:16:58,303 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 257.3999938964844
2023-01-07 08:16:58,303 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,303 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,303 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,303 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -24072.3359375
2023-01-07 08:16:58,303 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,303 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,304 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.85069274902344
2023-01-07 08:16:58,305 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -24072.3359375
2023-01-07 08:16:58,305 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,305 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,305 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,305 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -348.11578369140625
2023-01-07 08:16:58,305 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,305 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,306 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,307 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 255.9621124267578
2023-01-07 08:16:58,307 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,307 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,307 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,307 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -348.11578369140625
2023-01-07 08:16:58,307 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,307 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,307 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,309 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -348.11578369140625
2023-01-07 08:16:58,310 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,310 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,310 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,310 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1460.4013671875
2023-01-07 08:16:58,310 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,310 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,311 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1013.9971923828125
2023-01-07 08:16:58,311 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,311 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,311 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,311 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1460.4013671875
2023-01-07 08:16:58,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,312 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,313 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -1460.4013671875
2023-01-07 08:16:58,313 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,313 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,313 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,313 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1121.2130126953125
2023-01-07 08:16:58,313 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,313 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,314 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,314 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1024.601318359375
2023-01-07 08:16:58,315 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,315 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,315 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,315 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1121.2130126953125
2023-01-07 08:16:58,315 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,315 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,315 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,317 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1121.2130126953125
2023-01-07 08:16:58,317 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,317 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,317 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,317 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 258.3998107910156
2023-01-07 08:16:58,317 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,317 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,317 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:16:58,317 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,317 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,317 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,319 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 258.3998107910156
2023-01-07 08:16:58,319 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,319 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,319 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,319 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -2110.79248046875
2023-01-07 08:16:58,319 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,319 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,319 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,321 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -2110.79248046875
2023-01-07 08:16:58,321 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,321 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,321 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,321 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -551.2803344726562
2023-01-07 08:16:58,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,321 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,321 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,322 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 253.76300048828125
2023-01-07 08:16:58,322 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,322 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,322 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,322 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -551.2803344726562
2023-01-07 08:16:58,323 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,323 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,323 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,324 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -551.2803344726562
2023-01-07 08:16:58,324 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,324 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,324 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,325 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 121.17704772949219
2023-01-07 08:16:58,325 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,325 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,326 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1035.784423828125
2023-01-07 08:16:58,326 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,326 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,326 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,326 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 121.17704772949219
2023-01-07 08:16:58,326 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,326 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,326 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,328 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 121.17704772949219
2023-01-07 08:16:58,328 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,328 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,328 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,328 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -402.4701843261719
2023-01-07 08:16:58,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,328 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,328 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,329 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 258.16265869140625
2023-01-07 08:16:58,329 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,329 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,329 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,330 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -402.4701843261719
2023-01-07 08:16:58,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,330 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,331 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: -402.4701843261719
2023-01-07 08:16:58,331 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,331 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,331 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,332 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -164.15615844726562
2023-01-07 08:16:58,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,333 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 253.7120361328125
2023-01-07 08:16:58,333 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,333 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,333 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,333 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -164.15615844726562
2023-01-07 08:16:58,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,333 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,335 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -164.15615844726562
2023-01-07 08:16:58,335 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,335 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,335 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,335 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 24.89997100830078
2023-01-07 08:16:58,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,335 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,336 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1017.04736328125
2023-01-07 08:16:58,336 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,336 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,336 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,337 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 24.89997100830078
2023-01-07 08:16:58,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,337 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,338 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 24.89997100830078
2023-01-07 08:16:58,338 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,338 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,338 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,339 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 45.541603088378906
2023-01-07 08:16:58,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,339 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,340 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 254.711181640625
2023-01-07 08:16:58,340 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,340 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,340 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,340 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 45.541603088378906
2023-01-07 08:16:58,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,340 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,342 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 45.541603088378906
2023-01-07 08:16:58,342 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,342 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,342 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,342 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -148.56466674804688
2023-01-07 08:16:58,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,342 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,343 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 252.11099243164062
2023-01-07 08:16:58,343 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,343 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,343 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,344 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -148.56466674804688
2023-01-07 08:16:58,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,344 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,345 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -148.56466674804688
2023-01-07 08:16:58,345 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,345 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,345 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,346 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 125.61834716796875
2023-01-07 08:16:58,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,346 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,347 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1018.2921142578125
2023-01-07 08:16:58,347 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,347 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,347 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,347 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 125.61834716796875
2023-01-07 08:16:58,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,347 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,347 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,349 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 125.61834716796875
2023-01-07 08:16:58,349 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,349 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,349 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,349 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 234.55763244628906
2023-01-07 08:16:58,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,349 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,349 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,350 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 253.85382080078125
2023-01-07 08:16:58,350 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,350 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,350 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,351 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 234.55763244628906
2023-01-07 08:16:58,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,351 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,352 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 234.55763244628906
2023-01-07 08:16:58,352 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,352 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,352 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,353 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3100.9306640625
2023-01-07 08:16:58,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,353 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,354 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 252.79331970214844
2023-01-07 08:16:58,354 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,354 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,354 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,354 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3100.9306640625
2023-01-07 08:16:58,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,354 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,356 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -3100.9306640625
2023-01-07 08:16:58,356 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,356 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,356 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,356 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -20860.16796875
2023-01-07 08:16:58,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,357 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1023.8760986328125
2023-01-07 08:16:58,357 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,357 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,357 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,357 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -20860.16796875
2023-01-07 08:16:58,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,358 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,359 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -20860.16796875
2023-01-07 08:16:58,359 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,359 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,359 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,360 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -9357.12890625
2023-01-07 08:16:58,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,361 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 255.11895751953125
2023-01-07 08:16:58,361 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,361 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,361 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,361 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -9357.12890625
2023-01-07 08:16:58,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,363 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -9357.12890625
2023-01-07 08:16:58,363 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,363 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,363 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,363 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23785.70703125
2023-01-07 08:16:58,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,364 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 257.50921630859375
2023-01-07 08:16:58,364 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,364 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,364 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,364 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23785.70703125
2023-01-07 08:16:58,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,365 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,366 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -23785.70703125
2023-01-07 08:16:58,366 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,366 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,366 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,366 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50419.0234375
2023-01-07 08:16:58,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,367 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,368 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1020.1036376953125
2023-01-07 08:16:58,368 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,368 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,368 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,368 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50419.0234375
2023-01-07 08:16:58,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,370 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -50419.0234375
2023-01-07 08:16:58,370 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,370 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,370 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,370 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -42816.90234375
2023-01-07 08:16:58,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,371 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 603.3253784179688
2023-01-07 08:16:58,371 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,371 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,371 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,371 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -42816.90234375
2023-01-07 08:16:58,372 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,372 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,372 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,373 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -42816.90234375
2023-01-07 08:16:58,373 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,373 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,373 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,373 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 390.4900207519531
2023-01-07 08:16:58,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,374 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,375 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 604.3255615234375
2023-01-07 08:16:58,375 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,375 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,375 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,375 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 390.4900207519531
2023-01-07 08:16:58,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,376 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,377 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 390.4900207519531
2023-01-07 08:16:58,377 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,377 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,377 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,377 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -123134.25
2023-01-07 08:16:58,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,378 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,378 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2146.7978515625
2023-01-07 08:16:58,378 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,378 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,378 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,379 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -123134.25
2023-01-07 08:16:58,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,379 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,380 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -123134.25
2023-01-07 08:16:58,380 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,380 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,380 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,381 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26717.767578125
2023-01-07 08:16:58,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,381 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,382 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2112.862060546875
2023-01-07 08:16:58,382 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,382 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,382 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,382 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26717.767578125
2023-01-07 08:16:58,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,382 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,384 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -26717.767578125
2023-01-07 08:16:58,384 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,384 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,384 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,384 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 518.1917724609375
2023-01-07 08:16:58,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,385 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 604.6728515625
2023-01-07 08:16:58,385 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,385 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,385 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,386 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 518.1917724609375
2023-01-07 08:16:58,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,386 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,387 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 518.1917724609375
2023-01-07 08:16:58,387 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,387 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,387 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,388 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -34173.953125
2023-01-07 08:16:58,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,388 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,389 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 598.9451293945312
2023-01-07 08:16:58,389 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,389 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,389 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,389 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -34173.953125
2023-01-07 08:16:58,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,389 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,391 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -34173.953125
2023-01-07 08:16:58,391 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,391 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,391 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,391 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102892.90625
2023-01-07 08:16:58,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,391 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,391 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,392 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2142.8466796875
2023-01-07 08:16:58,392 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,393 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,393 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,393 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102892.90625
2023-01-07 08:16:58,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,395 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -102892.90625
2023-01-07 08:16:58,395 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,395 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,395 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,395 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -12692.052734375
2023-01-07 08:16:58,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,395 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,396 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 603.6232299804688
2023-01-07 08:16:58,396 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,396 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,396 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,397 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -12692.052734375
2023-01-07 08:16:58,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,398 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -12692.052734375
2023-01-07 08:16:58,398 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,398 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,398 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,399 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 864.2205200195312
2023-01-07 08:16:58,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,400 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 594.40869140625
2023-01-07 08:16:58,400 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,400 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,400 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,400 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 864.2205200195312
2023-01-07 08:16:58,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,401 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,402 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 864.2205200195312
2023-01-07 08:16:58,402 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,402 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,402 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,402 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -149050.34375
2023-01-07 08:16:58,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,403 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,403 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2464.06640625
2023-01-07 08:16:58,403 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,404 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,404 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,404 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -149050.34375
2023-01-07 08:16:58,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,404 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:58,406 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -149050.34375
2023-01-07 08:16:58,406 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:58,406 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:58,406 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:58,407 > [DEBUG] 0 :: 23.542531967163086
2023-01-07 08:16:58,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,409 > [DEBUG] 0 :: before allreduce fusion buffer :: -386388.5
2023-01-07 08:16:58,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,410 > [DEBUG] 0 :: before allreduce fusion buffer :: -273524.21875
2023-01-07 08:16:58,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,413 > [DEBUG] 0 :: before allreduce fusion buffer :: -37887.84375
2023-01-07 08:16:58,415 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,415 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,415 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,415 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,416 > [DEBUG] 0 :: before allreduce fusion buffer :: -1594757.25
2023-01-07 08:16:58,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,419 > [DEBUG] 0 :: before allreduce fusion buffer :: -1938846.25
2023-01-07 08:16:58,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,420 > [DEBUG] 0 :: before allreduce fusion buffer :: 26625420.0
2023-01-07 08:16:58,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,422 > [DEBUG] 0 :: before allreduce fusion buffer :: -54327.125
2023-01-07 08:16:58,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,423 > [DEBUG] 0 :: before allreduce fusion buffer :: 27629284.0
2023-01-07 08:16:58,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,425 > [DEBUG] 0 :: before allreduce fusion buffer :: -9039010.0
2023-01-07 08:16:58,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,426 > [DEBUG] 0 :: before allreduce fusion buffer :: 1901684.875
2023-01-07 08:16:58,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,428 > [DEBUG] 0 :: before allreduce fusion buffer :: 18699892.0
2023-01-07 08:16:58,429 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,429 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,429 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,429 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,430 > [DEBUG] 0 :: before allreduce fusion buffer :: 105801224.0
2023-01-07 08:16:58,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,431 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,431 > [DEBUG] 0 :: before allreduce fusion buffer :: 177473920.0
2023-01-07 08:16:58,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,432 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,432 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,433 > [DEBUG] 0 :: before allreduce fusion buffer :: 69077552.0
2023-01-07 08:16:58,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,434 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,434 > [DEBUG] 0 :: before allreduce fusion buffer :: 356992896.0
2023-01-07 08:16:58,435 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,435 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,435 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,435 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,436 > [DEBUG] 0 :: before allreduce fusion buffer :: 264435040.0
2023-01-07 08:16:58,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,437 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,437 > [DEBUG] 0 :: before allreduce fusion buffer :: -731291136.0
2023-01-07 08:16:58,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,439 > [DEBUG] 0 :: before allreduce fusion buffer :: 303248768.0
2023-01-07 08:16:58,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,441 > [DEBUG] 0 :: before allreduce fusion buffer :: 44864164.0
2023-01-07 08:16:58,441 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,441 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,442 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,442 > [DEBUG] 0 :: before allreduce fusion buffer :: 506234592.0
2023-01-07 08:16:58,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,444 > [DEBUG] 0 :: before allreduce fusion buffer :: -1067672832.0
2023-01-07 08:16:58,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,445 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,445 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,445 > [DEBUG] 0 :: before allreduce fusion buffer :: -980920384.0
2023-01-07 08:16:58,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,447 > [DEBUG] 0 :: before allreduce fusion buffer :: -1429583360.0
2023-01-07 08:16:58,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,448 > [DEBUG] 0 :: before allreduce fusion buffer :: -1221788288.0
2023-01-07 08:16:58,450 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,450 > [DEBUG] 0 :: before allreduce fusion buffer :: -6305222656.0
2023-01-07 08:16:58,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,451 > [DEBUG] 0 :: before allreduce fusion buffer :: -9590855680.0
2023-01-07 08:16:58,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,453 > [DEBUG] 0 :: before allreduce fusion buffer :: -19477569536.0
2023-01-07 08:16:58,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,454 > [DEBUG] 0 :: before allreduce fusion buffer :: -51559399424.0
2023-01-07 08:16:58,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,456 > [DEBUG] 0 :: before allreduce fusion buffer :: -34337325056.0
2023-01-07 08:16:58,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,457 > [DEBUG] 0 :: before allreduce fusion buffer :: -5778308608.0
2023-01-07 08:16:58,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,459 > [DEBUG] 0 :: before allreduce fusion buffer :: -52628729856.0
2023-01-07 08:16:58,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,460 > [DEBUG] 0 :: before allreduce fusion buffer :: -127289638912.0
2023-01-07 08:16:58,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,462 > [DEBUG] 0 :: before allreduce fusion buffer :: -424519598080.0
2023-01-07 08:16:58,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 65047136.0
2023-01-07 08:16:58,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,465 > [DEBUG] 0 :: before allreduce fusion buffer :: -713740910592.0
2023-01-07 08:16:58,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,466 > [DEBUG] 0 :: before allreduce fusion buffer :: -1538334916608.0
2023-01-07 08:16:58,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,468 > [DEBUG] 0 :: before allreduce fusion buffer :: -1554760073216.0
2023-01-07 08:16:58,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,469 > [DEBUG] 0 :: before allreduce fusion buffer :: -3093560033280.0
2023-01-07 08:16:58,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,471 > [DEBUG] 0 :: before allreduce fusion buffer :: -6187185602560.0
2023-01-07 08:16:58,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,472 > [DEBUG] 0 :: before allreduce fusion buffer :: -5684119207936.0
2023-01-07 08:16:58,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,474 > [DEBUG] 0 :: before allreduce fusion buffer :: -522046930944.0
2023-01-07 08:16:58,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,475 > [DEBUG] 0 :: before allreduce fusion buffer :: -7409821024256.0
2023-01-07 08:16:58,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,477 > [DEBUG] 0 :: before allreduce fusion buffer :: 12387658760192.0
2023-01-07 08:16:58,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,478 > [DEBUG] 0 :: before allreduce fusion buffer :: 11172130586624.0
2023-01-07 08:16:58,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,480 > [DEBUG] 0 :: before allreduce fusion buffer :: 98178112159744.0
2023-01-07 08:16:58,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,481 > [DEBUG] 0 :: before allreduce fusion buffer :: -48567716675584.0
2023-01-07 08:16:58,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,483 > [DEBUG] 0 :: before allreduce fusion buffer :: 216630013460480.0
2023-01-07 08:16:58,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,485 > [DEBUG] 0 :: before allreduce fusion buffer :: 412992948666368.0
2023-01-07 08:16:58,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,486 > [DEBUG] 0 :: before allreduce fusion buffer :: 755746740371456.0
2023-01-07 08:16:58,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,488 > [DEBUG] 0 :: before allreduce fusion buffer :: 1581816859328512.0
2023-01-07 08:16:58,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,489 > [DEBUG] 0 :: before allreduce fusion buffer :: 2637192329428992.0
2023-01-07 08:16:58,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,490 > [DEBUG] 0 :: before allreduce fusion buffer :: -194079103123456.0
2023-01-07 08:16:58,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,492 > [DEBUG] 0 :: before allreduce fusion buffer :: -198737920000.0
2023-01-07 08:16:58,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,493 > [DEBUG] 0 :: before allreduce fusion buffer :: -194077660282880.0
2023-01-07 08:16:58,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,495 > [DEBUG] 0 :: before allreduce fusion buffer :: 2415235935764480.0
2023-01-07 08:16:58,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,496 > [DEBUG] 0 :: before allreduce fusion buffer :: 6481871227584512.0
2023-01-07 08:16:58,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,585 > [DEBUG] 0 :: before allreduce fusion buffer :: 1453830860439552.0
2023-01-07 08:16:58,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,586 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.4416259592486912e+16
2023-01-07 08:16:58,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,587 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.7353633095942144e+16
2023-01-07 08:16:58,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,588 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,588 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.809306969800704e+16
2023-01-07 08:16:58,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,590 > [DEBUG] 0 :: before allreduce fusion buffer :: -18533840846848.0
2023-01-07 08:16:58,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,591 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.616760661213184e+16
2023-01-07 08:16:58,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,592 > [DEBUG] 0 :: before allreduce fusion buffer :: -75179040440320.0
2023-01-07 08:16:58,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,593 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.605403479192371e+16
2023-01-07 08:16:58,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,594 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0999736803577037e+17
2023-01-07 08:16:58,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,596 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.2112781716370227e+17
2023-01-07 08:16:58,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,597 > [DEBUG] 0 :: before allreduce fusion buffer :: -613991478984704.0
2023-01-07 08:16:58,767 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,767 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,768 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.4164241607675085e+17
2023-01-07 08:16:58,769 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,769 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,769 > [DEBUG] 0 :: before allreduce fusion buffer :: -2387286704521216.0
2023-01-07 08:16:58,770 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,770 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,770 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.80897517531693e+17
2023-01-07 08:16:58,771 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,771 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,772 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7468419518035395e+18
2023-01-07 08:16:58,772 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,773 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,773 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,773 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,773 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.583426475524902
2023-01-07 08:16:58,952 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,952 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,952 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.913087096310989e+16
2023-01-07 08:16:58,953 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,953 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,953 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.4895090579564134e+18
2023-01-07 08:16:58,954 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:58,954 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:58,955 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.652348385243955e+16
2023-01-07 08:16:59,068 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,068 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,068 > [DEBUG] 0 :: before allreduce fusion buffer :: -3327.41015625
2023-01-07 08:16:59,070 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,070 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,070 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.591786691750789e+17
2023-01-07 08:16:59,072 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,072 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,072 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,072 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,072 > [DEBUG] 0 :: before allreduce fusion buffer :: -9141.1396484375
2023-01-07 08:16:59,073 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,074 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,074 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4368127611987558e+17
2023-01-07 08:16:59,075 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,075 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,075 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.3070505851918746e+17
2023-01-07 08:16:59,076 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,076 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,076 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.613610513319854e+17
2023-01-07 08:16:59,077 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,077 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,077 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.7227221026639708e+18
2023-01-07 08:16:59,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,078 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,079 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.4454442053279416e+18
2023-01-07 08:16:59,080 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,080 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,080 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,080 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,080 > [DEBUG] 0 :: before allreduce fusion buffer :: 749919.3125
2023-01-07 08:16:59,081 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,081 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,082 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.890888410655883e+18
2023-01-07 08:16:59,082 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,083 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,083 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,083 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,083 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,083 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,083 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.72620158967344e+20
2023-01-07 08:16:59,085 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,085 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,085 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,086 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,086 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,086 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,087 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,087 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,087 > [DEBUG] 0 :: before allreduce fusion buffer :: -30.540761947631836
2023-01-07 08:16:59,088 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,088 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,088 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,088 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,089 > [DEBUG] 0 :: before allreduce fusion buffer :: 72.01510620117188
2023-01-07 08:16:59,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,090 > [DEBUG] 0 :: before allreduce fusion buffer :: 45.98423767089844
2023-01-07 08:16:59,091 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,091 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,091 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,091 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,092 > [DEBUG] 0 :: before allreduce fusion buffer :: -87.2685317993164
2023-01-07 08:16:59,093 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,093 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,093 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.018571853637695
2023-01-07 08:16:59,094 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,094 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,094 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,094 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,094 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.51602547178991e+26
2023-01-07 08:16:59,096 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,096 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,096 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.07607650756836
2023-01-07 08:16:59,097 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,097 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,097 > [DEBUG] 0 :: before allreduce fusion buffer :: -48.29452896118164
2023-01-07 08:16:59,099 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,099 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,099 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3024067878723145
2023-01-07 08:16:59,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,100 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.5586712533096174e+28
2023-01-07 08:16:59,102 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,102 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,102 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.777501106262207
2023-01-07 08:16:59,103 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,103 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,103 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.330280303955078
2023-01-07 08:16:59,104 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,104 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,105 > [DEBUG] 0 :: before allreduce fusion buffer :: 11285.37109375
2023-01-07 08:16:59,105 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,105 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,106 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,106 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,106 > [DEBUG] 0 :: before allreduce fusion buffer :: 104.7317123413086
2023-01-07 08:16:59,107 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,107 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,108 > [DEBUG] 0 :: before allreduce fusion buffer :: 41.74359130859375
2023-01-07 08:16:59,108 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,108 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,109 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,109 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,109 > [DEBUG] 0 :: before allreduce fusion buffer :: 76.42027282714844
2023-01-07 08:16:59,110 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,110 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,110 > [DEBUG] 0 :: before allreduce fusion buffer :: -31.448320388793945
2023-01-07 08:16:59,111 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,111 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,112 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.232883930206299
2023-01-07 08:16:59,114 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:16:59,115 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,115 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,115 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,115 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,116 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,116 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,116 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,116 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,116 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,117 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,117 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,117 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,117 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,117 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,118 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,118 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,118 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,118 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,119 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,119 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,119 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,119 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,120 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,120 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,120 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,120 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,120 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,121 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,121 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,121 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,121 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,122 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,122 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,122 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,122 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,122 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,123 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,123 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,123 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,123 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,124 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,124 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,125 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,125 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,125 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,125 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,125 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,126 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,126 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,126 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,127 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.092505179678721e+36
2023-01-07 08:16:59,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,131 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,131 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,131 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,131 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,131 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,131 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,131 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,131 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,132 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,132 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,132 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,132 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,132 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.740041437429768e+36
2023-01-07 08:16:59,133 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,133 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,133 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,133 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,134 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,134 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,134 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,134 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,134 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.1381503511886467e+21
2023-01-07 08:16:59,135 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,135 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,135 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,135 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,135 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,135 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,135 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,136 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,136 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,136 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,136 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,136 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.2799731063984373e+21
2023-01-07 08:16:59,137 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -11.12730598449707
2023-01-07 08:16:59,137 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,137 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,137 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,137 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 65.27420806884766
2023-01-07 08:16:59,137 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,137 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,137 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,138 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,138 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.72082682499315e+20
2023-01-07 08:16:59,139 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 65.27420806884766
2023-01-07 08:16:59,139 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,139 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,139 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,139 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: -35.69520568847656
2023-01-07 08:16:59,139 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,139 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,140 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,140 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,140 > [DEBUG] 0 :: before allreduce fusion buffer :: -405.992919921875
2023-01-07 08:16:59,141 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -35.69520568847656
2023-01-07 08:16:59,141 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,142 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,142 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,142 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -135.62371826171875
2023-01-07 08:16:59,142 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,142 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,142 > [DEBUG] 0 :: before allreduce fusion buffer :: 159.41897583007812
2023-01-07 08:16:59,143 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 61.27440643310547
2023-01-07 08:16:59,143 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,143 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,143 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,143 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -135.62371826171875
2023-01-07 08:16:59,143 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,143 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,143 > [DEBUG] 0 :: before allreduce fusion buffer :: -234.9833221435547
2023-01-07 08:16:59,145 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: -135.62371826171875
2023-01-07 08:16:59,145 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,145 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,145 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,145 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 60.56239318847656
2023-01-07 08:16:59,145 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,145 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,145 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,145 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,145 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,145 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,146 > [DEBUG] 0 :: before allreduce fusion buffer :: -214.7889404296875
2023-01-07 08:16:59,147 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 60.56239318847656
2023-01-07 08:16:59,147 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,147 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,147 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,148 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -96.48509979248047
2023-01-07 08:16:59,148 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,148 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,148 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.89244270324707
2023-01-07 08:16:59,149 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 26.071264266967773
2023-01-07 08:16:59,149 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,149 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,149 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,149 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 251.962890625
2023-01-07 08:16:59,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,150 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,150 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,150 > [DEBUG] 0 :: before allreduce fusion buffer :: 99.18183135986328
2023-01-07 08:16:59,151 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 251.962890625
2023-01-07 08:16:59,151 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,152 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,152 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,152 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -63.541439056396484
2023-01-07 08:16:59,152 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,152 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,152 > [DEBUG] 0 :: before allreduce fusion buffer :: 98.17082214355469
2023-01-07 08:16:59,153 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -38.29423904418945
2023-01-07 08:16:59,153 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,153 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,153 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,153 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -63.541439056396484
2023-01-07 08:16:59,153 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,153 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,153 > [DEBUG] 0 :: before allreduce fusion buffer :: -13174.716796875
2023-01-07 08:16:59,154 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 246.95352172851562
2023-01-07 08:16:59,154 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,154 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,154 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,155 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -63.541439056396484
2023-01-07 08:16:59,155 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,155 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,155 > [DEBUG] 0 :: before allreduce fusion buffer :: 134.896484375
2023-01-07 08:16:59,156 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: -4.647648334503174
2023-01-07 08:16:59,156 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,156 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,156 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,156 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 65.27420043945312
2023-01-07 08:16:59,156 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,156 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,157 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,157 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,157 > [DEBUG] 0 :: before allreduce fusion buffer :: 71.62507629394531
2023-01-07 08:16:59,158 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 65.27420043945312
2023-01-07 08:16:59,158 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,158 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,158 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,158 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -63.541439056396484
2023-01-07 08:16:59,158 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,158 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,159 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,159 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,159 > [DEBUG] 0 :: before allreduce fusion buffer :: -93.34090423583984
2023-01-07 08:16:59,160 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: -63.541439056396484
2023-01-07 08:16:59,160 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,160 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,160 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,160 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 65.27420043945312
2023-01-07 08:16:59,161 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,161 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,161 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,161 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,161 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.64995765686035
2023-01-07 08:16:59,163 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 65.27420043945312
2023-01-07 08:16:59,163 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,163 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,163 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,163 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -96.48509979248047
2023-01-07 08:16:59,163 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,163 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,163 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.117145538330078
2023-01-07 08:16:59,164 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: -59.51688766479492
2023-01-07 08:16:59,164 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,164 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,164 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,164 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -8.183683395385742
2023-01-07 08:16:59,165 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,165 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,165 > [DEBUG] 0 :: before allreduce fusion buffer :: 85.0734634399414
2023-01-07 08:16:59,166 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 249.96768188476562
2023-01-07 08:16:59,166 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,166 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,166 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,166 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -8.183683395385742
2023-01-07 08:16:59,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,166 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.76579761505127
2023-01-07 08:16:59,168 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: -8.183683395385742
2023-01-07 08:16:59,168 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,168 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,168 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,168 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -96.48509979248047
2023-01-07 08:16:59,168 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,168 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,169 > [DEBUG] 0 :: before allreduce fusion buffer :: -923.49658203125
2023-01-07 08:16:59,169 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 67.12535858154297
2023-01-07 08:16:59,169 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,169 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,169 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,170 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -96.48509979248047
2023-01-07 08:16:59,170 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,170 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,170 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.754507064819336
2023-01-07 08:16:59,171 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: -96.48509979248047
2023-01-07 08:16:59,171 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,171 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,171 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,172 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 65.67431640625
2023-01-07 08:16:59,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,172 > [DEBUG] 0 :: before allreduce fusion buffer :: -7480.8056640625
2023-01-07 08:16:59,174 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 65.67431640625
2023-01-07 08:16:59,174 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,174 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,174 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,174 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 423.3109130859375
2023-01-07 08:16:59,174 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,174 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,174 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,175 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 37.36722946166992
2023-01-07 08:16:59,176 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,176 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,176 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,176 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 330.0150451660156
2023-01-07 08:16:59,176 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,176 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,176 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,177 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 251.7628631591797
2023-01-07 08:16:59,177 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,177 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,177 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,178 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 423.3109130859375
2023-01-07 08:16:59,178 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,178 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,178 > [DEBUG] 0 :: before allreduce fusion buffer :: 3533.6923828125
2023-01-07 08:16:59,179 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 330.0150451660156
2023-01-07 08:16:59,179 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,179 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,179 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,179 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 423.3109130859375
2023-01-07 08:16:59,179 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,179 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,180 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,180 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 126.49742889404297
2023-01-07 08:16:59,181 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,181 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,181 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,181 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 423.3109130859375
2023-01-07 08:16:59,181 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,181 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,181 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,182 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 423.3109130859375
2023-01-07 08:16:59,183 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,183 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,183 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,183 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 127.66597747802734
2023-01-07 08:16:59,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,183 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,183 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,183 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,185 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 127.66597747802734
2023-01-07 08:16:59,185 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,185 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,185 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,185 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 490.55096435546875
2023-01-07 08:16:59,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,185 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,185 > [DEBUG] 0 :: before allreduce fusion buffer :: -8915009929216.0
2023-01-07 08:16:59,186 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 490.55096435546875
2023-01-07 08:16:59,186 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,187 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,187 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,187 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 522.02099609375
2023-01-07 08:16:59,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,187 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,188 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 522.02099609375
2023-01-07 08:16:59,189 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,189 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,189 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,189 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 60.71630096435547
2023-01-07 08:16:59,189 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,189 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,189 > [DEBUG] 0 :: before allreduce fusion buffer :: -639575552.0
2023-01-07 08:16:59,190 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 60.71630096435547
2023-01-07 08:16:59,190 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,190 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,190 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,190 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 147.2224578857422
2023-01-07 08:16:59,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,191 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,192 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 508.6784362792969
2023-01-07 08:16:59,192 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,192 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,192 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,192 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 147.2224578857422
2023-01-07 08:16:59,192 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,192 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,192 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,194 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 147.2224578857422
2023-01-07 08:16:59,194 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,194 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,194 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,194 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 127.23084259033203
2023-01-07 08:16:59,194 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,194 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,194 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,194 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,194 > [DEBUG] 0 :: before allreduce fusion buffer :: -557715947520.0
2023-01-07 08:16:59,196 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 127.23084259033203
2023-01-07 08:16:59,196 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,196 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,196 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,196 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 40.47438430786133
2023-01-07 08:16:59,196 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,196 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,196 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,198 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 40.47438430786133
2023-01-07 08:16:59,198 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,198 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,198 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,198 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 126.8998031616211
2023-01-07 08:16:59,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,199 > [DEBUG] 0 :: before allreduce fusion buffer :: -12051600637952.0
2023-01-07 08:16:59,200 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 126.8998031616211
2023-01-07 08:16:59,200 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,200 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,200 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,200 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: -226.4637451171875
2023-01-07 08:16:59,200 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,200 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,200 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,202 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -226.4637451171875
2023-01-07 08:16:59,202 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,202 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,202 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,202 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -123.02398681640625
2023-01-07 08:16:59,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,202 > [DEBUG] 0 :: before allreduce fusion buffer :: -385651220414464.0
2023-01-07 08:16:59,203 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 487.4565734863281
2023-01-07 08:16:59,203 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,203 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,203 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,204 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -123.02398681640625
2023-01-07 08:16:59,204 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,204 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,204 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,205 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -123.02398681640625
2023-01-07 08:16:59,205 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,205 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,205 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,206 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 126.80496215820312
2023-01-07 08:16:59,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,206 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,207 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 126.80496215820312
2023-01-07 08:16:59,207 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,208 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,208 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,208 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 29.040225982666016
2023-01-07 08:16:59,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,208 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,209 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 29.040225982666016
2023-01-07 08:16:59,209 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,210 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,210 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,210 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 127.65391540527344
2023-01-07 08:16:59,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,210 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,211 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 127.65391540527344
2023-01-07 08:16:59,212 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,212 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,212 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,212 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -51.7515869140625
2023-01-07 08:16:59,212 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,212 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,212 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,214 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -51.7515869140625
2023-01-07 08:16:59,214 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,214 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,214 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,214 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 524.498046875
2023-01-07 08:16:59,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,214 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,216 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 524.498046875
2023-01-07 08:16:59,216 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,216 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,216 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,216 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -137.17294311523438
2023-01-07 08:16:59,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,216 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,216 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,218 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -137.17294311523438
2023-01-07 08:16:59,218 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,218 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,218 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,218 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 127.67143249511719
2023-01-07 08:16:59,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,218 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,220 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 127.67143249511719
2023-01-07 08:16:59,220 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,220 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,220 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,220 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -1.7840824127197266
2023-01-07 08:16:59,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,220 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,222 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -1.7840824127197266
2023-01-07 08:16:59,222 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,222 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,222 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,222 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 129.94583129882812
2023-01-07 08:16:59,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,222 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,224 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 129.94583129882812
2023-01-07 08:16:59,224 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,224 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,224 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,224 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: -44.10048294067383
2023-01-07 08:16:59,224 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,224 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,225 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,226 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -44.10048294067383
2023-01-07 08:16:59,226 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,226 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,226 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,226 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 524.4584350585938
2023-01-07 08:16:59,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,227 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,228 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 524.4584350585938
2023-01-07 08:16:59,228 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,228 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,228 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,228 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 3.4446792602539062
2023-01-07 08:16:59,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,228 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,230 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 3.4446792602539062
2023-01-07 08:16:59,230 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,230 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,230 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,230 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 258.3418273925781
2023-01-07 08:16:59,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,230 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,231 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,231 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,231 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,232 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 258.3418273925781
2023-01-07 08:16:59,232 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,232 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,232 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,233 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -35847.75390625
2023-01-07 08:16:59,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,233 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,234 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -35847.75390625
2023-01-07 08:16:59,234 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,234 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,234 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,234 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -978.173583984375
2023-01-07 08:16:59,235 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,235 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,235 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,236 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 254.69662475585938
2023-01-07 08:16:59,236 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,236 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,236 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,236 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -978.173583984375
2023-01-07 08:16:59,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,236 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,238 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -978.173583984375
2023-01-07 08:16:59,238 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,238 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,238 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,238 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -2495.88671875
2023-01-07 08:16:59,238 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,238 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,238 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,239 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1013.21728515625
2023-01-07 08:16:59,239 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,240 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,240 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,240 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -2495.88671875
2023-01-07 08:16:59,240 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,240 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,240 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,242 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -2495.88671875
2023-01-07 08:16:59,242 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,242 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,242 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,242 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1783.771484375
2023-01-07 08:16:59,242 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,242 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,243 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,243 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1025.81689453125
2023-01-07 08:16:59,243 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,244 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,244 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,244 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1783.771484375
2023-01-07 08:16:59,244 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,244 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,244 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,245 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1783.771484375
2023-01-07 08:16:59,246 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,246 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,246 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,246 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 256.91094970703125
2023-01-07 08:16:59,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,246 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,246 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,246 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,246 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,248 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.91094970703125
2023-01-07 08:16:59,248 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,248 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,248 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,248 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -3511.67236328125
2023-01-07 08:16:59,248 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,248 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,248 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,250 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -3511.67236328125
2023-01-07 08:16:59,250 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,250 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,250 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,250 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -874.874267578125
2023-01-07 08:16:59,250 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,250 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,250 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,251 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 252.49749755859375
2023-01-07 08:16:59,251 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,251 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,251 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,251 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -874.874267578125
2023-01-07 08:16:59,251 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,251 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,252 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,253 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -874.874267578125
2023-01-07 08:16:59,253 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,253 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,253 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,253 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 237.11236572265625
2023-01-07 08:16:59,253 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,254 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,255 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1037.8883056640625
2023-01-07 08:16:59,255 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,255 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,255 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,255 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 237.11236572265625
2023-01-07 08:16:59,255 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,255 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,255 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,257 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 237.11236572265625
2023-01-07 08:16:59,257 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,257 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,257 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,257 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -567.04345703125
2023-01-07 08:16:59,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,257 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,257 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,258 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 256.9175720214844
2023-01-07 08:16:59,258 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,258 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,258 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,258 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -567.04345703125
2023-01-07 08:16:59,258 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,258 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,259 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,260 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: -567.04345703125
2023-01-07 08:16:59,260 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,260 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,260 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,260 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -104.06478881835938
2023-01-07 08:16:59,260 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,260 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,261 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,262 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 252.56158447265625
2023-01-07 08:16:59,262 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,262 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,262 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,262 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -104.06478881835938
2023-01-07 08:16:59,262 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,262 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,262 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,264 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -104.06478881835938
2023-01-07 08:16:59,264 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,264 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,264 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,264 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 101.78665161132812
2023-01-07 08:16:59,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,264 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,265 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1020.6141967773438
2023-01-07 08:16:59,265 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,265 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,265 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,265 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 101.78665161132812
2023-01-07 08:16:59,265 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,265 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,266 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,267 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 101.78665161132812
2023-01-07 08:16:59,267 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,267 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,267 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,267 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -341.6167297363281
2023-01-07 08:16:59,267 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,267 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,268 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,268 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 253.605224609375
2023-01-07 08:16:59,269 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,269 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,269 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,269 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -341.6167297363281
2023-01-07 08:16:59,269 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,269 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,269 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,270 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: -341.6167297363281
2023-01-07 08:16:59,270 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,271 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,271 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,271 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -194.0314178466797
2023-01-07 08:16:59,271 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,271 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,272 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 251.00115966796875
2023-01-07 08:16:59,272 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,272 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,272 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,272 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -194.0314178466797
2023-01-07 08:16:59,272 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,272 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,273 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,274 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -194.0314178466797
2023-01-07 08:16:59,274 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,274 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,274 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,274 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 198.41165161132812
2023-01-07 08:16:59,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,275 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,275 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.69189453125
2023-01-07 08:16:59,275 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,275 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,276 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,276 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 198.41165161132812
2023-01-07 08:16:59,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,276 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,276 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,277 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 198.41165161132812
2023-01-07 08:16:59,277 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,277 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,278 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,278 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 379.5831298828125
2023-01-07 08:16:59,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,278 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,279 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 253.2783660888672
2023-01-07 08:16:59,279 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,279 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,279 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,279 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 379.5831298828125
2023-01-07 08:16:59,279 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,279 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,279 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,281 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 379.5831298828125
2023-01-07 08:16:59,281 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,281 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,281 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,281 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -5251.603515625
2023-01-07 08:16:59,281 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,281 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,281 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,282 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 252.76669311523438
2023-01-07 08:16:59,282 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,282 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,282 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,283 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -5251.603515625
2023-01-07 08:16:59,283 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,283 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,283 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,284 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -5251.603515625
2023-01-07 08:16:59,284 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,284 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,285 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,285 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -34919.46484375
2023-01-07 08:16:59,285 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,285 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,286 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1025.936279296875
2023-01-07 08:16:59,286 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,286 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,286 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,286 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -34919.46484375
2023-01-07 08:16:59,286 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,286 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,286 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,288 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -34919.46484375
2023-01-07 08:16:59,288 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,288 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,288 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,288 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -15653.0390625
2023-01-07 08:16:59,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,288 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,289 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,289 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 258.45526123046875
2023-01-07 08:16:59,289 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,290 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,290 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,290 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -15653.0390625
2023-01-07 08:16:59,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,290 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,290 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,291 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -15653.0390625
2023-01-07 08:16:59,291 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,292 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,292 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,292 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -39764.5625
2023-01-07 08:16:59,292 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,292 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,292 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,293 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 260.8454895019531
2023-01-07 08:16:59,293 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,293 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,293 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,293 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -39764.5625
2023-01-07 08:16:59,293 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,293 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,293 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,295 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -39764.5625
2023-01-07 08:16:59,295 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,295 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,295 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,295 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -84246.421875
2023-01-07 08:16:59,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,295 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,296 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,296 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.3773193359375
2023-01-07 08:16:59,296 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,296 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,296 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,297 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -84246.421875
2023-01-07 08:16:59,297 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,297 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,297 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,298 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -84246.421875
2023-01-07 08:16:59,298 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,298 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,299 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,299 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -71739.4921875
2023-01-07 08:16:59,299 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,299 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,299 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,300 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 605.75146484375
2023-01-07 08:16:59,300 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,300 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,300 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,300 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -71739.4921875
2023-01-07 08:16:59,300 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,300 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,300 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,302 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -71739.4921875
2023-01-07 08:16:59,302 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,302 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,302 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,302 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 428.0843200683594
2023-01-07 08:16:59,302 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,302 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,302 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,304 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 606.7415771484375
2023-01-07 08:16:59,304 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,304 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,304 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,305 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 428.0843200683594
2023-01-07 08:16:59,305 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,305 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,305 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,307 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 428.0843200683594
2023-01-07 08:16:59,307 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,307 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,307 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,307 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -205863.640625
2023-01-07 08:16:59,307 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,307 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,307 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,308 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2148.2333984375
2023-01-07 08:16:59,308 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,308 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,308 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,309 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -205863.640625
2023-01-07 08:16:59,309 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,309 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,309 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,310 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -205863.640625
2023-01-07 08:16:59,310 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,310 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,310 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,310 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -44862.84375
2023-01-07 08:16:59,310 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,311 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,312 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2095.3515625
2023-01-07 08:16:59,312 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,312 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,312 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,312 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -44862.84375
2023-01-07 08:16:59,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,312 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,314 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -44862.84375
2023-01-07 08:16:59,314 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,314 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,314 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,314 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 552.6619262695312
2023-01-07 08:16:59,314 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,314 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,314 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,315 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 607.2044677734375
2023-01-07 08:16:59,315 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,315 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,315 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,315 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 552.6619262695312
2023-01-07 08:16:59,315 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,315 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,316 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,317 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 552.6619262695312
2023-01-07 08:16:59,317 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,317 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,317 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,317 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -57174.09375
2023-01-07 08:16:59,318 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,318 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,318 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,319 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 597.4866943359375
2023-01-07 08:16:59,319 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,319 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,319 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,319 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -57174.09375
2023-01-07 08:16:59,319 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,319 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,319 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,321 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -57174.09375
2023-01-07 08:16:59,321 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,321 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,321 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,321 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -171956.46875
2023-01-07 08:16:59,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,321 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,321 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,322 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2144.802734375
2023-01-07 08:16:59,322 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,322 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,322 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,322 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -171956.46875
2023-01-07 08:16:59,323 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,323 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,323 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,324 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -171956.46875
2023-01-07 08:16:59,324 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,324 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,324 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,325 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -21478.58984375
2023-01-07 08:16:59,325 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,325 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,326 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 606.275390625
2023-01-07 08:16:59,326 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,326 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,326 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,326 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -21478.58984375
2023-01-07 08:16:59,326 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,326 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,326 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,328 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -21478.58984375
2023-01-07 08:16:59,328 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,328 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,328 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,328 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 1128.724365234375
2023-01-07 08:16:59,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,328 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,328 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,329 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 589.4657592773438
2023-01-07 08:16:59,329 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,329 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,329 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,330 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 1128.724365234375
2023-01-07 08:16:59,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,330 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,331 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 1128.724365234375
2023-01-07 08:16:59,331 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,331 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,331 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,332 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -249592.0
2023-01-07 08:16:59,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,333 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2473.43310546875
2023-01-07 08:16:59,333 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,333 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,333 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,333 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -249592.0
2023-01-07 08:16:59,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,333 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:16:59,335 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -249592.0
2023-01-07 08:16:59,335 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:16:59,335 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:16:59,335 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:16:59,336 > [DEBUG] 0 :: 66.20438385009766
2023-01-07 08:16:59,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,340 > [DEBUG] 0 :: before allreduce fusion buffer :: 4011109376.0
2023-01-07 08:16:59,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,342 > [DEBUG] 0 :: before allreduce fusion buffer :: 14201608192.0
2023-01-07 08:16:59,345 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,345 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,346 > [DEBUG] 0 :: before allreduce fusion buffer :: -160.97586059570312
2023-01-07 08:16:59,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,348 > [DEBUG] 0 :: before allreduce fusion buffer :: 14201597952.0
2023-01-07 08:16:59,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,351 > [DEBUG] 0 :: before allreduce fusion buffer :: -4839.1982421875
2023-01-07 08:16:59,352 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,353 > [DEBUG] 0 :: before allreduce fusion buffer :: 24766263296.0
2023-01-07 08:16:59,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,355 > [DEBUG] 0 :: before allreduce fusion buffer :: -18480.990234375
2023-01-07 08:16:59,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,356 > [DEBUG] 0 :: before allreduce fusion buffer :: -923316.125
2023-01-07 08:16:59,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,358 > [DEBUG] 0 :: before allreduce fusion buffer :: -1624.694580078125
2023-01-07 08:16:59,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,359 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,359 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,359 > [DEBUG] 0 :: before allreduce fusion buffer :: 26583748608.0
2023-01-07 08:16:59,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,361 > [DEBUG] 0 :: before allreduce fusion buffer :: -38630.078125
2023-01-07 08:16:59,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,362 > [DEBUG] 0 :: before allreduce fusion buffer :: 24661676032.0
2023-01-07 08:16:59,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,364 > [DEBUG] 0 :: before allreduce fusion buffer :: -77559.6171875
2023-01-07 08:16:59,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,365 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,365 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 53162942464.0
2023-01-07 08:16:59,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,367 > [DEBUG] 0 :: before allreduce fusion buffer :: -175039.78125
2023-01-07 08:16:59,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 106325819392.0
2023-01-07 08:16:59,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,370 > [DEBUG] 0 :: before allreduce fusion buffer :: -26634.13671875
2023-01-07 08:16:59,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,371 > [DEBUG] 0 :: before allreduce fusion buffer :: 106325434368.0
2023-01-07 08:16:59,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,373 > [DEBUG] 0 :: before allreduce fusion buffer :: -693294.5
2023-01-07 08:16:59,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,374 > [DEBUG] 0 :: before allreduce fusion buffer :: 213924380672.0
2023-01-07 08:16:59,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,376 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,376 > [DEBUG] 0 :: before allreduce fusion buffer :: -2761387.25
2023-01-07 08:16:59,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,377 > [DEBUG] 0 :: before allreduce fusion buffer :: 223562366976.0
2023-01-07 08:16:59,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,379 > [DEBUG] 0 :: before allreduce fusion buffer :: -314029.8125
2023-01-07 08:16:59,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,380 > [DEBUG] 0 :: before allreduce fusion buffer :: 450397798400.0
2023-01-07 08:16:59,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,383 > [DEBUG] 0 :: before allreduce fusion buffer :: -627478.75
2023-01-07 08:16:59,383 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 789242707968.0
2023-01-07 08:16:59,385 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,385 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,386 > [DEBUG] 0 :: before allreduce fusion buffer :: -2446056.5
2023-01-07 08:16:59,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,387 > [DEBUG] 0 :: before allreduce fusion buffer :: 919066050560.0
2023-01-07 08:16:59,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,389 > [DEBUG] 0 :: before allreduce fusion buffer :: -5019558.0
2023-01-07 08:16:59,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,390 > [DEBUG] 0 :: before allreduce fusion buffer :: 1843679199232.0
2023-01-07 08:16:59,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,391 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,392 > [DEBUG] 0 :: before allreduce fusion buffer :: -10039301.0
2023-01-07 08:16:59,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 3238670106624.0
2023-01-07 08:16:59,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,395 > [DEBUG] 0 :: before allreduce fusion buffer :: -31392848.0
2023-01-07 08:16:59,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,396 > [DEBUG] 0 :: before allreduce fusion buffer :: 6620339765248.0
2023-01-07 08:16:59,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,398 > [DEBUG] 0 :: before allreduce fusion buffer :: -16805272.0
2023-01-07 08:16:59,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 13558474604544.0
2023-01-07 08:16:59,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,401 > [DEBUG] 0 :: before allreduce fusion buffer :: -206302496.0
2023-01-07 08:16:59,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,402 > [DEBUG] 0 :: before allreduce fusion buffer :: 25827186049024.0
2023-01-07 08:16:59,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,404 > [DEBUG] 0 :: before allreduce fusion buffer :: -491002240.0
2023-01-07 08:16:59,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,405 > [DEBUG] 0 :: before allreduce fusion buffer :: 25921362853888.0
2023-01-07 08:16:59,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,407 > [DEBUG] 0 :: before allreduce fusion buffer :: -1650420352.0
2023-01-07 08:16:59,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,408 > [DEBUG] 0 :: before allreduce fusion buffer :: 52393777561600.0
2023-01-07 08:16:59,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,410 > [DEBUG] 0 :: before allreduce fusion buffer :: -3300840704.0
2023-01-07 08:16:59,411 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,411 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,411 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,411 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,411 > [DEBUG] 0 :: before allreduce fusion buffer :: 100179483033600.0
2023-01-07 08:16:59,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,413 > [DEBUG] 0 :: before allreduce fusion buffer :: -7215036416.0
2023-01-07 08:16:59,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,414 > [DEBUG] 0 :: before allreduce fusion buffer :: -14575481856.0
2023-01-07 08:16:59,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,416 > [DEBUG] 0 :: before allreduce fusion buffer :: -26406713344.0
2023-01-07 08:16:59,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,417 > [DEBUG] 0 :: before allreduce fusion buffer :: 1014060679168.0
2023-01-07 08:16:59,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,419 > [DEBUG] 0 :: before allreduce fusion buffer :: -52813418496.0
2023-01-07 08:16:59,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,420 > [DEBUG] 0 :: before allreduce fusion buffer :: -108080250880.0
2023-01-07 08:16:59,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,421 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,422 > [DEBUG] 0 :: before allreduce fusion buffer :: -103328317440.0
2023-01-07 08:16:59,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,423 > [DEBUG] 0 :: before allreduce fusion buffer :: 2065108828160.0
2023-01-07 08:16:59,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,424 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,425 > [DEBUG] 0 :: before allreduce fusion buffer :: -139293409280.0
2023-01-07 08:16:59,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,426 > [DEBUG] 0 :: before allreduce fusion buffer :: -1694.06591796875
2023-01-07 08:16:59,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,428 > [DEBUG] 0 :: before allreduce fusion buffer :: -557185171456.0
2023-01-07 08:16:59,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,429 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,429 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,429 > [DEBUG] 0 :: before allreduce fusion buffer :: 4130217656320.0
2023-01-07 08:16:59,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,583 > [DEBUG] 0 :: before allreduce fusion buffer :: -1114370342912.0
2023-01-07 08:16:59,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,585 > [DEBUG] 0 :: before allreduce fusion buffer :: -2228740423680.0
2023-01-07 08:16:59,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,586 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,586 > [DEBUG] 0 :: before allreduce fusion buffer :: -4457504964608.0
2023-01-07 08:16:59,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,587 > [DEBUG] 0 :: before allreduce fusion buffer :: -8914985811968.0
2023-01-07 08:16:59,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,588 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,589 > [DEBUG] 0 :: before allreduce fusion buffer :: -8915006783488.0
2023-01-07 08:16:59,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,590 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.612120270729065
2023-01-07 08:16:59,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,591 > [DEBUG] 0 :: before allreduce fusion buffer :: -79946944.0
2023-01-07 08:16:59,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,592 > [DEBUG] 0 :: before allreduce fusion buffer :: -159893888.0
2023-01-07 08:16:59,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,593 > [DEBUG] 0 :: before allreduce fusion buffer :: -319787776.0
2023-01-07 08:16:59,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,595 > [DEBUG] 0 :: before allreduce fusion buffer :: -319787776.0
2023-01-07 08:16:59,596 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,596 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,596 > [DEBUG] 0 :: before allreduce fusion buffer :: -639575552.0
2023-01-07 08:16:59,766 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,766 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,767 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.321144104003906
2023-01-07 08:16:59,768 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,768 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,768 > [DEBUG] 0 :: before allreduce fusion buffer :: -1279151104.0
2023-01-07 08:16:59,769 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,769 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,769 > [DEBUG] 0 :: before allreduce fusion buffer :: -2558302208.0
2023-01-07 08:16:59,770 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,770 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,771 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.196661472320557
2023-01-07 08:16:59,771 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,771 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,772 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,772 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,772 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.1830692291259766
2023-01-07 08:16:59,951 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,951 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,951 > [DEBUG] 0 :: before allreduce fusion buffer :: -10233208832.0
2023-01-07 08:16:59,952 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,952 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,953 > [DEBUG] 0 :: before allreduce fusion buffer :: -20466417664.0
2023-01-07 08:16:59,954 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:16:59,954 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:16:59,954 > [DEBUG] 0 :: before allreduce fusion buffer :: 237925171200.0
2023-01-07 08:17:00,066 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,066 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,067 > [DEBUG] 0 :: before allreduce fusion buffer :: -40932835328.0
2023-01-07 08:17:00,068 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,068 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,068 > [DEBUG] 0 :: before allreduce fusion buffer :: 61675470848.0
2023-01-07 08:17:00,069 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,069 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,069 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,069 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,069 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.134617805480957
2023-01-07 08:17:00,071 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,071 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,071 > [DEBUG] 0 :: before allreduce fusion buffer :: 1033804120064.0
2023-01-07 08:17:00,072 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,072 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,072 > [DEBUG] 0 :: before allreduce fusion buffer :: -1506450079744.0
2023-01-07 08:17:00,073 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,073 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,073 > [DEBUG] 0 :: before allreduce fusion buffer :: -3012900159488.0
2023-01-07 08:17:00,074 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,074 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,074 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.2439846992492676
2023-01-07 08:17:00,075 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,076 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,076 > [DEBUG] 0 :: before allreduce fusion buffer :: -6025800318976.0
2023-01-07 08:17:00,077 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,077 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,077 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,077 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,077 > [DEBUG] 0 :: before allreduce fusion buffer :: 23642222100480.0
2023-01-07 08:17:00,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,078 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,079 > [DEBUG] 0 :: before allreduce fusion buffer :: -24103201275904.0
2023-01-07 08:17:00,079 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,079 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,080 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,080 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,080 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,080 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,080 > [DEBUG] 0 :: before allreduce fusion buffer :: 2461372776448.0
2023-01-07 08:17:00,081 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,082 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,082 > [DEBUG] 0 :: before allreduce fusion buffer :: -48206402551808.0
2023-01-07 08:17:00,083 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,083 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,083 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,084 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,084 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,084 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.1548688411712646
2023-01-07 08:17:00,085 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,085 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,085 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,085 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,085 > [DEBUG] 0 :: before allreduce fusion buffer :: 4870180454793216.0
2023-01-07 08:17:00,087 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,087 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,087 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9578571319580078
2023-01-07 08:17:00,088 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,088 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,088 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,088 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,088 > [DEBUG] 0 :: before allreduce fusion buffer :: 38.326995849609375
2023-01-07 08:17:00,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,090 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.31922721862793
2023-01-07 08:17:00,091 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,091 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,091 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,091 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,091 > [DEBUG] 0 :: before allreduce fusion buffer :: 59.48662185668945
2023-01-07 08:17:00,092 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,093 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,093 > [DEBUG] 0 :: before allreduce fusion buffer :: 13.234628677368164
2023-01-07 08:17:00,094 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,094 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,094 > [DEBUG] 0 :: before allreduce fusion buffer :: 782.5285034179688
2023-01-07 08:17:00,095 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,095 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,095 > [DEBUG] 0 :: before allreduce fusion buffer :: -1575.759765625
2023-01-07 08:17:00,096 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,096 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,096 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,097 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,097 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,097 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,097 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,097 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,097 > [DEBUG] 0 :: before allreduce fusion buffer :: -107.843994140625
2023-01-07 08:17:00,098 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,099 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,099 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6924107074737549
2023-01-07 08:17:00,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,100 > [DEBUG] 0 :: before allreduce fusion buffer :: -146.39242553710938
2023-01-07 08:17:00,101 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,101 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,101 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.039377212524414
2023-01-07 08:17:00,102 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,102 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,102 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,102 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,102 > [DEBUG] 0 :: before allreduce fusion buffer :: -364.82757568359375
2023-01-07 08:17:00,104 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,104 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,104 > [DEBUG] 0 :: before allreduce fusion buffer :: 3927.185546875
2023-01-07 08:17:00,105 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,105 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,105 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,105 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,105 > [DEBUG] 0 :: before allreduce fusion buffer :: -127.16624450683594
2023-01-07 08:17:00,107 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,107 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,107 > [DEBUG] 0 :: before allreduce fusion buffer :: 32.17829895019531
2023-01-07 08:17:00,108 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,108 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,108 > [DEBUG] 0 :: before allreduce fusion buffer :: 117.564697265625
2023-01-07 08:17:00,113 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:17:00,113 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,113 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,114 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,114 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,114 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,114 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,115 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,115 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,115 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,115 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,116 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,116 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,116 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,116 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,117 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,117 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,117 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,117 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,118 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,118 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,118 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,118 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,119 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,119 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,119 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,120 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,120 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,120 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,120 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,121 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,121 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,121 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,121 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,122 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,122 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,122 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,123 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,123 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,123 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,123 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,123 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,123 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,124 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,124 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,124 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,124 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,124 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,125 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,125 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,125 > [DEBUG] 0 :: before allreduce fusion buffer :: -1782484173848576.0
2023-01-07 08:17:00,128 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,128 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,128 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,128 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,129 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,129 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,129 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,129 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,129 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,129 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,129 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,129 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,130 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,130 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,131 > [DEBUG] 0 :: before allreduce fusion buffer :: -74677.96875
2023-01-07 08:17:00,131 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,131 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,132 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,132 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,132 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,132 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,132 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,132 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,132 > [DEBUG] 0 :: before allreduce fusion buffer :: 40.64964294433594
2023-01-07 08:17:00,133 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,133 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,133 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,133 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,133 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,133 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,133 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.976405143737793
2023-01-07 08:17:00,134 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,134 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,134 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,134 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,134 > [DEBUG] 0 :: before allreduce fusion buffer :: 24811023630336.0
2023-01-07 08:17:00,135 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -18.88309097290039
2023-01-07 08:17:00,135 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,135 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,135 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,135 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 67.8049545288086
2023-01-07 08:17:00,135 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,136 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,136 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,136 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,136 > [DEBUG] 0 :: before allreduce fusion buffer :: 368947822592.0
2023-01-07 08:17:00,137 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 67.8049545288086
2023-01-07 08:17:00,137 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,137 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,137 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,137 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: -33.03718566894531
2023-01-07 08:17:00,138 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,138 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,138 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,138 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,138 > [DEBUG] 0 :: before allreduce fusion buffer :: -1184.87255859375
2023-01-07 08:17:00,140 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -33.03718566894531
2023-01-07 08:17:00,140 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,140 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,140 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,140 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -251.10455322265625
2023-01-07 08:17:00,140 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,140 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,140 > [DEBUG] 0 :: before allreduce fusion buffer :: 83.4822769165039
2023-01-07 08:17:00,141 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 61.331932067871094
2023-01-07 08:17:00,141 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,141 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,141 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,141 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -251.10455322265625
2023-01-07 08:17:00,141 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,141 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,142 > [DEBUG] 0 :: before allreduce fusion buffer :: 45.307273864746094
2023-01-07 08:17:00,144 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: -251.10455322265625
2023-01-07 08:17:00,144 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,144 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,144 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,144 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 60.945682525634766
2023-01-07 08:17:00,144 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,144 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,144 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,145 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,145 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,145 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,145 > [DEBUG] 0 :: before allreduce fusion buffer :: 11797840003072.0
2023-01-07 08:17:00,147 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 60.945682525634766
2023-01-07 08:17:00,147 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,147 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,147 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,147 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -159.1077423095703
2023-01-07 08:17:00,147 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,147 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,147 > [DEBUG] 0 :: before allreduce fusion buffer :: 103261449224192.0
2023-01-07 08:17:00,148 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 47.85921096801758
2023-01-07 08:17:00,148 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,149 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,149 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,149 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 250.69772338867188
2023-01-07 08:17:00,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,149 > [DEBUG] 0 :: before allreduce fusion buffer :: 66.46681213378906
2023-01-07 08:17:00,151 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 250.69772338867188
2023-01-07 08:17:00,151 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,151 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,151 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,151 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -136.22225952148438
2023-01-07 08:17:00,151 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,151 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,151 > [DEBUG] 0 :: before allreduce fusion buffer :: 43.64274978637695
2023-01-07 08:17:00,152 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -78.63563537597656
2023-01-07 08:17:00,152 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,152 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,152 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,153 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -136.22225952148438
2023-01-07 08:17:00,153 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,153 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,153 > [DEBUG] 0 :: before allreduce fusion buffer :: -130.3262939453125
2023-01-07 08:17:00,154 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 246.6083984375
2023-01-07 08:17:00,154 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,154 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,154 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,154 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -136.22225952148438
2023-01-07 08:17:00,154 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,154 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,154 > [DEBUG] 0 :: before allreduce fusion buffer :: -61.008949279785156
2023-01-07 08:17:00,155 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: -56.8747444152832
2023-01-07 08:17:00,156 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,156 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,156 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,156 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 67.80442810058594
2023-01-07 08:17:00,156 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,156 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,156 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,156 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,156 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.054698944091797
2023-01-07 08:17:00,158 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 67.80442810058594
2023-01-07 08:17:00,158 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,158 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,158 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,158 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -136.22225952148438
2023-01-07 08:17:00,158 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,158 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,158 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,158 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,158 > [DEBUG] 0 :: before allreduce fusion buffer :: 99.35433959960938
2023-01-07 08:17:00,160 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: -136.22225952148438
2023-01-07 08:17:00,160 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,160 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,160 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,160 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 67.80506896972656
2023-01-07 08:17:00,160 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,160 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,160 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,160 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,161 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.605378150939941
2023-01-07 08:17:00,162 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 67.80506896972656
2023-01-07 08:17:00,162 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,162 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,162 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,162 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -159.1077423095703
2023-01-07 08:17:00,162 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,163 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,163 > [DEBUG] 0 :: before allreduce fusion buffer :: -52.4301643371582
2023-01-07 08:17:00,164 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: -106.38948822021484
2023-01-07 08:17:00,164 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,164 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,164 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,164 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -36.50393295288086
2023-01-07 08:17:00,164 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,164 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,164 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.822294415684403e+16
2023-01-07 08:17:00,165 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 248.24203491210938
2023-01-07 08:17:00,165 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,165 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,165 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,166 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -36.50393295288086
2023-01-07 08:17:00,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,166 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,166 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,166 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.167074203491211
2023-01-07 08:17:00,168 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: -36.50393295288086
2023-01-07 08:17:00,168 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,168 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,168 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,168 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -159.1077423095703
2023-01-07 08:17:00,168 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,168 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,168 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.474634170532227
2023-01-07 08:17:00,169 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 69.54120635986328
2023-01-07 08:17:00,169 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,169 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,169 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,169 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -159.1077423095703
2023-01-07 08:17:00,169 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,169 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,170 > [DEBUG] 0 :: before allreduce fusion buffer :: 21.603687286376953
2023-01-07 08:17:00,171 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: -159.1077423095703
2023-01-07 08:17:00,171 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,171 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,171 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,171 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 68.20527648925781
2023-01-07 08:17:00,171 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,171 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,172 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,172 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,172 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.47582244873047
2023-01-07 08:17:00,174 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 68.20527648925781
2023-01-07 08:17:00,174 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,174 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,174 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,174 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 475.6131286621094
2023-01-07 08:17:00,174 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,174 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,174 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,175 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 26.19771957397461
2023-01-07 08:17:00,175 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,175 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,176 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,176 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 310.8672180175781
2023-01-07 08:17:00,176 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,176 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,176 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,177 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 250.4973602294922
2023-01-07 08:17:00,177 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,177 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,177 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,177 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 475.6131286621094
2023-01-07 08:17:00,178 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,178 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,178 > [DEBUG] 0 :: before allreduce fusion buffer :: -9895777.0
2023-01-07 08:17:00,179 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 310.8672180175781
2023-01-07 08:17:00,179 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,179 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,179 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,179 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 475.6131286621094
2023-01-07 08:17:00,179 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,179 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,180 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,180 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 131.07240295410156
2023-01-07 08:17:00,180 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,180 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,180 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,181 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 475.6131286621094
2023-01-07 08:17:00,181 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,181 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,181 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,182 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 475.6131286621094
2023-01-07 08:17:00,182 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,182 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,183 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,183 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 130.09347534179688
2023-01-07 08:17:00,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,183 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,183 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,183 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,183 > [DEBUG] 0 :: before allreduce fusion buffer :: -795739136.0
2023-01-07 08:17:00,185 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 130.09347534179688
2023-01-07 08:17:00,185 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,185 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,185 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,185 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 505.6993408203125
2023-01-07 08:17:00,185 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,185 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,185 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,186 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 505.6993408203125
2023-01-07 08:17:00,187 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,187 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,187 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,187 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 524.0254516601562
2023-01-07 08:17:00,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,187 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,187 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,187 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,188 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 524.0254516601562
2023-01-07 08:17:00,188 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,189 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,189 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,189 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 46.6339111328125
2023-01-07 08:17:00,189 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,189 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,189 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,190 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 46.6339111328125
2023-01-07 08:17:00,190 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,190 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,190 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,191 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 87.29103088378906
2023-01-07 08:17:00,191 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,191 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,191 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,192 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 512.43994140625
2023-01-07 08:17:00,192 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,192 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,192 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,192 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 87.29103088378906
2023-01-07 08:17:00,192 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,192 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,192 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,194 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 87.29103088378906
2023-01-07 08:17:00,194 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,194 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,194 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,194 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 127.24714660644531
2023-01-07 08:17:00,194 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,194 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,194 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,194 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,195 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,196 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 127.24714660644531
2023-01-07 08:17:00,196 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,196 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,196 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,196 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 71.18348693847656
2023-01-07 08:17:00,196 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,196 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,197 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,198 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 71.18348693847656
2023-01-07 08:17:00,198 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,198 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,198 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,198 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 126.99964141845703
2023-01-07 08:17:00,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,198 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,198 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,199 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,200 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 126.99964141845703
2023-01-07 08:17:00,200 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,200 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,200 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,200 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: -215.29733276367188
2023-01-07 08:17:00,200 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,200 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,201 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,202 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -215.29733276367188
2023-01-07 08:17:00,202 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,202 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,202 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,202 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -181.5670623779297
2023-01-07 08:17:00,202 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,202 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,203 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,203 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 491.2549743652344
2023-01-07 08:17:00,204 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,204 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,204 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,204 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: -181.5670623779297
2023-01-07 08:17:00,204 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,204 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,204 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,205 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: -181.5670623779297
2023-01-07 08:17:00,205 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,206 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,206 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,206 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 125.88229370117188
2023-01-07 08:17:00,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,206 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,206 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,206 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,208 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 125.88229370117188
2023-01-07 08:17:00,208 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,208 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,208 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,208 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 41.89015197753906
2023-01-07 08:17:00,208 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,208 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,208 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,210 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 41.89015197753906
2023-01-07 08:17:00,210 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,210 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,210 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,210 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 127.32795715332031
2023-01-07 08:17:00,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,210 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,210 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,210 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,212 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 127.32795715332031
2023-01-07 08:17:00,212 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,212 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,212 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,212 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -55.680641174316406
2023-01-07 08:17:00,212 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,212 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,212 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,214 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -55.680641174316406
2023-01-07 08:17:00,214 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,214 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,214 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,214 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 527.599609375
2023-01-07 08:17:00,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,214 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,216 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 527.599609375
2023-01-07 08:17:00,216 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,216 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,216 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,216 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -328.9698181152344
2023-01-07 08:17:00,216 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,216 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,216 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,218 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -328.9698181152344
2023-01-07 08:17:00,218 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,218 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,218 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,218 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 127.33992767333984
2023-01-07 08:17:00,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,218 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,218 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,218 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,220 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 127.33992767333984
2023-01-07 08:17:00,220 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,220 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,220 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,220 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -109.80377197265625
2023-01-07 08:17:00,220 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,220 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,220 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,222 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -109.80377197265625
2023-01-07 08:17:00,222 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,222 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,222 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,222 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 130.0382080078125
2023-01-07 08:17:00,222 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,222 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,223 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,223 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,224 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 130.0382080078125
2023-01-07 08:17:00,224 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,224 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,224 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,224 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: -31.74295425415039
2023-01-07 08:17:00,224 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,224 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,225 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,226 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -31.74295425415039
2023-01-07 08:17:00,226 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,226 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,226 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,226 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 527.735595703125
2023-01-07 08:17:00,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,226 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,227 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,227 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,228 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 527.735595703125
2023-01-07 08:17:00,228 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,228 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,228 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,228 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: -333.67620849609375
2023-01-07 08:17:00,228 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,228 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,230 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: -333.67620849609375
2023-01-07 08:17:00,230 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,230 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,230 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,230 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 259.07794189453125
2023-01-07 08:17:00,230 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,230 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,231 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,231 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,231 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,232 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 259.07794189453125
2023-01-07 08:17:00,232 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,232 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,232 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,232 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -44493.72265625
2023-01-07 08:17:00,232 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,233 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,234 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -44493.72265625
2023-01-07 08:17:00,234 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,234 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,234 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,234 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -1236.8062744140625
2023-01-07 08:17:00,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,235 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,235 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,236 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 253.6600341796875
2023-01-07 08:17:00,236 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,236 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,236 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,236 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -1236.8062744140625
2023-01-07 08:17:00,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,236 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,238 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -1236.8062744140625
2023-01-07 08:17:00,238 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,238 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,238 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,238 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -3500.36962890625
2023-01-07 08:17:00,238 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,238 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,238 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,239 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1012.5960083007812
2023-01-07 08:17:00,239 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,239 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,239 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,239 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -3500.36962890625
2023-01-07 08:17:00,239 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,239 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,240 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,241 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -3500.36962890625
2023-01-07 08:17:00,241 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,241 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,241 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,241 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -2371.22314453125
2023-01-07 08:17:00,241 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,241 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,241 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,242 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1026.687744140625
2023-01-07 08:17:00,242 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,242 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,242 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,243 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -2371.22314453125
2023-01-07 08:17:00,243 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,243 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,243 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,244 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -2371.22314453125
2023-01-07 08:17:00,244 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,244 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,244 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,245 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 259.4898681640625
2023-01-07 08:17:00,245 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,245 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,245 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,245 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,245 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,246 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 259.4898681640625
2023-01-07 08:17:00,246 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,246 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,246 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,247 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -4659.697265625
2023-01-07 08:17:00,247 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,247 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,247 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,248 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -4659.697265625
2023-01-07 08:17:00,248 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,249 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,249 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,249 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -1154.6153564453125
2023-01-07 08:17:00,249 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,249 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,249 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,250 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 251.46090698242188
2023-01-07 08:17:00,250 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,250 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,250 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,250 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -1154.6153564453125
2023-01-07 08:17:00,250 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,250 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,250 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,252 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -1154.6153564453125
2023-01-07 08:17:00,252 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,252 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,252 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,252 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 220.73519897460938
2023-01-07 08:17:00,252 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,252 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,252 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,253 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1039.535888671875
2023-01-07 08:17:00,253 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,253 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,253 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,254 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 220.73519897460938
2023-01-07 08:17:00,254 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,254 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,254 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,255 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 220.73519897460938
2023-01-07 08:17:00,255 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,255 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,256 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,256 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -783.2703857421875
2023-01-07 08:17:00,256 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,256 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,256 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,257 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 255.90875244140625
2023-01-07 08:17:00,257 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,257 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,257 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,257 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -783.2703857421875
2023-01-07 08:17:00,257 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,257 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,257 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,259 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: -783.2703857421875
2023-01-07 08:17:00,259 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,259 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,259 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,259 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -241.145751953125
2023-01-07 08:17:00,259 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,259 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,259 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,260 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 251.62411499023438
2023-01-07 08:17:00,260 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,260 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,260 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,261 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -241.145751953125
2023-01-07 08:17:00,261 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,261 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,261 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,262 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -241.145751953125
2023-01-07 08:17:00,262 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,262 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,262 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,263 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 249.97633361816406
2023-01-07 08:17:00,263 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,263 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,263 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,264 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1022.8279418945312
2023-01-07 08:17:00,264 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,264 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,264 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,264 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 249.97633361816406
2023-01-07 08:17:00,264 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,264 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,264 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,266 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 249.97633361816406
2023-01-07 08:17:00,266 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,266 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,266 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,266 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -474.00067138671875
2023-01-07 08:17:00,266 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,266 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,266 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,267 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 252.70843505859375
2023-01-07 08:17:00,267 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,267 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,267 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,268 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -474.00067138671875
2023-01-07 08:17:00,268 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,268 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,268 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,269 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: -474.00067138671875
2023-01-07 08:17:00,269 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,269 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,269 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,269 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -202.44375610351562
2023-01-07 08:17:00,270 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,270 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,270 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,271 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 250.10543823242188
2023-01-07 08:17:00,271 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,271 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,271 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,271 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -202.44375610351562
2023-01-07 08:17:00,271 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,271 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,271 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,273 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -202.44375610351562
2023-01-07 08:17:00,273 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,273 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,273 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,273 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 251.574951171875
2023-01-07 08:17:00,273 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,273 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,273 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,274 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1029.93408203125
2023-01-07 08:17:00,274 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,274 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,274 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,274 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 251.574951171875
2023-01-07 08:17:00,274 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,274 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,275 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,276 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 251.574951171875
2023-01-07 08:17:00,276 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,276 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,276 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,276 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 478.56097412109375
2023-01-07 08:17:00,276 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,277 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,277 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,278 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 252.8104248046875
2023-01-07 08:17:00,278 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,278 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,278 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,278 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 478.56097412109375
2023-01-07 08:17:00,278 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,278 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,278 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,280 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 478.56097412109375
2023-01-07 08:17:00,280 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,280 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,280 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,280 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -6910.3173828125
2023-01-07 08:17:00,280 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,280 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,280 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,281 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 252.74549865722656
2023-01-07 08:17:00,281 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,281 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,281 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,281 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -6910.3173828125
2023-01-07 08:17:00,281 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,282 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,282 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,283 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -6910.3173828125
2023-01-07 08:17:00,283 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,283 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,283 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,283 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -45794.65234375
2023-01-07 08:17:00,284 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,284 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,284 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,285 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1026.8658447265625
2023-01-07 08:17:00,285 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,285 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,285 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,285 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -45794.65234375
2023-01-07 08:17:00,285 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,285 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,287 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -45794.65234375
2023-01-07 08:17:00,287 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,287 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,287 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,287 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -20531.54296875
2023-01-07 08:17:00,287 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,287 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,287 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,288 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 261.18817138671875
2023-01-07 08:17:00,288 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,288 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,288 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,288 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -20531.54296875
2023-01-07 08:17:00,288 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,289 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,289 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,290 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -20531.54296875
2023-01-07 08:17:00,290 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,290 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,290 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,290 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -52134.2890625
2023-01-07 08:17:00,290 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,291 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,291 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,292 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 263.05377197265625
2023-01-07 08:17:00,292 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,292 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,292 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,292 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -52134.2890625
2023-01-07 08:17:00,292 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,292 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,292 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,294 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -52134.2890625
2023-01-07 08:17:00,294 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,294 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,294 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,294 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -110409.8515625
2023-01-07 08:17:00,294 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,294 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,294 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,295 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1029.52001953125
2023-01-07 08:17:00,295 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,295 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,295 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,295 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -110409.8515625
2023-01-07 08:17:00,295 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,296 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,296 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,297 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -110409.8515625
2023-01-07 08:17:00,297 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,297 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,297 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,297 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -94087.40625
2023-01-07 08:17:00,298 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,298 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,299 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 606.5316162109375
2023-01-07 08:17:00,299 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,299 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,299 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,299 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -94087.40625
2023-01-07 08:17:00,299 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,299 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,299 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,301 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -94087.40625
2023-01-07 08:17:00,301 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,301 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,301 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,301 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 460.0096435546875
2023-01-07 08:17:00,301 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,301 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,301 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,302 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 608.7205200195312
2023-01-07 08:17:00,302 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,302 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,302 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,302 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 460.0096435546875
2023-01-07 08:17:00,302 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,303 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,303 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,304 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 460.0096435546875
2023-01-07 08:17:00,304 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,305 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,305 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,305 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -269771.3125
2023-01-07 08:17:00,305 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,305 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,305 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,306 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2153.516357421875
2023-01-07 08:17:00,306 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,306 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,306 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,306 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -269771.3125
2023-01-07 08:17:00,306 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,306 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,306 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,308 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -269771.3125
2023-01-07 08:17:00,308 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,308 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,308 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,308 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -58842.96875
2023-01-07 08:17:00,308 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,308 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,308 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,309 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2094.80224609375
2023-01-07 08:17:00,309 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,309 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,309 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,309 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -58842.96875
2023-01-07 08:17:00,309 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,310 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,311 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -58842.96875
2023-01-07 08:17:00,311 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,311 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,311 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,311 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 616.2150268554688
2023-01-07 08:17:00,312 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,312 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,312 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,313 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 607.984375
2023-01-07 08:17:00,313 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,313 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,313 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,313 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 616.2150268554688
2023-01-07 08:17:00,313 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,313 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,313 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,315 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 616.2150268554688
2023-01-07 08:17:00,315 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,315 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,315 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,315 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -74952.234375
2023-01-07 08:17:00,315 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,315 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,315 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,316 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 596.3005981445312
2023-01-07 08:17:00,316 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,316 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,316 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,316 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -74952.234375
2023-01-07 08:17:00,317 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,317 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,317 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,318 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -74952.234375
2023-01-07 08:17:00,318 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,318 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,318 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,319 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -225329.09375
2023-01-07 08:17:00,319 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,319 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,319 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,320 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2150.235107421875
2023-01-07 08:17:00,320 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,320 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,320 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,320 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -225329.09375
2023-01-07 08:17:00,320 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,320 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,320 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,322 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -225329.09375
2023-01-07 08:17:00,322 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,322 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,322 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,322 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -28216.65234375
2023-01-07 08:17:00,322 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,322 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,322 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,323 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 607.1209716796875
2023-01-07 08:17:00,323 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,323 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,323 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,323 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -28216.65234375
2023-01-07 08:17:00,324 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,324 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,324 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,325 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -28216.65234375
2023-01-07 08:17:00,325 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,325 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,325 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,326 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 1322.633056640625
2023-01-07 08:17:00,326 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,326 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,326 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,327 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 589.3603515625
2023-01-07 08:17:00,327 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,327 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,327 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,327 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 1322.633056640625
2023-01-07 08:17:00,327 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,327 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,327 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,329 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 1322.633056640625
2023-01-07 08:17:00,329 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,329 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,329 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,329 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -327401.6875
2023-01-07 08:17:00,329 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,329 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,329 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,330 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2488.52099609375
2023-01-07 08:17:00,330 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,330 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,330 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,330 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -327401.6875
2023-01-07 08:17:00,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,331 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,331 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:00,333 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -327401.6875
2023-01-07 08:17:00,333 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:17:00,333 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:17:00,333 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:17:00,334 > [DEBUG] 0 :: 161.43792724609375
2023-01-07 08:17:00,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,336 > [DEBUG] 0 :: before allreduce fusion buffer :: 1475452207104.0
2023-01-07 08:17:00,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,337 > [DEBUG] 0 :: before allreduce fusion buffer :: 12314501709824.0
2023-01-07 08:17:00,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,339 > [DEBUG] 0 :: before allreduce fusion buffer :: 2947336896512.0
2023-01-07 08:17:00,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,340 > [DEBUG] 0 :: before allreduce fusion buffer :: 11493307318272.0
2023-01-07 08:17:00,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,342 > [DEBUG] 0 :: before allreduce fusion buffer :: 5897562619904.0
2023-01-07 08:17:00,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,343 > [DEBUG] 0 :: before allreduce fusion buffer :: -3391274090496.0
2023-01-07 08:17:00,345 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,345 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 23590250479616.0
2023-01-07 08:17:00,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,346 > [DEBUG] 0 :: before allreduce fusion buffer :: 13188267507712.0
2023-01-07 08:17:00,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,348 > [DEBUG] 0 :: before allreduce fusion buffer :: 42751991218176.0
2023-01-07 08:17:00,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,349 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,349 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,349 > [DEBUG] 0 :: before allreduce fusion buffer :: -120039680.0
2023-01-07 08:17:00,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,351 > [DEBUG] 0 :: before allreduce fusion buffer :: 85493119188992.0
2023-01-07 08:17:00,352 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,352 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,352 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,352 > [DEBUG] 0 :: before allreduce fusion buffer :: -73402467483648.0
2023-01-07 08:17:00,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,354 > [DEBUG] 0 :: before allreduce fusion buffer :: 341994220027904.0
2023-01-07 08:17:00,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,355 > [DEBUG] 0 :: before allreduce fusion buffer :: 24959250333696.0
2023-01-07 08:17:00,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,357 > [DEBUG] 0 :: before allreduce fusion buffer :: 341972476755968.0
2023-01-07 08:17:00,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,358 > [DEBUG] 0 :: before allreduce fusion buffer :: 49918488084480.0
2023-01-07 08:17:00,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 692359868186624.0
2023-01-07 08:17:00,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 1518595.5
2023-01-07 08:17:00,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 1384545924415488.0
2023-01-07 08:17:00,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,365 > [DEBUG] 0 :: before allreduce fusion buffer :: -1018308962811904.0
2023-01-07 08:17:00,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,367 > [DEBUG] 0 :: before allreduce fusion buffer :: -468894397497344.0
2023-01-07 08:17:00,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,369 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,369 > [DEBUG] 0 :: before allreduce fusion buffer :: 192868291444736.0
2023-01-07 08:17:00,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 3302320360128512.0
2023-01-07 08:17:00,372 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,372 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,372 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,372 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,372 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.8841985020329984e+16
2023-01-07 08:17:00,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,374 > [DEBUG] 0 :: before allreduce fusion buffer :: 532991751225344.0
2023-01-07 08:17:00,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,375 > [DEBUG] 0 :: before allreduce fusion buffer :: 1065983502450688.0
2023-01-07 08:17:00,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,377 > [DEBUG] 0 :: before allreduce fusion buffer :: 2131967004901376.0
2023-01-07 08:17:00,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,378 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,378 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,378 > [DEBUG] 0 :: before allreduce fusion buffer :: 388636893773824.0
2023-01-07 08:17:00,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,380 > [DEBUG] 0 :: before allreduce fusion buffer :: 8527868019605504.0
2023-01-07 08:17:00,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,381 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.783792259825664e+16
2023-01-07 08:17:00,383 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,383 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,383 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.4111472078422016e+16
2023-01-07 08:17:00,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.4111472078422016e+16
2023-01-07 08:17:00,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,386 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.822294415684403e+16
2023-01-07 08:17:00,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,387 > [DEBUG] 0 :: before allreduce fusion buffer :: 646476262801408.0
2023-01-07 08:17:00,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,389 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3644588831368806e+17
2023-01-07 08:17:00,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,390 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.7510234475501978e+17
2023-01-07 08:17:00,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,392 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.4578355325475226e+17
2023-01-07 08:17:00,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0915671065095045e+18
2023-01-07 08:17:00,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,395 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.183134213019009e+18
2023-01-07 08:17:00,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,396 > [DEBUG] 0 :: before allreduce fusion buffer :: -390427291156480.0
2023-01-07 08:17:00,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,398 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.366268426038018e+18
2023-01-07 08:17:00,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.736559965122068e+18
2023-01-07 08:17:00,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,401 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.4762529134750366
2023-01-07 08:17:00,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,402 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7465073704152072e+19
2023-01-07 08:17:00,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,404 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.4930147408304144e+19
2023-01-07 08:17:00,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,405 > [DEBUG] 0 :: before allreduce fusion buffer :: -1099938708586496.0
2023-01-07 08:17:00,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3972058963321658e+20
2023-01-07 08:17:00,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,408 > [DEBUG] 0 :: before allreduce fusion buffer :: 2931774204149760.0
2023-01-07 08:17:00,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,411 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.7944117926643316e+20
2023-01-07 08:17:00,411 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,411 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,412 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.588823585328663e+20
2023-01-07 08:17:00,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,413 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1177647170657326e+21
2023-01-07 08:17:00,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 9853614902214656.0
2023-01-07 08:17:00,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,416 > [DEBUG] 0 :: before allreduce fusion buffer :: -4947894.0
2023-01-07 08:17:00,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,417 > [DEBUG] 0 :: before allreduce fusion buffer :: -973.8353881835938
2023-01-07 08:17:00,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,419 > [DEBUG] 0 :: before allreduce fusion buffer :: -9895776.0
2023-01-07 08:17:00,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,420 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.970397851418624e+16
2023-01-07 08:17:00,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,574 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,574 > [DEBUG] 0 :: before allreduce fusion buffer :: -19791546.0
2023-01-07 08:17:00,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,576 > [DEBUG] 0 :: before allreduce fusion buffer :: -39585080.0
2023-01-07 08:17:00,577 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,577 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,577 > [DEBUG] 0 :: before allreduce fusion buffer :: -42789492.0
2023-01-07 08:17:00,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,578 > [DEBUG] 0 :: before allreduce fusion buffer :: -85582920.0
2023-01-07 08:17:00,579 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,579 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,579 > [DEBUG] 0 :: before allreduce fusion buffer :: -171157968.0
2023-01-07 08:17:00,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,580 > [DEBUG] 0 :: before allreduce fusion buffer :: -342323872.0
2023-01-07 08:17:00,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,582 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,582 > [DEBUG] 0 :: before allreduce fusion buffer :: -684631936.0
2023-01-07 08:17:00,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,583 > [DEBUG] 0 :: before allreduce fusion buffer :: -397869568.0
2023-01-07 08:17:00,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,584 > [DEBUG] 0 :: before allreduce fusion buffer :: -1369263872.0
2023-01-07 08:17:00,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,585 > [DEBUG] 0 :: before allreduce fusion buffer :: -2738535168.0
2023-01-07 08:17:00,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,586 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,587 > [DEBUG] 0 :: before allreduce fusion buffer :: -4654103040.0
2023-01-07 08:17:00,758 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,758 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,758 > [DEBUG] 0 :: before allreduce fusion buffer :: -15788.87890625
2023-01-07 08:17:00,760 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,760 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,760 > [DEBUG] 0 :: before allreduce fusion buffer :: -9308206080.0
2023-01-07 08:17:00,761 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,761 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,761 > [DEBUG] 0 :: before allreduce fusion buffer :: -16970520576.0
2023-01-07 08:17:00,762 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,762 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,762 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.809396266937256
2023-01-07 08:17:00,763 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,763 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,763 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,763 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,764 > [DEBUG] 0 :: before allreduce fusion buffer :: -1641687040.0
2023-01-07 08:17:00,942 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,942 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,942 > [DEBUG] 0 :: before allreduce fusion buffer :: -33941008384.0
2023-01-07 08:17:00,943 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,943 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,943 > [DEBUG] 0 :: before allreduce fusion buffer :: -16656.8125
2023-01-07 08:17:00,944 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:00,944 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:00,945 > [DEBUG] 0 :: before allreduce fusion buffer :: -67882016768.0
2023-01-07 08:17:01,059 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,059 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,059 > [DEBUG] 0 :: before allreduce fusion buffer :: -135764074496.0
2023-01-07 08:17:01,060 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,060 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,061 > [DEBUG] 0 :: before allreduce fusion buffer :: -271528067072.0
2023-01-07 08:17:01,061 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,061 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,062 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,062 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,062 > [DEBUG] 0 :: before allreduce fusion buffer :: -68879.953125
2023-01-07 08:17:01,063 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,063 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,064 > [DEBUG] 0 :: before allreduce fusion buffer :: -427165614080.0
2023-01-07 08:17:01,064 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,064 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,065 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.4307388378441378e+23
2023-01-07 08:17:01,066 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,066 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,066 > [DEBUG] 0 :: before allreduce fusion buffer :: -854331228160.0
2023-01-07 08:17:01,067 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,067 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,067 > [DEBUG] 0 :: before allreduce fusion buffer :: -1708662456320.0
2023-01-07 08:17:01,068 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,068 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,068 > [DEBUG] 0 :: before allreduce fusion buffer :: -3417324912640.0
2023-01-07 08:17:01,069 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,069 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,069 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,070 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,070 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.578364281101241e+24
2023-01-07 08:17:01,071 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,071 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,071 > [DEBUG] 0 :: before allreduce fusion buffer :: -6834649825280.0
2023-01-07 08:17:01,072 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,072 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,072 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,073 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,073 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,073 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,073 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.4606640460333056e+16
2023-01-07 08:17:01,074 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,074 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,075 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:01,075 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,076 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,076 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:17:01,077 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,077 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,077 > [DEBUG] 0 :: before allreduce fusion buffer :: -8337250928558080.0
2023-01-07 08:17:01,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,078 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,078 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,078 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,078 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.117970323472384e+16
2023-01-07 08:17:01,080 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,080 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,080 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.4833984375
2023-01-07 08:17:01,081 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,081 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,081 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,081 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,081 > [DEBUG] 0 :: before allreduce fusion buffer :: 77.80946350097656
2023-01-07 08:17:01,083 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,083 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,083 > [DEBUG] 0 :: before allreduce fusion buffer :: -69.2974624633789
2023-01-07 08:17:01,084 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,084 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,084 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,084 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,084 > [DEBUG] 0 :: before allreduce fusion buffer :: -4558.0146484375
2023-01-07 08:17:01,085 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,085 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,086 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.468747615814209
2023-01-07 08:17:01,087 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,087 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,087 > [DEBUG] 0 :: before allreduce fusion buffer :: 234.14678955078125
2023-01-07 08:17:01,088 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,088 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,088 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.549776077270508
2023-01-07 08:17:01,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,090 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,090 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,090 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.6812206470720235e+31
2023-01-07 08:17:01,092 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,092 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,092 > [DEBUG] 0 :: before allreduce fusion buffer :: -79.81455993652344
2023-01-07 08:17:01,093 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,093 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,093 > [DEBUG] 0 :: before allreduce fusion buffer :: -760.529052734375
2023-01-07 08:17:01,094 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,094 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,094 > [DEBUG] 0 :: before allreduce fusion buffer :: 54.789817810058594
2023-01-07 08:17:01,095 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,095 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,096 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,096 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,096 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2289953035315238e+33
2023-01-07 08:17:01,097 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,097 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,097 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.027974510805653e+20
2023-01-07 08:17:01,098 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,098 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,098 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,098 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,099 > [DEBUG] 0 :: before allreduce fusion buffer :: -147.3346710205078
2023-01-07 08:17:01,100 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,100 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,100 > [DEBUG] 0 :: before allreduce fusion buffer :: -396.56219482421875
2023-01-07 08:17:01,101 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:17:01,101 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:17:01,101 > [DEBUG] 0 :: before allreduce fusion buffer :: 272.9116516113281
