[00;33m 	'cuda/11.3' does not supports the {CUDA_MPI}. [0m
[00;34m 	{CUDA_MPI} is only supported in cuda 11.4 version. [0m
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/38 [00:00<?, ?it/s]OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.
  0%|          | 0/38 [00:00<?, ?it/s]OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.
  0%|          | 0/38 [00:00<?, ?it/s]OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:00<00:32,  1.15it/s]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:00<00:35,  1.04it/s]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  3%|▎         | 1/38 [00:01<00:37,  1.00s/it]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:00<00:34,  1.09it/s]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  3%|▎         | 1/38 [00:00<00:35,  1.05it/s]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  3%|▎         | 1/38 [00:01<00:37,  1.01s/it]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:00<00:33,  1.10it/s]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:00<00:35,  1.04it/s]/scratch/hpc72a03/shardscheduler/torch_scheduler.py:1046: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
  5%|▌         | 2/38 [00:01<00:22,  1.61it/s]  8%|▊         | 3/38 [00:01<00:16,  2.17it/s] 11%|█         | 4/38 [00:01<00:11,  2.89it/s] 13%|█▎        | 5/38 [00:02<00:11,  2.90it/s] 16%|█▌        | 6/38 [00:02<00:10,  2.95it/s] 18%|█▊        | 7/38 [00:02<00:10,  3.05it/s] 21%|██        | 8/38 [00:03<00:09,  3.25it/s] 24%|██▎       | 9/38 [00:03<00:07,  3.82it/s] 26%|██▋       | 10/38 [00:03<00:07,  3.53it/s] 29%|██▉       | 11/38 [00:03<00:07,  3.50it/s] 32%|███▏      | 12/38 [00:04<00:07,  3.46it/s] 34%|███▍      | 13/38 [00:04<00:07,  3.37it/s] 37%|███▋      | 14/38 [00:04<00:07,  3.34it/s] 39%|███▉      | 15/38 [00:04<00:06,  3.47it/s] 42%|████▏     | 16/38 [00:05<00:05,  4.03it/s] 45%|████▍     | 17/38 [00:05<00:06,  3.47it/s] 47%|████▋     | 18/38 [00:05<00:05,  3.52it/s] 50%|█████     | 19/38 [00:06<00:05,  3.51it/s] 53%|█████▎    | 20/38 [00:06<00:05,  3.37i  5%|▌         | 2/38 [00:01<00:21,  1.66it/s]  8%|▊         | 3/38 [00:01<00:16,  2.18it/s] 11%|█         | 4/38 [00:01<00:11,  2.87it/s] 13%|█▎        | 5/38 [00:02<00:11,  2.91it/s] 16%|█▌        | 6/38 [00:02<00:10,  3.03it/s] 18%|█▊        | 7/38 [00:02<00:09,  3.11it/s] 21%|██        | 8/38 [00:03<00:09,  3.08it/s] 24%|██▎       | 9/38 [00:03<00:09,  2.92it/s] 26%|██▋       | 10/38 [00:03<00:09,  2.93it/s] 29%|██▉       | 11/38 [00:04<00:08,  3.05it/s] 32%|███▏      | 12/38 [00:04<00:08,  3.07it/s] 34%|███▍      | 13/38 [00:04<00:07,  3.13it/s] 37%|███▋      | 14/38 [00:05<00:07,  3.13it/s] 39%|███▉      | 15/38 [00:05<00:07,  2.98it/s] 42%|████▏     | 16/38 [00:05<00:07,  2.90it/s] 45%|████▍     | 17/38 [00:06<00:06,  3.02it/s] 47%|████▋     | 18/38 [00:06<00:06,  3.04it/s] 50%|█████     | 19/38 [00:06<00:06,  3.11it/s] 53%|█████▎    | 20/38 [00:06<00:05,  3.21i  5%|▌         | 2/38 [00:01<00:20,  1.72it/s]  8%|▊         | 3/38 [00:01<00:16,  2.07it/s] 11%|█         | 4/38 [00:01<00:11,  2.93it/s] 13%|█▎        | 5/38 [00:02<00:10,  3.01it/s] 16%|█▌        | 6/38 [00:02<00:10,  3.06it/s] 18%|█▊        | 7/38 [00:02<00:09,  3.11it/s] 21%|██        | 8/38 [00:03<00:09,  3.10it/s] 24%|██▎       | 9/38 [00:03<00:09,  2.92it/s] 26%|██▋       | 10/38 [00:03<00:09,  2.95it/s] 29%|██▉       | 11/38 [00:04<00:08,  3.05it/s] 32%|███▏      | 12/38 [00:04<00:08,  3.07it/s] 34%|███▍      | 13/38 [00:04<00:07,  3.14it/s] 37%|███▋      | 14/38 [00:04<00:07,  3.14it/s] 39%|███▉      | 15/38 [00:05<00:07,  2.99it/s] 42%|████▏     | 16/38 [00:05<00:07,  2.90it/s] 45%|████▍     | 17/38 [00:06<00:06,  3.03it/s] 47%|████▋     | 18/38 [00:06<00:06,  3.05it/s] 50%|█████     | 19/38 [00:06<00:06,  3.11it/s] 53%|█████▎    | 20/38 [00:06<00:05,  3.18i  5%|▌         | 2/38 [00:01<00:22,  1.62it/s]  8%|▊         | 3/38 [00:01<00:17,  1.99it/s] 11%|█         | 4/38 [00:02<00:15,  2.16it/s] 13%|█▎        | 5/38 [00:02<00:13,  2.38it/s] 16%|█▌        | 6/38 [00:02<00:12,  2.62it/s] 18%|█▊        | 7/38 [00:03<00:11,  2.74it/s] 21%|██        | 8/38 [00:03<00:11,  2.70it/s] 24%|██▎       | 9/38 [00:03<00:10,  2.78it/s] 26%|██▋       | 10/38 [00:04<00:09,  2.90it/s] 29%|██▉       | 11/38 [00:04<00:09,  2.97it/s] 32%|███▏      | 12/38 [00:04<00:08,  3.08it/s] 34%|███▍      | 13/38 [00:05<00:08,  3.12it/s] 37%|███▋      | 14/38 [00:05<00:08,  2.97it/s] 39%|███▉      | 15/38 [00:05<00:07,  2.89it/s] 42%|████▏     | 16/38 [00:06<00:07,  3.03it/s] 45%|████▍     | 17/38 [00:06<00:06,  3.04it/s] 47%|████▋     | 18/38 [00:06<00:06,  3.14it/s] 50%|█████     | 19/38 [00:07<00:05,  3.20it/s] 53%|█████▎    | 20/38 [00:07<00:05,  3.25i  5%|▌         | 2/38 [00:01<00:22,  1.60it/s]  8%|▊         | 3/38 [00:01<00:17,  2.00it/s] 11%|█         | 4/38 [00:02<00:15,  2.18it/s] 13%|█▎        | 5/38 [00:02<00:13,  2.38it/s] 16%|█▌        | 6/38 [00:02<00:12,  2.66it/s] 18%|█▊        | 7/38 [00:03<00:11,  2.77it/s] 21%|██        | 8/38 [00:03<00:11,  2.70it/s] 24%|██▎       | 9/38 [00:03<00:10,  2.80it/s] 26%|██▋       | 10/38 [00:04<00:09,  2.94it/s] 29%|██▉       | 11/38 [00:04<00:08,  3.01it/s] 32%|███▏      | 12/38 [00:04<00:08,  3.07it/s] 34%|███▍      | 13/38 [00:05<00:08,  3.10it/s] 37%|███▋      | 14/38 [00:05<00:08,  2.94it/s] 39%|███▉      | 15/38 [00:05<00:07,  2.89it/s] 42%|████▏     | 16/38 [00:06<00:07,  3.03it/s] 45%|████▍     | 17/38 [00:06<00:06,  3.05it/s] 47%|████▋     | 18/38 [00:06<00:06,  3.14it/s] 50%|█████     | 19/38 [00:07<00:05,  3.19it/s] 53%|█████▎    | 20/38 [00:07<00:05,  3.23i  5%|▌         | 2/38 [00:01<00:21,  1.64it/s]  8%|▊         | 3/38 [00:01<00:17,  1.99it/s] 11%|█         | 4/38 [00:02<00:15,  2.16it/s] 13%|█▎        | 5/38 [00:02<00:13,  2.37it/s] 16%|█▌        | 6/38 [00:02<00:12,  2.62it/s] 18%|█▊        | 7/38 [00:03<00:11,  2.75it/s] 21%|██        | 8/38 [00:03<00:11,  2.69it/s] 24%|██▎       | 9/38 [00:03<00:10,  2.78it/s] 26%|██▋       | 10/38 [00:04<00:09,  2.93it/s] 29%|██▉       | 11/38 [00:04<00:09,  2.98it/s] 32%|███▏      | 12/38 [00:04<00:08,  3.07it/s] 34%|███▍      | 13/38 [00:05<00:08,  3.10it/s] 37%|███▋      | 14/38 [00:05<00:08,  2.95it/s] 39%|███▉      | 15/38 [00:05<00:07,  2.90it/s] 42%|████▏     | 16/38 [00:06<00:07,  3.01it/s] 45%|████▍     | 17/38 [00:06<00:06,  3.06it/s] 47%|████▋     | 18/38 [00:06<00:06,  3.16it/s] 50%|█████     | 19/38 [00:07<00:05,  3.18it/s] 53%|█████▎    | 20/38 [00:07<00:05,  3.24i  5%|▌         | 2/38 [00:01<00:21,  1.70it/s]  8%|▊         | 3/38 [00:01<00:16,  2.10it/s] 11%|█         | 4/38 [00:02<00:15,  2.25it/s] 13%|█▎        | 5/38 [00:02<00:13,  2.45it/s] 16%|█▌        | 6/38 [00:02<00:11,  2.67it/s] 18%|█▊        | 7/38 [00:02<00:11,  2.80it/s] 21%|██        | 8/38 [00:03<00:10,  2.74it/s] 24%|██▎       | 9/38 [00:03<00:10,  2.80it/s] 26%|██▋       | 10/38 [00:04<00:09,  2.96it/s] 29%|██▉       | 11/38 [00:04<00:09,  2.99it/s] 32%|███▏      | 12/38 [00:04<00:08,  3.08it/s] 34%|███▍      | 13/38 [00:04<00:08,  3.10it/s] 37%|███▋      | 14/38 [00:05<00:08,  2.96it/s] 39%|███▉      | 15/38 [00:05<00:07,  2.89it/s] 42%|████▏     | 16/38 [00:05<00:07,  3.02it/s] 45%|████▍     | 17/38 [00:06<00:06,  3.04it/s] 47%|████▋     | 18/38 [00:06<00:06,  3.13it/s] 50%|█████     | 19/38 [00:06<00:05,  3.18it/s] 53%|█████▎    | 20/38 [00:07<00:05,  3.23i  5%|▌         | 2/38 [00:01<00:22,  1.63it/s]  8%|▊         | 3/38 [00:01<00:16,  2.08it/s] 11%|█         | 4/38 [00:02<00:15,  2.22it/s] 13%|█▎        | 5/38 [00:02<00:13,  2.44it/s] 16%|█▌        | 6/38 [00:02<00:12,  2.64it/s] 18%|█▊        | 7/38 [00:03<00:11,  2.80it/s] 21%|██        | 8/38 [00:03<00:11,  2.70it/s] 24%|██▎       | 9/38 [00:03<00:10,  2.79it/s] 26%|██▋       | 10/38 [00:04<00:09,  2.92it/s] 29%|██▉       | 11/38 [00:04<00:09,  2.99it/s] 32%|███▏      | 12/38 [00:04<00:08,  3.06it/s] 34%|███▍      | 13/38 [00:05<00:08,  3.10it/s] 37%|███▋      | 14/38 [00:05<00:08,  2.94it/s] 39%|███▉      | 15/38 [00:05<00:07,  2.91it/s] 42%|████▏     | 16/38 [00:06<00:07,  3.02it/s] 45%|████▍     | 17/38 [00:06<00:06,  3.06it/s] 47%|████▋     | 18/38 [00:06<00:06,  3.14it/s] 50%|█████     | 19/38 [00:06<00:05,  3.19it/s] 53%|█████▎    | 20/38 [00:07<00:05,  3.25it/s] 55%|█████▌    | 21/38 [00:06<00:05,  3.40it/s] 58%|█████▊    | 22/38 [00:06<00:04,  3.37it/s] 61%|██████    | 23/38 [00:07<00:04,  3.35it/s] 63%|██████▎   | 24/38 [00:07<00:04,  3.26it/s] 66%|██████▌   | 25/38 [00:07<00:03,  3.28it/s] 68%|██████▊   | 26/38 [00:08<00:03,  3.26it/s] 71%|███████   | 27/38 [00:08<00:03,  3.28it/s] 74%|███████▎  | 28/38 [00:09<00:03,  2.77it/s] 76%|███████▋  | 29/38 [00:09<00:03,  2.72it/s] 79%|███████▉  | 30/38 [00:09<00:03,  2.58it/s] 82%|████████▏ | 31/38 [00:10<00:02,  2.51it/s] 84%|████████▍ | 32/38 [00:10<00:02,  2.73it/s] 87%|████████▋ | 33/38 [00:10<00:01,  2.91it/s] 89%|████████▉ | 34/38 [00:11<00:01,  3.16it/s] 92%|█████████▏| 35/38 [00:11<00:00,  3.71it/s] 95%|█████████▍| 36/38 [00:11<00:00,  3.60it/s] 97%|█████████▋| 37/38 [00:11<00:00,  3.44it/s]100%|██████████| 38/38 [00:12<00:00,  3.39it/s]100%|██████████| 38/38 [00:12<00:00,  3.11it/s]srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 149923 ON gpu18 CANCELLED AT 2022-11-13T16:11:45 ***
t/s] 55%|█████▌    | 21/38 [00:07<00:05,  3.17it/s] 58%|█████▊    | 22/38 [00:07<00:04,  3.25it/s] 61%|██████    | 23/38 [00:08<00:04,  3.23it/s] 63%|██████▎   | 24/38 [00:08<00:04,  3.31it/s] 66%|██████▌   | 25/38 [00:08<00:04,  2.90it/s] 68%|██████▊   | 26/38 [00:09<00:03,  3.47it/s] 71%|███████   | 27/38 [00:09<00:03,  3.32it/s] 74%|███████▎  | 28/38 [00:09<00:03,  3.04it/s] 76%|███████▋  | 29/38 [00:10<00:03,  2.81it/s] 79%|███████▉  | 30/38 [00:10<00:02,  2.95it/s] 82%|████████▏ | 31/38 [00:10<00:02,  3.07it/s] 84%|████████▍ | 32/38 [00:11<00:01,  3.11it/s] 87%|████████▋ | 33/38 [00:11<00:01,  2.95it/s] 89%|████████▉ | 34/38 [00:11<00:01,  2.99it/s] 92%|█████████▏| 35/38 [00:12<00:00,  3.11it/s]slurmstepd: error: *** STEP 149923.0 ON gpu18 CANCELLED AT 2022-11-13T16:11:45 ***
