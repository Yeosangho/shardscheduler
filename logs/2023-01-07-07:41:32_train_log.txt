2023-01-07 07:41:40,508 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 07:41:40,509 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:40,546 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -1.24530029296875
2023-01-07 07:41:40,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:40,546 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 9408
2023-01-07 07:41:40,546 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:40,546 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:40,546 > [DEBUG] 0 :: scheduled task in conv1._dp_wrapped_module.flat_param_0 :: 0, FW, [AR, [[1, torch.Size([128]) 0 0], [4, torch.Size([36864]) 24374 24374]]]
2023-01-07 07:41:40,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,240 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,240 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,240 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 07:41:41,240 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,240 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,240 > [DEBUG] 0 :: scheduled task in bn1._dp_wrapped_module.flat_param_0 :: 1, FW, [AR, [[2, torch.Size([4096]) 0 0], [4, torch.Size([36864]) 29806 29806]]]
2023-01-07 07:41:41,241 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,242 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -0.7520308494567871
2023-01-07 07:41:41,242 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,242 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 07:41:41,243 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,243 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,243 > [DEBUG] 0 :: scheduled task in layer1.0.conv1._dp_wrapped_module.flat_param_0 :: 2, FW, [AR, [[4, torch.Size([36864]) 29895 29895]]]
2023-01-07 07:41:41,243 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,243 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,244 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,244 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 07:41:41,244 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,244 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,244 > [DEBUG] 0 :: scheduled task in layer1.0.bn1._dp_wrapped_module.flat_param_0 :: 3, FW, [AR, [[4, torch.Size([36864]) 34135 34135]]]
2023-01-07 07:41:41,244 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,245 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 4.865289688110352
2023-01-07 07:41:41,245 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,245 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 07:41:41,245 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,245 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,245 > [DEBUG] 0 :: scheduled task in layer1.0.conv2._dp_wrapped_module.flat_param_0 :: 4, FW, [AR, [[5, torch.Size([128]) 0 0], [6, torch.Size([16384]) 0 0], [18, torch.Size([36864]) 16953 16953]]]
2023-01-07 07:41:41,245 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,282 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,282 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,282 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 07:41:41,282 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,282 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,282 > [DEBUG] 0 :: scheduled task in layer1.0.bn2._dp_wrapped_module.flat_param_0 :: 5, FW, [AR, [[18, torch.Size([36864]) 19948 19948]]]
2023-01-07 07:41:41,282 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,283 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 5.5570220947265625
2023-01-07 07:41:41,284 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,284 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 07:41:41,284 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,284 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,284 > [DEBUG] 0 :: scheduled task in layer1.0.conv3._dp_wrapped_module.flat_param_0 :: 6, FW, [AR, [[7, torch.Size([512]) 0 0], [10, torch.Size([16384]) 5999 5999]]]
2023-01-07 07:41:41,284 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,285 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,286 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,286 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,286 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,286 > [DEBUG] 0 :: scheduled task in layer1.0.bn3._dp_wrapped_module.flat_param_0 :: 7, FW, [AR, [[12, torch.Size([36864]) 4826 4826]]]
2023-01-07 07:41:41,286 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,286 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 21.8030948638916
2023-01-07 07:41:41,286 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,287 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 07:41:41,287 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,287 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,287 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.0._dp_wrapped_module.flat_param_0 :: 8, FW, [AR, [[12, torch.Size([36864]) 9052 9052]]]
2023-01-07 07:41:41,287 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,288 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,288 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,288 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,288 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,288 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,288 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.1._dp_wrapped_module.flat_param_0 :: 9, FW, [AR, [[12, torch.Size([36864]) 13245 13245]]]
2023-01-07 07:41:41,288 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,289 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: -22.67413330078125
2023-01-07 07:41:41,289 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,289 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 07:41:41,289 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,289 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,289 > [DEBUG] 0 :: scheduled task in layer1.1.conv1._dp_wrapped_module.flat_param_0 :: 10, FW, [AR, [[11, torch.Size([128]) 0 0], [12, torch.Size([36864]) 15961 15961]]]
2023-01-07 07:41:41,290 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,290 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,290 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,291 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 07:41:41,291 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,291 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,291 > [DEBUG] 0 :: scheduled task in layer1.1.bn1._dp_wrapped_module.flat_param_0 :: 11, FW, [AR, [[12, torch.Size([36864]) 35400 35400], [24, torch.Size([147456]) 133638 133638]]]
2023-01-07 07:41:41,291 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,292 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 19.15532684326172
2023-01-07 07:41:41,292 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,292 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 07:41:41,292 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,292 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,292 > [DEBUG] 0 :: scheduled task in layer1.1.conv2._dp_wrapped_module.flat_param_0 :: 12, FW, [AR, [[13, torch.Size([128]) 0 0], [14, torch.Size([16384]) 5438 5438]]]
2023-01-07 07:41:41,292 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,293 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,293 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,293 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 07:41:41,293 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,293 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,293 > [DEBUG] 0 :: scheduled task in layer1.1.bn2._dp_wrapped_module.flat_param_0 :: 13, FW, [AR, [[18, torch.Size([36864]) 22600 22600]]]
2023-01-07 07:41:41,293 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,294 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 11.206676483154297
2023-01-07 07:41:41,294 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,295 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 07:41:41,295 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,295 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,295 > [DEBUG] 0 :: scheduled task in layer1.1.conv3._dp_wrapped_module.flat_param_0 :: 14, FW, [AR, [[16, torch.Size([16384]) 8376 8376]]]
2023-01-07 07:41:41,295 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,295 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,296 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,296 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,296 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,296 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,296 > [DEBUG] 0 :: scheduled task in layer1.1.bn3._dp_wrapped_module.flat_param_0 :: 15, FW, [AR, [[16, torch.Size([16384]) 15379 15379], [18, torch.Size([36864]) 26760 26760]]]
2023-01-07 07:41:41,296 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,297 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: -52.058815002441406
2023-01-07 07:41:41,297 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,297 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 07:41:41,297 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,297 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,297 > [DEBUG] 0 :: scheduled task in layer1.2.conv1._dp_wrapped_module.flat_param_0 :: 16, FW, [AR, [[18, torch.Size([36864]) 29950 29950]]]
2023-01-07 07:41:41,297 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,298 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,298 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 07:41:41,298 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,298 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,298 > [DEBUG] 0 :: scheduled task in layer1.2.bn1._dp_wrapped_module.flat_param_0 :: 17, FW, [AR, [[18, torch.Size([36864]) 34171 34171]]]
2023-01-07 07:41:41,299 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,299 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: -9.85119342803955
2023-01-07 07:41:41,299 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,300 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 07:41:41,300 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,300 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,300 > [DEBUG] 0 :: scheduled task in layer1.2.conv2._dp_wrapped_module.flat_param_0 :: 18, FW, [AR, [[19, torch.Size([128]) 0 0], [20, torch.Size([16384]) 0 0], [22, torch.Size([32768]) 14465 14465]]]
2023-01-07 07:41:41,300 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,301 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,301 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,301 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 07:41:41,301 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,301 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,301 > [DEBUG] 0 :: scheduled task in layer1.2.bn2._dp_wrapped_module.flat_param_0 :: 19, FW, [AR, [[24, torch.Size([147456]) 134884 134884]]]
2023-01-07 07:41:41,301 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,302 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 7.454243183135986
2023-01-07 07:41:41,302 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,302 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 07:41:41,302 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,302 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,302 > [DEBUG] 0 :: scheduled task in layer1.2.conv3._dp_wrapped_module.flat_param_0 :: 20, FW, [AR, [[22, torch.Size([32768]) 24699 24699]]]
2023-01-07 07:41:41,303 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,303 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,303 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,304 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,304 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,304 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,304 > [DEBUG] 0 :: scheduled task in layer1.2.bn3._dp_wrapped_module.flat_param_0 :: 21, FW, [AR, [[24, torch.Size([147456]) 137525 137525]]]
2023-01-07 07:41:41,304 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,305 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 14.316507339477539
2023-01-07 07:41:41,305 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,305 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 32768
2023-01-07 07:41:41,305 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,305 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,305 > [DEBUG] 0 :: scheduled task in layer2.0.conv1._dp_wrapped_module.flat_param_0 :: 22, FW, [AR, [[24, torch.Size([147456]) 140496 140496]]]
2023-01-07 07:41:41,305 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,306 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,306 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,306 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,306 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,306 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,306 > [DEBUG] 0 :: scheduled task in layer2.0.bn1._dp_wrapped_module.flat_param_0 :: 23, FW, [AR, [[24, torch.Size([147456]) 144875 144875]]]
2023-01-07 07:41:41,306 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,307 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: -9.485372543334961
2023-01-07 07:41:41,307 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,308 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 07:41:41,308 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,308 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,308 > [DEBUG] 0 :: scheduled task in layer2.0.conv2._dp_wrapped_module.flat_param_0 :: 24, FW, [AR, [[25, torch.Size([256]) 0 0], [26, torch.Size([65536]) 55354 55354]]]
2023-01-07 07:41:41,308 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,309 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,309 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,309 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,309 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,309 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,309 > [DEBUG] 0 :: scheduled task in layer2.0.bn2._dp_wrapped_module.flat_param_0 :: 25, FW, [AR, [[26, torch.Size([65536]) 62932 62932]]]
2023-01-07 07:41:41,309 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,310 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 19.09139633178711
2023-01-07 07:41:41,310 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,310 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 07:41:41,310 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,311 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,311 > [DEBUG] 0 :: scheduled task in layer2.0.conv3._dp_wrapped_module.flat_param_0 :: 26, FW, [AR, [[27, torch.Size([1024]) 0 0], [28, torch.Size([131072]) 121409 121409]]]
2023-01-07 07:41:41,311 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,311 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,311 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,312 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,312 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,312 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,312 > [DEBUG] 0 :: scheduled task in layer2.0.bn3._dp_wrapped_module.flat_param_0 :: 27, FW, [AR, [[28, torch.Size([131072]) 128101 128101]]]
2023-01-07 07:41:41,312 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,313 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 8.277016639709473
2023-01-07 07:41:41,313 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,313 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 07:41:41,313 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,313 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,313 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.0._dp_wrapped_module.flat_param_0 :: 28, FW, [AR, [[30, torch.Size([65536]) 58518 58518]]]
2023-01-07 07:41:41,314 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,315 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,315 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,315 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,315 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,315 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,315 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.1._dp_wrapped_module.flat_param_0 :: 29, FW, [AR, [[30, torch.Size([65536]) 62926 62926]]]
2023-01-07 07:41:41,315 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,316 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -8.041526794433594
2023-01-07 07:41:41,316 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,316 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 07:41:41,316 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,316 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,316 > [DEBUG] 0 :: scheduled task in layer2.1.conv1._dp_wrapped_module.flat_param_0 :: 30, FW, [AR, [[31, torch.Size([256]) 0 0], [32, torch.Size([147456]) 137276 137276]]]
2023-01-07 07:41:41,316 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,317 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,317 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,318 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,318 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,318 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,318 > [DEBUG] 0 :: scheduled task in layer2.1.bn1._dp_wrapped_module.flat_param_0 :: 31, FW, [AR, [[32, torch.Size([147456]) 144843 144843]]]
2023-01-07 07:41:41,318 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,319 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -23.321985244750977
2023-01-07 07:41:41,319 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,319 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 07:41:41,319 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,319 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,319 > [DEBUG] 0 :: scheduled task in layer2.1.conv2._dp_wrapped_module.flat_param_0 :: 32, FW, [AR, [[33, torch.Size([256]) 0 0], [34, torch.Size([65536]) 55010 55010]]]
2023-01-07 07:41:41,319 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,320 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,320 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,320 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,320 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,321 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,321 > [DEBUG] 0 :: scheduled task in layer2.1.bn2._dp_wrapped_module.flat_param_0 :: 33, FW, [AR, [[34, torch.Size([65536]) 62519 62519]]]
2023-01-07 07:41:41,321 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,321 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -3.7495665550231934
2023-01-07 07:41:41,322 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,322 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 07:41:41,322 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,322 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,322 > [DEBUG] 0 :: scheduled task in layer2.1.conv3._dp_wrapped_module.flat_param_0 :: 34, FW, [AR, [[36, torch.Size([65536]) 58337 58337]]]
2023-01-07 07:41:41,322 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,323 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,323 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,323 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,323 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,323 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,323 > [DEBUG] 0 :: scheduled task in layer2.1.bn3._dp_wrapped_module.flat_param_0 :: 35, FW, [AR, [[36, torch.Size([65536]) 62837 62837]]]
2023-01-07 07:41:41,323 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,324 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 38.91859436035156
2023-01-07 07:41:41,324 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,324 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 07:41:41,324 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,325 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,325 > [DEBUG] 0 :: scheduled task in layer2.2.conv1._dp_wrapped_module.flat_param_0 :: 36, FW, [AR, [[37, torch.Size([256]) 0 0], [38, torch.Size([147456]) 136838 136838]]]
2023-01-07 07:41:41,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,325 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,325 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,326 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,326 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,326 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,326 > [DEBUG] 0 :: scheduled task in layer2.2.bn1._dp_wrapped_module.flat_param_0 :: 37, FW, [AR, [[38, torch.Size([147456]) 144611 144611]]]
2023-01-07 07:41:41,326 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,327 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 2.0721518993377686
2023-01-07 07:41:41,327 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,327 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 07:41:41,327 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,327 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,327 > [DEBUG] 0 :: scheduled task in layer2.2.conv2._dp_wrapped_module.flat_param_0 :: 38, FW, [AR, [[39, torch.Size([256]) 0 0], [40, torch.Size([65536]) 54391 54391]]]
2023-01-07 07:41:41,327 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,328 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,328 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,328 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,328 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,328 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,328 > [DEBUG] 0 :: scheduled task in layer2.2.bn2._dp_wrapped_module.flat_param_0 :: 39, FW, [AR, [[40, torch.Size([65536]) 62211 62211]]]
2023-01-07 07:41:41,329 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,329 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -0.8927364349365234
2023-01-07 07:41:41,329 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,330 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 07:41:41,330 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,330 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,330 > [DEBUG] 0 :: scheduled task in layer2.2.conv3._dp_wrapped_module.flat_param_0 :: 40, FW, [AR, [[41, torch.Size([1024]) 0 0], [42, torch.Size([65536]) 58457 58457]]]
2023-01-07 07:41:41,330 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,331 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,331 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,331 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,331 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,331 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,331 > [DEBUG] 0 :: scheduled task in layer2.2.bn3._dp_wrapped_module.flat_param_0 :: 41, FW, [AR, [[42, torch.Size([65536]) 62434 62434]]]
2023-01-07 07:41:41,331 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,332 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -12.038360595703125
2023-01-07 07:41:41,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,332 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 07:41:41,332 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,332 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,332 > [DEBUG] 0 :: scheduled task in layer2.3.conv1._dp_wrapped_module.flat_param_0 :: 42, FW, [AR, [[43, torch.Size([256]) 0 0], [44, torch.Size([147456]) 136250 136250]]]
2023-01-07 07:41:41,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,333 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,333 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,333 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,333 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,333 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,334 > [DEBUG] 0 :: scheduled task in layer2.3.bn1._dp_wrapped_module.flat_param_0 :: 43, FW, [AR, [[44, torch.Size([147456]) 144343 144343]]]
2023-01-07 07:41:41,334 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,335 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -35.73182678222656
2023-01-07 07:41:41,335 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,335 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 07:41:41,335 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,335 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,335 > [DEBUG] 0 :: scheduled task in layer2.3.conv2._dp_wrapped_module.flat_param_0 :: 44, FW, [AR, [[45, torch.Size([256]) 0 0], [46, torch.Size([65536]) 53786 53786]]]
2023-01-07 07:41:41,335 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,336 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,336 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,336 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 07:41:41,336 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,336 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,336 > [DEBUG] 0 :: scheduled task in layer2.3.bn2._dp_wrapped_module.flat_param_0 :: 45, FW, [AR, [[46, torch.Size([65536]) 62012 62012]]]
2023-01-07 07:41:41,336 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,337 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 17.20201873779297
2023-01-07 07:41:41,337 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,337 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 07:41:41,337 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,338 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,338 > [DEBUG] 0 :: scheduled task in layer2.3.conv3._dp_wrapped_module.flat_param_0 :: 46, FW, [AR, [[47, torch.Size([1024]) 0 0], [48, torch.Size([131072]) 123183 123183]]]
2023-01-07 07:41:41,338 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,338 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,338 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,339 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,339 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,339 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,339 > [DEBUG] 0 :: scheduled task in layer2.3.bn3._dp_wrapped_module.flat_param_0 :: 47, FW, [AR, [[48, torch.Size([131072]) 127567 127567]]]
2023-01-07 07:41:41,339 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,340 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 4.680936813354492
2023-01-07 07:41:41,340 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,340 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 07:41:41,340 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,340 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,340 > [DEBUG] 0 :: scheduled task in layer3.0.conv1._dp_wrapped_module.flat_param_0 :: 48, FW, [AR, [[49, torch.Size([512]) 0 0], [50, torch.Size([589824]) 577505 577505]]]
2023-01-07 07:41:41,340 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,341 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,341 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,341 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,341 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,342 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,342 > [DEBUG] 0 :: scheduled task in layer3.0.bn1._dp_wrapped_module.flat_param_0 :: 49, FW, [AR, [[50, torch.Size([589824]) 586102 586102]]]
2023-01-07 07:41:41,342 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,342 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: 55.699363708496094
2023-01-07 07:41:41,343 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,343 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 07:41:41,343 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,343 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,343 > [DEBUG] 0 :: scheduled task in layer3.0.conv2._dp_wrapped_module.flat_param_0 :: 50, FW, [AR, [[52, torch.Size([262144]) 248915 248915]]]
2023-01-07 07:41:41,343 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,344 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,344 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,344 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,344 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,344 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,344 > [DEBUG] 0 :: scheduled task in layer3.0.bn2._dp_wrapped_module.flat_param_0 :: 51, FW, [AR, [[52, torch.Size([262144]) 258136 258136]]]
2023-01-07 07:41:41,344 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,345 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: 8.803061485290527
2023-01-07 07:41:41,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,346 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,346 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,346 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,346 > [DEBUG] 0 :: scheduled task in layer3.0.conv3._dp_wrapped_module.flat_param_0 :: 52, FW, [AR, [[54, torch.Size([524288]) 514056 514056]]]
2023-01-07 07:41:41,346 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,347 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 07:41:41,347 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,347 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 07:41:41,347 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,347 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,347 > [DEBUG] 0 :: scheduled task in layer3.0.bn3._dp_wrapped_module.flat_param_0 :: 53, FW, [AR, [[54, torch.Size([524288]) 520083 520083]]]
2023-01-07 07:41:41,347 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,348 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -71.79257202148438
2023-01-07 07:41:41,348 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,348 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 07:41:41,348 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,348 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,348 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.0._dp_wrapped_module.flat_param_0 :: 54, FW, [AR, [[56, torch.Size([262144]) 251612 251612]]]
2023-01-07 07:41:41,349 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,349 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 07:41:41,349 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,350 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 07:41:41,350 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,350 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,350 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.1._dp_wrapped_module.flat_param_0 :: 55, FW, [AR, [[56, torch.Size([262144]) 258055 258055]]]
2023-01-07 07:41:41,350 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,351 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 52.23896026611328
2023-01-07 07:41:41,351 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,351 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,351 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,351 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,351 > [DEBUG] 0 :: scheduled task in layer3.1.conv1._dp_wrapped_module.flat_param_0 :: 56, FW, [AR, [[57, torch.Size([512]) 0 0], [58, torch.Size([589824]) 575870 575870]]]
2023-01-07 07:41:41,351 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,352 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,352 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,352 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,352 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,352 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,352 > [DEBUG] 0 :: scheduled task in layer3.1.bn1._dp_wrapped_module.flat_param_0 :: 57, FW, [AR, [[58, torch.Size([589824]) 585646 585646]]]
2023-01-07 07:41:41,353 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,353 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -5.056705474853516
2023-01-07 07:41:41,353 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,354 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 07:41:41,354 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,354 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,354 > [DEBUG] 0 :: scheduled task in layer3.1.conv2._dp_wrapped_module.flat_param_0 :: 58, FW, [AR, [[60, torch.Size([262144]) 250298 250298]]]
2023-01-07 07:41:41,354 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,355 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,355 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,355 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,355 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,355 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,355 > [DEBUG] 0 :: scheduled task in layer3.1.bn2._dp_wrapped_module.flat_param_0 :: 59, FW, [AR, [[60, torch.Size([262144]) 257996 257996]]]
2023-01-07 07:41:41,355 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,356 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -10.145367622375488
2023-01-07 07:41:41,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,356 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,356 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,357 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,357 > [DEBUG] 0 :: scheduled task in layer3.1.conv3._dp_wrapped_module.flat_param_0 :: 60, FW, [AR, [[62, torch.Size([262144]) 251486 251486]]]
2023-01-07 07:41:41,357 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,357 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 07:41:41,357 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,358 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 07:41:41,358 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,358 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,358 > [DEBUG] 0 :: scheduled task in layer3.1.bn3._dp_wrapped_module.flat_param_0 :: 61, FW, [AR, [[62, torch.Size([262144]) 257960 257960]]]
2023-01-07 07:41:41,358 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,359 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 31.957576751708984
2023-01-07 07:41:41,359 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,359 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,359 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,359 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,359 > [DEBUG] 0 :: scheduled task in layer3.2.conv1._dp_wrapped_module.flat_param_0 :: 62, FW, [AR, [[64, torch.Size([589824]) 578797 578797]]]
2023-01-07 07:41:41,359 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,360 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,360 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,360 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,360 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,360 > [DEBUG] 0 :: scheduled task in layer3.2.bn1._dp_wrapped_module.flat_param_0 :: 63, FW, [AR, [[64, torch.Size([589824]) 585633 585633]]]
2023-01-07 07:41:41,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,361 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: -3.0289926528930664
2023-01-07 07:41:41,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,362 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 07:41:41,362 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,362 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,362 > [DEBUG] 0 :: scheduled task in layer3.2.conv2._dp_wrapped_module.flat_param_0 :: 64, FW, [AR, [[66, torch.Size([262144]) 250265 250265]]]
2023-01-07 07:41:41,362 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,363 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,363 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,363 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,363 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,363 > [DEBUG] 0 :: scheduled task in layer3.2.bn2._dp_wrapped_module.flat_param_0 :: 65, FW, [AR, [[66, torch.Size([262144]) 257992 257992]]]
2023-01-07 07:41:41,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,364 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -8.541306495666504
2023-01-07 07:41:41,364 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,364 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,364 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,364 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,364 > [DEBUG] 0 :: scheduled task in layer3.2.conv3._dp_wrapped_module.flat_param_0 :: 66, FW, [AR, [[68, torch.Size([262144]) 251489 251489]]]
2023-01-07 07:41:41,364 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,365 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 07:41:41,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,365 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 07:41:41,365 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,365 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,365 > [DEBUG] 0 :: scheduled task in layer3.2.bn3._dp_wrapped_module.flat_param_0 :: 67, FW, [AR, [[68, torch.Size([262144]) 257975 257975]]]
2023-01-07 07:41:41,366 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,366 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 48.289466857910156
2023-01-07 07:41:41,366 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,367 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,367 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,367 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,367 > [DEBUG] 0 :: scheduled task in layer3.3.conv1._dp_wrapped_module.flat_param_0 :: 68, FW, [AR, [[70, torch.Size([589824]) 578834 578834]]]
2023-01-07 07:41:41,367 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,368 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,368 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,368 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,368 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,368 > [DEBUG] 0 :: scheduled task in layer3.3.bn1._dp_wrapped_module.flat_param_0 :: 69, FW, [AR, [[70, torch.Size([589824]) 585643 585643]]]
2023-01-07 07:41:41,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,369 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: -13.345979690551758
2023-01-07 07:41:41,369 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,369 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 07:41:41,369 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,370 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,370 > [DEBUG] 0 :: scheduled task in layer3.3.conv2._dp_wrapped_module.flat_param_0 :: 70, FW, [AR, [[72, torch.Size([262144]) 250221 250221]]]
2023-01-07 07:41:41,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,370 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,371 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,371 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,371 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,371 > [DEBUG] 0 :: scheduled task in layer3.3.bn2._dp_wrapped_module.flat_param_0 :: 71, FW, [AR, [[72, torch.Size([262144]) 257983 257983]]]
2023-01-07 07:41:41,371 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,372 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 8.192964553833008
2023-01-07 07:41:41,372 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,372 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,372 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,372 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,372 > [DEBUG] 0 :: scheduled task in layer3.3.conv3._dp_wrapped_module.flat_param_0 :: 72, FW, [AR, [[74, torch.Size([262144]) 251508 251508]]]
2023-01-07 07:41:41,372 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,373 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 07:41:41,373 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,373 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 07:41:41,373 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,373 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,373 > [DEBUG] 0 :: scheduled task in layer3.3.bn3._dp_wrapped_module.flat_param_0 :: 73, FW, [AR, [[74, torch.Size([262144]) 257957 257957]]]
2023-01-07 07:41:41,373 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,374 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -71.32942962646484
2023-01-07 07:41:41,374 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,375 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,375 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,375 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,375 > [DEBUG] 0 :: scheduled task in layer3.4.conv1._dp_wrapped_module.flat_param_0 :: 74, FW, [AR, [[76, torch.Size([589824]) 578817 578817]]]
2023-01-07 07:41:41,375 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,376 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,376 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,376 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,376 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,376 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,376 > [DEBUG] 0 :: scheduled task in layer3.4.bn1._dp_wrapped_module.flat_param_0 :: 75, FW, [AR, [[76, torch.Size([589824]) 585626 585626]]]
2023-01-07 07:41:41,376 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,377 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -6.6282958984375
2023-01-07 07:41:41,377 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,377 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 07:41:41,377 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,377 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,377 > [DEBUG] 0 :: scheduled task in layer3.4.conv2._dp_wrapped_module.flat_param_0 :: 76, FW, [AR, [[78, torch.Size([262144]) 250146 250146]]]
2023-01-07 07:41:41,378 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,378 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,378 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,378 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,379 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,379 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,379 > [DEBUG] 0 :: scheduled task in layer3.4.bn2._dp_wrapped_module.flat_param_0 :: 77, FW, [AR, [[78, torch.Size([262144]) 258090 258090]]]
2023-01-07 07:41:41,379 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,379 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: 5.85734748840332
2023-01-07 07:41:41,380 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,380 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,380 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,380 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,380 > [DEBUG] 0 :: scheduled task in layer3.4.conv3._dp_wrapped_module.flat_param_0 :: 78, FW, [AR, [[80, torch.Size([262144]) 252751 252751]]]
2023-01-07 07:41:41,380 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,381 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 07:41:41,381 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,381 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 07:41:41,381 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,381 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,381 > [DEBUG] 0 :: scheduled task in layer3.4.bn3._dp_wrapped_module.flat_param_0 :: 79, FW, [AR, [[80, torch.Size([262144]) 258004 258004]]]
2023-01-07 07:41:41,381 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,382 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: 10.695408821105957
2023-01-07 07:41:41,382 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,383 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,383 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,383 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,383 > [DEBUG] 0 :: scheduled task in layer3.5.conv1._dp_wrapped_module.flat_param_0 :: 80, FW, [AR, [[82, torch.Size([589824]) 579303 579303]]]
2023-01-07 07:41:41,383 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,383 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,384 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,384 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,384 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,384 > [DEBUG] 0 :: scheduled task in layer3.5.bn1._dp_wrapped_module.flat_param_0 :: 81, FW, [AR, [[82, torch.Size([589824]) 585666 585666]]]
2023-01-07 07:41:41,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,385 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: 75.11569213867188
2023-01-07 07:41:41,385 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,385 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 07:41:41,385 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,385 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,385 > [DEBUG] 0 :: scheduled task in layer3.5.conv2._dp_wrapped_module.flat_param_0 :: 82, FW, [AR, [[84, torch.Size([262144]) 249049 249049]]]
2023-01-07 07:41:41,385 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,386 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,386 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,386 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 07:41:41,386 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,386 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,387 > [DEBUG] 0 :: scheduled task in layer3.5.bn2._dp_wrapped_module.flat_param_0 :: 83, FW, [AR, [[84, torch.Size([262144]) 258029 258029]]]
2023-01-07 07:41:41,387 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,387 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: 27.568273544311523
2023-01-07 07:41:41,387 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,388 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 07:41:41,388 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,388 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,388 > [DEBUG] 0 :: scheduled task in layer3.5.conv3._dp_wrapped_module.flat_param_0 :: 84, FW, [AR, [[86, torch.Size([524288]) 513996 513996]]]
2023-01-07 07:41:41,388 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,389 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 07:41:41,389 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,389 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 07:41:41,389 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,389 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,389 > [DEBUG] 0 :: scheduled task in layer3.5.bn3._dp_wrapped_module.flat_param_0 :: 85, FW, [AR, [[86, torch.Size([524288]) 520257 520257]]]
2023-01-07 07:41:41,389 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,390 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -41.552024841308594
2023-01-07 07:41:41,390 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,390 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 07:41:41,390 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,390 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,390 > [DEBUG] 0 :: scheduled task in layer4.0.conv1._dp_wrapped_module.flat_param_0 :: 86, FW, [AR, [[88, torch.Size([2359296]) 2348986 2348986]]]
2023-01-07 07:41:41,391 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,391 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,391 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,392 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,392 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,392 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,392 > [DEBUG] 0 :: scheduled task in layer4.0.bn1._dp_wrapped_module.flat_param_0 :: 87, FW, [AR, [[88, torch.Size([2359296]) 2355264 2355264]]]
2023-01-07 07:41:41,392 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,393 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -36.109256744384766
2023-01-07 07:41:41,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,393 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 07:41:41,393 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,393 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,393 > [DEBUG] 0 :: scheduled task in layer4.0.conv2._dp_wrapped_module.flat_param_0 :: 88, FW, [AR, [[90, torch.Size([1048576]) 1038739 1038739]]]
2023-01-07 07:41:41,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,394 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,394 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,394 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,394 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,394 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,394 > [DEBUG] 0 :: scheduled task in layer4.0.bn2._dp_wrapped_module.flat_param_0 :: 89, FW, [AR, [[90, torch.Size([1048576]) 1044678 1044678]]]
2023-01-07 07:41:41,394 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,395 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -18.98105812072754
2023-01-07 07:41:41,395 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,396 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 07:41:41,396 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,396 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,396 > [DEBUG] 0 :: scheduled task in layer4.0.conv3._dp_wrapped_module.flat_param_0 :: 90, FW, [AR, [[92, torch.Size([2097152]) 2086529 2086529]]]
2023-01-07 07:41:41,396 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,396 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 07:41:41,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,397 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 07:41:41,397 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,397 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,397 > [DEBUG] 0 :: scheduled task in layer4.0.bn3._dp_wrapped_module.flat_param_0 :: 91, FW, [AR, [[92, torch.Size([2097152]) 2093335 2093335]]]
2023-01-07 07:41:41,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,398 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 49.12293243408203
2023-01-07 07:41:41,398 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,398 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2097152
2023-01-07 07:41:41,398 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,398 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,398 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.0._dp_wrapped_module.flat_param_0 :: 92, FW, [AR, [[94, torch.Size([1048576]) 1039183 1039183]]]
2023-01-07 07:41:41,398 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,399 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 07:41:41,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,399 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 07:41:41,399 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,399 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,399 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.1._dp_wrapped_module.flat_param_0 :: 93, FW, [AR, [[94, torch.Size([1048576]) 1044932 1044932]]]
2023-01-07 07:41:41,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,400 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: 45.70293045043945
2023-01-07 07:41:41,400 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,400 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 07:41:41,401 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,401 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,401 > [DEBUG] 0 :: scheduled task in layer4.1.conv1._dp_wrapped_module.flat_param_0 :: 94, FW, [AR, [[96, torch.Size([2359296]) 2350332 2350332]]]
2023-01-07 07:41:41,401 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,401 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,402 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,402 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,402 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,402 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,402 > [DEBUG] 0 :: scheduled task in layer4.1.bn1._dp_wrapped_module.flat_param_0 :: 95, FW, [AR, [[96, torch.Size([2359296]) 2355789 2355789]]]
2023-01-07 07:41:41,402 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,403 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 4.411893844604492
2023-01-07 07:41:41,403 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,403 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 07:41:41,403 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,403 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,403 > [DEBUG] 0 :: scheduled task in layer4.1.conv2._dp_wrapped_module.flat_param_0 :: 96, FW, [AR, [[98, torch.Size([1048576]) 1038824 1038824]]]
2023-01-07 07:41:41,403 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,404 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,404 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,404 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,405 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,405 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,405 > [DEBUG] 0 :: scheduled task in layer4.1.bn2._dp_wrapped_module.flat_param_0 :: 97, FW, [AR, [[98, torch.Size([1048576]) 1045258 1045258]]]
2023-01-07 07:41:41,405 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,405 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -52.94636535644531
2023-01-07 07:41:41,406 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,406 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 07:41:41,406 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,406 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,406 > [DEBUG] 0 :: scheduled task in layer4.1.conv3._dp_wrapped_module.flat_param_0 :: 98, FW, [AR, [[100, torch.Size([1048576]) 1041045 1041045]]]
2023-01-07 07:41:41,406 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,407 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 07:41:41,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,407 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 07:41:41,407 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,407 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,407 > [DEBUG] 0 :: scheduled task in layer4.1.bn3._dp_wrapped_module.flat_param_0 :: 99, FW, [AR, [[100, torch.Size([1048576]) 1045245 1045245]]]
2023-01-07 07:41:41,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,408 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -1.468430519104004
2023-01-07 07:41:41,408 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,408 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 07:41:41,409 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,409 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,409 > [DEBUG] 0 :: scheduled task in layer4.2.conv1._dp_wrapped_module.flat_param_0 :: 100, FW, [AR, [[102, torch.Size([2359296]) 2351012 2351012]]]
2023-01-07 07:41:41,409 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,409 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,409 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,410 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,410 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,410 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,410 > [DEBUG] 0 :: scheduled task in layer4.2.bn1._dp_wrapped_module.flat_param_0 :: 101, FW, [AR, [[102, torch.Size([2359296]) 2356170 2356170]]]
2023-01-07 07:41:41,410 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,411 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 2.085000991821289
2023-01-07 07:41:41,411 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,411 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 07:41:41,411 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,411 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,411 > [DEBUG] 0 :: scheduled task in layer4.2.conv2._dp_wrapped_module.flat_param_0 :: 102, FW, [AR, [[104, torch.Size([1048576]) 1040523 1040523]]]
2023-01-07 07:41:41,411 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,412 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,412 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,412 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 07:41:41,412 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,412 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,412 > [DEBUG] 0 :: scheduled task in layer4.2.bn2._dp_wrapped_module.flat_param_0 :: 103, FW, [AR, [[104, torch.Size([1048576]) 1045407 1045407]]]
2023-01-07 07:41:41,412 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,413 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 34.895591735839844
2023-01-07 07:41:41,413 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,414 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 07:41:41,414 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,414 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,414 > [DEBUG] 0 :: scheduled task in layer4.2.conv3._dp_wrapped_module.flat_param_0 :: 104, FW, [AR, [[106, torch.Size([2049000]) 2039302 2039302]]]
2023-01-07 07:41:41,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,414 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 07:41:41,415 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,415 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 07:41:41,415 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,415 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,415 > [DEBUG] 0 :: scheduled task in layer4.2.bn3._dp_wrapped_module.flat_param_0 :: 105, FW, [AR, [[106, torch.Size([2049000]) 2045884 2045884]]]
2023-01-07 07:41:41,415 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,416 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: 10.603769302368164
2023-01-07 07:41:41,416 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:41,416 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2049000
2023-01-07 07:41:41,416 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,417 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 07:41:41,417 > [DEBUG] 0 :: scheduled task in fc._dp_wrapped_module.flat_param_0 :: No scheduled
2023-01-07 07:41:41,418 > [DEBUG] 0 :: 7.117834568023682
2023-01-07 07:41:41,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,422 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,422 > [DEBUG] 0 :: before allreduce fusion buffer :: -375.8829345703125
2023-01-07 07:41:41,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,426 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,427 > [DEBUG] 0 :: before allreduce fusion buffer :: -348.36993408203125
2023-01-07 07:41:41,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,438 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,438 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.23129811882972717
2023-01-07 07:41:41,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,439 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,439 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.8026833534240723
2023-01-07 07:41:41,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,442 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,442 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.11220249533653259
2023-01-07 07:41:41,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,443 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,443 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4310687184333801
2023-01-07 07:41:41,445 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,445 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,445 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9487848281860352
2023-01-07 07:41:41,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,446 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,446 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4697040319442749
2023-01-07 07:41:41,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,448 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,448 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.06806887686252594
2023-01-07 07:41:41,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,449 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.777616024017334
2023-01-07 07:41:41,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,451 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,451 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4113647937774658
2023-01-07 07:41:41,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,452 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,453 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8115108609199524
2023-01-07 07:41:41,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,454 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,454 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.506500244140625
2023-01-07 07:41:41,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,455 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.32734113931655884
2023-01-07 07:41:41,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,458 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,458 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.06726492941379547
2023-01-07 07:41:41,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,459 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,459 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5350788235664368
2023-01-07 07:41:41,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,460 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,461 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.03604254499077797
2023-01-07 07:41:41,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,462 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,462 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5178152322769165
2023-01-07 07:41:41,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,465 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,465 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4322452247142792
2023-01-07 07:41:41,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,466 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,466 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.076737880706787
2023-01-07 07:41:41,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,468 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.578446865081787
2023-01-07 07:41:41,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,469 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,469 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.32016658782958984
2023-01-07 07:41:41,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,471 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,471 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.0522041916847229
2023-01-07 07:41:41,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,472 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,472 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7867140769958496
2023-01-07 07:41:41,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,474 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,474 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.48614245653152466
2023-01-07 07:41:41,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,475 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,475 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3326398432254791
2023-01-07 07:41:41,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,477 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,477 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.49401748180389404
2023-01-07 07:41:41,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,478 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,478 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.693821430206299
2023-01-07 07:41:41,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,480 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,480 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9388538599014282
2023-01-07 07:41:41,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,481 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,481 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.22150683403015137
2023-01-07 07:41:41,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,483 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,483 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3780168890953064
2023-01-07 07:41:41,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,483 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,484 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.1852762699127197
2023-01-07 07:41:41,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,485 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,485 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2868238091468811
2023-01-07 07:41:41,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,486 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,486 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.523759126663208
2023-01-07 07:41:41,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,488 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,488 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.02384193241596222
2023-01-07 07:41:41,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,489 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,489 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.699399471282959
2023-01-07 07:41:41,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,491 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,491 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6043708324432373
2023-01-07 07:41:41,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,492 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,492 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1472500562667847
2023-01-07 07:41:41,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,493 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,493 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9429768323898315
2023-01-07 07:41:41,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,494 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,495 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5915592908859253
2023-01-07 07:41:41,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,496 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,496 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4960508346557617
2023-01-07 07:41:41,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,497 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,497 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.014381825923919678
2023-01-07 07:41:41,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,499 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,499 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9776031970977783
2023-01-07 07:41:41,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,500 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,500 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.46729850769043
2023-01-07 07:41:41,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,501 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,502 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2832087278366089
2023-01-07 07:41:41,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,502 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,503 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.2810003757476807
2023-01-07 07:41:41,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,504 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,504 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.7156620025634766
2023-01-07 07:41:41,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,505 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,506 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.889330506324768
2023-01-07 07:41:41,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,507 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,507 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.5776143074035645
2023-01-07 07:41:41,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,508 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1277815103530884
2023-01-07 07:41:41,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,509 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,509 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.2704851627349854
2023-01-07 07:41:41,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,510 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,511 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,511 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.904424667358398
2023-01-07 07:41:41,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,513 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,513 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9719141721725464
2023-01-07 07:41:41,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,514 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,514 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.2778944969177246
2023-01-07 07:41:41,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,515 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,515 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0934865474700928
2023-01-07 07:41:41,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,516 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,517 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.379204750061035
2023-01-07 07:41:41,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,518 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,519 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2171306610107422
2023-01-07 07:41:41,519 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,519 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.606149673461914
2023-01-07 07:41:41,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,521 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,521 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7498329877853394
2023-01-07 07:41:41,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,522 > [DEBUG] 0 :: before allreduce fusion buffer :: 23.773605346679688
2023-01-07 07:41:41,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,523 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,524 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.07560364902019501
2023-01-07 07:41:41,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,525 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.215208053588867
2023-01-07 07:41:41,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,526 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,526 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.010263442993164
2023-01-07 07:41:41,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,527 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.847734451293945
2023-01-07 07:41:41,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,528 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,529 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.5209723711013794
2023-01-07 07:41:41,529 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,530 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.419082641601562
2023-01-07 07:41:41,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,531 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,531 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3611815571784973
2023-01-07 07:41:41,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,532 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.45674991607666
2023-01-07 07:41:41,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,533 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,533 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.873985290527344
2023-01-07 07:41:41,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,534 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.453831195831299
2023-01-07 07:41:41,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,535 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,536 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.5592732429504395
2023-01-07 07:41:41,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,536 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,537 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.1797840595245361
2023-01-07 07:41:41,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,538 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,538 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.187163829803467
2023-01-07 07:41:41,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,539 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.649677038192749
2023-01-07 07:41:41,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,540 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,540 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.2676453590393066
2023-01-07 07:41:41,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,541 > [DEBUG] 0 :: before allreduce fusion buffer :: 22.684572219848633
2023-01-07 07:41:41,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,543 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.542842864990234
2023-01-07 07:41:41,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,543 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,544 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,544 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,544 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.539011001586914
2023-01-07 07:41:41,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,545 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.3995518684387207
2023-01-07 07:41:41,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,547 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.075153350830078
2023-01-07 07:41:41,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,548 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.2813806533813477
2023-01-07 07:41:41,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,549 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8927767276763916
2023-01-07 07:41:41,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,550 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,550 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.206323623657227
2023-01-07 07:41:41,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,551 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,551 > [DEBUG] 0 :: before allreduce fusion buffer :: 40.50763702392578
2023-01-07 07:41:41,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,553 > [DEBUG] 0 :: before allreduce fusion buffer :: 38.01060104370117
2023-01-07 07:41:41,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,554 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,554 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,554 > [DEBUG] 0 :: before allreduce fusion buffer :: -18.162872314453125
2023-01-07 07:41:41,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,556 > [DEBUG] 0 :: before allreduce fusion buffer :: 19.9886417388916
2023-01-07 07:41:41,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,557 > [DEBUG] 0 :: before allreduce fusion buffer :: -42.67185974121094
2023-01-07 07:41:41,559 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,559 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,559 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.91433334350586
2023-01-07 07:41:41,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,560 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,560 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.90003967285156
2023-01-07 07:41:41,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,562 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.589956283569336
2023-01-07 07:41:41,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,563 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,563 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,563 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.4750561714172363
2023-01-07 07:41:41,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,564 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,564 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.40108442306518555
2023-01-07 07:41:41,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,565 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,566 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.65639877319336
2023-01-07 07:41:41,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 60.35528564453125
2023-01-07 07:41:41,569 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,569 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,569 > [DEBUG] 0 :: before allreduce fusion buffer :: -102.74537658691406
2023-01-07 07:41:41,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,570 > [DEBUG] 0 :: before allreduce fusion buffer :: 57.69082260131836
2023-01-07 07:41:41,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,571 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,571 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,571 > [DEBUG] 0 :: before allreduce fusion buffer :: 73.61909484863281
2023-01-07 07:41:41,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,573 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,573 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.201257705688477
2023-01-07 07:41:41,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,574 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,574 > [DEBUG] 0 :: before allreduce fusion buffer :: 77.83120727539062
2023-01-07 07:41:41,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,575 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.6502628326416
2023-01-07 07:41:41,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,576 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,576 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,576 > [DEBUG] 0 :: before allreduce fusion buffer :: 34.94871139526367
2023-01-07 07:41:41,577 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,578 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,578 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.253307342529297
2023-01-07 07:41:41,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,578 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,579 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,579 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,579 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.656147003173828
2023-01-07 07:41:41,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,581 > [DEBUG] 0 :: before allreduce fusion buffer :: 32.64984130859375
2023-01-07 07:41:41,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,582 > [DEBUG] 0 :: before allreduce fusion buffer :: -22.140106201171875
2023-01-07 07:41:41,588 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 07:41:41,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,588 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,588 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,595 > [DEBUG] 0 :: before allreduce fusion buffer :: -2446.121337890625
2023-01-07 07:41:41,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,598 > [DEBUG] 0 :: before allreduce fusion buffer :: 77.34080505371094
2023-01-07 07:41:41,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,599 > [DEBUG] 0 :: before allreduce fusion buffer :: 48.41820526123047
2023-01-07 07:41:41,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,600 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.3087158203125
2023-01-07 07:41:41,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,601 > [DEBUG] 0 :: before allreduce fusion buffer :: 735.3317260742188
2023-01-07 07:41:41,602 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -1.24530029296875
2023-01-07 07:41:41,602 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,602 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,602 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,602 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 07:41:41,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,602 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,602 > [DEBUG] 0 :: before allreduce fusion buffer :: -147.71188354492188
2023-01-07 07:41:41,603 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,603 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,603 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,603 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,603 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: -0.7520308494567871
2023-01-07 07:41:41,603 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,604 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,604 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,604 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,604 > [DEBUG] 0 :: before allreduce fusion buffer :: 210.7755889892578
2023-01-07 07:41:41,605 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: -0.7520308494567871
2023-01-07 07:41:41,605 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,605 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,605 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,605 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 4.865289688110352
2023-01-07 07:41:41,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,606 > [DEBUG] 0 :: before allreduce fusion buffer :: 137.04330444335938
2023-01-07 07:41:41,606 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 66.39997100830078
2023-01-07 07:41:41,606 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,606 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,606 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,606 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 4.865289688110352
2023-01-07 07:41:41,606 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,607 > [DEBUG] 0 :: before allreduce fusion buffer :: -80.91504669189453
2023-01-07 07:41:41,608 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 4.865289688110352
2023-01-07 07:41:41,608 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,608 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,608 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,608 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 07:41:41,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,608 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,608 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,608 > [DEBUG] 0 :: before allreduce fusion buffer :: -98.72077941894531
2023-01-07 07:41:41,609 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,610 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,610 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,610 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,610 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -9.85119342803955
2023-01-07 07:41:41,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,610 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.54583740234375
2023-01-07 07:41:41,611 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 5.5570220947265625
2023-01-07 07:41:41,611 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,611 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,611 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,611 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 07:41:41,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,611 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,611 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,611 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.161834716796875
2023-01-07 07:41:41,613 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,613 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,613 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,613 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,613 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 19.15532684326172
2023-01-07 07:41:41,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,613 > [DEBUG] 0 :: before allreduce fusion buffer :: -22.044532775878906
2023-01-07 07:41:41,614 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -5.595541000366211
2023-01-07 07:41:41,614 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,614 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,614 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,614 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 19.15532684326172
2023-01-07 07:41:41,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,614 > [DEBUG] 0 :: before allreduce fusion buffer :: -142.14134216308594
2023-01-07 07:41:41,615 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 249.60000610351562
2023-01-07 07:41:41,615 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,615 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,615 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,615 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 19.15532684326172
2023-01-07 07:41:41,615 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,615 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,615 > [DEBUG] 0 :: before allreduce fusion buffer :: 51.721473693847656
2023-01-07 07:41:41,616 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: -22.67413330078125
2023-01-07 07:41:41,616 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,616 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,616 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,616 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 07:41:41,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,617 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,617 > [DEBUG] 0 :: before allreduce fusion buffer :: -243.10281372070312
2023-01-07 07:41:41,618 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,618 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,618 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,618 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,618 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 19.15532684326172
2023-01-07 07:41:41,618 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,618 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,618 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,618 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,618 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.850088119506836
2023-01-07 07:41:41,619 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 19.15532684326172
2023-01-07 07:41:41,619 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,619 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,619 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,620 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 07:41:41,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,620 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,620 > [DEBUG] 0 :: before allreduce fusion buffer :: -31.131948471069336
2023-01-07 07:41:41,621 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,621 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,621 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,621 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,621 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -9.85119342803955
2023-01-07 07:41:41,621 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,621 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,621 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.864807605743408
2023-01-07 07:41:41,622 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 11.206676483154297
2023-01-07 07:41:41,622 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,622 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,622 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,622 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -52.058815002441406
2023-01-07 07:41:41,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,623 > [DEBUG] 0 :: before allreduce fusion buffer :: -26.941638946533203
2023-01-07 07:41:41,623 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 248.20004272460938
2023-01-07 07:41:41,623 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,623 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,624 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,624 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -52.058815002441406
2023-01-07 07:41:41,624 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,624 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,624 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,624 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,624 > [DEBUG] 0 :: before allreduce fusion buffer :: 89.59832763671875
2023-01-07 07:41:41,625 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: -52.058815002441406
2023-01-07 07:41:41,625 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,625 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,625 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,625 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -9.85119342803955
2023-01-07 07:41:41,625 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,625 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,626 > [DEBUG] 0 :: before allreduce fusion buffer :: -43.479888916015625
2023-01-07 07:41:41,626 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 62.20000076293945
2023-01-07 07:41:41,626 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,626 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,626 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,626 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: -9.85119342803955
2023-01-07 07:41:41,626 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,627 > [DEBUG] 0 :: before allreduce fusion buffer :: 113.69908142089844
2023-01-07 07:41:41,628 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: -9.85119342803955
2023-01-07 07:41:41,628 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,628 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,628 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,628 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 07:41:41,628 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,628 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,628 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,628 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,629 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,629 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,629 > [DEBUG] 0 :: before allreduce fusion buffer :: -49.374210357666016
2023-01-07 07:41:41,630 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 07:41:41,630 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,630 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,630 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,630 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -9.485372543334961
2023-01-07 07:41:41,630 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,630 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,630 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.62212371826172
2023-01-07 07:41:41,631 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 7.454243183135986
2023-01-07 07:41:41,631 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,631 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,631 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,631 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 14.316507339477539
2023-01-07 07:41:41,631 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,631 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,632 > [DEBUG] 0 :: before allreduce fusion buffer :: -14.92404556274414
2023-01-07 07:41:41,632 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 247.79998779296875
2023-01-07 07:41:41,632 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,633 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,633 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,633 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -9.485372543334961
2023-01-07 07:41:41,633 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,633 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,633 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.109355926513672
2023-01-07 07:41:41,634 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 14.316507339477539
2023-01-07 07:41:41,634 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,634 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,634 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,634 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -9.485372543334961
2023-01-07 07:41:41,634 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,634 > [DEBUG] 0 :: before allreduce fusion buffer :: -26.57386589050293
2023-01-07 07:41:41,635 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 127.00003051757812
2023-01-07 07:41:41,635 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,635 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,635 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,635 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: -9.485372543334961
2023-01-07 07:41:41,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,635 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,635 > [DEBUG] 0 :: before allreduce fusion buffer :: 33.38697052001953
2023-01-07 07:41:41,636 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: -9.485372543334961
2023-01-07 07:41:41,636 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,636 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,637 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,637 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 07:41:41,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,637 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,637 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,637 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.36665916442871
2023-01-07 07:41:41,638 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,638 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,638 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,638 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,638 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 19.09139633178711
2023-01-07 07:41:41,638 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,638 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,638 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.345834732055664
2023-01-07 07:41:41,640 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 19.09139633178711
2023-01-07 07:41:41,640 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,640 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,640 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,640 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 07:41:41,640 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,640 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,640 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,640 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,640 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.524712562561035
2023-01-07 07:41:41,641 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,641 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,641 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,641 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,641 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 8.277016639709473
2023-01-07 07:41:41,641 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,641 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,642 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9380841255187988
2023-01-07 07:41:41,642 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 8.277016639709473
2023-01-07 07:41:41,643 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,643 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,643 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,643 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -8.041526794433594
2023-01-07 07:41:41,643 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,643 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,643 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.43441158533096313
2023-01-07 07:41:41,644 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 505.6001281738281
2023-01-07 07:41:41,644 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,644 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,644 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,644 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -8.041526794433594
2023-01-07 07:41:41,644 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,644 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,644 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5623502731323242
2023-01-07 07:41:41,645 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -8.041526794433594
2023-01-07 07:41:41,645 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,645 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,645 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,645 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 07:41:41,645 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,645 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,646 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,646 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,646 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4560964107513428
2023-01-07 07:41:41,647 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,647 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,647 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,647 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,647 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: -23.321985244750977
2023-01-07 07:41:41,647 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,648 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,648 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.6378999948501587
2023-01-07 07:41:41,649 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -23.321985244750977
2023-01-07 07:41:41,649 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,649 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,649 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,649 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 07:41:41,649 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,649 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,649 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,649 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,649 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.69146728515625
2023-01-07 07:41:41,650 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,650 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,650 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,651 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,651 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: -3.7495665550231934
2023-01-07 07:41:41,651 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,651 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,651 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.62380051612854
2023-01-07 07:41:41,652 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: -3.7495665550231934
2023-01-07 07:41:41,652 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,652 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,652 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,652 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 38.91859436035156
2023-01-07 07:41:41,652 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,652 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,652 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.16266095638275146
2023-01-07 07:41:41,653 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 510.7998046875
2023-01-07 07:41:41,653 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,653 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,653 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,653 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 38.91859436035156
2023-01-07 07:41:41,653 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,653 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,654 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.289238452911377
2023-01-07 07:41:41,655 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 38.91859436035156
2023-01-07 07:41:41,655 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,655 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,655 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,655 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 07:41:41,655 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,655 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,655 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,655 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,655 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.317482948303223
2023-01-07 07:41:41,656 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,656 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,656 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,656 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,656 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 2.0721518993377686
2023-01-07 07:41:41,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,657 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.2309751510620117
2023-01-07 07:41:41,658 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 2.0721518993377686
2023-01-07 07:41:41,658 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,658 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,658 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,658 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 07:41:41,658 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,658 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,658 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,658 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,658 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.5752997398376465
2023-01-07 07:41:41,659 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,659 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,660 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,660 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,660 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -0.8927364349365234
2023-01-07 07:41:41,660 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,660 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,660 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.690045356750488
2023-01-07 07:41:41,661 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -0.8927364349365234
2023-01-07 07:41:41,661 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,661 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,661 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,661 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 07:41:41,661 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,661 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,661 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,661 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,662 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.166132926940918
2023-01-07 07:41:41,662 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,662 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,663 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,663 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,663 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -12.038360595703125
2023-01-07 07:41:41,663 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,663 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,663 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.1503967046737671
2023-01-07 07:41:41,664 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -12.038360595703125
2023-01-07 07:41:41,664 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,664 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,664 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,664 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 07:41:41,664 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,665 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,665 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,665 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,665 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.105107307434082
2023-01-07 07:41:41,666 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,666 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,666 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,666 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,666 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -35.73182678222656
2023-01-07 07:41:41,666 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,666 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,666 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.2304813861846924
2023-01-07 07:41:41,667 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -35.73182678222656
2023-01-07 07:41:41,667 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,667 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,667 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,667 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 07:41:41,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,668 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,668 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,668 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.5611214637756348
2023-01-07 07:41:41,669 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 07:41:41,669 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,669 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,669 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,669 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 17.20201873779297
2023-01-07 07:41:41,669 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,669 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,669 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.4442105293273926
2023-01-07 07:41:41,670 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 17.20201873779297
2023-01-07 07:41:41,670 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,670 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,670 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,671 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 07:41:41,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,671 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,671 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,671 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.0053257942199707
2023-01-07 07:41:41,672 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 07:41:41,672 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,672 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,672 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,672 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 4.680936813354492
2023-01-07 07:41:41,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,672 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6658005714416504
2023-01-07 07:41:41,674 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 4.680936813354492
2023-01-07 07:41:41,674 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,674 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,674 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,674 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 07:41:41,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,674 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,674 > [DEBUG] 0 :: before allreduce fusion buffer :: 27.879684448242188
2023-01-07 07:41:41,675 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,676 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,676 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,676 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,676 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: 55.699363708496094
2023-01-07 07:41:41,676 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,676 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,676 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.490970134735107
2023-01-07 07:41:41,677 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: 55.699363708496094
2023-01-07 07:41:41,677 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,677 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,677 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,677 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: 8.803061485290527
2023-01-07 07:41:41,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,678 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,678 > [DEBUG] 0 :: before allreduce fusion buffer :: 13.215489387512207
2023-01-07 07:41:41,678 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 262.599853515625
2023-01-07 07:41:41,678 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,678 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,678 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,679 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: 8.803061485290527
2023-01-07 07:41:41,679 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,679 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,679 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.020893096923828
2023-01-07 07:41:41,680 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: 8.803061485290527
2023-01-07 07:41:41,680 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,680 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,680 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,680 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -71.79257202148438
2023-01-07 07:41:41,680 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,680 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,681 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.918555498123169
2023-01-07 07:41:41,681 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1025.8291015625
2023-01-07 07:41:41,681 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,681 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,681 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,681 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -71.79257202148438
2023-01-07 07:41:41,682 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,682 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.2758736610412598
2023-01-07 07:41:41,683 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -71.79257202148438
2023-01-07 07:41:41,683 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,683 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,683 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,683 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 52.23896026611328
2023-01-07 07:41:41,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,683 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7718754410743713
2023-01-07 07:41:41,684 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1034.20166015625
2023-01-07 07:41:41,684 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,684 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,684 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,684 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 52.23896026611328
2023-01-07 07:41:41,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,684 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.17086640000343323
2023-01-07 07:41:41,686 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 52.23896026611328
2023-01-07 07:41:41,686 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,686 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,686 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,686 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 07:41:41,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,686 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 07:41:41,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,686 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,686 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.8479044437408447
2023-01-07 07:41:41,687 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 07:41:41,687 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,687 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,687 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,688 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -5.056705474853516
2023-01-07 07:41:41,688 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,688 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,688 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6975064277648926
2023-01-07 07:41:41,689 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -5.056705474853516
2023-01-07 07:41:41,689 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,689 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,689 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,689 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -10.145367622375488
2023-01-07 07:41:41,689 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,689 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5195746421813965
2023-01-07 07:41:41,690 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 259.59967041015625
2023-01-07 07:41:41,690 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,690 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,690 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,690 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -10.145367622375488
2023-01-07 07:41:41,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,690 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.5577867031097412
2023-01-07 07:41:41,692 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -10.145367622375488
2023-01-07 07:41:41,692 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,692 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,692 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,692 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 31.957576751708984
2023-01-07 07:41:41,692 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,692 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,692 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7061631679534912
2023-01-07 07:41:41,693 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1041.982666015625
2023-01-07 07:41:41,693 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,693 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,693 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,693 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 31.957576751708984
2023-01-07 07:41:41,693 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,693 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,693 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.575953483581543
2023-01-07 07:41:41,695 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 31.957576751708984
2023-01-07 07:41:41,695 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,695 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,695 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,695 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -3.0289926528930664
2023-01-07 07:41:41,695 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,695 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,695 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.388779640197754
2023-01-07 07:41:41,696 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 258.399169921875
2023-01-07 07:41:41,696 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,696 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,696 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,696 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: -3.0289926528930664
2023-01-07 07:41:41,696 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,696 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,696 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.127046585083008
2023-01-07 07:41:41,697 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: -3.0289926528930664
2023-01-07 07:41:41,697 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,697 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,698 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,698 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -8.541306495666504
2023-01-07 07:41:41,698 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,698 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,698 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.17116005718708038
2023-01-07 07:41:41,699 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 255.8031768798828
2023-01-07 07:41:41,699 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,699 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,699 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,699 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -8.541306495666504
2023-01-07 07:41:41,699 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,699 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,699 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.641808271408081
2023-01-07 07:41:41,700 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -8.541306495666504
2023-01-07 07:41:41,700 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,700 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,700 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,700 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 48.289466857910156
2023-01-07 07:41:41,701 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,701 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,701 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.40849676728248596
2023-01-07 07:41:41,701 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1094.4073486328125
2023-01-07 07:41:41,701 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,701 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,701 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,702 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 48.289466857910156
2023-01-07 07:41:41,702 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,702 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,702 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2812516987323761
2023-01-07 07:41:41,703 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 48.289466857910156
2023-01-07 07:41:41,703 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,703 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,703 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,704 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -13.345979690551758
2023-01-07 07:41:41,704 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,704 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,704 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.288658618927002
2023-01-07 07:41:41,704 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 298.5999755859375
2023-01-07 07:41:41,704 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,705 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,705 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,705 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -13.345979690551758
2023-01-07 07:41:41,705 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,705 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,705 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.338798999786377
2023-01-07 07:41:41,706 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: -13.345979690551758
2023-01-07 07:41:41,706 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,706 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,706 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,706 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 8.192964553833008
2023-01-07 07:41:41,707 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,707 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,707 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.10454702377319336
2023-01-07 07:41:41,707 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 300.79913330078125
2023-01-07 07:41:41,707 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,707 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,708 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,708 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 8.192964553833008
2023-01-07 07:41:41,708 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,708 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,708 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7257041931152344
2023-01-07 07:41:41,709 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 8.192964553833008
2023-01-07 07:41:41,709 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,709 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,709 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,709 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -71.32942962646484
2023-01-07 07:41:41,709 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,709 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,710 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.1451807022094727
2023-01-07 07:41:41,710 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1100.402099609375
2023-01-07 07:41:41,710 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,710 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,710 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,711 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -71.32942962646484
2023-01-07 07:41:41,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,711 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0038371086120605
2023-01-07 07:41:41,712 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -71.32942962646484
2023-01-07 07:41:41,712 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,712 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,712 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,712 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -6.6282958984375
2023-01-07 07:41:41,712 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,712 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,713 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5583912134170532
2023-01-07 07:41:41,713 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 301.5997314453125
2023-01-07 07:41:41,713 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,713 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,713 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,714 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -6.6282958984375
2023-01-07 07:41:41,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,714 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9091389179229736
2023-01-07 07:41:41,715 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -6.6282958984375
2023-01-07 07:41:41,715 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,715 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,715 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,715 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: 5.85734748840332
2023-01-07 07:41:41,715 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,715 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,715 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8642334938049316
2023-01-07 07:41:41,716 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 301.7999572753906
2023-01-07 07:41:41,716 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,716 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,716 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,716 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: 5.85734748840332
2023-01-07 07:41:41,716 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,716 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,717 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.27605530619621277
2023-01-07 07:41:41,718 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: 5.85734748840332
2023-01-07 07:41:41,718 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,718 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,718 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,718 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: 10.695408821105957
2023-01-07 07:41:41,718 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,718 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,718 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.4181926250457764
2023-01-07 07:41:41,719 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1111.203125
2023-01-07 07:41:41,719 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,719 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,719 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,719 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: 10.695408821105957
2023-01-07 07:41:41,719 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,719 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,719 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.050882577896118
2023-01-07 07:41:41,721 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: 10.695408821105957
2023-01-07 07:41:41,721 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,721 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,721 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,721 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: 75.11569213867188
2023-01-07 07:41:41,721 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,721 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,721 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3352645635604858
2023-01-07 07:41:41,722 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 303.39971923828125
2023-01-07 07:41:41,722 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,722 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,722 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,722 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: 75.11569213867188
2023-01-07 07:41:41,722 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,722 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,722 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.053081750869751
2023-01-07 07:41:41,723 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: 75.11569213867188
2023-01-07 07:41:41,724 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,724 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,724 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,724 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: 27.568273544311523
2023-01-07 07:41:41,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,724 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2714977264404297
2023-01-07 07:41:41,725 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 303.999755859375
2023-01-07 07:41:41,725 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,725 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,725 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,725 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: 27.568273544311523
2023-01-07 07:41:41,725 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,725 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,725 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5164926052093506
2023-01-07 07:41:41,726 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: 27.568273544311523
2023-01-07 07:41:41,726 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,726 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,726 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,727 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -41.552024841308594
2023-01-07 07:41:41,727 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,727 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,727 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3733455240726471
2023-01-07 07:41:41,727 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1101.607421875
2023-01-07 07:41:41,728 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,728 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,728 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,728 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -41.552024841308594
2023-01-07 07:41:41,728 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,728 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,728 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7703540325164795
2023-01-07 07:41:41,729 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -41.552024841308594
2023-01-07 07:41:41,729 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,729 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,729 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,729 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -36.109256744384766
2023-01-07 07:41:41,729 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,729 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,730 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.5235202312469482
2023-01-07 07:41:41,730 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 598.7994384765625
2023-01-07 07:41:41,730 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,730 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,730 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,731 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -36.109256744384766
2023-01-07 07:41:41,731 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,731 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,731 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.0040123462677
2023-01-07 07:41:41,732 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -36.109256744384766
2023-01-07 07:41:41,732 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,732 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,732 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,732 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -18.98105812072754
2023-01-07 07:41:41,733 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,733 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,733 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.02848801016807556
2023-01-07 07:41:41,733 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 599.5992431640625
2023-01-07 07:41:41,733 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,733 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,734 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,734 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -18.98105812072754
2023-01-07 07:41:41,734 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,734 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,734 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.26808178424835205
2023-01-07 07:41:41,735 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -18.98105812072754
2023-01-07 07:41:41,735 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,735 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,735 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,735 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 49.12293243408203
2023-01-07 07:41:41,735 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,735 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,736 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9939639568328857
2023-01-07 07:41:41,736 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2130.39794921875
2023-01-07 07:41:41,736 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,736 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,736 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,736 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 49.12293243408203
2023-01-07 07:41:41,736 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,736 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,737 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1952259540557861
2023-01-07 07:41:41,738 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 49.12293243408203
2023-01-07 07:41:41,738 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,738 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,738 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,738 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: 45.70293045043945
2023-01-07 07:41:41,738 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,738 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,738 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.1758745014667511
2023-01-07 07:41:41,739 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2111.193359375
2023-01-07 07:41:41,739 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,739 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,739 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,739 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: 45.70293045043945
2023-01-07 07:41:41,739 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,739 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,739 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.09496157616376877
2023-01-07 07:41:41,740 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: 45.70293045043945
2023-01-07 07:41:41,740 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,740 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,741 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,741 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 4.411893844604492
2023-01-07 07:41:41,741 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,741 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,741 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.05315501242876053
2023-01-07 07:41:41,741 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 598.9991455078125
2023-01-07 07:41:41,742 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,742 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,742 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,742 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: 4.411893844604492
2023-01-07 07:41:41,742 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,742 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,742 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.47779572010040283
2023-01-07 07:41:41,743 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: 4.411893844604492
2023-01-07 07:41:41,743 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,743 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,743 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,744 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -52.94636535644531
2023-01-07 07:41:41,744 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,744 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,744 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.1417401134967804
2023-01-07 07:41:41,744 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 598.8011474609375
2023-01-07 07:41:41,745 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,745 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,745 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,745 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -52.94636535644531
2023-01-07 07:41:41,745 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,745 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,745 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7302818298339844
2023-01-07 07:41:41,746 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -52.94636535644531
2023-01-07 07:41:41,746 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,746 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,746 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,747 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -1.468430519104004
2023-01-07 07:41:41,747 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,747 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,747 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.07776646316051483
2023-01-07 07:41:41,747 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2076.600341796875
2023-01-07 07:41:41,748 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,748 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,748 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,748 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -1.468430519104004
2023-01-07 07:41:41,748 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,748 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,748 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.10537618398666382
2023-01-07 07:41:41,749 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -1.468430519104004
2023-01-07 07:41:41,749 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,749 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,749 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,749 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 2.085000991821289
2023-01-07 07:41:41,749 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,749 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,750 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5791015625
2023-01-07 07:41:41,750 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 600.2005615234375
2023-01-07 07:41:41,750 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,750 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,750 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,750 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 2.085000991821289
2023-01-07 07:41:41,751 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,751 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,751 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3069353699684143
2023-01-07 07:41:41,752 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 2.085000991821289
2023-01-07 07:41:41,752 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,752 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,752 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,752 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 34.895591735839844
2023-01-07 07:41:41,752 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,752 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,752 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.37947213649749756
2023-01-07 07:41:41,753 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 600.5993041992188
2023-01-07 07:41:41,753 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,753 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,753 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,753 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 34.895591735839844
2023-01-07 07:41:41,753 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,753 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,754 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.25713247060775757
2023-01-07 07:41:41,755 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 34.895591735839844
2023-01-07 07:41:41,755 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,755 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,755 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,755 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: 10.603769302368164
2023-01-07 07:41:41,755 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,755 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,755 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7617685794830322
2023-01-07 07:41:41,756 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2449.60400390625
2023-01-07 07:41:41,756 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,756 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,756 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,756 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: 10.603769302368164
2023-01-07 07:41:41,756 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,756 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,757 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.255921483039856
2023-01-07 07:41:41,758 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: 10.603769302368164
2023-01-07 07:41:41,758 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:41,758 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:41,758 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:41,759 > [DEBUG] 0 :: 7.353175640106201
2023-01-07 07:41:41,761 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,761 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,761 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,761 > [DEBUG] 0 :: before allreduce fusion buffer :: -584.23974609375
2023-01-07 07:41:41,762 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,762 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,762 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,763 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,763 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,763 > [DEBUG] 0 :: before allreduce fusion buffer :: -580.1905517578125
2023-01-07 07:41:41,765 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,765 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,766 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,766 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.9400634765625
2023-01-07 07:41:41,767 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,767 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,767 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,767 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,767 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,767 > [DEBUG] 0 :: before allreduce fusion buffer :: -283.02001953125
2023-01-07 07:41:41,769 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,769 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,770 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,770 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.227569580078125
2023-01-07 07:41:41,771 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,771 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,771 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,771 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,771 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,771 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.4990386962890625
2023-01-07 07:41:41,773 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,773 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,773 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,774 > [DEBUG] 0 :: before allreduce fusion buffer :: -27.91433334350586
2023-01-07 07:41:41,775 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,775 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,775 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,775 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,775 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,775 > [DEBUG] 0 :: before allreduce fusion buffer :: -29.21310806274414
2023-01-07 07:41:41,777 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,777 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,777 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,777 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.29829406738281
2023-01-07 07:41:41,778 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,779 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,779 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,779 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,779 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,779 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.24695587158203
2023-01-07 07:41:41,781 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,781 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,781 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,781 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.010894775390625
2023-01-07 07:41:41,782 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,782 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,783 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,783 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,783 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,783 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8348865509033203
2023-01-07 07:41:41,785 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,785 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,785 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,785 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.69070816040039
2023-01-07 07:41:41,786 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,786 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,786 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,787 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,787 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,787 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.0133056640625
2023-01-07 07:41:41,789 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,789 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,789 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,789 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.58782958984375
2023-01-07 07:41:41,790 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,790 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,790 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,790 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,791 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,791 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.101816177368164
2023-01-07 07:41:41,793 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,793 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,793 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,793 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.65461730957031
2023-01-07 07:41:41,794 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,794 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,794 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,794 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,794 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,795 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.732337951660156
2023-01-07 07:41:41,797 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,797 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,797 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,797 > [DEBUG] 0 :: before allreduce fusion buffer :: -31.063337326049805
2023-01-07 07:41:41,798 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,798 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,798 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,798 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,798 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,799 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.16003522276878357
2023-01-07 07:41:41,800 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,801 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,801 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,801 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.52726745605469
2023-01-07 07:41:41,802 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,802 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,802 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,802 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,802 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,802 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8687535524368286
2023-01-07 07:41:41,804 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,804 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,804 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,805 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.329559326171875
2023-01-07 07:41:41,806 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,806 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,806 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,807 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,807 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,807 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.664772033691406
2023-01-07 07:41:41,809 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,809 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,809 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,809 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.925315856933594
2023-01-07 07:41:41,810 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,810 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,810 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,810 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,810 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,811 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.589816093444824
2023-01-07 07:41:41,812 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,813 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,813 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,813 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.987693786621094
2023-01-07 07:41:41,814 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,814 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,814 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,814 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,814 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,814 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1270701885223389
2023-01-07 07:41:41,816 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,816 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,816 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,817 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.170166015625
2023-01-07 07:41:41,818 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,818 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,818 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,818 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,818 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,818 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.60322380065918
2023-01-07 07:41:41,977 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,977 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,977 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,977 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.98479461669922
2023-01-07 07:41:41,978 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,978 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,978 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:41,978 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:41,978 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:41,979 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.57495880126953
2023-01-07 07:41:42,160 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,161 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,161 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,161 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.125152587890625
2023-01-07 07:41:42,161 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,161 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,162 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,162 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,162 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,162 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3779381513595581
2023-01-07 07:41:42,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,461 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,462 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.11799621582031
2023-01-07 07:41:42,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,462 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,463 > [DEBUG] 0 :: before allreduce fusion buffer :: -64.38870239257812
2023-01-07 07:41:42,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,464 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,464 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.940940856933594
2023-01-07 07:41:42,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,465 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,465 > [DEBUG] 0 :: before allreduce fusion buffer :: -232.198486328125
2023-01-07 07:41:42,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,466 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,466 > [DEBUG] 0 :: before allreduce fusion buffer :: -32.1403923034668
2023-01-07 07:41:42,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,467 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,467 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5690275430679321
2023-01-07 07:41:42,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,468 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.794066846370697
2023-01-07 07:41:42,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,469 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,469 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.5376150608062744
2023-01-07 07:41:42,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,471 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,471 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.587332248687744
2023-01-07 07:41:42,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,471 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,472 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8171619176864624
2023-01-07 07:41:42,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,473 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,473 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.989227294921875
2023-01-07 07:41:42,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,474 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,474 > [DEBUG] 0 :: before allreduce fusion buffer :: -23.140827178955078
2023-01-07 07:41:42,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,475 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,475 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.43905872106552124
2023-01-07 07:41:42,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,476 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,476 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.132171154022217
2023-01-07 07:41:42,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,478 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,478 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4150571823120117
2023-01-07 07:41:42,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,478 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.663062572479248
2023-01-07 07:41:42,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,479 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,479 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.713172435760498
2023-01-07 07:41:42,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,480 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,480 > [DEBUG] 0 :: before allreduce fusion buffer :: -23.556726455688477
2023-01-07 07:41:42,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,481 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,482 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9023207426071167
2023-01-07 07:41:42,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,482 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,482 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.318599700927734
2023-01-07 07:41:42,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,484 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,484 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9002652168273926
2023-01-07 07:41:42,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,484 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,485 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.8158886432647705
2023-01-07 07:41:42,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,486 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,486 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.2215295135974884
2023-01-07 07:41:42,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,487 > [DEBUG] 0 :: before allreduce fusion buffer :: 29.66478729248047
2023-01-07 07:41:42,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,488 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,488 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.20850837230682373
2023-01-07 07:41:42,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,489 > [DEBUG] 0 :: before allreduce fusion buffer :: 5669.3076171875
2023-01-07 07:41:42,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,489 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,489 > [DEBUG] 0 :: before allreduce fusion buffer :: 778.4774780273438
2023-01-07 07:41:42,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,490 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.617633819580078
2023-01-07 07:41:42,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,491 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,491 > [DEBUG] 0 :: before allreduce fusion buffer :: 44.57341003417969
2023-01-07 07:41:42,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,492 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.0671849250793457
2023-01-07 07:41:42,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,493 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,493 > [DEBUG] 0 :: before allreduce fusion buffer :: 91.39443969726562
2023-01-07 07:41:42,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,494 > [DEBUG] 0 :: before allreduce fusion buffer :: 37.16950607299805
2023-01-07 07:41:42,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,495 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,495 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.253751754760742
2023-01-07 07:41:42,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,496 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.979222297668457
2023-01-07 07:41:42,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,496 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,496 > [DEBUG] 0 :: before allreduce fusion buffer :: -168.69964599609375
2023-01-07 07:41:42,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,497 > [DEBUG] 0 :: before allreduce fusion buffer :: -148.91452026367188
2023-01-07 07:41:42,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,498 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,498 > [DEBUG] 0 :: before allreduce fusion buffer :: -167.62210083007812
2023-01-07 07:41:42,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,499 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,499 > [DEBUG] 0 :: before allreduce fusion buffer :: -89.54440307617188
2023-01-07 07:41:42,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,501 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,501 > [DEBUG] 0 :: before allreduce fusion buffer :: 44.58357620239258
2023-01-07 07:41:42,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,501 > [DEBUG] 0 :: before allreduce fusion buffer :: 31.202600479125977
2023-01-07 07:41:42,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,502 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,502 > [DEBUG] 0 :: before allreduce fusion buffer :: -1601.8564453125
2023-01-07 07:41:42,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,503 > [DEBUG] 0 :: before allreduce fusion buffer :: -453.0145568847656
2023-01-07 07:41:42,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,504 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,504 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,504 > [DEBUG] 0 :: before allreduce fusion buffer :: -80.17510986328125
2023-01-07 07:41:42,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,505 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,505 > [DEBUG] 0 :: before allreduce fusion buffer :: 585.2457275390625
2023-01-07 07:41:42,506 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,506 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,506 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,506 > [DEBUG] 0 :: before allreduce fusion buffer :: 196.886474609375
2023-01-07 07:41:42,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,507 > [DEBUG] 0 :: before allreduce fusion buffer :: 2198.94287109375
2023-01-07 07:41:42,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,508 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,508 > [DEBUG] 0 :: before allreduce fusion buffer :: 1135.768310546875
2023-01-07 07:41:42,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,509 > [DEBUG] 0 :: before allreduce fusion buffer :: -120.85928344726562
2023-01-07 07:41:42,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,510 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,510 > [DEBUG] 0 :: before allreduce fusion buffer :: -1901.581298828125
2023-01-07 07:41:42,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,511 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,511 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,511 > [DEBUG] 0 :: before allreduce fusion buffer :: -7522.720703125
2023-01-07 07:41:42,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,512 > [DEBUG] 0 :: before allreduce fusion buffer :: 2370.24169921875
2023-01-07 07:41:42,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,513 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,513 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,513 > [DEBUG] 0 :: before allreduce fusion buffer :: 83277.015625
2023-01-07 07:41:42,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,514 > [DEBUG] 0 :: before allreduce fusion buffer :: -2040.0047607421875
2023-01-07 07:41:42,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,515 > [DEBUG] 0 :: before allreduce fusion buffer :: 3908.16015625
2023-01-07 07:41:42,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,516 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,516 > [DEBUG] 0 :: before allreduce fusion buffer :: 3933.542724609375
2023-01-07 07:41:42,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,517 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,517 > [DEBUG] 0 :: before allreduce fusion buffer :: -4598.49072265625
2023-01-07 07:41:42,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,518 > [DEBUG] 0 :: before allreduce fusion buffer :: -3980.10400390625
2023-01-07 07:41:42,519 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,519 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,519 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,519 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,519 > [DEBUG] 0 :: before allreduce fusion buffer :: 407458.5625
2023-01-07 07:41:42,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,520 > [DEBUG] 0 :: before allreduce fusion buffer :: 35429.5
2023-01-07 07:41:42,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,521 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,521 > [DEBUG] 0 :: before allreduce fusion buffer :: -8014754304.0
2023-01-07 07:41:42,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,522 > [DEBUG] 0 :: before allreduce fusion buffer :: 693898.8125
2023-01-07 07:41:42,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,523 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,523 > [DEBUG] 0 :: before allreduce fusion buffer :: -6451110400.0
2023-01-07 07:41:42,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,524 > [DEBUG] 0 :: before allreduce fusion buffer :: -8666.607421875
2023-01-07 07:41:42,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,525 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,525 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,526 > [DEBUG] 0 :: before allreduce fusion buffer :: 53551.8984375
2023-01-07 07:41:42,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,527 > [DEBUG] 0 :: before allreduce fusion buffer :: -86.41064453125
2023-01-07 07:41:42,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,528 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,528 > [DEBUG] 0 :: before allreduce fusion buffer :: -119512391680.0
2023-01-07 07:41:42,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,529 > [DEBUG] 0 :: before allreduce fusion buffer :: -12060.32421875
2023-01-07 07:41:42,529 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,529 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,530 > [DEBUG] 0 :: before allreduce fusion buffer :: -38150.94921875
2023-01-07 07:41:42,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,531 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,531 > [DEBUG] 0 :: before allreduce fusion buffer :: -62096.4765625
2023-01-07 07:41:42,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,532 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,532 > [DEBUG] 0 :: before allreduce fusion buffer :: 1277491.75
2023-01-07 07:41:42,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,533 > [DEBUG] 0 :: before allreduce fusion buffer :: 181491.484375
2023-01-07 07:41:42,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,534 > [DEBUG] 0 :: before allreduce fusion buffer :: 267612.65625
2023-01-07 07:41:42,536 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 07:41:42,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,536 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 389980094464.0
2023-01-07 07:41:42,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,545 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 3114370334720.0
2023-01-07 07:41:42,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,549 > [DEBUG] 0 :: before allreduce fusion buffer :: 6249542320128.0
2023-01-07 07:41:42,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,550 > [DEBUG] 0 :: before allreduce fusion buffer :: 2925826.75
2023-01-07 07:41:42,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,551 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,551 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: 99.48558044433594
2023-01-07 07:41:42,551 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,551 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,551 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,551 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 66.20000457763672
2023-01-07 07:41:42,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,551 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,552 > [DEBUG] 0 :: before allreduce fusion buffer :: 127950.875
2023-01-07 07:41:42,553 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 66.20000457763672
2023-01-07 07:41:42,553 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,553 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,553 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,553 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 31.649768829345703
2023-01-07 07:41:42,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,553 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,553 > [DEBUG] 0 :: before allreduce fusion buffer :: 2592257.5
2023-01-07 07:41:42,555 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 31.649768829345703
2023-01-07 07:41:42,555 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,555 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,555 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,555 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 183.7830810546875
2023-01-07 07:41:42,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,555 > [DEBUG] 0 :: before allreduce fusion buffer :: 64223.37109375
2023-01-07 07:41:42,556 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 66.39997100830078
2023-01-07 07:41:42,556 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,556 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,556 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,556 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 183.7830810546875
2023-01-07 07:41:42,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,556 > [DEBUG] 0 :: before allreduce fusion buffer :: 416338.1875
2023-01-07 07:41:42,557 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 183.7830810546875
2023-01-07 07:41:42,557 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,557 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,557 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,557 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 66.80000305175781
2023-01-07 07:41:42,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,558 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,558 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,558 > [DEBUG] 0 :: before allreduce fusion buffer :: -56967856.0
2023-01-07 07:41:42,559 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 66.80000305175781
2023-01-07 07:41:42,559 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,559 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,559 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,559 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 108.54647827148438
2023-01-07 07:41:42,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,560 > [DEBUG] 0 :: before allreduce fusion buffer :: 20125668.0
2023-01-07 07:41:42,560 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 33.865074157714844
2023-01-07 07:41:42,561 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,561 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,561 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,561 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 259.39996337890625
2023-01-07 07:41:42,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,561 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,561 > [DEBUG] 0 :: before allreduce fusion buffer :: 29262674.0
2023-01-07 07:41:42,562 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 259.39996337890625
2023-01-07 07:41:42,562 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,562 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,562 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,562 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 87.52503204345703
2023-01-07 07:41:42,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,563 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,563 > [DEBUG] 0 :: before allreduce fusion buffer :: 723703360.0
2023-01-07 07:41:42,563 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -5.595541000366211
2023-01-07 07:41:42,563 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,563 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,563 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,564 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 87.52503204345703
2023-01-07 07:41:42,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,564 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,564 > [DEBUG] 0 :: before allreduce fusion buffer :: -118865.75
2023-01-07 07:41:42,564 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 249.60000610351562
2023-01-07 07:41:42,565 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,565 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,565 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,565 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 87.52503204345703
2023-01-07 07:41:42,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,565 > [DEBUG] 0 :: before allreduce fusion buffer :: -31912.994140625
2023-01-07 07:41:42,566 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: -0.4699563980102539
2023-01-07 07:41:42,566 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,566 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,566 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 63.20033264160156
2023-01-07 07:41:42,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,566 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,566 > [DEBUG] 0 :: before allreduce fusion buffer :: 60046.30078125
2023-01-07 07:41:42,567 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 63.20033264160156
2023-01-07 07:41:42,567 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,567 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,567 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 87.52503204345703
2023-01-07 07:41:42,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 42081.1015625
2023-01-07 07:41:42,569 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 87.52503204345703
2023-01-07 07:41:42,569 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,569 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,569 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,569 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 65.20117950439453
2023-01-07 07:41:42,569 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,569 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,569 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,569 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,570 > [DEBUG] 0 :: before allreduce fusion buffer :: -17744.421875
2023-01-07 07:41:42,571 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 65.20117950439453
2023-01-07 07:41:42,571 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,571 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,571 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,571 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 108.54647827148438
2023-01-07 07:41:42,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,571 > [DEBUG] 0 :: before allreduce fusion buffer :: 16612.00390625
2023-01-07 07:41:42,572 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 41.30290222167969
2023-01-07 07:41:42,572 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,572 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,572 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,572 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 0.5502784252166748
2023-01-07 07:41:42,572 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,572 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,572 > [DEBUG] 0 :: before allreduce fusion buffer :: -32158.35546875
2023-01-07 07:41:42,573 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 248.20004272460938
2023-01-07 07:41:42,573 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,573 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,573 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,573 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 0.5502784252166748
2023-01-07 07:41:42,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,573 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,574 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,574 > [DEBUG] 0 :: before allreduce fusion buffer :: -1692.323486328125
2023-01-07 07:41:42,575 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 0.5502784252166748
2023-01-07 07:41:42,575 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,575 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,575 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,575 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 108.54647827148438
2023-01-07 07:41:42,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,575 > [DEBUG] 0 :: before allreduce fusion buffer :: 40867.55078125
2023-01-07 07:41:42,576 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 62.20000076293945
2023-01-07 07:41:42,576 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,576 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,576 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,576 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 108.54647827148438
2023-01-07 07:41:42,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,576 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,576 > [DEBUG] 0 :: before allreduce fusion buffer :: 183859478528.0
2023-01-07 07:41:42,577 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 108.54647827148438
2023-01-07 07:41:42,577 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,577 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,577 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,578 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 63.20000457763672
2023-01-07 07:41:42,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,578 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,578 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,578 > [DEBUG] 0 :: before allreduce fusion buffer :: -12292763648.0
2023-01-07 07:41:42,579 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 63.20000457763672
2023-01-07 07:41:42,579 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,579 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,580 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,580 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 374.3810119628906
2023-01-07 07:41:42,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,580 > [DEBUG] 0 :: before allreduce fusion buffer :: -998.31005859375
2023-01-07 07:41:42,581 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 10.653218269348145
2023-01-07 07:41:42,581 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,581 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,581 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,581 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 455.5525207519531
2023-01-07 07:41:42,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,581 > [DEBUG] 0 :: before allreduce fusion buffer :: 5985.580078125
2023-01-07 07:41:42,582 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 247.79998779296875
2023-01-07 07:41:42,582 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,582 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,582 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,582 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 374.3810119628906
2023-01-07 07:41:42,582 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,582 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,583 > [DEBUG] 0 :: before allreduce fusion buffer :: -201.57321166992188
2023-01-07 07:41:42,583 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 455.5525207519531
2023-01-07 07:41:42,583 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,584 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,584 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,584 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 374.3810119628906
2023-01-07 07:41:42,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,584 > [DEBUG] 0 :: before allreduce fusion buffer :: -10969.162109375
2023-01-07 07:41:42,585 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 127.00003051757812
2023-01-07 07:41:42,585 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,585 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,585 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,585 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 374.3810119628906
2023-01-07 07:41:42,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,585 > [DEBUG] 0 :: before allreduce fusion buffer :: -1767.0811767578125
2023-01-07 07:41:42,586 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 374.3810119628906
2023-01-07 07:41:42,586 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,586 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,586 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,586 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 129.83766174316406
2023-01-07 07:41:42,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,587 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,587 > [DEBUG] 0 :: before allreduce fusion buffer :: 198391250288640.0
2023-01-07 07:41:42,588 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 129.83766174316406
2023-01-07 07:41:42,588 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,588 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,588 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,588 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 375.7483825683594
2023-01-07 07:41:42,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,588 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,588 > [DEBUG] 0 :: before allreduce fusion buffer :: -383.1541442871094
2023-01-07 07:41:42,589 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 375.7483825683594
2023-01-07 07:41:42,589 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,589 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,589 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,590 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 510.39984130859375
2023-01-07 07:41:42,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,590 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,590 > [DEBUG] 0 :: before allreduce fusion buffer :: 1834.8585205078125
2023-01-07 07:41:42,591 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 510.39984130859375
2023-01-07 07:41:42,591 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,591 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,591 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,591 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -10.647611618041992
2023-01-07 07:41:42,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,591 > [DEBUG] 0 :: before allreduce fusion buffer :: -1590.375244140625
2023-01-07 07:41:42,592 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -10.647611618041992
2023-01-07 07:41:42,592 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,592 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,592 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,592 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -88.94740295410156
2023-01-07 07:41:42,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,593 > [DEBUG] 0 :: before allreduce fusion buffer :: -614.2657470703125
2023-01-07 07:41:42,593 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 500.99810791015625
2023-01-07 07:41:42,593 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,593 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,593 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,593 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -88.94740295410156
2023-01-07 07:41:42,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,594 > [DEBUG] 0 :: before allreduce fusion buffer :: 79.20577239990234
2023-01-07 07:41:42,595 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -88.94740295410156
2023-01-07 07:41:42,595 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,595 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,595 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,595 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 125.199951171875
2023-01-07 07:41:42,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,595 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,595 > [DEBUG] 0 :: before allreduce fusion buffer :: -599.3922119140625
2023-01-07 07:41:42,596 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 125.199951171875
2023-01-07 07:41:42,596 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,596 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,597 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,597 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: -33.32005310058594
2023-01-07 07:41:42,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,597 > [DEBUG] 0 :: before allreduce fusion buffer :: -639.849365234375
2023-01-07 07:41:42,598 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: -33.32005310058594
2023-01-07 07:41:42,598 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,598 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,598 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,598 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 125.20003509521484
2023-01-07 07:41:42,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,598 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,599 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.26397705078125
2023-01-07 07:41:42,600 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 125.20003509521484
2023-01-07 07:41:42,600 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,600 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,600 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,600 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 103.37635040283203
2023-01-07 07:41:42,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,600 > [DEBUG] 0 :: before allreduce fusion buffer :: 49.36389923095703
2023-01-07 07:41:42,601 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 103.37635040283203
2023-01-07 07:41:42,601 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,601 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,601 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,601 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 26.194503784179688
2023-01-07 07:41:42,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,602 > [DEBUG] 0 :: before allreduce fusion buffer :: -90.422607421875
2023-01-07 07:41:42,602 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 520.69580078125
2023-01-07 07:41:42,602 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,602 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,602 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,602 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 26.194503784179688
2023-01-07 07:41:42,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,603 > [DEBUG] 0 :: before allreduce fusion buffer :: -71.81380462646484
2023-01-07 07:41:42,604 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 26.194503784179688
2023-01-07 07:41:42,604 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,604 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,604 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,604 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 125.39998626708984
2023-01-07 07:41:42,604 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,604 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,604 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,604 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,604 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,604 > [DEBUG] 0 :: before allreduce fusion buffer :: -424.75665283203125
2023-01-07 07:41:42,605 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 125.39998626708984
2023-01-07 07:41:42,605 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,605 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,606 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,606 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: -331.0689697265625
2023-01-07 07:41:42,606 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,606 > [DEBUG] 0 :: before allreduce fusion buffer :: 23.105880737304688
2023-01-07 07:41:42,607 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -331.0689697265625
2023-01-07 07:41:42,607 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,607 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,607 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,607 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 130.19989013671875
2023-01-07 07:41:42,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,607 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,607 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,607 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,608 > [DEBUG] 0 :: before allreduce fusion buffer :: -43.82376480102539
2023-01-07 07:41:42,608 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 130.19989013671875
2023-01-07 07:41:42,608 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,609 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,609 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,609 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -91.41265869140625
2023-01-07 07:41:42,609 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,609 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,609 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.708695411682129
2023-01-07 07:41:42,610 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -91.41265869140625
2023-01-07 07:41:42,610 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,610 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,610 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,610 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 516.5975341796875
2023-01-07 07:41:42,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,610 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,611 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.257542610168457
2023-01-07 07:41:42,611 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 516.5975341796875
2023-01-07 07:41:42,611 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,612 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,612 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,612 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -2.2186927795410156
2023-01-07 07:41:42,612 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,612 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.69024658203125
2023-01-07 07:41:42,613 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -2.2186927795410156
2023-01-07 07:41:42,613 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,613 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,613 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,613 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 125.20000457763672
2023-01-07 07:41:42,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,613 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,614 > [DEBUG] 0 :: before allreduce fusion buffer :: 14.752618789672852
2023-01-07 07:41:42,615 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 125.20000457763672
2023-01-07 07:41:42,615 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,615 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,615 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,615 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -163.42437744140625
2023-01-07 07:41:42,615 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,615 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,615 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.312173843383789
2023-01-07 07:41:42,616 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -163.42437744140625
2023-01-07 07:41:42,616 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,616 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,616 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,616 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 128.59979248046875
2023-01-07 07:41:42,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,616 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,617 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,618 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.59979248046875
2023-01-07 07:41:42,618 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,618 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,618 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,618 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: -10.926383972167969
2023-01-07 07:41:42,618 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,618 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,618 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,619 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -10.926383972167969
2023-01-07 07:41:42,620 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,620 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,620 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,620 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 500.59991455078125
2023-01-07 07:41:42,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,620 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,620 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,621 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 500.59991455078125
2023-01-07 07:41:42,621 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,621 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,621 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,621 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 72.93675231933594
2023-01-07 07:41:42,621 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,621 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,621 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,622 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 72.93675231933594
2023-01-07 07:41:42,623 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,623 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,623 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,623 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 249.39996337890625
2023-01-07 07:41:42,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,623 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,623 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,624 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 249.39996337890625
2023-01-07 07:41:42,624 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,624 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,624 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,624 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: 905.4352416992188
2023-01-07 07:41:42,624 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,624 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,625 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,626 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: 905.4352416992188
2023-01-07 07:41:42,626 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,626 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,626 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,626 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -320.689697265625
2023-01-07 07:41:42,626 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,626 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,627 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 256.4979248046875
2023-01-07 07:41:42,627 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,627 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,627 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,627 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -320.689697265625
2023-01-07 07:41:42,627 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,627 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,627 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,628 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -320.689697265625
2023-01-07 07:41:42,628 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,628 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,628 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,628 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1218.847412109375
2023-01-07 07:41:42,629 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,629 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,629 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,629 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1019.7244262695312
2023-01-07 07:41:42,629 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,629 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,629 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,630 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1218.847412109375
2023-01-07 07:41:42,630 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,630 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,630 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,631 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -1218.847412109375
2023-01-07 07:41:42,631 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,631 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,631 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,631 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1272.302490234375
2023-01-07 07:41:42,631 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,631 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,631 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,632 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1038.11181640625
2023-01-07 07:41:42,632 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,632 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,632 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,632 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1272.302490234375
2023-01-07 07:41:42,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,632 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,633 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1272.302490234375
2023-01-07 07:41:42,633 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,633 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,633 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,634 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 268.39996337890625
2023-01-07 07:41:42,634 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,634 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 07:41:42,634 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,634 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,635 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 268.39996337890625
2023-01-07 07:41:42,635 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,635 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,635 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,635 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -1912.9013671875
2023-01-07 07:41:42,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,635 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,635 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,636 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -1912.9013671875
2023-01-07 07:41:42,636 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,636 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,637 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,637 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -385.0957336425781
2023-01-07 07:41:42,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,637 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,637 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,637 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 253.49774169921875
2023-01-07 07:41:42,638 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,638 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,638 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,638 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -385.0957336425781
2023-01-07 07:41:42,638 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,638 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,638 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,639 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -385.0957336425781
2023-01-07 07:41:42,639 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,639 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,639 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,639 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 321.6695251464844
2023-01-07 07:41:42,639 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,639 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,639 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,640 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1033.9461669921875
2023-01-07 07:41:42,640 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,640 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,640 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,640 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 321.6695251464844
2023-01-07 07:41:42,640 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,640 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,641 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,642 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 321.6695251464844
2023-01-07 07:41:42,642 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,642 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,642 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,642 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 186.00238037109375
2023-01-07 07:41:42,642 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,642 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,642 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,643 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 262.42083740234375
2023-01-07 07:41:42,643 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,643 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,643 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,643 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 186.00238037109375
2023-01-07 07:41:42,643 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,643 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,643 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,644 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 186.00238037109375
2023-01-07 07:41:42,644 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,644 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,644 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,645 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -10.659599304199219
2023-01-07 07:41:42,645 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,645 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,645 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,645 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 249.7012481689453
2023-01-07 07:41:42,645 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,646 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,646 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,646 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -10.659599304199219
2023-01-07 07:41:42,646 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,646 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,646 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,647 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -10.659599304199219
2023-01-07 07:41:42,647 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,647 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,647 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,647 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 108.71484375
2023-01-07 07:41:42,647 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,647 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,648 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,648 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1085.179443359375
2023-01-07 07:41:42,648 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,648 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,648 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,648 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 108.71484375
2023-01-07 07:41:42,648 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,648 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,649 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,650 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 108.71484375
2023-01-07 07:41:42,650 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,650 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,650 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,650 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 339.0436096191406
2023-01-07 07:41:42,650 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,650 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,650 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,651 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 292.498046875
2023-01-07 07:41:42,651 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,651 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,651 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,651 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 339.0436096191406
2023-01-07 07:41:42,651 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,651 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,651 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,652 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 339.0436096191406
2023-01-07 07:41:42,652 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,652 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,652 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,653 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 56.55461883544922
2023-01-07 07:41:42,653 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,653 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,653 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,653 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 294.69720458984375
2023-01-07 07:41:42,653 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,654 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,654 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,654 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 56.55461883544922
2023-01-07 07:41:42,654 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,654 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,654 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,655 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 56.55461883544922
2023-01-07 07:41:42,655 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,655 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,655 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,655 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -65.70864868164062
2023-01-07 07:41:42,655 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,655 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,655 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,656 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1083.287109375
2023-01-07 07:41:42,656 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,656 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,656 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,656 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -65.70864868164062
2023-01-07 07:41:42,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,657 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,658 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -65.70864868164062
2023-01-07 07:41:42,658 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,658 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,658 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,658 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -132.0376434326172
2023-01-07 07:41:42,658 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,658 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,658 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,659 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 295.49786376953125
2023-01-07 07:41:42,659 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,659 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,659 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,659 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -132.0376434326172
2023-01-07 07:41:42,659 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,659 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,659 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,660 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -132.0376434326172
2023-01-07 07:41:42,660 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,660 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,660 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,660 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3149.8486328125
2023-01-07 07:41:42,660 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,661 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,661 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,661 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 295.6981201171875
2023-01-07 07:41:42,661 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,661 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,661 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,662 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3149.8486328125
2023-01-07 07:41:42,662 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,662 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,662 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,663 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -3149.8486328125
2023-01-07 07:41:42,663 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,663 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,663 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,663 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -20703.01171875
2023-01-07 07:41:42,663 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,663 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,663 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,664 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1118.816650390625
2023-01-07 07:41:42,664 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,664 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,664 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,664 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -20703.01171875
2023-01-07 07:41:42,664 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,664 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,664 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,665 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -20703.01171875
2023-01-07 07:41:42,665 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,666 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,666 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,666 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -8912.119140625
2023-01-07 07:41:42,666 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,666 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,666 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,667 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 297.0009460449219
2023-01-07 07:41:42,667 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,667 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,667 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,667 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -8912.119140625
2023-01-07 07:41:42,667 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,667 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,667 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,668 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -8912.119140625
2023-01-07 07:41:42,668 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,668 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,668 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,668 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23523.431640625
2023-01-07 07:41:42,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,668 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,669 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,669 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 298.0481262207031
2023-01-07 07:41:42,669 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,669 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,669 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,669 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23523.431640625
2023-01-07 07:41:42,670 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,670 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,670 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,671 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -23523.431640625
2023-01-07 07:41:42,671 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,671 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,671 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,671 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50331.9921875
2023-01-07 07:41:42,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,671 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,671 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,672 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1083.902587890625
2023-01-07 07:41:42,672 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,672 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,672 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,672 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50331.9921875
2023-01-07 07:41:42,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,672 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,673 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -50331.9921875
2023-01-07 07:41:42,673 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,673 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,674 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,674 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -43038.15625
2023-01-07 07:41:42,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,674 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,674 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 600.750732421875
2023-01-07 07:41:42,675 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,675 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,675 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,675 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -43038.15625
2023-01-07 07:41:42,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,675 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,676 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -43038.15625
2023-01-07 07:41:42,676 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,676 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,676 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,676 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -204.68077087402344
2023-01-07 07:41:42,676 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,676 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,677 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,677 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 601.719482421875
2023-01-07 07:41:42,677 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,677 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,677 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,678 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -204.68077087402344
2023-01-07 07:41:42,678 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,678 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,678 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,679 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -204.68077087402344
2023-01-07 07:41:42,679 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,679 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,679 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,679 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -123168.7265625
2023-01-07 07:41:42,679 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,679 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,680 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,680 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2188.1806640625
2023-01-07 07:41:42,680 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,680 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,680 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,681 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -123168.7265625
2023-01-07 07:41:42,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,681 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,681 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,682 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -123168.7265625
2023-01-07 07:41:42,682 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,682 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,682 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,682 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26843.90625
2023-01-07 07:41:42,682 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,682 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,683 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2085.594482421875
2023-01-07 07:41:42,683 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,683 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,683 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,683 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26843.90625
2023-01-07 07:41:42,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,683 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,684 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -26843.90625
2023-01-07 07:41:42,684 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,684 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,684 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,685 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -451.4361877441406
2023-01-07 07:41:42,685 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,685 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,685 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,685 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 608.82177734375
2023-01-07 07:41:42,685 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,686 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,686 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,686 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -451.4361877441406
2023-01-07 07:41:42,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,686 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,686 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,687 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -451.4361877441406
2023-01-07 07:41:42,687 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,687 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,687 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,687 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -34046.71875
2023-01-07 07:41:42,687 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,687 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,688 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,688 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 608.623779296875
2023-01-07 07:41:42,688 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,688 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,688 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,688 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -34046.71875
2023-01-07 07:41:42,688 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,689 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,690 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -34046.71875
2023-01-07 07:41:42,690 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,690 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,690 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,690 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102862.828125
2023-01-07 07:41:42,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,690 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,691 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2051.0
2023-01-07 07:41:42,691 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,691 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,691 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,691 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102862.828125
2023-01-07 07:41:42,691 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,691 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,691 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,692 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -102862.828125
2023-01-07 07:41:42,692 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,693 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,693 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,693 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -13016.37890625
2023-01-07 07:41:42,693 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,693 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,693 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,693 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 610.023193359375
2023-01-07 07:41:42,694 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,694 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,694 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,694 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -13016.37890625
2023-01-07 07:41:42,694 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,694 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,694 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,695 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -13016.37890625
2023-01-07 07:41:42,695 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,695 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,695 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,695 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 3.519317626953125
2023-01-07 07:41:42,695 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,695 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,696 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,696 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 610.4221801757812
2023-01-07 07:41:42,696 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,696 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,696 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,696 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 3.519317626953125
2023-01-07 07:41:42,697 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,697 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,697 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,698 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 3.519317626953125
2023-01-07 07:41:42,698 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,698 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,698 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,698 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -148796.78125
2023-01-07 07:41:42,698 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,698 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,698 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,699 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2424.785888671875
2023-01-07 07:41:42,699 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,699 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,699 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,699 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -148796.78125
2023-01-07 07:41:42,699 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,699 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,699 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:42,701 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -148796.78125
2023-01-07 07:41:42,701 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:42,701 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:42,701 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:42,702 > [DEBUG] 0 :: 18.7752628326416
2023-01-07 07:41:42,704 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,704 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,704 > [DEBUG] 0 :: before allreduce fusion buffer :: 48822251520.0
2023-01-07 07:41:42,706 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,706 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,706 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,706 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,706 > [DEBUG] 0 :: before allreduce fusion buffer :: -2848459.5
2023-01-07 07:41:42,709 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,710 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,710 > [DEBUG] 0 :: before allreduce fusion buffer :: -21501016.0
2023-01-07 07:41:42,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,712 > [DEBUG] 0 :: before allreduce fusion buffer :: 48831021056.0
2023-01-07 07:41:42,713 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,713 > [DEBUG] 0 :: before allreduce fusion buffer :: 97622327296.0
2023-01-07 07:41:42,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,714 > [DEBUG] 0 :: before allreduce fusion buffer :: 97660911616.0
2023-01-07 07:41:42,715 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,716 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,716 > [DEBUG] 0 :: before allreduce fusion buffer :: 97566392320.0
2023-01-07 07:41:42,716 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,716 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,717 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,717 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,717 > [DEBUG] 0 :: before allreduce fusion buffer :: 301656.25
2023-01-07 07:41:42,718 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,718 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,718 > [DEBUG] 0 :: before allreduce fusion buffer :: -336871520.0
2023-01-07 07:41:42,719 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,719 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,719 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,719 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,719 > [DEBUG] 0 :: before allreduce fusion buffer :: 195382935552.0
2023-01-07 07:41:42,720 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,721 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,721 > [DEBUG] 0 :: before allreduce fusion buffer :: 390646562816.0
2023-01-07 07:41:42,721 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,721 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,722 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,722 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,722 > [DEBUG] 0 :: before allreduce fusion buffer :: 781363052544.0
2023-01-07 07:41:42,723 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,723 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,723 > [DEBUG] 0 :: before allreduce fusion buffer :: 1559782490112.0
2023-01-07 07:41:42,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,724 > [DEBUG] 0 :: before allreduce fusion buffer :: 5166621.0
2023-01-07 07:41:42,725 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,725 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,725 > [DEBUG] 0 :: before allreduce fusion buffer :: 3124771684352.0
2023-01-07 07:41:42,726 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,726 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,726 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,726 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,726 > [DEBUG] 0 :: before allreduce fusion buffer :: 1421376.25
2023-01-07 07:41:42,727 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,727 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,728 > [DEBUG] 0 :: before allreduce fusion buffer :: 790.4725341796875
2023-01-07 07:41:42,728 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,728 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,728 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,728 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,728 > [DEBUG] 0 :: before allreduce fusion buffer :: -1898335.75
2023-01-07 07:41:42,730 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,730 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,730 > [DEBUG] 0 :: before allreduce fusion buffer :: 88717.21875
2023-01-07 07:41:42,730 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,730 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,730 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,731 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,731 > [DEBUG] 0 :: before allreduce fusion buffer :: -3585592.5
2023-01-07 07:41:42,732 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,732 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,732 > [DEBUG] 0 :: before allreduce fusion buffer :: 1178857.25
2023-01-07 07:41:42,733 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,733 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,733 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,733 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,733 > [DEBUG] 0 :: before allreduce fusion buffer :: -7564576.0
2023-01-07 07:41:42,734 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,734 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,734 > [DEBUG] 0 :: before allreduce fusion buffer :: 1837526.0
2023-01-07 07:41:42,735 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,735 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,735 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,735 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,735 > [DEBUG] 0 :: before allreduce fusion buffer :: -14848239.0
2023-01-07 07:41:42,736 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,737 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,737 > [DEBUG] 0 :: before allreduce fusion buffer :: 3907751.5
2023-01-07 07:41:42,737 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,737 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,737 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,737 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,738 > [DEBUG] 0 :: before allreduce fusion buffer :: 3981356.0
2023-01-07 07:41:42,739 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,739 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,739 > [DEBUG] 0 :: before allreduce fusion buffer :: 9460772.0
2023-01-07 07:41:42,739 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,739 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,740 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,740 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,740 > [DEBUG] 0 :: before allreduce fusion buffer :: -28495074.0
2023-01-07 07:41:42,741 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,741 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,741 > [DEBUG] 0 :: before allreduce fusion buffer :: 15479864.0
2023-01-07 07:41:42,742 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,742 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,742 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,742 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,742 > [DEBUG] 0 :: before allreduce fusion buffer :: -41789740.0
2023-01-07 07:41:42,743 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,743 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,743 > [DEBUG] 0 :: before allreduce fusion buffer :: 10063296.0
2023-01-07 07:41:42,744 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,744 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,744 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,744 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,744 > [DEBUG] 0 :: before allreduce fusion buffer :: 40799988.0
2023-01-07 07:41:42,745 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,745 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,745 > [DEBUG] 0 :: before allreduce fusion buffer :: 14546569.0
2023-01-07 07:41:42,746 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,746 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,746 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,746 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,746 > [DEBUG] 0 :: before allreduce fusion buffer :: -33415656.0
2023-01-07 07:41:42,747 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,747 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,747 > [DEBUG] 0 :: before allreduce fusion buffer :: 176376192.0
2023-01-07 07:41:42,748 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,748 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,748 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,748 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,748 > [DEBUG] 0 :: before allreduce fusion buffer :: 144911552.0
2023-01-07 07:41:42,749 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,749 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,749 > [DEBUG] 0 :: before allreduce fusion buffer :: 668107712.0
2023-01-07 07:41:42,750 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,750 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,750 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,750 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,750 > [DEBUG] 0 :: before allreduce fusion buffer :: 169536656.0
2023-01-07 07:41:42,751 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,751 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,752 > [DEBUG] 0 :: before allreduce fusion buffer :: -36267.3125
2023-01-07 07:41:42,752 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,752 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,752 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,752 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,752 > [DEBUG] 0 :: before allreduce fusion buffer :: -267374208.0
2023-01-07 07:41:42,753 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,754 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,754 > [DEBUG] 0 :: before allreduce fusion buffer :: 1344677632.0
2023-01-07 07:41:42,754 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,754 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,754 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,754 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,755 > [DEBUG] 0 :: before allreduce fusion buffer :: 143475776.0
2023-01-07 07:41:42,756 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,756 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,756 > [DEBUG] 0 :: before allreduce fusion buffer :: 2689306112.0
2023-01-07 07:41:42,756 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,756 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,757 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,757 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,757 > [DEBUG] 0 :: before allreduce fusion buffer :: 264386.09375
2023-01-07 07:41:42,758 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,758 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,758 > [DEBUG] 0 :: before allreduce fusion buffer :: 5378510848.0
2023-01-07 07:41:42,758 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,759 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,759 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,759 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,759 > [DEBUG] 0 :: before allreduce fusion buffer :: -1051004096.0
2023-01-07 07:41:42,760 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,760 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,760 > [DEBUG] 0 :: before allreduce fusion buffer :: 10757449728.0
2023-01-07 07:41:42,761 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,761 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,761 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,761 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,761 > [DEBUG] 0 :: before allreduce fusion buffer :: 3322258432.0
2023-01-07 07:41:42,787 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,787 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,787 > [DEBUG] 0 :: before allreduce fusion buffer :: 21514735616.0
2023-01-07 07:41:42,787 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,787 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,788 > [DEBUG] 0 :: before allreduce fusion buffer :: 21516431360.0
2023-01-07 07:41:42,788 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,788 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,789 > [DEBUG] 0 :: before allreduce fusion buffer :: 43029651456.0
2023-01-07 07:41:42,789 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,789 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,789 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,789 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,789 > [DEBUG] 0 :: before allreduce fusion buffer :: -2101436160.0
2023-01-07 07:41:42,790 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,791 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,791 > [DEBUG] 0 :: before allreduce fusion buffer :: 91723923456.0
2023-01-07 07:41:42,791 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,791 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,791 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,791 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,792 > [DEBUG] 0 :: before allreduce fusion buffer :: 1539218.0
2023-01-07 07:41:42,793 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,793 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,793 > [DEBUG] 0 :: before allreduce fusion buffer :: 91929714688.0
2023-01-07 07:41:42,793 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,793 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,794 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,794 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,794 > [DEBUG] 0 :: before allreduce fusion buffer :: 4503812096.0
2023-01-07 07:41:42,971 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,971 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,971 > [DEBUG] 0 :: before allreduce fusion buffer :: 91929722880.0
2023-01-07 07:41:42,972 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,972 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,972 > [DEBUG] 0 :: before allreduce fusion buffer :: 91934613504.0
2023-01-07 07:41:42,973 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,973 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,973 > [DEBUG] 0 :: before allreduce fusion buffer :: -6146388992.0
2023-01-07 07:41:42,974 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,974 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,974 > [DEBUG] 0 :: before allreduce fusion buffer :: 183859445760.0
2023-01-07 07:41:42,975 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,975 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,975 > [DEBUG] 0 :: before allreduce fusion buffer :: 367718924288.0
2023-01-07 07:41:42,976 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,976 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,976 > [DEBUG] 0 :: before allreduce fusion buffer :: 735437914112.0
2023-01-07 07:41:42,977 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,977 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,977 > [DEBUG] 0 :: before allreduce fusion buffer :: 1470875697152.0
2023-01-07 07:41:42,977 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,977 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,978 > [DEBUG] 0 :: before allreduce fusion buffer :: 6640.52001953125
2023-01-07 07:41:42,978 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,978 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,979 > [DEBUG] 0 :: before allreduce fusion buffer :: 2941751394304.0
2023-01-07 07:41:42,979 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,979 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,979 > [DEBUG] 0 :: before allreduce fusion buffer :: 11641.779296875
2023-01-07 07:41:42,980 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:42,980 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:42,980 > [DEBUG] 0 :: before allreduce fusion buffer :: 2941751394304.0
2023-01-07 07:41:43,154 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,154 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,155 > [DEBUG] 0 :: before allreduce fusion buffer :: 5883502788608.0
2023-01-07 07:41:43,156 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,156 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,156 > [DEBUG] 0 :: before allreduce fusion buffer :: 11767005577216.0
2023-01-07 07:41:43,156 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,156 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,157 > [DEBUG] 0 :: before allreduce fusion buffer :: 11767006625792.0
2023-01-07 07:41:43,157 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,157 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,157 > [DEBUG] 0 :: before allreduce fusion buffer :: 23534013251584.0
2023-01-07 07:41:43,158 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,158 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,158 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,158 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,158 > [DEBUG] 0 :: before allreduce fusion buffer :: 24846.96875
2023-01-07 07:41:43,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,339 > [DEBUG] 0 :: before allreduce fusion buffer :: 47068026503168.0
2023-01-07 07:41:43,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,340 > [DEBUG] 0 :: before allreduce fusion buffer :: 29025.2578125
2023-01-07 07:41:43,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,341 > [DEBUG] 0 :: before allreduce fusion buffer :: 94136053006336.0
2023-01-07 07:41:43,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,454 > [DEBUG] 0 :: before allreduce fusion buffer :: 188272106012672.0
2023-01-07 07:41:43,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,455 > [DEBUG] 0 :: before allreduce fusion buffer :: 99195625144320.0
2023-01-07 07:41:43,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 384555030675456.0
2023-01-07 07:41:43,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,457 > [DEBUG] 0 :: before allreduce fusion buffer :: 746768245456896.0
2023-01-07 07:41:43,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,458 > [DEBUG] 0 :: before allreduce fusion buffer :: 15816.1728515625
2023-01-07 07:41:43,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,459 > [DEBUG] 0 :: before allreduce fusion buffer :: 1499856669507584.0
2023-01-07 07:41:43,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,460 > [DEBUG] 0 :: before allreduce fusion buffer :: 35513.9296875
2023-01-07 07:41:43,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,461 > [DEBUG] 0 :: before allreduce fusion buffer :: 2999713339015168.0
2023-01-07 07:41:43,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,462 > [DEBUG] 0 :: before allreduce fusion buffer :: 2825166673412096.0
2023-01-07 07:41:43,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 507.19769287109375
2023-01-07 07:41:43,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,464 > [DEBUG] 0 :: before allreduce fusion buffer :: 815037153280000.0
2023-01-07 07:41:43,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,465 > [DEBUG] 0 :: before allreduce fusion buffer :: -1584.7777099609375
2023-01-07 07:41:43,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,466 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.3997706712121344e+16
2023-01-07 07:41:43,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,467 > [DEBUG] 0 :: before allreduce fusion buffer :: -1391.507568359375
2023-01-07 07:41:43,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6722781658172607
2023-01-07 07:41:43,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,469 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,470 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.180564880371094
2023-01-07 07:41:43,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,471 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,472 > [DEBUG] 0 :: before allreduce fusion buffer :: -36.244163513183594
2023-01-07 07:41:43,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,473 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,474 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.295511245727539
2023-01-07 07:41:43,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,475 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,476 > [DEBUG] 0 :: before allreduce fusion buffer :: -216.40505981445312
2023-01-07 07:41:43,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,478 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,478 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.84553527832031
2023-01-07 07:41:43,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,479 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,480 > [DEBUG] 0 :: before allreduce fusion buffer :: -4301251072.0
2023-01-07 07:41:43,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,481 > [DEBUG] 0 :: before allreduce fusion buffer :: 61.842559814453125
2023-01-07 07:41:43,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,482 > [DEBUG] 0 :: before allreduce fusion buffer :: 28.812726974487305
2023-01-07 07:41:43,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,483 > [DEBUG] 0 :: before allreduce fusion buffer :: -78.12759399414062
2023-01-07 07:41:43,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,484 > [DEBUG] 0 :: before allreduce fusion buffer :: 97.05801391601562
2023-01-07 07:41:43,490 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 07:41:43,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,497 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.922659932985291e+23
2023-01-07 07:41:43,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,500 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.9381279463882327e+24
2023-01-07 07:41:43,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,502 > [DEBUG] 0 :: before allreduce fusion buffer :: 5899159076864.0
2023-01-07 07:41:43,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,503 > [DEBUG] 0 :: before allreduce fusion buffer :: 8844518359040.0
2023-01-07 07:41:43,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,503 > [DEBUG] 0 :: before allreduce fusion buffer :: 97056194560000.0
2023-01-07 07:41:43,504 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: 114.18293762207031
2023-01-07 07:41:43,504 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,504 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,504 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,504 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 66.4976577758789
2023-01-07 07:41:43,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,504 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,504 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,504 > [DEBUG] 0 :: before allreduce fusion buffer :: 58.60818862915039
2023-01-07 07:41:43,505 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 66.4976577758789
2023-01-07 07:41:43,505 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,505 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,505 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,506 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 30.359243392944336
2023-01-07 07:41:43,506 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,506 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,506 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,506 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,506 > [DEBUG] 0 :: before allreduce fusion buffer :: -1124263.0
2023-01-07 07:41:43,507 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 30.359243392944336
2023-01-07 07:41:43,507 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,507 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,507 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,507 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 244.90188598632812
2023-01-07 07:41:43,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,508 > [DEBUG] 0 :: before allreduce fusion buffer :: 188.57662963867188
2023-01-07 07:41:43,508 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 67.1078109741211
2023-01-07 07:41:43,508 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,508 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,508 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,509 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 244.90188598632812
2023-01-07 07:41:43,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,509 > [DEBUG] 0 :: before allreduce fusion buffer :: -57078.0
2023-01-07 07:41:43,510 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 244.90188598632812
2023-01-07 07:41:43,510 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,510 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,510 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,510 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 67.9552993774414
2023-01-07 07:41:43,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,511 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.402324676513672
2023-01-07 07:41:43,512 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 67.9552993774414
2023-01-07 07:41:43,512 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,512 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,512 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,512 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 145.55169677734375
2023-01-07 07:41:43,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,512 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,513 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 32.346702575683594
2023-01-07 07:41:43,513 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,513 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,513 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,513 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 253.29806518554688
2023-01-07 07:41:43,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,513 > [DEBUG] 0 :: before allreduce fusion buffer :: -153.44366455078125
2023-01-07 07:41:43,515 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 253.29806518554688
2023-01-07 07:41:43,515 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,515 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,515 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,515 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 215.3780059814453
2023-01-07 07:41:43,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,515 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.417916297912598
2023-01-07 07:41:43,516 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 34.47209167480469
2023-01-07 07:41:43,516 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,516 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,516 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,516 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 215.3780059814453
2023-01-07 07:41:43,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,516 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.532651901245117
2023-01-07 07:41:43,517 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 246.47982788085938
2023-01-07 07:41:43,517 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,517 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,517 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,517 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 215.3780059814453
2023-01-07 07:41:43,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,517 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.575454711914062
2023-01-07 07:41:43,518 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 34.46758270263672
2023-01-07 07:41:43,518 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,518 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,518 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,518 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 63.49798583984375
2023-01-07 07:41:43,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,519 > [DEBUG] 0 :: before allreduce fusion buffer :: -95.56599426269531
2023-01-07 07:41:43,520 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 63.49798583984375
2023-01-07 07:41:43,520 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,520 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,520 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,520 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 215.3780059814453
2023-01-07 07:41:43,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,520 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.289810180664062
2023-01-07 07:41:43,521 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 215.3780059814453
2023-01-07 07:41:43,521 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,521 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,521 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,521 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 66.9224853515625
2023-01-07 07:41:43,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,522 > [DEBUG] 0 :: before allreduce fusion buffer :: -42.82060241699219
2023-01-07 07:41:43,523 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 66.9224853515625
2023-01-07 07:41:43,523 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,523 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,523 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,523 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 145.55169677734375
2023-01-07 07:41:43,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,523 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,524 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 34.621028900146484
2023-01-07 07:41:43,524 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,524 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,524 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,524 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 9.745847702026367
2023-01-07 07:41:43,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,525 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.268001556396484
2023-01-07 07:41:43,525 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 242.09811401367188
2023-01-07 07:41:43,525 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,525 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,525 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,525 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 9.745847702026367
2023-01-07 07:41:43,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,526 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.4736385345458984
2023-01-07 07:41:43,527 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 9.745847702026367
2023-01-07 07:41:43,527 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,527 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,527 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,527 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 145.55169677734375
2023-01-07 07:41:43,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,527 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,528 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 62.49765396118164
2023-01-07 07:41:43,528 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,528 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,528 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,528 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 145.55169677734375
2023-01-07 07:41:43,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,528 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,529 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 145.55169677734375
2023-01-07 07:41:43,529 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,529 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,529 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,529 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 61.554405212402344
2023-01-07 07:41:43,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,530 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.220576047897339
2023-01-07 07:41:43,531 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 61.554405212402344
2023-01-07 07:41:43,531 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,531 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,531 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,531 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 691.8760375976562
2023-01-07 07:41:43,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,532 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,532 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 10.786361694335938
2023-01-07 07:41:43,532 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,532 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,532 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,533 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 454.1150817871094
2023-01-07 07:41:43,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,533 > [DEBUG] 0 :: before allreduce fusion buffer :: 7462.16943359375
2023-01-07 07:41:43,534 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 241.69805908203125
2023-01-07 07:41:43,534 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,534 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,534 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,534 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 691.8760375976562
2023-01-07 07:41:43,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,534 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,535 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 454.1150817871094
2023-01-07 07:41:43,535 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,535 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,535 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,535 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 691.8760375976562
2023-01-07 07:41:43,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,535 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,535 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,536 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 123.57701110839844
2023-01-07 07:41:43,536 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,536 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,536 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,536 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 691.8760375976562
2023-01-07 07:41:43,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,537 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,538 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 691.8760375976562
2023-01-07 07:41:43,538 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,538 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,538 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,538 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 126.41462707519531
2023-01-07 07:41:43,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,538 > [DEBUG] 0 :: before allreduce fusion buffer :: -63.47919464111328
2023-01-07 07:41:43,539 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 126.41462707519531
2023-01-07 07:41:43,539 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,539 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,539 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,539 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 526.9512939453125
2023-01-07 07:41:43,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,540 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,541 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 526.9512939453125
2023-01-07 07:41:43,541 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,541 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,541 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,541 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 505.7669677734375
2023-01-07 07:41:43,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,541 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,542 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 505.7669677734375
2023-01-07 07:41:43,542 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,542 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,542 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,542 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 136.41075134277344
2023-01-07 07:41:43,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,543 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 136.41075134277344
2023-01-07 07:41:43,543 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,543 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,544 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,544 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 63.10020446777344
2023-01-07 07:41:43,544 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,544 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,544 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,545 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 500.99810791015625
2023-01-07 07:41:43,545 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,545 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,545 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,545 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 63.10020446777344
2023-01-07 07:41:43,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,545 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,545 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,546 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 63.10020446777344
2023-01-07 07:41:43,546 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,546 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,546 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,546 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 121.77691650390625
2023-01-07 07:41:43,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,547 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,548 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 121.77691650390625
2023-01-07 07:41:43,548 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,548 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,548 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,548 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 259.0448913574219
2023-01-07 07:41:43,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,549 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 259.0448913574219
2023-01-07 07:41:43,549 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,549 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,549 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,549 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 121.14334106445312
2023-01-07 07:41:43,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,550 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,551 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 121.14334106445312
2023-01-07 07:41:43,551 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,551 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,551 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,551 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 206.45123291015625
2023-01-07 07:41:43,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,551 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,552 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 206.45123291015625
2023-01-07 07:41:43,552 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,552 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,552 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,553 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 74.82804870605469
2023-01-07 07:41:43,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,553 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,553 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 520.69580078125
2023-01-07 07:41:43,554 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,554 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,554 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,554 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 74.82804870605469
2023-01-07 07:41:43,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,554 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,555 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 74.82804870605469
2023-01-07 07:41:43,555 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,555 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,555 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,555 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 121.3232192993164
2023-01-07 07:41:43,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,556 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,557 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 121.3232192993164
2023-01-07 07:41:43,557 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,557 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,557 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,557 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: -599.3986206054688
2023-01-07 07:41:43,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,557 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,558 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -599.3986206054688
2023-01-07 07:41:43,558 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,558 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,558 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,558 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 131.67391967773438
2023-01-07 07:41:43,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,559 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,559 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,559 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,560 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 131.67391967773438
2023-01-07 07:41:43,560 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,560 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,560 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,560 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -144.4929656982422
2023-01-07 07:41:43,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,560 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,561 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -144.4929656982422
2023-01-07 07:41:43,561 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,561 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,561 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,561 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 517.2275390625
2023-01-07 07:41:43,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,562 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,563 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 517.2275390625
2023-01-07 07:41:43,563 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,563 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,563 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,563 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -3.38629150390625
2023-01-07 07:41:43,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,563 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,563 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,564 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -3.38629150390625
2023-01-07 07:41:43,564 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,564 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,564 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,564 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 121.16764831542969
2023-01-07 07:41:43,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,565 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,566 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 121.16764831542969
2023-01-07 07:41:43,566 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,566 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,566 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -225.54693603515625
2023-01-07 07:41:43,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,567 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,568 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -225.54693603515625
2023-01-07 07:41:43,568 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,568 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,568 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 125.00557708740234
2023-01-07 07:41:43,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,569 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 125.00557708740234
2023-01-07 07:41:43,569 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,569 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,569 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,569 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 4.317455291748047
2023-01-07 07:41:43,569 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,570 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,571 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 4.317455291748047
2023-01-07 07:41:43,571 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,571 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,571 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,571 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 494.53582763671875
2023-01-07 07:41:43,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,571 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,572 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 494.53582763671875
2023-01-07 07:41:43,572 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,572 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,572 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,573 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 136.78372192382812
2023-01-07 07:41:43,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,573 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,573 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,574 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 136.78372192382812
2023-01-07 07:41:43,574 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,574 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,574 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,574 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 248.08731079101562
2023-01-07 07:41:43,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,574 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,575 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,576 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 248.08731079101562
2023-01-07 07:41:43,576 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,576 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,576 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,576 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -7116.90478515625
2023-01-07 07:41:43,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,576 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,576 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,577 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -7116.90478515625
2023-01-07 07:41:43,577 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,577 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,577 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,577 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -869.491455078125
2023-01-07 07:41:43,577 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,578 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,578 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 251.7811279296875
2023-01-07 07:41:43,578 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,578 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,578 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,579 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -869.491455078125
2023-01-07 07:41:43,579 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,579 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,579 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,580 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -869.491455078125
2023-01-07 07:41:43,580 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,580 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,580 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,580 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -13186.7744140625
2023-01-07 07:41:43,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,580 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,581 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1015.0054931640625
2023-01-07 07:41:43,581 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,581 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,581 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,581 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -13186.7744140625
2023-01-07 07:41:43,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,581 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,582 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -13186.7744140625
2023-01-07 07:41:43,582 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,582 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,582 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,583 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -13243.80078125
2023-01-07 07:41:43,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,583 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,584 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1041.13427734375
2023-01-07 07:41:43,584 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,584 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,584 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,584 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -13243.80078125
2023-01-07 07:41:43,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,584 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,585 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -13243.80078125
2023-01-07 07:41:43,585 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,585 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,585 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,585 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 267.2130126953125
2023-01-07 07:41:43,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,586 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,586 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,587 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 267.2130126953125
2023-01-07 07:41:43,587 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,587 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,587 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,587 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -26622.0
2023-01-07 07:41:43,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,587 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,588 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -26622.0
2023-01-07 07:41:43,588 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,588 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,588 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,589 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -7995.2099609375
2023-01-07 07:41:43,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,589 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,589 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 248.78094482421875
2023-01-07 07:41:43,589 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,590 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,590 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,590 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -7995.2099609375
2023-01-07 07:41:43,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,590 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,591 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -7995.2099609375
2023-01-07 07:41:43,591 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,591 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,591 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,591 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 486.7474365234375
2023-01-07 07:41:43,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,591 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,592 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1027.73388671875
2023-01-07 07:41:43,592 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,592 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,592 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,592 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 486.7474365234375
2023-01-07 07:41:43,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,593 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,594 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 486.7474365234375
2023-01-07 07:41:43,594 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,594 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,594 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,594 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 225.39108276367188
2023-01-07 07:41:43,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,594 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,595 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 265.52960205078125
2023-01-07 07:41:43,595 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,595 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,595 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,595 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 225.39108276367188
2023-01-07 07:41:43,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,595 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,596 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 225.39108276367188
2023-01-07 07:41:43,596 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,597 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,597 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,597 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -26.404281616210938
2023-01-07 07:41:43,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,597 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,598 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 244.98443603515625
2023-01-07 07:41:43,598 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,598 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,598 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,598 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -26.404281616210938
2023-01-07 07:41:43,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,598 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,599 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -26.404281616210938
2023-01-07 07:41:43,599 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,599 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,599 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,599 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 92.19879913330078
2023-01-07 07:41:43,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,600 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,600 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1078.2076416015625
2023-01-07 07:41:43,600 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,600 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,600 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,600 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 92.19879913330078
2023-01-07 07:41:43,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,601 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,602 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 92.19879913330078
2023-01-07 07:41:43,602 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,602 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,602 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,602 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 566.7706909179688
2023-01-07 07:41:43,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,602 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,603 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 287.93060302734375
2023-01-07 07:41:43,603 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,603 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,603 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,603 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 566.7706909179688
2023-01-07 07:41:43,603 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,603 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,603 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,604 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 566.7706909179688
2023-01-07 07:41:43,604 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,604 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,604 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,605 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -17.311054229736328
2023-01-07 07:41:43,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,605 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,605 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 290.13031005859375
2023-01-07 07:41:43,606 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,606 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,606 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,606 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -17.311054229736328
2023-01-07 07:41:43,606 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,606 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,607 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -17.311054229736328
2023-01-07 07:41:43,607 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,607 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,607 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,607 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -92.05128479003906
2023-01-07 07:41:43,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,607 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,607 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,608 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1070.218505859375
2023-01-07 07:41:43,608 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,608 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,608 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,608 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -92.05128479003906
2023-01-07 07:41:43,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,609 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,610 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -92.05128479003906
2023-01-07 07:41:43,610 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,610 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,610 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,610 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -562.4508666992188
2023-01-07 07:41:43,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,610 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,611 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 290.940185546875
2023-01-07 07:41:43,611 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,611 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,611 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,611 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -562.4508666992188
2023-01-07 07:41:43,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,611 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,611 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,612 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -562.4508666992188
2023-01-07 07:41:43,612 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,612 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,612 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,613 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -5776.4091796875
2023-01-07 07:41:43,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,613 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,613 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 290.9813232421875
2023-01-07 07:41:43,613 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,613 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,614 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,614 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -5776.4091796875
2023-01-07 07:41:43,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,614 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,615 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -5776.4091796875
2023-01-07 07:41:43,615 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,615 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,615 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,615 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -37058.87890625
2023-01-07 07:41:43,615 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,615 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,615 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,616 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1124.7020263671875
2023-01-07 07:41:43,616 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,616 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,616 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,616 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -37058.87890625
2023-01-07 07:41:43,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,617 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,618 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -37058.87890625
2023-01-07 07:41:43,618 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,618 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,618 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,618 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -16080.62890625
2023-01-07 07:41:43,618 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,618 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,618 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,619 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 292.22943115234375
2023-01-07 07:41:43,619 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,619 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,619 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,619 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -16080.62890625
2023-01-07 07:41:43,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,619 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,620 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -16080.62890625
2023-01-07 07:41:43,620 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,620 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,620 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,621 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -42165.171875
2023-01-07 07:41:43,621 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,621 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,621 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,622 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 293.677734375
2023-01-07 07:41:43,622 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,622 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,622 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,622 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -42165.171875
2023-01-07 07:41:43,622 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,622 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,622 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,623 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -42165.171875
2023-01-07 07:41:43,623 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,623 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,623 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,623 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -89883.71875
2023-01-07 07:41:43,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,624 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,624 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1070.2530517578125
2023-01-07 07:41:43,624 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,624 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,624 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,624 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -89883.71875
2023-01-07 07:41:43,624 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,625 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,625 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,626 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -89883.71875
2023-01-07 07:41:43,626 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,626 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,626 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,626 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -76901.640625
2023-01-07 07:41:43,626 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,626 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,627 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 602.2592163085938
2023-01-07 07:41:43,627 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,627 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,627 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,627 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -76901.640625
2023-01-07 07:41:43,627 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,627 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,627 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,628 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -76901.640625
2023-01-07 07:41:43,628 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,629 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,629 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,629 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -466.3309020996094
2023-01-07 07:41:43,629 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,629 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,629 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,630 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 603.3584594726562
2023-01-07 07:41:43,630 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,630 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,630 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,630 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -466.3309020996094
2023-01-07 07:41:43,630 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,630 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,630 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,631 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -466.3309020996094
2023-01-07 07:41:43,631 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,631 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,631 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,632 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -219938.234375
2023-01-07 07:41:43,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,632 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,632 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2221.9755859375
2023-01-07 07:41:43,632 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,633 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,633 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,633 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -219938.234375
2023-01-07 07:41:43,633 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,633 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,633 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,634 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -219938.234375
2023-01-07 07:41:43,634 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,634 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,634 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,634 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -48103.5390625
2023-01-07 07:41:43,634 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,634 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,635 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2065.806884765625
2023-01-07 07:41:43,635 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,635 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,635 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,635 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -48103.5390625
2023-01-07 07:41:43,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,635 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,635 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,636 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -48103.5390625
2023-01-07 07:41:43,637 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,637 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,637 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,637 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -956.6509399414062
2023-01-07 07:41:43,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,637 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,637 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,638 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 616.4146728515625
2023-01-07 07:41:43,638 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,638 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,638 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,638 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -956.6509399414062
2023-01-07 07:41:43,638 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,638 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,638 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,639 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -956.6509399414062
2023-01-07 07:41:43,639 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,639 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,639 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,639 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -60831.16015625
2023-01-07 07:41:43,639 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,640 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,640 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,640 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 616.2166748046875
2023-01-07 07:41:43,640 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,640 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,640 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,641 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -60831.16015625
2023-01-07 07:41:43,641 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,641 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,641 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,642 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -60831.16015625
2023-01-07 07:41:43,642 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,642 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,642 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,642 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -183646.75
2023-01-07 07:41:43,642 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,642 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,642 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,643 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2031.208251953125
2023-01-07 07:41:43,643 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,643 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,643 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,643 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -183646.75
2023-01-07 07:41:43,643 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,643 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,643 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,644 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -183646.75
2023-01-07 07:41:43,645 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,645 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,645 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,645 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -23417.9609375
2023-01-07 07:41:43,645 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,645 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,645 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,646 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 617.615966796875
2023-01-07 07:41:43,646 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,646 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,646 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,646 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -23417.9609375
2023-01-07 07:41:43,646 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,646 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,646 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,647 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -23417.9609375
2023-01-07 07:41:43,647 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,647 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,647 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,647 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -519.8748168945312
2023-01-07 07:41:43,648 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,648 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,648 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,648 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 618.0152587890625
2023-01-07 07:41:43,648 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,648 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,649 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,649 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -519.8748168945312
2023-01-07 07:41:43,649 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,649 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,649 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,650 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: -519.8748168945312
2023-01-07 07:41:43,650 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,650 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,650 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,650 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -266502.375
2023-01-07 07:41:43,650 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,650 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,651 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,651 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2405.4541015625
2023-01-07 07:41:43,651 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,651 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,651 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,651 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -266502.375
2023-01-07 07:41:43,652 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,652 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,652 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:43,653 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -266502.375
2023-01-07 07:41:43,653 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:43,653 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:43,653 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:43,654 > [DEBUG] 0 :: 120.36225891113281
2023-01-07 07:41:43,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,656 > [DEBUG] 0 :: before allreduce fusion buffer :: 1161.186279296875
2023-01-07 07:41:43,658 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,658 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,658 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,658 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,659 > [DEBUG] 0 :: before allreduce fusion buffer :: -145.93777465820312
2023-01-07 07:41:43,661 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,661 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,662 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.170564651489258
2023-01-07 07:41:43,663 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,663 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,664 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,664 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,664 > [DEBUG] 0 :: before allreduce fusion buffer :: -238790.921875
2023-01-07 07:41:43,667 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,667 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,667 > [DEBUG] 0 :: before allreduce fusion buffer :: 3730.96630859375
2023-01-07 07:41:43,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,668 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,668 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,668 > [DEBUG] 0 :: before allreduce fusion buffer :: 3725.387451171875
2023-01-07 07:41:43,669 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,669 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,669 > [DEBUG] 0 :: before allreduce fusion buffer :: 8401.94921875
2023-01-07 07:41:43,670 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,670 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,670 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,670 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,670 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.546043872833252
2023-01-07 07:41:43,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,671 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,672 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6612340211868286
2023-01-07 07:41:43,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,673 > [DEBUG] 0 :: before allreduce fusion buffer :: -450531.34375
2023-01-07 07:41:43,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,674 > [DEBUG] 0 :: before allreduce fusion buffer :: -60.72727966308594
2023-01-07 07:41:43,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,675 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.769817352294922
2023-01-07 07:41:43,676 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,676 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,676 > [DEBUG] 0 :: before allreduce fusion buffer :: -29.874160766601562
2023-01-07 07:41:43,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,677 > [DEBUG] 0 :: before allreduce fusion buffer :: -299449.375
2023-01-07 07:41:43,678 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,678 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,678 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5281479358673096
2023-01-07 07:41:43,679 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,679 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,679 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,679 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,679 > [DEBUG] 0 :: before allreduce fusion buffer :: -274.20355224609375
2023-01-07 07:41:43,680 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,680 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,680 > [DEBUG] 0 :: before allreduce fusion buffer :: -126.79499816894531
2023-01-07 07:41:43,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,681 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,681 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,681 > [DEBUG] 0 :: before allreduce fusion buffer :: -1200847.0
2023-01-07 07:41:43,682 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,683 > [DEBUG] 0 :: before allreduce fusion buffer :: -125.24434661865234
2023-01-07 07:41:43,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,683 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.539215087890625
2023-01-07 07:41:43,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,685 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,685 > [DEBUG] 0 :: before allreduce fusion buffer :: -265.67108154296875
2023-01-07 07:41:43,685 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,685 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,685 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,685 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,686 > [DEBUG] 0 :: before allreduce fusion buffer :: -152.8604736328125
2023-01-07 07:41:43,687 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,687 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,687 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.942286252975464
2023-01-07 07:41:43,687 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,688 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,688 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,688 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,688 > [DEBUG] 0 :: before allreduce fusion buffer :: -200.47305297851562
2023-01-07 07:41:43,689 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,689 > [DEBUG] 0 :: before allreduce fusion buffer :: -2029.892333984375
2023-01-07 07:41:43,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,690 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.536218643188477
2023-01-07 07:41:43,691 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,691 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,692 > [DEBUG] 0 :: before allreduce fusion buffer :: -4078.632080078125
2023-01-07 07:41:43,692 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,692 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,692 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,692 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,693 > [DEBUG] 0 :: before allreduce fusion buffer :: -318.6923828125
2023-01-07 07:41:43,694 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,694 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,694 > [DEBUG] 0 :: before allreduce fusion buffer :: -8120.34326171875
2023-01-07 07:41:43,694 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,694 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,694 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,695 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,695 > [DEBUG] 0 :: before allreduce fusion buffer :: -354.3288879394531
2023-01-07 07:41:43,696 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,696 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,696 > [DEBUG] 0 :: before allreduce fusion buffer :: -16251.5625
2023-01-07 07:41:43,696 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,697 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,697 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,697 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,697 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.008316040039062
2023-01-07 07:41:43,698 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,698 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,698 > [DEBUG] 0 :: before allreduce fusion buffer :: -65007.015625
2023-01-07 07:41:43,699 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,699 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,699 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,699 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,699 > [DEBUG] 0 :: before allreduce fusion buffer :: -469.23046875
2023-01-07 07:41:43,700 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,700 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,700 > [DEBUG] 0 :: before allreduce fusion buffer :: -130004.3828125
2023-01-07 07:41:43,701 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,701 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,701 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,701 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,701 > [DEBUG] 0 :: before allreduce fusion buffer :: -1285.947998046875
2023-01-07 07:41:43,702 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,702 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,702 > [DEBUG] 0 :: before allreduce fusion buffer :: -260009.65625
2023-01-07 07:41:43,703 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,703 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,703 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,703 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,703 > [DEBUG] 0 :: before allreduce fusion buffer :: -307.4700927734375
2023-01-07 07:41:43,704 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,704 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,704 > [DEBUG] 0 :: before allreduce fusion buffer :: -520018.6875
2023-01-07 07:41:43,705 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,705 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,705 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,705 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,705 > [DEBUG] 0 :: before allreduce fusion buffer :: -1867.641357421875
2023-01-07 07:41:43,706 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,706 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,706 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.44941782951355
2023-01-07 07:41:43,707 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,707 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,707 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,707 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,707 > [DEBUG] 0 :: before allreduce fusion buffer :: -4335.30517578125
2023-01-07 07:41:43,708 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,708 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,709 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.1378350257873535
2023-01-07 07:41:43,709 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,709 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,709 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,709 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,710 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.3825902938842773
2023-01-07 07:41:43,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,711 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.145256996154785
2023-01-07 07:41:43,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,712 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,712 > [DEBUG] 0 :: before allreduce fusion buffer :: 321.624755859375
2023-01-07 07:41:43,713 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,713 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.146036148071289
2023-01-07 07:41:43,713 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,714 > [DEBUG] 0 :: before allreduce fusion buffer :: -6790.5185546875
2023-01-07 07:41:43,781 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,781 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,781 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.9963417053222656
2023-01-07 07:41:43,782 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,782 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,782 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3342578411102295
2023-01-07 07:41:43,783 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,783 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,783 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.2184600830078125
2023-01-07 07:41:43,783 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,783 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,784 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,784 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,784 > [DEBUG] 0 :: before allreduce fusion buffer :: -15155.3994140625
2023-01-07 07:41:43,785 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,785 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,785 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.14986515045166
2023-01-07 07:41:43,786 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,786 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,786 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,786 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,786 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.2354736328125
2023-01-07 07:41:43,787 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,787 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,787 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.454106330871582
2023-01-07 07:41:43,788 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,788 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,788 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,788 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,788 > [DEBUG] 0 :: before allreduce fusion buffer :: -31956.658203125
2023-01-07 07:41:43,964 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,964 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,964 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.549675941467285
2023-01-07 07:41:43,965 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,965 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,965 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.812817573547363
2023-01-07 07:41:43,966 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,966 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,966 > [DEBUG] 0 :: before allreduce fusion buffer :: -18.019058227539062
2023-01-07 07:41:43,967 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,967 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,967 > [DEBUG] 0 :: before allreduce fusion buffer :: -19.376691818237305
2023-01-07 07:41:43,968 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,968 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,968 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.048079490661621
2023-01-07 07:41:43,969 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,969 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,969 > [DEBUG] 0 :: before allreduce fusion buffer :: 30.72142791748047
2023-01-07 07:41:43,969 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,970 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,970 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.446995735168457
2023-01-07 07:41:43,970 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,970 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,970 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.72860336303711
2023-01-07 07:41:43,971 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,971 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,971 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.970681190490723
2023-01-07 07:41:43,972 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,972 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,972 > [DEBUG] 0 :: before allreduce fusion buffer :: 19.910802841186523
2023-01-07 07:41:43,973 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:43,973 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:43,973 > [DEBUG] 0 :: before allreduce fusion buffer :: -18.931766510009766
2023-01-07 07:41:44,147 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,147 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,147 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.3277645111084
2023-01-07 07:41:44,148 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,148 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,148 > [DEBUG] 0 :: before allreduce fusion buffer :: 37.59809112548828
2023-01-07 07:41:44,149 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,149 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,149 > [DEBUG] 0 :: before allreduce fusion buffer :: 89.02381896972656
2023-01-07 07:41:44,150 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,150 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,150 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.150665760040283
2023-01-07 07:41:44,151 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,151 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,151 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,151 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,151 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.606595039367676
2023-01-07 07:41:44,329 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,330 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.775670051574707
2023-01-07 07:41:44,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,331 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,331 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.64404582977295
2023-01-07 07:41:44,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,332 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.229026794433594
2023-01-07 07:41:44,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,448 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.12482261657715
2023-01-07 07:41:44,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 11.885943412780762
2023-01-07 07:41:44,450 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,450 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,450 > [DEBUG] 0 :: before allreduce fusion buffer :: 29.484474182128906
2023-01-07 07:41:44,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,452 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.5303075313568115
2023-01-07 07:41:44,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,452 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.163942813873291
2023-01-07 07:41:44,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,453 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.7314865589141846
2023-01-07 07:41:44,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,454 > [DEBUG] 0 :: before allreduce fusion buffer :: 28.934127807617188
2023-01-07 07:41:44,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,455 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.666830539703369
2023-01-07 07:41:44,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,456 > [DEBUG] 0 :: before allreduce fusion buffer :: -14.287847518920898
2023-01-07 07:41:44,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,457 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.793966293334961
2023-01-07 07:41:44,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,458 > [DEBUG] 0 :: before allreduce fusion buffer :: -2382.97314453125
2023-01-07 07:41:44,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,459 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.85633659362793
2023-01-07 07:41:44,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,460 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.73462677001953
2023-01-07 07:41:44,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,461 > [DEBUG] 0 :: before allreduce fusion buffer :: 26.198833465576172
2023-01-07 07:41:44,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,462 > [DEBUG] 0 :: before allreduce fusion buffer :: -110.15731048583984
2023-01-07 07:41:44,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,463 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.385345458984375
2023-01-07 07:41:44,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,464 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9664573669433594
2023-01-07 07:41:44,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,465 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.621192932128906
2023-01-07 07:41:44,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,466 > [DEBUG] 0 :: before allreduce fusion buffer :: 51.9283447265625
2023-01-07 07:41:44,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,467 > [DEBUG] 0 :: before allreduce fusion buffer :: -18.532764434814453
2023-01-07 07:41:44,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.69080924987793
2023-01-07 07:41:44,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,469 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.195965766906738
2023-01-07 07:41:44,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,471 > [DEBUG] 0 :: before allreduce fusion buffer :: -7719573.0
2023-01-07 07:41:44,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,472 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.75277042388916
2023-01-07 07:41:44,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,472 > [DEBUG] 0 :: before allreduce fusion buffer :: -58.52546691894531
2023-01-07 07:41:44,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,473 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.5894410610198975
2023-01-07 07:41:44,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,474 > [DEBUG] 0 :: before allreduce fusion buffer :: -430.1362609863281
2023-01-07 07:41:44,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,475 > [DEBUG] 0 :: before allreduce fusion buffer :: -147.16229248046875
2023-01-07 07:41:44,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,476 > [DEBUG] 0 :: before allreduce fusion buffer :: -91.10684204101562
2023-01-07 07:41:44,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,477 > [DEBUG] 0 :: before allreduce fusion buffer :: -224.41905212402344
2023-01-07 07:41:44,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,478 > [DEBUG] 0 :: before allreduce fusion buffer :: -327.6031494140625
2023-01-07 07:41:44,480 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 07:41:44,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,485 > [DEBUG] 0 :: before allreduce fusion buffer :: -998334070784.0
2023-01-07 07:41:44,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,491 > [DEBUG] 0 :: before allreduce fusion buffer :: -63893409890304.0
2023-01-07 07:41:44,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,492 > [DEBUG] 0 :: before allreduce fusion buffer :: -12650243.0
2023-01-07 07:41:44,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,493 > [DEBUG] 0 :: before allreduce fusion buffer :: -255573639561216.0
2023-01-07 07:41:44,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,494 > [DEBUG] 0 :: before allreduce fusion buffer :: -993564164096.0
2023-01-07 07:41:44,494 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: 118.7486572265625
2023-01-07 07:41:44,494 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,494 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,494 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,495 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 66.72774505615234
2023-01-07 07:41:44,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,495 > [DEBUG] 0 :: before allreduce fusion buffer :: -88.46688842773438
2023-01-07 07:41:44,496 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 66.72774505615234
2023-01-07 07:41:44,496 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,496 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,496 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,496 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 29.377771377563477
2023-01-07 07:41:44,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,497 > [DEBUG] 0 :: before allreduce fusion buffer :: -5252816306176.0
2023-01-07 07:41:44,498 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 29.377771377563477
2023-01-07 07:41:44,498 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,498 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,498 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,498 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 300.4105529785156
2023-01-07 07:41:44,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,499 > [DEBUG] 0 :: before allreduce fusion buffer :: 66.2879867553711
2023-01-07 07:41:44,499 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 67.65497589111328
2023-01-07 07:41:44,499 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,499 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,500 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,500 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 300.4105529785156
2023-01-07 07:41:44,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,500 > [DEBUG] 0 :: before allreduce fusion buffer :: -105.00875091552734
2023-01-07 07:41:44,501 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 300.4105529785156
2023-01-07 07:41:44,501 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,501 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,501 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,501 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 68.79737091064453
2023-01-07 07:41:44,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,502 > [DEBUG] 0 :: before allreduce fusion buffer :: -39041663762432.0
2023-01-07 07:41:44,503 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 68.79737091064453
2023-01-07 07:41:44,503 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,503 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,503 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,503 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 161.40975952148438
2023-01-07 07:41:44,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,504 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.175750732421875
2023-01-07 07:41:44,504 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 36.78049850463867
2023-01-07 07:41:44,504 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,504 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,504 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,505 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 248.5812530517578
2023-01-07 07:41:44,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,505 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.5587120056152344
2023-01-07 07:41:44,506 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 248.5812530517578
2023-01-07 07:41:44,506 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,506 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,506 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,506 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 320.2519836425781
2023-01-07 07:41:44,506 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,506 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,507 > [DEBUG] 0 :: before allreduce fusion buffer :: 179.6382293701172
2023-01-07 07:41:44,507 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 65.44448852539062
2023-01-07 07:41:44,507 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,507 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,507 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,508 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 320.2519836425781
2023-01-07 07:41:44,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,508 > [DEBUG] 0 :: before allreduce fusion buffer :: -71.12959289550781
2023-01-07 07:41:44,508 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 244.06790161132812
2023-01-07 07:41:44,509 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,509 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,509 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,509 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 320.2519836425781
2023-01-07 07:41:44,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,509 > [DEBUG] 0 :: before allreduce fusion buffer :: 53.421016693115234
2023-01-07 07:41:44,510 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 63.63665771484375
2023-01-07 07:41:44,510 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,510 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,510 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,510 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 63.72807693481445
2023-01-07 07:41:44,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,510 > [DEBUG] 0 :: before allreduce fusion buffer :: 138.83389282226562
2023-01-07 07:41:44,511 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 63.72807693481445
2023-01-07 07:41:44,511 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,512 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,512 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,512 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 320.2519836425781
2023-01-07 07:41:44,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,512 > [DEBUG] 0 :: before allreduce fusion buffer :: 71.905517578125
2023-01-07 07:41:44,513 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 320.2519836425781
2023-01-07 07:41:44,513 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,513 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,513 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,513 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 66.99243927001953
2023-01-07 07:41:44,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,514 > [DEBUG] 0 :: before allreduce fusion buffer :: 165.82064819335938
2023-01-07 07:41:44,515 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 66.99243927001953
2023-01-07 07:41:44,515 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,515 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,515 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,515 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 161.40975952148438
2023-01-07 07:41:44,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,516 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.138531684875488
2023-01-07 07:41:44,516 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 25.432113647460938
2023-01-07 07:41:44,516 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,516 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,517 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,517 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 16.16187858581543
2023-01-07 07:41:44,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,517 > [DEBUG] 0 :: before allreduce fusion buffer :: -62.778648376464844
2023-01-07 07:41:44,518 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 237.38131713867188
2023-01-07 07:41:44,518 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,518 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,518 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,518 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 16.16187858581543
2023-01-07 07:41:44,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,518 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.478017807006836
2023-01-07 07:41:44,519 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 16.16187858581543
2023-01-07 07:41:44,519 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,519 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,520 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,520 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 161.40975952148438
2023-01-07 07:41:44,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,520 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.057489395141602
2023-01-07 07:41:44,521 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 62.72774124145508
2023-01-07 07:41:44,521 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,521 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,521 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,521 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 161.40975952148438
2023-01-07 07:41:44,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,521 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7651801109313965
2023-01-07 07:41:44,522 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 161.40975952148438
2023-01-07 07:41:44,522 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,522 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,522 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,522 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 62.2598876953125
2023-01-07 07:41:44,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,523 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,524 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 62.2598876953125
2023-01-07 07:41:44,524 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,524 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,524 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,524 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 747.276123046875
2023-01-07 07:41:44,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,525 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,525 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 17.79102897644043
2023-01-07 07:41:44,526 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,526 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,526 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,526 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 451.5899658203125
2023-01-07 07:41:44,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,526 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,527 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 236.98126220703125
2023-01-07 07:41:44,527 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,527 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,527 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,527 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 747.276123046875
2023-01-07 07:41:44,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,528 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,528 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 451.5899658203125
2023-01-07 07:41:44,528 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,529 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,529 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,529 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 747.276123046875
2023-01-07 07:41:44,529 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,529 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,530 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 120.93099975585938
2023-01-07 07:41:44,530 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,530 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,530 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,530 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 747.276123046875
2023-01-07 07:41:44,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,530 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,531 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 747.276123046875
2023-01-07 07:41:44,531 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,531 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,531 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,531 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 123.76861572265625
2023-01-07 07:41:44,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,532 > [DEBUG] 0 :: before allreduce fusion buffer :: -7164.37890625
2023-01-07 07:41:44,533 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 123.76861572265625
2023-01-07 07:41:44,533 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,533 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,533 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,533 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 598.0704956054688
2023-01-07 07:41:44,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,534 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,535 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 598.0704956054688
2023-01-07 07:41:44,535 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,535 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,535 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,535 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 502.305419921875
2023-01-07 07:41:44,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,535 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,535 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,535 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,536 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 502.305419921875
2023-01-07 07:41:44,536 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,536 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,536 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,536 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 155.45838928222656
2023-01-07 07:41:44,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,537 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,538 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 155.45838928222656
2023-01-07 07:41:44,538 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,538 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,538 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,538 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 179.1718292236328
2023-01-07 07:41:44,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,538 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,539 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 497.4407653808594
2023-01-07 07:41:44,539 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,539 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,539 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,539 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 179.1718292236328
2023-01-07 07:41:44,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,540 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,541 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 179.1718292236328
2023-01-07 07:41:44,541 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,541 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,541 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,541 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 119.13090515136719
2023-01-07 07:41:44,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,541 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,542 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 119.13090515136719
2023-01-07 07:41:44,542 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,542 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,542 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,542 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 337.9267272949219
2023-01-07 07:41:44,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,544 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 337.9267272949219
2023-01-07 07:41:44,544 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,544 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,544 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,544 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 120.02430725097656
2023-01-07 07:41:44,544 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,544 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,544 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,544 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,545 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,546 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 120.02430725097656
2023-01-07 07:41:44,546 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,546 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,546 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,546 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 288.38824462890625
2023-01-07 07:41:44,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,547 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 288.38824462890625
2023-01-07 07:41:44,547 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,547 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,548 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,548 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 121.70604705810547
2023-01-07 07:41:44,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,549 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 528.3453979492188
2023-01-07 07:41:44,549 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,549 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,549 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,549 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 121.70604705810547
2023-01-07 07:41:44,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,549 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,550 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 121.70604705810547
2023-01-07 07:41:44,550 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,550 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,550 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,550 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 119.65977478027344
2023-01-07 07:41:44,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,551 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,552 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 119.65977478027344
2023-01-07 07:41:44,552 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,552 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,552 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,552 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: -818.8126831054688
2023-01-07 07:41:44,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,553 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,554 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -818.8126831054688
2023-01-07 07:41:44,554 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,554 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,554 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,554 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 130.01303100585938
2023-01-07 07:41:44,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,554 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,555 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 130.01303100585938
2023-01-07 07:41:44,555 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,555 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,555 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,556 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: -157.1781005859375
2023-01-07 07:41:44,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,556 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,557 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: -157.1781005859375
2023-01-07 07:41:44,557 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,557 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,557 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,557 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 517.3644409179688
2023-01-07 07:41:44,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,558 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,559 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 517.3644409179688
2023-01-07 07:41:44,559 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,559 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,559 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,559 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: 25.942569732666016
2023-01-07 07:41:44,559 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,559 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,559 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,560 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 25.942569732666016
2023-01-07 07:41:44,560 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,560 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,560 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,560 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 119.50560760498047
2023-01-07 07:41:44,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,561 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,562 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 119.50560760498047
2023-01-07 07:41:44,562 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,562 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,562 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,562 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: -251.33114624023438
2023-01-07 07:41:44,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,562 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,564 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: -251.33114624023438
2023-01-07 07:41:44,564 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,564 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,564 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,564 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 123.34242248535156
2023-01-07 07:41:44,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,564 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,564 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,564 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,566 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 123.34242248535156
2023-01-07 07:41:44,566 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,566 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,566 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 28.65936851501465
2023-01-07 07:41:44,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,567 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,568 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 28.65936851501465
2023-01-07 07:41:44,568 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,568 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,568 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 501.1827392578125
2023-01-07 07:41:44,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,569 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 501.1827392578125
2023-01-07 07:41:44,569 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,570 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,570 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,570 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 123.59056091308594
2023-01-07 07:41:44,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,570 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,571 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 123.59056091308594
2023-01-07 07:41:44,571 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,571 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,571 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,571 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 246.80654907226562
2023-01-07 07:41:44,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,572 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,572 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,572 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,573 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 246.80654907226562
2023-01-07 07:41:44,573 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,573 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,573 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,573 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -22843.43359375
2023-01-07 07:41:44,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,573 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,573 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,574 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -22843.43359375
2023-01-07 07:41:44,575 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,575 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,575 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,575 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -1293.363037109375
2023-01-07 07:41:44,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,575 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,576 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 247.91741943359375
2023-01-07 07:41:44,576 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,576 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,576 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,576 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -1293.363037109375
2023-01-07 07:41:44,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,576 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,577 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,578 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -1293.363037109375
2023-01-07 07:41:44,578 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,578 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,578 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,578 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -34195.828125
2023-01-07 07:41:44,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,578 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,579 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1011.1400756835938
2023-01-07 07:41:44,579 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,579 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,579 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,579 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -34195.828125
2023-01-07 07:41:44,579 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,579 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,580 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,580 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -34195.828125
2023-01-07 07:41:44,581 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,581 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,581 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,581 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -28860.47265625
2023-01-07 07:41:44,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,581 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,582 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1043.6102294921875
2023-01-07 07:41:44,582 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,582 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,582 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,582 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -28860.47265625
2023-01-07 07:41:44,582 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,582 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,582 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,583 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -28860.47265625
2023-01-07 07:41:44,584 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,584 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,584 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,584 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 265.91949462890625
2023-01-07 07:41:44,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,584 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,585 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 265.91949462890625
2023-01-07 07:41:44,585 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,585 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,585 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,585 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -63778.8515625
2023-01-07 07:41:44,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,586 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,586 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,587 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -63778.8515625
2023-01-07 07:41:44,587 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,587 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,587 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,587 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -16332.611328125
2023-01-07 07:41:44,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,588 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,588 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 244.917236328125
2023-01-07 07:41:44,588 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,588 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,588 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,589 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -16332.611328125
2023-01-07 07:41:44,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,589 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,590 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -16332.611328125
2023-01-07 07:41:44,590 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,590 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,590 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,590 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 608.1077270507812
2023-01-07 07:41:44,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,590 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,591 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1022.6451416015625
2023-01-07 07:41:44,591 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,591 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,591 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,591 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 608.1077270507812
2023-01-07 07:41:44,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,592 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,593 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 608.1077270507812
2023-01-07 07:41:44,593 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,593 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,593 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,593 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 240.0068817138672
2023-01-07 07:41:44,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,593 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,594 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 268.0761413574219
2023-01-07 07:41:44,594 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,594 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,594 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,594 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 240.0068817138672
2023-01-07 07:41:44,594 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,594 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,594 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,596 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 240.0068817138672
2023-01-07 07:41:44,596 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,596 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,596 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,596 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -51.93540954589844
2023-01-07 07:41:44,596 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,596 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,596 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,597 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 241.1207275390625
2023-01-07 07:41:44,597 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,597 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,597 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,597 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: -51.93540954589844
2023-01-07 07:41:44,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,597 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,598 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: -51.93540954589844
2023-01-07 07:41:44,598 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,599 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,599 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,599 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 67.77481079101562
2023-01-07 07:41:44,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,599 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,600 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1072.496826171875
2023-01-07 07:41:44,600 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,600 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,600 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,600 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 67.77481079101562
2023-01-07 07:41:44,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,600 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,601 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 67.77481079101562
2023-01-07 07:41:44,601 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,601 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,601 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,602 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 755.2848510742188
2023-01-07 07:41:44,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,602 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,603 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 284.18927001953125
2023-01-07 07:41:44,603 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,603 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,603 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,603 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 755.2848510742188
2023-01-07 07:41:44,603 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,603 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,603 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,604 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 755.2848510742188
2023-01-07 07:41:44,604 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,604 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,604 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,604 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -72.28453826904297
2023-01-07 07:41:44,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,605 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,605 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 286.3893737792969
2023-01-07 07:41:44,605 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,605 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,606 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,606 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -72.28453826904297
2023-01-07 07:41:44,606 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,606 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,607 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -72.28453826904297
2023-01-07 07:41:44,607 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,607 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,607 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,607 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -98.48126220703125
2023-01-07 07:41:44,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,607 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,608 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,608 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1059.5135498046875
2023-01-07 07:41:44,608 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,608 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,608 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,609 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -98.48126220703125
2023-01-07 07:41:44,609 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,609 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,609 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,610 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -98.48126220703125
2023-01-07 07:41:44,610 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,610 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,610 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,610 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -946.43603515625
2023-01-07 07:41:44,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,610 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,611 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 287.206787109375
2023-01-07 07:41:44,611 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,611 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,611 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,611 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -946.43603515625
2023-01-07 07:41:44,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,612 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,613 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -946.43603515625
2023-01-07 07:41:44,613 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,613 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,613 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,613 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -7978.95751953125
2023-01-07 07:41:44,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,613 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,614 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 287.11767578125
2023-01-07 07:41:44,614 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,614 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,614 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,614 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -7978.95751953125
2023-01-07 07:41:44,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,615 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,616 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -7978.95751953125
2023-01-07 07:41:44,616 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,616 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,616 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,616 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -50751.77734375
2023-01-07 07:41:44,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,616 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,617 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1129.52294921875
2023-01-07 07:41:44,617 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,617 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,617 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,617 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -50751.77734375
2023-01-07 07:41:44,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,617 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,618 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -50751.77734375
2023-01-07 07:41:44,619 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,619 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,619 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,619 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -22069.82421875
2023-01-07 07:41:44,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,619 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,620 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 288.3209228515625
2023-01-07 07:41:44,620 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,620 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,620 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,620 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -22069.82421875
2023-01-07 07:41:44,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,620 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,621 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -22069.82421875
2023-01-07 07:41:44,621 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,622 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,622 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,622 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -57778.88671875
2023-01-07 07:41:44,622 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,622 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,622 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,623 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 290.2876281738281
2023-01-07 07:41:44,623 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,623 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,623 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,623 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -57778.88671875
2023-01-07 07:41:44,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,623 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,624 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -57778.88671875
2023-01-07 07:41:44,624 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,624 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,624 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,625 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -123025.8828125
2023-01-07 07:41:44,625 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,625 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,625 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,625 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1059.45947265625
2023-01-07 07:41:44,625 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,626 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,626 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,626 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -123025.8828125
2023-01-07 07:41:44,626 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,626 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,627 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -123025.8828125
2023-01-07 07:41:44,627 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,627 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,627 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,627 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -105255.84375
2023-01-07 07:41:44,628 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,628 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,628 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,628 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 603.5421142578125
2023-01-07 07:41:44,628 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,628 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,629 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,629 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -105255.84375
2023-01-07 07:41:44,629 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,629 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,629 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,630 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -105255.84375
2023-01-07 07:41:44,630 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,630 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,630 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,630 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -648.0616455078125
2023-01-07 07:41:44,630 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,630 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,631 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,631 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 604.7716064453125
2023-01-07 07:41:44,631 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,631 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,631 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,632 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -648.0616455078125
2023-01-07 07:41:44,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,632 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,633 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -648.0616455078125
2023-01-07 07:41:44,633 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,633 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,633 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,633 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -301007.0625
2023-01-07 07:41:44,633 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,634 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,634 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2229.048095703125
2023-01-07 07:41:44,634 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,634 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,634 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,635 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -301007.0625
2023-01-07 07:41:44,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,635 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,635 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,636 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -301007.0625
2023-01-07 07:41:44,636 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,636 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,636 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,636 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -65903.7109375
2023-01-07 07:41:44,636 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,636 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,636 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,637 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2049.59814453125
2023-01-07 07:41:44,637 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,637 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,637 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,637 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -65903.7109375
2023-01-07 07:41:44,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,637 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,638 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,639 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -65903.7109375
2023-01-07 07:41:44,639 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,639 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,639 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,639 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -1402.9510498046875
2023-01-07 07:41:44,639 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,639 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,639 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,640 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 622.63427734375
2023-01-07 07:41:44,640 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,640 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,640 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,640 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -1402.9510498046875
2023-01-07 07:41:44,640 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,640 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,641 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,642 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -1402.9510498046875
2023-01-07 07:41:44,642 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,642 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,642 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,642 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -83275.984375
2023-01-07 07:41:44,642 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,642 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,642 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,643 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 622.436279296875
2023-01-07 07:41:44,643 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,643 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,643 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,643 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -83275.984375
2023-01-07 07:41:44,643 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,643 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,643 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,645 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -83275.984375
2023-01-07 07:41:44,645 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,645 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,645 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,645 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -251349.078125
2023-01-07 07:41:44,645 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,645 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,645 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,646 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2014.9814453125
2023-01-07 07:41:44,646 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,646 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,646 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,646 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -251349.078125
2023-01-07 07:41:44,646 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,646 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,646 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,647 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -251349.078125
2023-01-07 07:41:44,648 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,648 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,648 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,648 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -32123.576171875
2023-01-07 07:41:44,648 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,648 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,648 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,649 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 623.83544921875
2023-01-07 07:41:44,649 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,649 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,649 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,649 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -32123.576171875
2023-01-07 07:41:44,649 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,649 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,649 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,650 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -32123.576171875
2023-01-07 07:41:44,650 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,650 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,651 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,651 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -952.302490234375
2023-01-07 07:41:44,651 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,651 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,651 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,652 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 624.2350463867188
2023-01-07 07:41:44,652 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,652 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,652 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,652 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -952.302490234375
2023-01-07 07:41:44,652 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,652 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,652 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,653 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: -952.302490234375
2023-01-07 07:41:44,653 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,653 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,653 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,654 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -365144.34375
2023-01-07 07:41:44,654 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,654 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,654 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,654 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2389.6259765625
2023-01-07 07:41:44,655 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,655 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,655 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,655 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -365144.34375
2023-01-07 07:41:44,655 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,655 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,655 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 07:41:44,656 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -365144.34375
2023-01-07 07:41:44,657 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 07:41:44,657 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 07:41:44,657 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 07:41:44,658 > [DEBUG] 0 :: 228.5672149658203
2023-01-07 07:41:44,660 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,660 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,660 > [DEBUG] 0 :: before allreduce fusion buffer :: -405.5325927734375
2023-01-07 07:41:44,662 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,662 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,662 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,662 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,663 > [DEBUG] 0 :: before allreduce fusion buffer :: -167.59933471679688
2023-01-07 07:41:44,665 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,666 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,666 > [DEBUG] 0 :: before allreduce fusion buffer :: -55.78897476196289
2023-01-07 07:41:44,667 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,667 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,667 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,667 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,668 > [DEBUG] 0 :: before allreduce fusion buffer :: -50473808.0
2023-01-07 07:41:44,669 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,669 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,669 > [DEBUG] 0 :: before allreduce fusion buffer :: -78.29674530029297
2023-01-07 07:41:44,670 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,670 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,670 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,670 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,670 > [DEBUG] 0 :: before allreduce fusion buffer :: -76.07730102539062
2023-01-07 07:41:44,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,671 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,672 > [DEBUG] 0 :: before allreduce fusion buffer :: 75.60161590576172
2023-01-07 07:41:44,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,673 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,673 > [DEBUG] 0 :: before allreduce fusion buffer :: 276.5367736816406
2023-01-07 07:41:44,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,674 > [DEBUG] 0 :: before allreduce fusion buffer :: -153.41046142578125
2023-01-07 07:41:44,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,675 > [DEBUG] 0 :: before allreduce fusion buffer :: -98482360.0
2023-01-07 07:41:44,676 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,676 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,677 > [DEBUG] 0 :: before allreduce fusion buffer :: -895.5032958984375
2023-01-07 07:41:44,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,678 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,678 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,678 > [DEBUG] 0 :: before allreduce fusion buffer :: -1553.551513671875
2023-01-07 07:41:44,679 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,679 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,679 > [DEBUG] 0 :: before allreduce fusion buffer :: -1782.284423828125
2023-01-07 07:41:44,680 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,680 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,680 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,680 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,680 > [DEBUG] 0 :: before allreduce fusion buffer :: -95788736.0
2023-01-07 07:41:44,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,681 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,681 > [DEBUG] 0 :: before allreduce fusion buffer :: -3580.544921875
2023-01-07 07:41:44,682 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,682 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,682 > [DEBUG] 0 :: before allreduce fusion buffer :: 703.1556396484375
2023-01-07 07:41:44,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,684 > [DEBUG] 0 :: before allreduce fusion buffer :: -3579.796142578125
2023-01-07 07:41:44,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,684 > [DEBUG] 0 :: before allreduce fusion buffer :: -292755712.0
2023-01-07 07:41:44,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,686 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,686 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.185410022735596
2023-01-07 07:41:44,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,686 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,687 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,687 > [DEBUG] 0 :: before allreduce fusion buffer :: -3280.902587890625
2023-01-07 07:41:44,688 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,688 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,688 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.028165817260742
2023-01-07 07:41:44,689 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,689 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,689 > [DEBUG] 0 :: before allreduce fusion buffer :: 104.45793151855469
2023-01-07 07:41:44,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,690 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.395766019821167
2023-01-07 07:41:44,691 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,691 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,691 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,691 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,692 > [DEBUG] 0 :: before allreduce fusion buffer :: -5268.66064453125
2023-01-07 07:41:44,693 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,693 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,693 > [DEBUG] 0 :: before allreduce fusion buffer :: -16041.5078125
2023-01-07 07:41:44,693 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,693 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,693 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,694 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,694 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.13036131858825684
2023-01-07 07:41:44,695 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,695 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,695 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6854387521743774
2023-01-07 07:41:44,695 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,696 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,696 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,696 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,696 > [DEBUG] 0 :: before allreduce fusion buffer :: 195.196533203125
2023-01-07 07:41:44,697 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,697 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,697 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.218110084533691
2023-01-07 07:41:44,698 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,698 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,698 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,698 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,698 > [DEBUG] 0 :: before allreduce fusion buffer :: 2397.833984375
2023-01-07 07:41:44,699 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,699 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,699 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.548914909362793
2023-01-07 07:41:44,700 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,700 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,700 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,700 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,700 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.590383768081665
2023-01-07 07:41:44,701 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,701 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,701 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.767872333526611
2023-01-07 07:41:44,702 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,702 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,702 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,702 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,702 > [DEBUG] 0 :: before allreduce fusion buffer :: 1299.0540771484375
2023-01-07 07:41:44,703 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,703 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,703 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.400578498840332
2023-01-07 07:41:44,704 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,704 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,704 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,704 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,704 > [DEBUG] 0 :: before allreduce fusion buffer :: 6212.28515625
2023-01-07 07:41:44,705 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,705 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,706 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.2041516304016113
2023-01-07 07:41:44,706 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,706 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,706 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,706 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,706 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.5213205814361572
2023-01-07 07:41:44,707 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,708 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,708 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.156322479248047
2023-01-07 07:41:44,708 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,708 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,708 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,708 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,709 > [DEBUG] 0 :: before allreduce fusion buffer :: 3882.393798828125
2023-01-07 07:41:44,710 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,710 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,710 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.697721004486084
2023-01-07 07:41:44,710 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,710 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,711 > [DEBUG] 0 :: before allreduce fusion buffer :: 10095.7763671875
2023-01-07 07:41:44,712 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,712 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,712 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.81412124633789
2023-01-07 07:41:44,712 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,713 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,713 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.911473274230957
2023-01-07 07:41:44,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,714 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.136445999145508
2023-01-07 07:41:44,715 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,715 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,715 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,715 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,715 > [DEBUG] 0 :: before allreduce fusion buffer :: 26941.15234375
2023-01-07 07:41:44,716 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,716 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,716 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.438206672668457
2023-01-07 07:41:44,717 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,717 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,717 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,717 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,717 > [DEBUG] 0 :: before allreduce fusion buffer :: 37828.34765625
2023-01-07 07:41:44,770 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,770 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,770 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.231005668640137
2023-01-07 07:41:44,771 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,771 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,771 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.595876693725586
2023-01-07 07:41:44,772 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,772 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,772 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.041898727416992
2023-01-07 07:41:44,772 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,772 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,773 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,773 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,773 > [DEBUG] 0 :: before allreduce fusion buffer :: 83352.65625
2023-01-07 07:41:44,774 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,774 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,774 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.6816980838775635
2023-01-07 07:41:44,775 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,775 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,775 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,775 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,775 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7776768207550049
2023-01-07 07:41:44,776 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,776 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,776 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.438887119293213
2023-01-07 07:41:44,777 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,777 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,777 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,777 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,777 > [DEBUG] 0 :: before allreduce fusion buffer :: 166649.0625
2023-01-07 07:41:44,954 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,954 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,954 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.4562259912490845
2023-01-07 07:41:44,955 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,955 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,955 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.916787624359131
2023-01-07 07:41:44,956 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,956 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,956 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.79115104675293
2023-01-07 07:41:44,956 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,957 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,957 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.783599853515625
2023-01-07 07:41:44,957 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,957 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,958 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.490765571594238
2023-01-07 07:41:44,958 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,958 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,958 > [DEBUG] 0 :: before allreduce fusion buffer :: 43.00742721557617
2023-01-07 07:41:44,959 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,959 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,959 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.24568176269531
2023-01-07 07:41:44,960 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,960 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,960 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.002630710601807
2023-01-07 07:41:44,961 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,961 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,961 > [DEBUG] 0 :: before allreduce fusion buffer :: -58.88911056518555
2023-01-07 07:41:44,962 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,962 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,962 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.25692892074585
2023-01-07 07:41:44,963 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:44,963 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:44,963 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.701786518096924
2023-01-07 07:41:45,138 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,138 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,138 > [DEBUG] 0 :: before allreduce fusion buffer :: 26.246627807617188
2023-01-07 07:41:45,139 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,139 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,139 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.8505616188049316
2023-01-07 07:41:45,140 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,140 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,140 > [DEBUG] 0 :: before allreduce fusion buffer :: 122.68983459472656
2023-01-07 07:41:45,141 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,141 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,141 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.140010833740234
2023-01-07 07:41:45,142 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,142 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,142 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,142 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,142 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.800682067871094
2023-01-07 07:41:45,321 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,321 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,321 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.527502059936523
2023-01-07 07:41:45,322 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,322 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,322 > [DEBUG] 0 :: before allreduce fusion buffer :: -14.634838104248047
2023-01-07 07:41:45,323 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,323 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,323 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.374721050262451
2023-01-07 07:41:45,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,438 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.528709411621094
2023-01-07 07:41:45,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,440 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.046187400817871
2023-01-07 07:41:45,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,441 > [DEBUG] 0 :: before allreduce fusion buffer :: -30.240673065185547
2023-01-07 07:41:45,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,442 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,442 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.61510944366455
2023-01-07 07:41:45,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,442 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,443 > [DEBUG] 0 :: before allreduce fusion buffer :: -32.32597351074219
2023-01-07 07:41:45,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,443 > [DEBUG] 0 :: before allreduce fusion buffer :: 30.882793426513672
2023-01-07 07:41:45,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,444 > [DEBUG] 0 :: before allreduce fusion buffer :: 19.563011169433594
2023-01-07 07:41:45,445 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,445 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,445 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.792067527770996
2023-01-07 07:41:45,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,446 > [DEBUG] 0 :: before allreduce fusion buffer :: 46.97602844238281
2023-01-07 07:41:45,447 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,447 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,447 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.126893997192383
2023-01-07 07:41:45,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,448 > [DEBUG] 0 :: before allreduce fusion buffer :: 117.18418884277344
2023-01-07 07:41:45,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,450 > [DEBUG] 0 :: before allreduce fusion buffer :: -164.3509979248047
2023-01-07 07:41:45,450 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,450 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1205291748046875
2023-01-07 07:41:45,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,451 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.240104675292969
2023-01-07 07:41:45,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,452 > [DEBUG] 0 :: before allreduce fusion buffer :: -34.29255676269531
2023-01-07 07:41:45,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,453 > [DEBUG] 0 :: before allreduce fusion buffer :: 28.69671630859375
2023-01-07 07:41:45,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,454 > [DEBUG] 0 :: before allreduce fusion buffer :: 234.53518676757812
2023-01-07 07:41:45,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.869797229766846
2023-01-07 07:41:45,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 1840.4925537109375
2023-01-07 07:41:45,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,457 > [DEBUG] 0 :: before allreduce fusion buffer :: -30.55555534362793
2023-01-07 07:41:45,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,458 > [DEBUG] 0 :: before allreduce fusion buffer :: -202.59495544433594
2023-01-07 07:41:45,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,459 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.087448120117188
2023-01-07 07:41:45,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,461 > [DEBUG] 0 :: before allreduce fusion buffer :: 284541.8125
2023-01-07 07:41:45,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,462 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.73699378967285
2023-01-07 07:41:45,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 282.09210205078125
2023-01-07 07:41:45,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,464 > [DEBUG] 0 :: before allreduce fusion buffer :: -29.464984893798828
2023-01-07 07:41:45,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,465 > [DEBUG] 0 :: before allreduce fusion buffer :: 3409501.5
2023-01-07 07:41:45,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,466 > [DEBUG] 0 :: before allreduce fusion buffer :: 109.14598083496094
2023-01-07 07:41:45,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,467 > [DEBUG] 0 :: before allreduce fusion buffer :: -194.7498016357422
2023-01-07 07:41:45,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,468 > [DEBUG] 0 :: before allreduce fusion buffer :: -486.1954345703125
2023-01-07 07:41:45,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 07:41:45,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 07:41:45,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 349.0235900878906
