2023-01-07 08:10:49,183 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:10:49,184 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:49,222 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: 2.4733664989471436
2023-01-07 08:10:49,222 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:49,223 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 9408
2023-01-07 08:10:49,223 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:49,223 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:49,223 > [DEBUG] 0 :: scheduled task in conv1._dp_wrapped_module.flat_param_0 :: 0, FW, [AR, [[1, torch.Size([128]) 0 0], [4, torch.Size([36864]) 24374 24374]]]
2023-01-07 08:10:49,223 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,079 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,080 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,080 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:10:50,080 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,080 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,080 > [DEBUG] 0 :: scheduled task in bn1._dp_wrapped_module.flat_param_0 :: 1, FW, [AR, [[2, torch.Size([4096]) 0 0], [4, torch.Size([36864]) 29806 29806]]]
2023-01-07 08:10:50,080 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,082 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 26.03603172302246
2023-01-07 08:10:50,082 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,083 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:10:50,083 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,083 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,083 > [DEBUG] 0 :: scheduled task in layer1.0.conv1._dp_wrapped_module.flat_param_0 :: 2, FW, [AR, [[4, torch.Size([36864]) 29895 29895]]]
2023-01-07 08:10:50,083 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,084 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,084 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,084 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:10:50,084 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,084 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,084 > [DEBUG] 0 :: scheduled task in layer1.0.bn1._dp_wrapped_module.flat_param_0 :: 3, FW, [AR, [[4, torch.Size([36864]) 34135 34135]]]
2023-01-07 08:10:50,085 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,086 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 3.609463691711426
2023-01-07 08:10:50,086 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,086 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:10:50,086 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,086 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,086 > [DEBUG] 0 :: scheduled task in layer1.0.conv2._dp_wrapped_module.flat_param_0 :: 4, FW, [AR, [[5, torch.Size([128]) 0 0], [6, torch.Size([16384]) 0 0], [18, torch.Size([36864]) 16953 16953]]]
2023-01-07 08:10:50,086 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,124 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,124 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,124 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:10:50,124 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,124 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,125 > [DEBUG] 0 :: scheduled task in layer1.0.bn2._dp_wrapped_module.flat_param_0 :: 5, FW, [AR, [[18, torch.Size([36864]) 19948 19948]]]
2023-01-07 08:10:50,125 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,126 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: -15.96937370300293
2023-01-07 08:10:50,126 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,126 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:10:50,126 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,127 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,127 > [DEBUG] 0 :: scheduled task in layer1.0.conv3._dp_wrapped_module.flat_param_0 :: 6, FW, [AR, [[7, torch.Size([512]) 0 0], [10, torch.Size([16384]) 5999 5999]]]
2023-01-07 08:10:50,127 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,128 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,128 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,128 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,128 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,128 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,128 > [DEBUG] 0 :: scheduled task in layer1.0.bn3._dp_wrapped_module.flat_param_0 :: 7, FW, [AR, [[12, torch.Size([36864]) 4826 4826]]]
2023-01-07 08:10:50,129 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,129 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 4.586517333984375
2023-01-07 08:10:50,129 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,130 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:10:50,130 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,130 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,130 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.0._dp_wrapped_module.flat_param_0 :: 8, FW, [AR, [[12, torch.Size([36864]) 9052 9052]]]
2023-01-07 08:10:50,130 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,131 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,131 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,131 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,131 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,131 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,132 > [DEBUG] 0 :: scheduled task in layer1.0.downsample.1._dp_wrapped_module.flat_param_0 :: 9, FW, [AR, [[12, torch.Size([36864]) 13245 13245]]]
2023-01-07 08:10:50,132 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,133 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: -16.002477645874023
2023-01-07 08:10:50,133 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,133 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:10:50,133 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,133 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,133 > [DEBUG] 0 :: scheduled task in layer1.1.conv1._dp_wrapped_module.flat_param_0 :: 10, FW, [AR, [[11, torch.Size([128]) 0 0], [12, torch.Size([36864]) 15961 15961]]]
2023-01-07 08:10:50,133 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,134 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,134 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,135 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:10:50,135 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,135 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,135 > [DEBUG] 0 :: scheduled task in layer1.1.bn1._dp_wrapped_module.flat_param_0 :: 11, FW, [AR, [[12, torch.Size([36864]) 35400 35400], [24, torch.Size([147456]) 133638 133638]]]
2023-01-07 08:10:50,135 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,136 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 12.989543914794922
2023-01-07 08:10:50,136 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,137 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:10:50,137 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,137 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,137 > [DEBUG] 0 :: scheduled task in layer1.1.conv2._dp_wrapped_module.flat_param_0 :: 12, FW, [AR, [[13, torch.Size([128]) 0 0], [14, torch.Size([16384]) 5438 5438]]]
2023-01-07 08:10:50,137 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,138 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,138 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,138 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:10:50,138 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,138 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,138 > [DEBUG] 0 :: scheduled task in layer1.1.bn2._dp_wrapped_module.flat_param_0 :: 13, FW, [AR, [[18, torch.Size([36864]) 22600 22600]]]
2023-01-07 08:10:50,138 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,140 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 11.421207427978516
2023-01-07 08:10:50,140 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,140 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:10:50,140 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,140 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,140 > [DEBUG] 0 :: scheduled task in layer1.1.conv3._dp_wrapped_module.flat_param_0 :: 14, FW, [AR, [[16, torch.Size([16384]) 8376 8376]]]
2023-01-07 08:10:50,140 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,141 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,141 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,142 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,142 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,142 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,142 > [DEBUG] 0 :: scheduled task in layer1.1.bn3._dp_wrapped_module.flat_param_0 :: 15, FW, [AR, [[16, torch.Size([16384]) 15379 15379], [18, torch.Size([36864]) 26760 26760]]]
2023-01-07 08:10:50,142 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,143 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: -14.69498062133789
2023-01-07 08:10:50,143 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,143 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:10:50,143 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,143 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,143 > [DEBUG] 0 :: scheduled task in layer1.2.conv1._dp_wrapped_module.flat_param_0 :: 16, FW, [AR, [[18, torch.Size([36864]) 29950 29950]]]
2023-01-07 08:10:50,144 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,144 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,145 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,145 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:10:50,145 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,145 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,145 > [DEBUG] 0 :: scheduled task in layer1.2.bn1._dp_wrapped_module.flat_param_0 :: 17, FW, [AR, [[18, torch.Size([36864]) 34171 34171]]]
2023-01-07 08:10:50,145 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,146 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 16.334102630615234
2023-01-07 08:10:50,146 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,147 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 36864
2023-01-07 08:10:50,147 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,147 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,147 > [DEBUG] 0 :: scheduled task in layer1.2.conv2._dp_wrapped_module.flat_param_0 :: 18, FW, [AR, [[19, torch.Size([128]) 0 0], [20, torch.Size([16384]) 0 0], [22, torch.Size([32768]) 14465 14465]]]
2023-01-07 08:10:50,147 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,148 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,148 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,148 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 128
2023-01-07 08:10:50,148 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,148 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,148 > [DEBUG] 0 :: scheduled task in layer1.2.bn2._dp_wrapped_module.flat_param_0 :: 19, FW, [AR, [[24, torch.Size([147456]) 134884 134884]]]
2023-01-07 08:10:50,149 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,150 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 13.217470169067383
2023-01-07 08:10:50,150 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,150 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 16384
2023-01-07 08:10:50,150 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,150 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,150 > [DEBUG] 0 :: scheduled task in layer1.2.conv3._dp_wrapped_module.flat_param_0 :: 20, FW, [AR, [[22, torch.Size([32768]) 24699 24699]]]
2023-01-07 08:10:50,150 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,151 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,151 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,152 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,152 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,152 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,152 > [DEBUG] 0 :: scheduled task in layer1.2.bn3._dp_wrapped_module.flat_param_0 :: 21, FW, [AR, [[24, torch.Size([147456]) 137525 137525]]]
2023-01-07 08:10:50,152 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,153 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: -4.182164192199707
2023-01-07 08:10:50,153 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,153 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 32768
2023-01-07 08:10:50,154 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,154 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,154 > [DEBUG] 0 :: scheduled task in layer2.0.conv1._dp_wrapped_module.flat_param_0 :: 22, FW, [AR, [[24, torch.Size([147456]) 140496 140496]]]
2023-01-07 08:10:50,154 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,155 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,155 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,155 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,155 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,155 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,155 > [DEBUG] 0 :: scheduled task in layer2.0.bn1._dp_wrapped_module.flat_param_0 :: 23, FW, [AR, [[24, torch.Size([147456]) 144875 144875]]]
2023-01-07 08:10:50,155 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,157 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 0.20351552963256836
2023-01-07 08:10:50,157 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,157 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:10:50,157 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,157 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,157 > [DEBUG] 0 :: scheduled task in layer2.0.conv2._dp_wrapped_module.flat_param_0 :: 24, FW, [AR, [[25, torch.Size([256]) 0 0], [26, torch.Size([65536]) 55354 55354]]]
2023-01-07 08:10:50,157 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,159 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,159 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,159 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,159 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,159 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,159 > [DEBUG] 0 :: scheduled task in layer2.0.bn2._dp_wrapped_module.flat_param_0 :: 25, FW, [AR, [[26, torch.Size([65536]) 62932 62932]]]
2023-01-07 08:10:50,159 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,160 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: -8.174488067626953
2023-01-07 08:10:50,160 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,161 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:10:50,161 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,161 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,161 > [DEBUG] 0 :: scheduled task in layer2.0.conv3._dp_wrapped_module.flat_param_0 :: 26, FW, [AR, [[27, torch.Size([1024]) 0 0], [28, torch.Size([131072]) 121409 121409]]]
2023-01-07 08:10:50,161 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,162 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,162 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,162 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,162 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,162 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,162 > [DEBUG] 0 :: scheduled task in layer2.0.bn3._dp_wrapped_module.flat_param_0 :: 27, FW, [AR, [[28, torch.Size([131072]) 128101 128101]]]
2023-01-07 08:10:50,163 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,164 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 25.176406860351562
2023-01-07 08:10:50,164 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,164 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 08:10:50,164 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,164 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,164 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.0._dp_wrapped_module.flat_param_0 :: 28, FW, [AR, [[30, torch.Size([65536]) 58518 58518]]]
2023-01-07 08:10:50,164 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,165 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,166 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,166 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,166 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,166 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,166 > [DEBUG] 0 :: scheduled task in layer2.0.downsample.1._dp_wrapped_module.flat_param_0 :: 29, FW, [AR, [[30, torch.Size([65536]) 62926 62926]]]
2023-01-07 08:10:50,166 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,167 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1.0197086334228516
2023-01-07 08:10:50,167 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,168 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:10:50,168 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,168 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,168 > [DEBUG] 0 :: scheduled task in layer2.1.conv1._dp_wrapped_module.flat_param_0 :: 30, FW, [AR, [[31, torch.Size([256]) 0 0], [32, torch.Size([147456]) 137276 137276]]]
2023-01-07 08:10:50,168 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,169 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,169 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,169 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,169 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,170 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,170 > [DEBUG] 0 :: scheduled task in layer2.1.bn1._dp_wrapped_module.flat_param_0 :: 31, FW, [AR, [[32, torch.Size([147456]) 144843 144843]]]
2023-01-07 08:10:50,170 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,171 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 4.209651947021484
2023-01-07 08:10:50,171 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,171 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:10:50,171 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,171 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,172 > [DEBUG] 0 :: scheduled task in layer2.1.conv2._dp_wrapped_module.flat_param_0 :: 32, FW, [AR, [[33, torch.Size([256]) 0 0], [34, torch.Size([65536]) 55010 55010]]]
2023-01-07 08:10:50,172 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,173 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,173 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,173 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,173 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,173 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,173 > [DEBUG] 0 :: scheduled task in layer2.1.bn2._dp_wrapped_module.flat_param_0 :: 33, FW, [AR, [[34, torch.Size([65536]) 62519 62519]]]
2023-01-07 08:10:50,173 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,174 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 26.955251693725586
2023-01-07 08:10:50,175 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,175 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:10:50,175 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,175 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,176 > [DEBUG] 0 :: scheduled task in layer2.1.conv3._dp_wrapped_module.flat_param_0 :: 34, FW, [AR, [[36, torch.Size([65536]) 58337 58337]]]
2023-01-07 08:10:50,176 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,178 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,178 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,179 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,179 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,179 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,179 > [DEBUG] 0 :: scheduled task in layer2.1.bn3._dp_wrapped_module.flat_param_0 :: 35, FW, [AR, [[36, torch.Size([65536]) 62837 62837]]]
2023-01-07 08:10:50,179 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,181 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 29.957128524780273
2023-01-07 08:10:50,181 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,181 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:10:50,181 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,181 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,181 > [DEBUG] 0 :: scheduled task in layer2.2.conv1._dp_wrapped_module.flat_param_0 :: 36, FW, [AR, [[37, torch.Size([256]) 0 0], [38, torch.Size([147456]) 136838 136838]]]
2023-01-07 08:10:50,181 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,182 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,182 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,183 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,183 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,183 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,183 > [DEBUG] 0 :: scheduled task in layer2.2.bn1._dp_wrapped_module.flat_param_0 :: 37, FW, [AR, [[38, torch.Size([147456]) 144611 144611]]]
2023-01-07 08:10:50,183 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,184 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 13.131409645080566
2023-01-07 08:10:50,184 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,185 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:10:50,185 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,185 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,185 > [DEBUG] 0 :: scheduled task in layer2.2.conv2._dp_wrapped_module.flat_param_0 :: 38, FW, [AR, [[39, torch.Size([256]) 0 0], [40, torch.Size([65536]) 54391 54391]]]
2023-01-07 08:10:50,185 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,186 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,186 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,186 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,186 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,186 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,186 > [DEBUG] 0 :: scheduled task in layer2.2.bn2._dp_wrapped_module.flat_param_0 :: 39, FW, [AR, [[40, torch.Size([65536]) 62211 62211]]]
2023-01-07 08:10:50,186 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,187 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: 13.698368072509766
2023-01-07 08:10:50,188 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,188 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:10:50,188 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,188 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,188 > [DEBUG] 0 :: scheduled task in layer2.2.conv3._dp_wrapped_module.flat_param_0 :: 40, FW, [AR, [[41, torch.Size([1024]) 0 0], [42, torch.Size([65536]) 58457 58457]]]
2023-01-07 08:10:50,188 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,189 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,189 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,190 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,190 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,190 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,190 > [DEBUG] 0 :: scheduled task in layer2.2.bn3._dp_wrapped_module.flat_param_0 :: 41, FW, [AR, [[42, torch.Size([65536]) 62434 62434]]]
2023-01-07 08:10:50,190 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,191 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -14.372568130493164
2023-01-07 08:10:50,191 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,191 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:10:50,191 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,191 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,191 > [DEBUG] 0 :: scheduled task in layer2.3.conv1._dp_wrapped_module.flat_param_0 :: 42, FW, [AR, [[43, torch.Size([256]) 0 0], [44, torch.Size([147456]) 136250 136250]]]
2023-01-07 08:10:50,192 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,192 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,193 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,193 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,193 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,193 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,193 > [DEBUG] 0 :: scheduled task in layer2.3.bn1._dp_wrapped_module.flat_param_0 :: 43, FW, [AR, [[44, torch.Size([147456]) 144343 144343]]]
2023-01-07 08:10:50,193 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,194 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 15.708341598510742
2023-01-07 08:10:50,195 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,195 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 147456
2023-01-07 08:10:50,195 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,195 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,195 > [DEBUG] 0 :: scheduled task in layer2.3.conv2._dp_wrapped_module.flat_param_0 :: 44, FW, [AR, [[45, torch.Size([256]) 0 0], [46, torch.Size([65536]) 53786 53786]]]
2023-01-07 08:10:50,195 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,196 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,196 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,196 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 256
2023-01-07 08:10:50,197 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,197 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,197 > [DEBUG] 0 :: scheduled task in layer2.3.bn2._dp_wrapped_module.flat_param_0 :: 45, FW, [AR, [[46, torch.Size([65536]) 62012 62012]]]
2023-01-07 08:10:50,197 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,198 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -8.675992012023926
2023-01-07 08:10:50,198 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,198 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 65536
2023-01-07 08:10:50,198 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,198 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,198 > [DEBUG] 0 :: scheduled task in layer2.3.conv3._dp_wrapped_module.flat_param_0 :: 46, FW, [AR, [[47, torch.Size([1024]) 0 0], [48, torch.Size([131072]) 123183 123183]]]
2023-01-07 08:10:50,198 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,199 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,199 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,200 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,200 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,200 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,200 > [DEBUG] 0 :: scheduled task in layer2.3.bn3._dp_wrapped_module.flat_param_0 :: 47, FW, [AR, [[48, torch.Size([131072]) 127567 127567]]]
2023-01-07 08:10:50,200 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,201 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 23.072154998779297
2023-01-07 08:10:50,201 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,202 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 131072
2023-01-07 08:10:50,202 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,202 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,202 > [DEBUG] 0 :: scheduled task in layer3.0.conv1._dp_wrapped_module.flat_param_0 :: 48, FW, [AR, [[49, torch.Size([512]) 0 0], [50, torch.Size([589824]) 577505 577505]]]
2023-01-07 08:10:50,202 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,203 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,203 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,203 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,203 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,203 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,204 > [DEBUG] 0 :: scheduled task in layer3.0.bn1._dp_wrapped_module.flat_param_0 :: 49, FW, [AR, [[50, torch.Size([589824]) 586102 586102]]]
2023-01-07 08:10:50,204 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,205 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -12.14183235168457
2023-01-07 08:10:50,205 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,205 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:10:50,205 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,205 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,205 > [DEBUG] 0 :: scheduled task in layer3.0.conv2._dp_wrapped_module.flat_param_0 :: 50, FW, [AR, [[52, torch.Size([262144]) 248915 248915]]]
2023-01-07 08:10:50,205 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,206 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,207 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,207 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,207 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,207 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,207 > [DEBUG] 0 :: scheduled task in layer3.0.bn2._dp_wrapped_module.flat_param_0 :: 51, FW, [AR, [[52, torch.Size([262144]) 258136 258136]]]
2023-01-07 08:10:50,207 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,208 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: 20.73180389404297
2023-01-07 08:10:50,208 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,209 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,209 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,209 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,209 > [DEBUG] 0 :: scheduled task in layer3.0.conv3._dp_wrapped_module.flat_param_0 :: 52, FW, [AR, [[54, torch.Size([524288]) 514056 514056]]]
2023-01-07 08:10:50,209 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,210 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:10:50,210 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,210 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:10:50,210 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,210 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,211 > [DEBUG] 0 :: scheduled task in layer3.0.bn3._dp_wrapped_module.flat_param_0 :: 53, FW, [AR, [[54, torch.Size([524288]) 520083 520083]]]
2023-01-07 08:10:50,211 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,211 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 1.1122112274169922
2023-01-07 08:10:50,212 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,212 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 08:10:50,212 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,212 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,212 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.0._dp_wrapped_module.flat_param_0 :: 54, FW, [AR, [[56, torch.Size([262144]) 251612 251612]]]
2023-01-07 08:10:50,212 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,213 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:10:50,213 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,214 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:10:50,214 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,214 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,214 > [DEBUG] 0 :: scheduled task in layer3.0.downsample.1._dp_wrapped_module.flat_param_0 :: 55, FW, [AR, [[56, torch.Size([262144]) 258055 258055]]]
2023-01-07 08:10:50,214 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,215 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 14.865394592285156
2023-01-07 08:10:50,215 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,215 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,215 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,215 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,215 > [DEBUG] 0 :: scheduled task in layer3.1.conv1._dp_wrapped_module.flat_param_0 :: 56, FW, [AR, [[57, torch.Size([512]) 0 0], [58, torch.Size([589824]) 575870 575870]]]
2023-01-07 08:10:50,216 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,217 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,217 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,217 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,217 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,217 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,217 > [DEBUG] 0 :: scheduled task in layer3.1.bn1._dp_wrapped_module.flat_param_0 :: 57, FW, [AR, [[58, torch.Size([589824]) 585646 585646]]]
2023-01-07 08:10:50,217 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,218 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: 32.60767364501953
2023-01-07 08:10:50,219 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,219 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:10:50,219 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,219 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,219 > [DEBUG] 0 :: scheduled task in layer3.1.conv2._dp_wrapped_module.flat_param_0 :: 58, FW, [AR, [[60, torch.Size([262144]) 250298 250298]]]
2023-01-07 08:10:50,219 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,220 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,220 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,221 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,221 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,221 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,221 > [DEBUG] 0 :: scheduled task in layer3.1.bn2._dp_wrapped_module.flat_param_0 :: 59, FW, [AR, [[60, torch.Size([262144]) 257996 257996]]]
2023-01-07 08:10:50,221 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,222 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -29.30276107788086
2023-01-07 08:10:50,222 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,222 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,222 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,222 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,223 > [DEBUG] 0 :: scheduled task in layer3.1.conv3._dp_wrapped_module.flat_param_0 :: 60, FW, [AR, [[62, torch.Size([262144]) 251486 251486]]]
2023-01-07 08:10:50,223 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,223 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:10:50,224 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,224 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:10:50,224 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,224 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,224 > [DEBUG] 0 :: scheduled task in layer3.1.bn3._dp_wrapped_module.flat_param_0 :: 61, FW, [AR, [[62, torch.Size([262144]) 257960 257960]]]
2023-01-07 08:10:50,224 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,225 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: -59.47146224975586
2023-01-07 08:10:50,226 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,226 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,226 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,226 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,226 > [DEBUG] 0 :: scheduled task in layer3.2.conv1._dp_wrapped_module.flat_param_0 :: 62, FW, [AR, [[64, torch.Size([589824]) 578797 578797]]]
2023-01-07 08:10:50,226 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,227 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,227 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,227 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,227 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,227 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,228 > [DEBUG] 0 :: scheduled task in layer3.2.bn1._dp_wrapped_module.flat_param_0 :: 63, FW, [AR, [[64, torch.Size([589824]) 585633 585633]]]
2023-01-07 08:10:50,228 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,229 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 29.793678283691406
2023-01-07 08:10:50,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,229 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:10:50,229 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,229 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,229 > [DEBUG] 0 :: scheduled task in layer3.2.conv2._dp_wrapped_module.flat_param_0 :: 64, FW, [AR, [[66, torch.Size([262144]) 250265 250265]]]
2023-01-07 08:10:50,229 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,230 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,230 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,231 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,231 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,231 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,231 > [DEBUG] 0 :: scheduled task in layer3.2.bn2._dp_wrapped_module.flat_param_0 :: 65, FW, [AR, [[66, torch.Size([262144]) 257992 257992]]]
2023-01-07 08:10:50,231 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,232 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: 6.1346282958984375
2023-01-07 08:10:50,232 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,232 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,233 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,233 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,233 > [DEBUG] 0 :: scheduled task in layer3.2.conv3._dp_wrapped_module.flat_param_0 :: 66, FW, [AR, [[68, torch.Size([262144]) 251489 251489]]]
2023-01-07 08:10:50,233 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,234 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:10:50,234 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,234 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:10:50,234 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,234 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,234 > [DEBUG] 0 :: scheduled task in layer3.2.bn3._dp_wrapped_module.flat_param_0 :: 67, FW, [AR, [[68, torch.Size([262144]) 257975 257975]]]
2023-01-07 08:10:50,234 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,235 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 31.802913665771484
2023-01-07 08:10:50,235 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,236 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,236 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,236 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,236 > [DEBUG] 0 :: scheduled task in layer3.3.conv1._dp_wrapped_module.flat_param_0 :: 68, FW, [AR, [[70, torch.Size([589824]) 578834 578834]]]
2023-01-07 08:10:50,236 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,237 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,237 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,237 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,237 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,238 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,238 > [DEBUG] 0 :: scheduled task in layer3.3.bn1._dp_wrapped_module.flat_param_0 :: 69, FW, [AR, [[70, torch.Size([589824]) 585643 585643]]]
2023-01-07 08:10:50,238 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,239 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 29.217912673950195
2023-01-07 08:10:50,239 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,239 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:10:50,239 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,239 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,239 > [DEBUG] 0 :: scheduled task in layer3.3.conv2._dp_wrapped_module.flat_param_0 :: 70, FW, [AR, [[72, torch.Size([262144]) 250221 250221]]]
2023-01-07 08:10:50,240 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,240 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,240 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,241 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,241 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,241 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,241 > [DEBUG] 0 :: scheduled task in layer3.3.bn2._dp_wrapped_module.flat_param_0 :: 71, FW, [AR, [[72, torch.Size([262144]) 257983 257983]]]
2023-01-07 08:10:50,241 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,242 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 40.07816696166992
2023-01-07 08:10:50,242 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,243 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,243 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,243 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,243 > [DEBUG] 0 :: scheduled task in layer3.3.conv3._dp_wrapped_module.flat_param_0 :: 72, FW, [AR, [[74, torch.Size([262144]) 251508 251508]]]
2023-01-07 08:10:50,243 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,244 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:10:50,244 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,244 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:10:50,244 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,244 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,244 > [DEBUG] 0 :: scheduled task in layer3.3.bn3._dp_wrapped_module.flat_param_0 :: 73, FW, [AR, [[74, torch.Size([262144]) 257957 257957]]]
2023-01-07 08:10:50,244 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,245 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 35.902854919433594
2023-01-07 08:10:50,246 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,246 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,246 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,246 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,246 > [DEBUG] 0 :: scheduled task in layer3.4.conv1._dp_wrapped_module.flat_param_0 :: 74, FW, [AR, [[76, torch.Size([589824]) 578817 578817]]]
2023-01-07 08:10:50,246 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,247 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,247 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,247 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,247 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,247 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,248 > [DEBUG] 0 :: scheduled task in layer3.4.bn1._dp_wrapped_module.flat_param_0 :: 75, FW, [AR, [[76, torch.Size([589824]) 585626 585626]]]
2023-01-07 08:10:50,248 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,249 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 29.78942108154297
2023-01-07 08:10:50,249 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,249 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:10:50,249 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,249 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,249 > [DEBUG] 0 :: scheduled task in layer3.4.conv2._dp_wrapped_module.flat_param_0 :: 76, FW, [AR, [[78, torch.Size([262144]) 250146 250146]]]
2023-01-07 08:10:50,249 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,250 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,250 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,251 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,251 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,251 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,251 > [DEBUG] 0 :: scheduled task in layer3.4.bn2._dp_wrapped_module.flat_param_0 :: 77, FW, [AR, [[78, torch.Size([262144]) 258090 258090]]]
2023-01-07 08:10:50,251 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,252 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -3.1448216438293457
2023-01-07 08:10:50,252 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,252 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,252 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,253 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,253 > [DEBUG] 0 :: scheduled task in layer3.4.conv3._dp_wrapped_module.flat_param_0 :: 78, FW, [AR, [[80, torch.Size([262144]) 252751 252751]]]
2023-01-07 08:10:50,253 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,254 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:10:50,254 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,254 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:10:50,254 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,254 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,254 > [DEBUG] 0 :: scheduled task in layer3.4.bn3._dp_wrapped_module.flat_param_0 :: 79, FW, [AR, [[80, torch.Size([262144]) 258004 258004]]]
2023-01-07 08:10:50,254 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,255 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -22.040939331054688
2023-01-07 08:10:50,256 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,256 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,256 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,256 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,256 > [DEBUG] 0 :: scheduled task in layer3.5.conv1._dp_wrapped_module.flat_param_0 :: 80, FW, [AR, [[82, torch.Size([589824]) 579303 579303]]]
2023-01-07 08:10:50,256 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,257 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,257 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,257 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,257 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,258 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,258 > [DEBUG] 0 :: scheduled task in layer3.5.bn1._dp_wrapped_module.flat_param_0 :: 81, FW, [AR, [[82, torch.Size([589824]) 585666 585666]]]
2023-01-07 08:10:50,258 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,259 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: 31.254535675048828
2023-01-07 08:10:50,259 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,259 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 589824
2023-01-07 08:10:50,259 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,259 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,259 > [DEBUG] 0 :: scheduled task in layer3.5.conv2._dp_wrapped_module.flat_param_0 :: 82, FW, [AR, [[84, torch.Size([262144]) 249049 249049]]]
2023-01-07 08:10:50,260 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,260 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,260 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,261 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 512
2023-01-07 08:10:50,261 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,261 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,261 > [DEBUG] 0 :: scheduled task in layer3.5.bn2._dp_wrapped_module.flat_param_0 :: 83, FW, [AR, [[84, torch.Size([262144]) 258029 258029]]]
2023-01-07 08:10:50,261 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,262 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -0.5114307403564453
2023-01-07 08:10:50,262 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,262 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 262144
2023-01-07 08:10:50,263 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,263 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,263 > [DEBUG] 0 :: scheduled task in layer3.5.conv3._dp_wrapped_module.flat_param_0 :: 84, FW, [AR, [[86, torch.Size([524288]) 513996 513996]]]
2023-01-07 08:10:50,263 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,264 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1024.0
2023-01-07 08:10:50,264 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,264 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2048
2023-01-07 08:10:50,264 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,264 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,264 > [DEBUG] 0 :: scheduled task in layer3.5.bn3._dp_wrapped_module.flat_param_0 :: 85, FW, [AR, [[86, torch.Size([524288]) 520257 520257]]]
2023-01-07 08:10:50,264 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,265 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -17.57099723815918
2023-01-07 08:10:50,266 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,266 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 524288
2023-01-07 08:10:50,266 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,266 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,266 > [DEBUG] 0 :: scheduled task in layer4.0.conv1._dp_wrapped_module.flat_param_0 :: 86, FW, [AR, [[88, torch.Size([2359296]) 2348986 2348986]]]
2023-01-07 08:10:50,266 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,267 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,267 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,268 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,268 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,268 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,268 > [DEBUG] 0 :: scheduled task in layer4.0.bn1._dp_wrapped_module.flat_param_0 :: 87, FW, [AR, [[88, torch.Size([2359296]) 2355264 2355264]]]
2023-01-07 08:10:50,268 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,269 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: 24.63208770751953
2023-01-07 08:10:50,269 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,269 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:10:50,269 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,269 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,269 > [DEBUG] 0 :: scheduled task in layer4.0.conv2._dp_wrapped_module.flat_param_0 :: 88, FW, [AR, [[90, torch.Size([1048576]) 1038739 1038739]]]
2023-01-07 08:10:50,270 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,271 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,271 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,271 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,271 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,271 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,271 > [DEBUG] 0 :: scheduled task in layer4.0.bn2._dp_wrapped_module.flat_param_0 :: 89, FW, [AR, [[90, torch.Size([1048576]) 1044678 1044678]]]
2023-01-07 08:10:50,271 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,272 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 14.661914825439453
2023-01-07 08:10:50,273 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,273 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:10:50,273 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,273 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,273 > [DEBUG] 0 :: scheduled task in layer4.0.conv3._dp_wrapped_module.flat_param_0 :: 90, FW, [AR, [[92, torch.Size([2097152]) 2086529 2086529]]]
2023-01-07 08:10:50,273 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,274 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:10:50,274 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,274 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:10:50,274 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,275 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,275 > [DEBUG] 0 :: scheduled task in layer4.0.bn3._dp_wrapped_module.flat_param_0 :: 91, FW, [AR, [[92, torch.Size([2097152]) 2093335 2093335]]]
2023-01-07 08:10:50,275 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,276 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -39.88478469848633
2023-01-07 08:10:50,276 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,276 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2097152
2023-01-07 08:10:50,276 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,276 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,276 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.0._dp_wrapped_module.flat_param_0 :: 92, FW, [AR, [[94, torch.Size([1048576]) 1039183 1039183]]]
2023-01-07 08:10:50,276 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,277 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:10:50,277 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,278 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:10:50,278 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,278 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,278 > [DEBUG] 0 :: scheduled task in layer4.0.downsample.1._dp_wrapped_module.flat_param_0 :: 93, FW, [AR, [[94, torch.Size([1048576]) 1044932 1044932]]]
2023-01-07 08:10:50,278 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,279 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: 81.16545867919922
2023-01-07 08:10:50,279 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,279 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:10:50,279 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,279 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,279 > [DEBUG] 0 :: scheduled task in layer4.1.conv1._dp_wrapped_module.flat_param_0 :: 94, FW, [AR, [[96, torch.Size([2359296]) 2350332 2350332]]]
2023-01-07 08:10:50,280 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,281 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,281 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,281 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,281 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,281 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,281 > [DEBUG] 0 :: scheduled task in layer4.1.bn1._dp_wrapped_module.flat_param_0 :: 95, FW, [AR, [[96, torch.Size([2359296]) 2355789 2355789]]]
2023-01-07 08:10:50,281 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,282 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -5.967223644256592
2023-01-07 08:10:50,282 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,283 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:10:50,283 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,283 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,283 > [DEBUG] 0 :: scheduled task in layer4.1.conv2._dp_wrapped_module.flat_param_0 :: 96, FW, [AR, [[98, torch.Size([1048576]) 1038824 1038824]]]
2023-01-07 08:10:50,283 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,284 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,284 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,285 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,285 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,285 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,285 > [DEBUG] 0 :: scheduled task in layer4.1.bn2._dp_wrapped_module.flat_param_0 :: 97, FW, [AR, [[98, torch.Size([1048576]) 1045258 1045258]]]
2023-01-07 08:10:50,285 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,286 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: 2.017467498779297
2023-01-07 08:10:50,286 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,286 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:10:50,286 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,286 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,286 > [DEBUG] 0 :: scheduled task in layer4.1.conv3._dp_wrapped_module.flat_param_0 :: 98, FW, [AR, [[100, torch.Size([1048576]) 1041045 1041045]]]
2023-01-07 08:10:50,287 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,287 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:10:50,288 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,288 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:10:50,288 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,288 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,288 > [DEBUG] 0 :: scheduled task in layer4.1.bn3._dp_wrapped_module.flat_param_0 :: 99, FW, [AR, [[100, torch.Size([1048576]) 1045245 1045245]]]
2023-01-07 08:10:50,288 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,289 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -20.75659942626953
2023-01-07 08:10:50,289 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,290 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:10:50,290 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,290 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,290 > [DEBUG] 0 :: scheduled task in layer4.2.conv1._dp_wrapped_module.flat_param_0 :: 100, FW, [AR, [[102, torch.Size([2359296]) 2351012 2351012]]]
2023-01-07 08:10:50,290 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,291 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,291 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,291 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,291 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,291 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,291 > [DEBUG] 0 :: scheduled task in layer4.2.bn1._dp_wrapped_module.flat_param_0 :: 101, FW, [AR, [[102, torch.Size([2359296]) 2356170 2356170]]]
2023-01-07 08:10:50,291 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,293 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 53.04460525512695
2023-01-07 08:10:50,293 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,293 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2359296
2023-01-07 08:10:50,293 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,293 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,293 > [DEBUG] 0 :: scheduled task in layer4.2.conv2._dp_wrapped_module.flat_param_0 :: 102, FW, [AR, [[104, torch.Size([1048576]) 1040523 1040523]]]
2023-01-07 08:10:50,293 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,294 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,294 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,295 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1024
2023-01-07 08:10:50,295 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,295 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,295 > [DEBUG] 0 :: scheduled task in layer4.2.bn2._dp_wrapped_module.flat_param_0 :: 103, FW, [AR, [[104, torch.Size([1048576]) 1045407 1045407]]]
2023-01-07 08:10:50,295 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,296 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 45.91598129272461
2023-01-07 08:10:50,296 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,296 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 1048576
2023-01-07 08:10:50,296 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,296 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,296 > [DEBUG] 0 :: scheduled task in layer4.2.conv3._dp_wrapped_module.flat_param_0 :: 104, FW, [AR, [[106, torch.Size([2049000]) 2039302 2039302]]]
2023-01-07 08:10:50,297 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,297 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2048.0
2023-01-07 08:10:50,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,298 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 4096
2023-01-07 08:10:50,298 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,298 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,298 > [DEBUG] 0 :: scheduled task in layer4.2.bn3._dp_wrapped_module.flat_param_0 :: 105, FW, [AR, [[106, torch.Size([2049000]) 2045884 2045884]]]
2023-01-07 08:10:50,298 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,300 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -23.07699966430664
2023-01-07 08:10:50,300 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:50,300 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is not fully commnicated!!! communicated parameter : 0 orig size : 2049000
2023-01-07 08:10:50,300 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,300 > [DEBUG] 0 :: ########### task is not assigned to module############
2023-01-07 08:10:50,300 > [DEBUG] 0 :: scheduled task in fc._dp_wrapped_module.flat_param_0 :: No scheduled
2023-01-07 08:10:50,301 > [DEBUG] 0 :: 7.494607925415039
2023-01-07 08:10:50,306 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,306 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,307 > [DEBUG] 0 :: before allreduce fusion buffer :: -362.09130859375
2023-01-07 08:10:50,310 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,310 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,310 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,310 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,310 > [DEBUG] 0 :: before allreduce fusion buffer :: -329.9656677246094
2023-01-07 08:10:50,322 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,322 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,323 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.1547437459230423
2023-01-07 08:10:50,324 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,324 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,324 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,324 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,324 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7668392658233643
2023-01-07 08:10:50,327 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,327 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,327 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6936691999435425
2023-01-07 08:10:50,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,328 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,328 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,328 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,328 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.21222175657749176
2023-01-07 08:10:50,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,330 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,330 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.22661727666854858
2023-01-07 08:10:50,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,331 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,331 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,331 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,332 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.2950596809387207
2023-01-07 08:10:50,334 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,334 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,335 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.2225354164838791
2023-01-07 08:10:50,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,336 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,336 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.36063551902771
2023-01-07 08:10:50,338 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,338 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,338 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.13982968032360077
2023-01-07 08:10:50,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,339 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,339 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,339 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,339 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0642609596252441
2023-01-07 08:10:50,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,341 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,341 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2395782619714737
2023-01-07 08:10:50,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,342 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,343 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9302293658256531
2023-01-07 08:10:50,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,345 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.2448089122772217
2023-01-07 08:10:50,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,346 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,346 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5971437096595764
2023-01-07 08:10:50,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,348 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,348 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8503293991088867
2023-01-07 08:10:50,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,349 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,349 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,349 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3442342281341553
2023-01-07 08:10:50,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,352 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,352 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.08296229690313339
2023-01-07 08:10:50,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,353 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,353 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.430247783660889
2023-01-07 08:10:50,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,355 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,355 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.02597782015800476
2023-01-07 08:10:50,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,356 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,357 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.048932433128357
2023-01-07 08:10:50,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,358 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,359 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4060908854007721
2023-01-07 08:10:50,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,360 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9417170286178589
2023-01-07 08:10:50,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,362 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.407056212425232
2023-01-07 08:10:50,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,363 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,364 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.7663053274154663
2023-01-07 08:10:50,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,366 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,366 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.868269443511963
2023-01-07 08:10:50,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,367 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,367 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3254458010196686
2023-01-07 08:10:50,369 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,369 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,369 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.709196925163269
2023-01-07 08:10:50,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,370 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.111060857772827
2023-01-07 08:10:50,372 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,372 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,372 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.1678848266601562
2023-01-07 08:10:50,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,373 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,373 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.06140559911727905
2023-01-07 08:10:50,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,375 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,375 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.380393624305725
2023-01-07 08:10:50,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,376 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,376 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,376 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.553574562072754
2023-01-07 08:10:50,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,378 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,378 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3075835406780243
2023-01-07 08:10:50,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,379 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,380 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8522682189941406
2023-01-07 08:10:50,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,381 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,381 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6230943202972412
2023-01-07 08:10:50,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,382 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,383 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,383 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5329506993293762
2023-01-07 08:10:50,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,384 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,385 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.222615957260132
2023-01-07 08:10:50,385 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,385 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,386 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6435874700546265
2023-01-07 08:10:50,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,388 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,388 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.08186323940753937
2023-01-07 08:10:50,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,389 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,389 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.6963844299316406
2023-01-07 08:10:50,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,391 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,391 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.003645896911621
2023-01-07 08:10:50,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,392 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,392 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.670226573944092
2023-01-07 08:10:50,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,394 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,394 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5675175786018372
2023-01-07 08:10:50,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,395 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,395 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.052899718284607
2023-01-07 08:10:50,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,397 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,397 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.37893491983413696
2023-01-07 08:10:50,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,398 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3010327816009521
2023-01-07 08:10:50,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,400 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,400 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8814815878868103
2023-01-07 08:10:50,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,401 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8530449867248535
2023-01-07 08:10:50,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,403 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,403 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7505235075950623
2023-01-07 08:10:50,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,404 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,404 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.700026035308838
2023-01-07 08:10:50,406 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,406 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,406 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.6156113147735596
2023-01-07 08:10:50,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,407 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,408 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.648066997528076
2023-01-07 08:10:50,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,409 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,410 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.5163984298706055
2023-01-07 08:10:50,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,410 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,411 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,411 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,411 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.515446662902832
2023-01-07 08:10:50,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,413 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,413 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.27708101272583
2023-01-07 08:10:50,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.01036548614502
2023-01-07 08:10:50,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,416 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,416 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.2544612884521484
2023-01-07 08:10:50,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,417 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.7060633897781372
2023-01-07 08:10:50,418 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,418 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,419 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.8533730506896973
2023-01-07 08:10:50,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,420 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.14151668548584
2023-01-07 08:10:50,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,421 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,421 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.29005241394043
2023-01-07 08:10:50,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,422 > [DEBUG] 0 :: before allreduce fusion buffer :: 22.34689712524414
2023-01-07 08:10:50,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,424 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,424 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.191368103027344
2023-01-07 08:10:50,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,425 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.789266586303711
2023-01-07 08:10:50,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,426 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,427 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.0091289281845093
2023-01-07 08:10:50,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,428 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.03660249710083
2023-01-07 08:10:50,429 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,429 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,429 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.821883678436279
2023-01-07 08:10:50,430 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,430 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,430 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.713825225830078
2023-01-07 08:10:50,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,431 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,431 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.92303466796875
2023-01-07 08:10:50,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,432 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,433 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.229347229003906
2023-01-07 08:10:50,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,434 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,434 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.126184463500977
2023-01-07 08:10:50,435 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,435 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,436 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.4130473136901855
2023-01-07 08:10:50,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,437 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,437 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.416866302490234
2023-01-07 08:10:50,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,438 > [DEBUG] 0 :: before allreduce fusion buffer :: 25.134716033935547
2023-01-07 08:10:50,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,439 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,439 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.561251401901245
2023-01-07 08:10:50,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,440 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,441 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.664511203765869
2023-01-07 08:10:50,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,443 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,443 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1951985359191895
2023-01-07 08:10:50,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,444 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.660543918609619
2023-01-07 08:10:50,445 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,445 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,445 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.828599452972412
2023-01-07 08:10:50,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,446 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.13475513458252
2023-01-07 08:10:50,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,448 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,448 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.454937219619751
2023-01-07 08:10:50,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,449 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 61.88243865966797
2023-01-07 08:10:50,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,451 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.264781951904297
2023-01-07 08:10:50,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,452 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,452 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,453 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.128036499023438
2023-01-07 08:10:50,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,455 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.102607727050781
2023-01-07 08:10:50,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.546476364135742
2023-01-07 08:10:50,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,458 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,458 > [DEBUG] 0 :: before allreduce fusion buffer :: 50.65534973144531
2023-01-07 08:10:50,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,460 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,461 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.24940299987793
2023-01-07 08:10:50,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.358144760131836
2023-01-07 08:10:50,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,463 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,464 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,464 > [DEBUG] 0 :: before allreduce fusion buffer :: -26.922245025634766
2023-01-07 08:10:50,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,466 > [DEBUG] 0 :: before allreduce fusion buffer :: -25.638578414916992
2023-01-07 08:10:50,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,467 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,467 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.162086486816406
2023-01-07 08:10:50,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,468 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.253305435180664
2023-01-07 08:10:50,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,469 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,469 > [DEBUG] 0 :: before allreduce fusion buffer :: 16.141578674316406
2023-01-07 08:10:50,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,471 > [DEBUG] 0 :: before allreduce fusion buffer :: -26.70811653137207
2023-01-07 08:10:50,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,472 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,472 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,472 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.873077392578125
2023-01-07 08:10:50,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,474 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.743808746337891
2023-01-07 08:10:50,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,475 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,475 > [DEBUG] 0 :: before allreduce fusion buffer :: 135.137939453125
2023-01-07 08:10:50,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,476 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,477 > [DEBUG] 0 :: before allreduce fusion buffer :: 28.568496704101562
2023-01-07 08:10:50,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,478 > [DEBUG] 0 :: before allreduce fusion buffer :: 68.47254180908203
2023-01-07 08:10:50,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,480 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,480 > [DEBUG] 0 :: before allreduce fusion buffer :: -70.40672302246094
2023-01-07 08:10:50,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,481 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,481 > [DEBUG] 0 :: before allreduce fusion buffer :: 109.7469482421875
2023-01-07 08:10:50,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,483 > [DEBUG] 0 :: before allreduce fusion buffer :: 41.080379486083984
2023-01-07 08:10:50,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,484 > [DEBUG] 0 :: before allreduce fusion buffer :: -178.38963317871094
2023-01-07 08:10:50,486 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:10:50,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,486 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,491 > [DEBUG] 0 :: before allreduce fusion buffer :: -685.92578125
2023-01-07 08:10:50,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,494 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.97555923461914
2023-01-07 08:10:50,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,496 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.840527534484863
2023-01-07 08:10:50,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,497 > [DEBUG] 0 :: before allreduce fusion buffer :: -50.24539566040039
2023-01-07 08:10:50,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,498 > [DEBUG] 0 :: before allreduce fusion buffer :: 681.1512451171875
2023-01-07 08:10:50,499 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: 2.4733664989471436
2023-01-07 08:10:50,499 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,499 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,499 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,499 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:10:50,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,499 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,500 > [DEBUG] 0 :: before allreduce fusion buffer :: 169.91481018066406
2023-01-07 08:10:50,501 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,501 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,501 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,501 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,501 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 26.03603172302246
2023-01-07 08:10:50,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,502 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,502 > [DEBUG] 0 :: before allreduce fusion buffer :: -106.02413940429688
2023-01-07 08:10:50,504 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 26.03603172302246
2023-01-07 08:10:50,504 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,504 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,504 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,504 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 3.609463691711426
2023-01-07 08:10:50,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,504 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,504 > [DEBUG] 0 :: before allreduce fusion buffer :: -134.56463623046875
2023-01-07 08:10:50,505 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 68.20001220703125
2023-01-07 08:10:50,505 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,505 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,505 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,505 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 3.609463691711426
2023-01-07 08:10:50,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,506 > [DEBUG] 0 :: before allreduce fusion buffer :: 103.78898620605469
2023-01-07 08:10:50,507 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 3.609463691711426
2023-01-07 08:10:50,507 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,507 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,507 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,507 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:10:50,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,507 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,507 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,508 > [DEBUG] 0 :: before allreduce fusion buffer :: 72.46013641357422
2023-01-07 08:10:50,510 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,510 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,510 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,510 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,510 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 16.334102630615234
2023-01-07 08:10:50,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,510 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.8856508731842041
2023-01-07 08:10:50,511 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: -15.96937370300293
2023-01-07 08:10:50,511 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,511 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,511 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,511 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:10:50,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,511 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,512 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.348259925842285
2023-01-07 08:10:50,513 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,514 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,514 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,514 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,514 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 12.989543914794922
2023-01-07 08:10:50,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,514 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.57928466796875
2023-01-07 08:10:50,515 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 11.390154838562012
2023-01-07 08:10:50,515 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,515 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,515 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,515 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 12.989543914794922
2023-01-07 08:10:50,515 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,515 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,515 > [DEBUG] 0 :: before allreduce fusion buffer :: 52.44573211669922
2023-01-07 08:10:50,516 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 266.00006103515625
2023-01-07 08:10:50,516 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,516 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,516 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,517 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 12.989543914794922
2023-01-07 08:10:50,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,517 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.64751434326172
2023-01-07 08:10:50,518 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: -16.002477645874023
2023-01-07 08:10:50,518 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,518 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,518 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,518 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:10:50,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,518 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,519 > [DEBUG] 0 :: before allreduce fusion buffer :: 13.901954650878906
2023-01-07 08:10:50,520 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,520 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,520 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,520 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,520 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 12.989543914794922
2023-01-07 08:10:50,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,521 > [DEBUG] 0 :: before allreduce fusion buffer :: 51.9172477722168
2023-01-07 08:10:50,522 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 12.989543914794922
2023-01-07 08:10:50,522 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,522 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,522 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,522 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:10:50,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,522 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,523 > [DEBUG] 0 :: before allreduce fusion buffer :: -32.7794189453125
2023-01-07 08:10:50,524 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,524 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,525 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,525 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,525 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 16.334102630615234
2023-01-07 08:10:50,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,525 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.392784118652344
2023-01-07 08:10:50,526 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 11.421207427978516
2023-01-07 08:10:50,526 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,526 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,526 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,526 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -14.69498062133789
2023-01-07 08:10:50,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,527 > [DEBUG] 0 :: before allreduce fusion buffer :: 23.561004638671875
2023-01-07 08:10:50,527 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 268.00592041015625
2023-01-07 08:10:50,527 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,528 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,528 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,528 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -14.69498062133789
2023-01-07 08:10:50,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,528 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.827638626098633
2023-01-07 08:10:50,530 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: -14.69498062133789
2023-01-07 08:10:50,530 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,530 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,530 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,530 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 16.334102630615234
2023-01-07 08:10:50,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,530 > [DEBUG] 0 :: before allreduce fusion buffer :: 69.15142059326172
2023-01-07 08:10:50,531 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 66.20001220703125
2023-01-07 08:10:50,531 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,531 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,531 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,531 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 16.334102630615234
2023-01-07 08:10:50,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,532 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6739263534545898
2023-01-07 08:10:50,533 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 16.334102630615234
2023-01-07 08:10:50,533 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,533 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,533 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,533 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 64.0
2023-01-07 08:10:50,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,533 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,534 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,534 > [DEBUG] 0 :: before allreduce fusion buffer :: -62.3853759765625
2023-01-07 08:10:50,536 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 64.0
2023-01-07 08:10:50,536 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,536 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,536 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,536 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 0.20351552963256836
2023-01-07 08:10:50,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,536 > [DEBUG] 0 :: before allreduce fusion buffer :: 33.82243728637695
2023-01-07 08:10:50,537 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 13.217470169067383
2023-01-07 08:10:50,537 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,537 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,537 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,538 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: -4.182164192199707
2023-01-07 08:10:50,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,538 > [DEBUG] 0 :: before allreduce fusion buffer :: 31.05068016052246
2023-01-07 08:10:50,539 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 261.99945068359375
2023-01-07 08:10:50,539 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,539 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,539 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,539 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 0.20351552963256836
2023-01-07 08:10:50,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,540 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.5775146484375
2023-01-07 08:10:50,541 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: -4.182164192199707
2023-01-07 08:10:50,541 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,541 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,541 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,541 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 0.20351552963256836
2023-01-07 08:10:50,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,541 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.571954727172852
2023-01-07 08:10:50,542 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 133.7999725341797
2023-01-07 08:10:50,542 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,542 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,542 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,542 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 0.20351552963256836
2023-01-07 08:10:50,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.6190218925476074
2023-01-07 08:10:50,545 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 0.20351552963256836
2023-01-07 08:10:50,545 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,545 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,545 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,545 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:10:50,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,545 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,545 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.631295204162598
2023-01-07 08:10:50,547 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,547 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,547 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,547 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,547 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: -8.174488067626953
2023-01-07 08:10:50,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,547 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.13447463512420654
2023-01-07 08:10:50,549 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: -8.174488067626953
2023-01-07 08:10:50,549 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,549 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,549 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,549 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:10:50,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,549 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,550 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.66850471496582
2023-01-07 08:10:50,551 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,551 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,551 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,551 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,551 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 25.176406860351562
2023-01-07 08:10:50,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,552 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.395024299621582
2023-01-07 08:10:50,553 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 25.176406860351562
2023-01-07 08:10:50,553 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,553 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,553 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,553 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -1.0197086334228516
2023-01-07 08:10:50,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,553 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.199666976928711
2023-01-07 08:10:50,554 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 530.8001098632812
2023-01-07 08:10:50,554 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,554 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,554 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,555 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -1.0197086334228516
2023-01-07 08:10:50,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,555 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.174535274505615
2023-01-07 08:10:50,556 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1.0197086334228516
2023-01-07 08:10:50,556 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,556 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,556 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,556 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:10:50,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,557 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,557 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,557 > [DEBUG] 0 :: before allreduce fusion buffer :: 67.86759185791016
2023-01-07 08:10:50,559 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,559 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,559 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,559 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,559 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 4.209651947021484
2023-01-07 08:10:50,559 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,559 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,559 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.771318435668945
2023-01-07 08:10:50,561 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 4.209651947021484
2023-01-07 08:10:50,561 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,561 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,561 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,561 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:10:50,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,561 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,562 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.715499877929688
2023-01-07 08:10:50,563 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,563 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,563 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,563 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,563 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 26.955251693725586
2023-01-07 08:10:50,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,563 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,563 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.551369667053223
2023-01-07 08:10:50,565 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 26.955251693725586
2023-01-07 08:10:50,565 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,565 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,565 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,565 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 29.957128524780273
2023-01-07 08:10:50,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,565 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.410007476806641
2023-01-07 08:10:50,566 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 544.400390625
2023-01-07 08:10:50,566 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,566 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,566 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 29.957128524780273
2023-01-07 08:10:50,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,567 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.373047828674316
2023-01-07 08:10:50,568 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 29.957128524780273
2023-01-07 08:10:50,568 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,568 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,568 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:10:50,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,568 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,569 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,569 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,569 > [DEBUG] 0 :: before allreduce fusion buffer :: 28.10478401184082
2023-01-07 08:10:50,570 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,570 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,570 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,570 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,570 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 13.131409645080566
2023-01-07 08:10:50,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,571 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.513845920562744
2023-01-07 08:10:50,572 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 13.131409645080566
2023-01-07 08:10:50,572 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,572 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,572 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,572 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:10:50,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,573 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,573 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,573 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.587561845779419
2023-01-07 08:10:50,574 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,574 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,574 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,574 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,574 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: 13.698368072509766
2023-01-07 08:10:50,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,575 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.695428848266602
2023-01-07 08:10:50,576 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: 13.698368072509766
2023-01-07 08:10:50,576 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,576 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,576 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,576 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:10:50,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,577 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,577 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,577 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,577 > [DEBUG] 0 :: before allreduce fusion buffer :: 9.09829330444336
2023-01-07 08:10:50,578 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,578 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,578 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,578 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,578 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -14.372568130493164
2023-01-07 08:10:50,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,579 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,579 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9242711067199707
2023-01-07 08:10:50,580 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -14.372568130493164
2023-01-07 08:10:50,580 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,580 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,580 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,581 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:10:50,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,581 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,581 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.128205299377441
2023-01-07 08:10:50,582 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,582 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,582 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,583 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,583 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: 15.708341598510742
2023-01-07 08:10:50,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,583 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.211239814758301
2023-01-07 08:10:50,584 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 15.708341598510742
2023-01-07 08:10:50,584 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,584 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,584 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,585 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 128.0
2023-01-07 08:10:50,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,585 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,585 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.937359809875488
2023-01-07 08:10:50,586 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 128.0
2023-01-07 08:10:50,586 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,586 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,587 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,587 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: -8.675992012023926
2023-01-07 08:10:50,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,587 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8751382231712341
2023-01-07 08:10:50,588 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: -8.675992012023926
2023-01-07 08:10:50,588 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,588 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,588 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,589 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 512.0
2023-01-07 08:10:50,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,589 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,589 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4441509246826172
2023-01-07 08:10:50,590 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 512.0
2023-01-07 08:10:50,590 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,590 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,590 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,591 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 23.072154998779297
2023-01-07 08:10:50,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,591 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.329150676727295
2023-01-07 08:10:50,593 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 23.072154998779297
2023-01-07 08:10:50,593 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,593 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,593 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,593 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:10:50,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,593 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,593 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6796613931655884
2023-01-07 08:10:50,595 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,595 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,595 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,595 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,595 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -12.14183235168457
2023-01-07 08:10:50,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,596 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.279336929321289
2023-01-07 08:10:50,597 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -12.14183235168457
2023-01-07 08:10:50,597 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,597 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,597 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,597 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: 20.73180389404297
2023-01-07 08:10:50,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,598 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.826738119125366
2023-01-07 08:10:50,598 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 287.39959716796875
2023-01-07 08:10:50,599 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,599 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,599 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,599 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: 20.73180389404297
2023-01-07 08:10:50,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,599 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4336853623390198
2023-01-07 08:10:50,601 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: 20.73180389404297
2023-01-07 08:10:50,601 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,601 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,601 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,601 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 1.1122112274169922
2023-01-07 08:10:50,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,601 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.803035736083984
2023-01-07 08:10:50,602 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1064.99853515625
2023-01-07 08:10:50,602 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,602 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,602 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,602 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 1.1122112274169922
2023-01-07 08:10:50,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,603 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.4443612098693848
2023-01-07 08:10:50,604 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 1.1122112274169922
2023-01-07 08:10:50,604 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,604 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,604 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,604 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 14.865394592285156
2023-01-07 08:10:50,604 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,604 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,604 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.193993330001831
2023-01-07 08:10:50,605 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1101.202880859375
2023-01-07 08:10:50,605 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,605 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,606 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,606 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: 14.865394592285156
2023-01-07 08:10:50,606 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,606 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9652032256126404
2023-01-07 08:10:50,608 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: 14.865394592285156
2023-01-07 08:10:50,608 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,608 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,608 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,608 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 256.0
2023-01-07 08:10:50,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,608 > [DEBUG] 0 :: add param_num to self.comm_param_size_dict
2023-01-07 08:10:50,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,608 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.370638847351074
2023-01-07 08:10:50,610 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 256.0
2023-01-07 08:10:50,610 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,610 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,610 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,610 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: 32.60767364501953
2023-01-07 08:10:50,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,610 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.9303808212280273
2023-01-07 08:10:50,612 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: 32.60767364501953
2023-01-07 08:10:50,612 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,612 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,612 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,612 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -29.30276107788086
2023-01-07 08:10:50,612 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,612 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.5306763648986816
2023-01-07 08:10:50,613 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 295.80841064453125
2023-01-07 08:10:50,613 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,613 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,613 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,613 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -29.30276107788086
2023-01-07 08:10:50,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,614 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.266432762145996
2023-01-07 08:10:50,615 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -29.30276107788086
2023-01-07 08:10:50,615 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,615 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,615 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,615 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: -59.47146224975586
2023-01-07 08:10:50,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,616 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.8875720500946045
2023-01-07 08:10:50,617 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1103.6044921875
2023-01-07 08:10:50,617 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,617 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,617 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,617 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: -59.47146224975586
2023-01-07 08:10:50,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,617 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.4133458137512207
2023-01-07 08:10:50,619 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: -59.47146224975586
2023-01-07 08:10:50,619 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,619 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,619 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,619 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 29.793678283691406
2023-01-07 08:10:50,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,619 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.396543502807617
2023-01-07 08:10:50,620 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 297.79937744140625
2023-01-07 08:10:50,620 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,620 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,620 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,621 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 29.793678283691406
2023-01-07 08:10:50,621 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,621 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,621 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9581254720687866
2023-01-07 08:10:50,623 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 29.793678283691406
2023-01-07 08:10:50,623 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,623 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,623 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,623 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 6.1346282958984375
2023-01-07 08:10:50,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,623 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.9248456954956055
2023-01-07 08:10:50,624 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 299.79962158203125
2023-01-07 08:10:50,624 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,624 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,624 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,624 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 6.1346282958984375
2023-01-07 08:10:50,625 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,625 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,625 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.7196855545043945
2023-01-07 08:10:50,626 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: 6.1346282958984375
2023-01-07 08:10:50,627 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,627 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,627 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,627 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 31.802913665771484
2023-01-07 08:10:50,627 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,627 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,627 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.25375229120254517
2023-01-07 08:10:50,628 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1090.394775390625
2023-01-07 08:10:50,628 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,628 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,628 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,628 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 31.802913665771484
2023-01-07 08:10:50,628 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,628 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,628 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.250479221343994
2023-01-07 08:10:50,630 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 31.802913665771484
2023-01-07 08:10:50,630 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,630 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,630 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,630 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 29.217912673950195
2023-01-07 08:10:50,631 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,631 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,631 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9152331352233887
2023-01-07 08:10:50,632 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 301.39910888671875
2023-01-07 08:10:50,632 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,632 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,632 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,632 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 29.217912673950195
2023-01-07 08:10:50,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,632 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1407909393310547
2023-01-07 08:10:50,634 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 29.217912673950195
2023-01-07 08:10:50,634 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,634 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,634 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,634 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 40.07816696166992
2023-01-07 08:10:50,634 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,634 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.9620108604431152
2023-01-07 08:10:50,635 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 302.3996887207031
2023-01-07 08:10:50,635 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,635 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,635 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,636 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 40.07816696166992
2023-01-07 08:10:50,636 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,636 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,636 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6068806648254395
2023-01-07 08:10:50,637 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 40.07816696166992
2023-01-07 08:10:50,637 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,637 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,638 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,638 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 35.902854919433594
2023-01-07 08:10:50,638 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,638 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,638 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.8773198127746582
2023-01-07 08:10:50,639 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1100.2001953125
2023-01-07 08:10:50,639 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,639 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,639 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,639 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: 35.902854919433594
2023-01-07 08:10:50,639 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,639 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,639 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.919759750366211
2023-01-07 08:10:50,641 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: 35.902854919433594
2023-01-07 08:10:50,641 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,641 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,641 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,641 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 29.78942108154297
2023-01-07 08:10:50,641 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,641 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,642 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.368124008178711
2023-01-07 08:10:50,642 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 302.60009765625
2023-01-07 08:10:50,643 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,643 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,643 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,643 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: 29.78942108154297
2023-01-07 08:10:50,643 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,643 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,643 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.9393711090087891
2023-01-07 08:10:50,644 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: 29.78942108154297
2023-01-07 08:10:50,645 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,645 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,645 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,645 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3.1448216438293457
2023-01-07 08:10:50,645 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,645 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,645 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5632035732269287
2023-01-07 08:10:50,646 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 303.5995788574219
2023-01-07 08:10:50,646 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,646 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,646 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,646 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -3.1448216438293457
2023-01-07 08:10:50,646 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,646 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,646 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.22809180617332458
2023-01-07 08:10:50,648 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -3.1448216438293457
2023-01-07 08:10:50,648 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,648 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,648 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,648 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -22.040939331054688
2023-01-07 08:10:50,648 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,648 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,649 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7265517115592957
2023-01-07 08:10:50,649 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1100.800537109375
2023-01-07 08:10:50,650 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,650 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,650 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,650 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -22.040939331054688
2023-01-07 08:10:50,650 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,650 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,650 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.457583487033844
2023-01-07 08:10:50,652 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -22.040939331054688
2023-01-07 08:10:50,652 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,652 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,652 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,652 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: 31.254535675048828
2023-01-07 08:10:50,652 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,652 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,652 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.9517765045166016
2023-01-07 08:10:50,653 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 303.5997619628906
2023-01-07 08:10:50,653 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,653 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,653 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,654 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: 31.254535675048828
2023-01-07 08:10:50,654 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,654 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,654 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5035048723220825
2023-01-07 08:10:50,655 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: 31.254535675048828
2023-01-07 08:10:50,655 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,655 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,655 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,656 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -0.5114307403564453
2023-01-07 08:10:50,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,656 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8598759174346924
2023-01-07 08:10:50,657 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 304.19970703125
2023-01-07 08:10:50,657 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,657 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,657 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,657 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -0.5114307403564453
2023-01-07 08:10:50,657 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,657 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,657 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.643860399723053
2023-01-07 08:10:50,659 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -0.5114307403564453
2023-01-07 08:10:50,659 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,659 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,659 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,659 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -17.57099723815918
2023-01-07 08:10:50,659 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,659 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,660 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.8136300444602966
2023-01-07 08:10:50,660 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1103.99462890625
2023-01-07 08:10:50,660 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,660 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,660 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,661 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -17.57099723815918
2023-01-07 08:10:50,661 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,661 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,661 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2137203812599182
2023-01-07 08:10:50,662 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -17.57099723815918
2023-01-07 08:10:50,662 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,662 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,662 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,663 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: 24.63208770751953
2023-01-07 08:10:50,663 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,663 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,663 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.179758906364441
2023-01-07 08:10:50,664 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 598.6013793945312
2023-01-07 08:10:50,664 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,664 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,664 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,664 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: 24.63208770751953
2023-01-07 08:10:50,664 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,664 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,664 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.7615307569503784
2023-01-07 08:10:50,666 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: 24.63208770751953
2023-01-07 08:10:50,666 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,666 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,666 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,666 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 14.661914825439453
2023-01-07 08:10:50,667 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,667 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,667 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.3446640074253082
2023-01-07 08:10:50,668 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 512.4021606445312
2023-01-07 08:10:50,668 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,668 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,668 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,668 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: 14.661914825439453
2023-01-07 08:10:50,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,668 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,668 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.2968508005142212
2023-01-07 08:10:50,670 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: 14.661914825439453
2023-01-07 08:10:50,670 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,670 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,670 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,670 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -39.88478469848633
2023-01-07 08:10:50,670 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,670 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,670 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9991496801376343
2023-01-07 08:10:50,671 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2131.402099609375
2023-01-07 08:10:50,671 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,671 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,671 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,671 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -39.88478469848633
2023-01-07 08:10:50,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,671 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,672 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.38965731859207153
2023-01-07 08:10:50,673 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -39.88478469848633
2023-01-07 08:10:50,673 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,673 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,673 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,673 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: 81.16545867919922
2023-01-07 08:10:50,673 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,674 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6591089367866516
2023-01-07 08:10:50,674 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2142.80029296875
2023-01-07 08:10:50,675 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,675 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,675 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,675 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: 81.16545867919922
2023-01-07 08:10:50,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,675 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.3460790514945984
2023-01-07 08:10:50,677 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: 81.16545867919922
2023-01-07 08:10:50,677 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,677 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,677 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,677 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -5.967223644256592
2023-01-07 08:10:50,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,677 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.23389780521392822
2023-01-07 08:10:50,678 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 602.208984375
2023-01-07 08:10:50,678 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,678 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,678 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,678 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -5.967223644256592
2023-01-07 08:10:50,678 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,678 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,679 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.4848555028438568
2023-01-07 08:10:50,680 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -5.967223644256592
2023-01-07 08:10:50,680 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,680 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,680 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,680 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: 2.017467498779297
2023-01-07 08:10:50,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,681 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,681 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7986274361610413
2023-01-07 08:10:50,682 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 601.7993774414062
2023-01-07 08:10:50,682 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,682 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,682 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,682 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: 2.017467498779297
2023-01-07 08:10:50,682 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,682 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.100154161453247
2023-01-07 08:10:50,684 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: 2.017467498779297
2023-01-07 08:10:50,684 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,684 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,684 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,684 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -20.75659942626953
2023-01-07 08:10:50,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,684 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4877087473869324
2023-01-07 08:10:50,685 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2150.39306640625
2023-01-07 08:10:50,685 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,685 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,685 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,685 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -20.75659942626953
2023-01-07 08:10:50,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,686 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,686 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5024486780166626
2023-01-07 08:10:50,687 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -20.75659942626953
2023-01-07 08:10:50,687 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,687 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,687 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,688 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 53.04460525512695
2023-01-07 08:10:50,688 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,688 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,688 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0836629867553711
2023-01-07 08:10:50,689 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 601.0021362304688
2023-01-07 08:10:50,689 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,689 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,689 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,689 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: 53.04460525512695
2023-01-07 08:10:50,689 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,689 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.04188511148095131
2023-01-07 08:10:50,691 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: 53.04460525512695
2023-01-07 08:10:50,691 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,691 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,691 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,691 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 45.91598129272461
2023-01-07 08:10:50,691 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,691 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,692 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.25862279534339905
2023-01-07 08:10:50,693 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 600.800048828125
2023-01-07 08:10:50,693 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,693 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,693 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,693 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 45.91598129272461
2023-01-07 08:10:50,693 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,693 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,693 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.22185444831848145
2023-01-07 08:10:50,695 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 45.91598129272461
2023-01-07 08:10:50,695 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,695 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,695 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,695 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -23.07699966430664
2023-01-07 08:10:50,695 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,695 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,695 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.3824257850646973
2023-01-07 08:10:50,696 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2449.997314453125
2023-01-07 08:10:50,696 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,696 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,696 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,697 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -23.07699966430664
2023-01-07 08:10:50,697 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,697 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,697 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.1798105239868164
2023-01-07 08:10:50,699 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -23.07699966430664
2023-01-07 08:10:50,699 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:50,699 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:50,699 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:50,700 > [DEBUG] 0 :: 7.173498630523682
2023-01-07 08:10:50,702 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,702 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,702 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,702 > [DEBUG] 0 :: before allreduce fusion buffer :: -595.7972412109375
2023-01-07 08:10:50,703 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,703 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,703 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,703 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,703 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,703 > [DEBUG] 0 :: before allreduce fusion buffer :: -587.8785400390625
2023-01-07 08:10:50,707 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,708 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,708 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,708 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.350074768066406
2023-01-07 08:10:50,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,711 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,711 > [DEBUG] 0 :: before allreduce fusion buffer :: -265.8284912109375
2023-01-07 08:10:50,713 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,713 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,713 > [DEBUG] 0 :: before allreduce fusion buffer :: -33.91616439819336
2023-01-07 08:10:50,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,714 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,715 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.4843475818634033
2023-01-07 08:10:50,716 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,716 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,716 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,716 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.67131805419922
2023-01-07 08:10:50,717 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,717 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,717 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,717 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,718 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,718 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.04202651977539
2023-01-07 08:10:50,719 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,719 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,719 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,720 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.10453796386719
2023-01-07 08:10:50,720 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,720 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,721 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,721 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,721 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,721 > [DEBUG] 0 :: before allreduce fusion buffer :: -25.776500701904297
2023-01-07 08:10:50,722 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,722 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,723 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,723 > [DEBUG] 0 :: before allreduce fusion buffer :: -41.63876724243164
2023-01-07 08:10:50,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,724 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,724 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.15707504749298096
2023-01-07 08:10:50,725 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,726 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,726 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,726 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.60215377807617
2023-01-07 08:10:50,727 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,727 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,727 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,727 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,727 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,727 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.302640914916992
2023-01-07 08:10:50,729 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,729 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,729 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,729 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.42315673828125
2023-01-07 08:10:50,730 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,730 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,730 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,730 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,730 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,730 > [DEBUG] 0 :: before allreduce fusion buffer :: -8.921272277832031
2023-01-07 08:10:50,732 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,732 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,732 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,732 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.338111877441406
2023-01-07 08:10:50,733 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,733 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,733 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,733 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,733 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,733 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.950496792793274
2023-01-07 08:10:50,735 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,735 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,735 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,735 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.6923516988754272
2023-01-07 08:10:50,736 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,736 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,736 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,736 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,736 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,737 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.45376908779144287
2023-01-07 08:10:50,738 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,738 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,738 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,738 > [DEBUG] 0 :: before allreduce fusion buffer :: -35.96888732910156
2023-01-07 08:10:50,740 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,740 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,740 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,740 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,740 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,740 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.628342390060425
2023-01-07 08:10:50,742 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,742 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,742 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,742 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.64360427856445
2023-01-07 08:10:50,743 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,743 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,743 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,743 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,743 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,743 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.487290382385254
2023-01-07 08:10:50,745 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,745 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,745 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,745 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.26673889160156
2023-01-07 08:10:50,746 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,746 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,746 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,746 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,746 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,746 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.786327362060547
2023-01-07 08:10:50,748 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,748 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,748 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,748 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.20629119873047
2023-01-07 08:10:50,749 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,749 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,749 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,749 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,749 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,749 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.389299392700195
2023-01-07 08:10:50,751 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,751 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,751 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,751 > [DEBUG] 0 :: before allreduce fusion buffer :: -37.655242919921875
2023-01-07 08:10:50,752 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,752 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,752 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,752 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,752 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,753 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.641754150390625
2023-01-07 08:10:50,871 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,871 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,871 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,872 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.17766571044922
2023-01-07 08:10:50,873 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,873 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,873 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:50,873 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:50,873 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:50,873 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.866220474243164
2023-01-07 08:10:51,055 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,055 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,055 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,055 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.37640380859375
2023-01-07 08:10:51,056 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,056 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,056 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,056 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,056 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,057 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.2110109329223633
2023-01-07 08:10:51,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,356 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,356 > [DEBUG] 0 :: before allreduce fusion buffer :: -38.79724884033203
2023-01-07 08:10:51,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,357 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,359 > [DEBUG] 0 :: before allreduce fusion buffer :: -741.2275390625
2023-01-07 08:10:51,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,360 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,361 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.839759826660156
2023-01-07 08:10:51,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,362 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,362 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.9754638671875
2023-01-07 08:10:51,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,363 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,364 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.31987762451172
2023-01-07 08:10:51,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,365 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,365 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.284956932067871
2023-01-07 08:10:51,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,367 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,367 > [DEBUG] 0 :: before allreduce fusion buffer :: 114390.2734375
2023-01-07 08:10:51,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,368 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,368 > [DEBUG] 0 :: before allreduce fusion buffer :: 356300.78125
2023-01-07 08:10:51,369 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,370 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 102431.15625
2023-01-07 08:10:51,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,371 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,371 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.60216522216797
2023-01-07 08:10:51,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,373 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,373 > [DEBUG] 0 :: before allreduce fusion buffer :: -39.27935791015625
2023-01-07 08:10:51,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,374 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,374 > [DEBUG] 0 :: before allreduce fusion buffer :: -12.266130447387695
2023-01-07 08:10:51,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,376 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,376 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,376 > [DEBUG] 0 :: before allreduce fusion buffer :: -17192.578125
2023-01-07 08:10:51,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,377 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,378 > [DEBUG] 0 :: before allreduce fusion buffer :: -17208.546875
2023-01-07 08:10:51,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,379 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,379 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.09452819824219
2023-01-07 08:10:51,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,380 > [DEBUG] 0 :: before allreduce fusion buffer :: -48.062992095947266
2023-01-07 08:10:51,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,382 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,382 > [DEBUG] 0 :: before allreduce fusion buffer :: -40.869537353515625
2023-01-07 08:10:51,383 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,383 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,383 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,383 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,383 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,383 > [DEBUG] 0 :: before allreduce fusion buffer :: -1101448.375
2023-01-07 08:10:51,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,385 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,385 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.25110626220703
2023-01-07 08:10:51,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,386 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,386 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.822537899017334
2023-01-07 08:10:51,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,388 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,388 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.816444396972656
2023-01-07 08:10:51,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,389 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,389 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.995571136474609
2023-01-07 08:10:51,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,391 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,391 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,391 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.9638495445251465
2023-01-07 08:10:51,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,392 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.63823127746582
2023-01-07 08:10:51,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,393 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,393 > [DEBUG] 0 :: before allreduce fusion buffer :: -4090968.25
2023-01-07 08:10:51,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,394 > [DEBUG] 0 :: before allreduce fusion buffer :: 44.23458480834961
2023-01-07 08:10:51,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,396 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,396 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.990418434143066
2023-01-07 08:10:51,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,397 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.6816846132278442
2023-01-07 08:10:51,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,398 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,398 > [DEBUG] 0 :: before allreduce fusion buffer :: -68.95802307128906
2023-01-07 08:10:51,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,399 > [DEBUG] 0 :: before allreduce fusion buffer :: 12.67625617980957
2023-01-07 08:10:51,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,400 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,401 > [DEBUG] 0 :: before allreduce fusion buffer :: -41.93144226074219
2023-01-07 08:10:51,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,402 > [DEBUG] 0 :: before allreduce fusion buffer :: -186.03897094726562
2023-01-07 08:10:51,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,403 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,403 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,403 > [DEBUG] 0 :: before allreduce fusion buffer :: -234.29173278808594
2023-01-07 08:10:51,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,404 > [DEBUG] 0 :: before allreduce fusion buffer :: -599.84375
2023-01-07 08:10:51,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,405 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,405 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.67538833618164
2023-01-07 08:10:51,406 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,406 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 267.0578918457031
2023-01-07 08:10:51,408 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,408 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,408 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,408 > [DEBUG] 0 :: before allreduce fusion buffer :: 407.1233825683594
2023-01-07 08:10:51,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,409 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,409 > [DEBUG] 0 :: before allreduce fusion buffer :: -346.92791748046875
2023-01-07 08:10:51,411 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,411 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,411 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,411 > [DEBUG] 0 :: before allreduce fusion buffer :: -806.444580078125
2023-01-07 08:10:51,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,412 > [DEBUG] 0 :: before allreduce fusion buffer :: -107.25634765625
2023-01-07 08:10:51,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,413 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 398.2580261230469
2023-01-07 08:10:51,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,415 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,415 > [DEBUG] 0 :: before allreduce fusion buffer :: 4543.97998046875
2023-01-07 08:10:51,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,416 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,416 > [DEBUG] 0 :: before allreduce fusion buffer :: -16482.26953125
2023-01-07 08:10:51,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,417 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,417 > [DEBUG] 0 :: before allreduce fusion buffer :: -10361.3515625
2023-01-07 08:10:51,419 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,419 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,419 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,419 > [DEBUG] 0 :: before allreduce fusion buffer :: -16837.265625
2023-01-07 08:10:51,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,420 > [DEBUG] 0 :: before allreduce fusion buffer :: -3187.51513671875
2023-01-07 08:10:51,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,421 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,421 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,422 > [DEBUG] 0 :: before allreduce fusion buffer :: -2127.82861328125
2023-01-07 08:10:51,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,423 > [DEBUG] 0 :: before allreduce fusion buffer :: -29244.5703125
2023-01-07 08:10:51,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,424 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,424 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,424 > [DEBUG] 0 :: before allreduce fusion buffer :: 49302.6015625
2023-01-07 08:10:51,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,425 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,425 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,425 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,425 > [DEBUG] 0 :: before allreduce fusion buffer :: -279171.875
2023-01-07 08:10:51,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,427 > [DEBUG] 0 :: before allreduce fusion buffer :: 583175.375
2023-01-07 08:10:51,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,428 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,429 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,429 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,429 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,429 > [DEBUG] 0 :: before allreduce fusion buffer :: -166242631548928.0
2023-01-07 08:10:51,430 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,430 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,431 > [DEBUG] 0 :: before allreduce fusion buffer :: -46214.515625
2023-01-07 08:10:51,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,432 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,432 > [DEBUG] 0 :: before allreduce fusion buffer :: -137606.125
2023-01-07 08:10:51,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,433 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,433 > [DEBUG] 0 :: before allreduce fusion buffer :: -316264.625
2023-01-07 08:10:51,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,434 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,434 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,434 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,434 > [DEBUG] 0 :: before allreduce fusion buffer :: -721569.8125
2023-01-07 08:10:51,436 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,436 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,436 > [DEBUG] 0 :: before allreduce fusion buffer :: -386583.3125
2023-01-07 08:10:51,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,437 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,437 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,437 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,437 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,438 > [DEBUG] 0 :: before allreduce fusion buffer :: -751059790200832.0
2023-01-07 08:10:51,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,439 > [DEBUG] 0 :: before allreduce fusion buffer :: -93905.3984375
2023-01-07 08:10:51,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,440 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,441 > [DEBUG] 0 :: before allreduce fusion buffer :: -3401396397277184.0
2023-01-07 08:10:51,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,442 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,442 > [DEBUG] 0 :: before allreduce fusion buffer :: -132153.5
2023-01-07 08:10:51,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,443 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,443 > [DEBUG] 0 :: before allreduce fusion buffer :: -181958.25
2023-01-07 08:10:51,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,445 > [DEBUG] 0 :: before allreduce fusion buffer :: -72671.484375
2023-01-07 08:10:51,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,446 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,446 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,446 > [DEBUG] 0 :: before allreduce fusion buffer :: -1307929.5
2023-01-07 08:10:51,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,448 > [DEBUG] 0 :: before allreduce fusion buffer :: -3520.55810546875
2023-01-07 08:10:51,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,449 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,449 > [DEBUG] 0 :: before allreduce fusion buffer :: -29884.8125
2023-01-07 08:10:51,450 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,451 > [DEBUG] 0 :: before allreduce fusion buffer :: -325218.84375
2023-01-07 08:10:51,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,452 > [DEBUG] 0 :: before allreduce fusion buffer :: 43456808.0
2023-01-07 08:10:51,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,453 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,454 > [DEBUG] 0 :: before allreduce fusion buffer :: 79720272.0
2023-01-07 08:10:51,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,455 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,455 > [DEBUG] 0 :: before allreduce fusion buffer :: -42885912.0
2023-01-07 08:10:51,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,457 > [DEBUG] 0 :: before allreduce fusion buffer :: -11368675.0
2023-01-07 08:10:51,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,458 > [DEBUG] 0 :: before allreduce fusion buffer :: -12857514.0
2023-01-07 08:10:51,462 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:10:51,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,463 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,467 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,467 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,472 > [DEBUG] 0 :: before allreduce fusion buffer :: 371819982880768.0
2023-01-07 08:10:51,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,476 > [DEBUG] 0 :: before allreduce fusion buffer :: -269944180703232.0
2023-01-07 08:10:51,476 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,477 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.044600017446502e+16
2023-01-07 08:10:51,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,478 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,478 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,478 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.608902136425349e+17
2023-01-07 08:10:51,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,479 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.217804272850698e+17
2023-01-07 08:10:51,480 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -54.520118713378906
2023-01-07 08:10:51,480 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,480 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,480 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,480 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 67.79998779296875
2023-01-07 08:10:51,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,481 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,481 > [DEBUG] 0 :: before allreduce fusion buffer :: -19991260.0
2023-01-07 08:10:51,482 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 67.79998779296875
2023-01-07 08:10:51,482 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,482 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,482 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,482 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 25.83608627319336
2023-01-07 08:10:51,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,483 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,483 > [DEBUG] 0 :: before allreduce fusion buffer :: 16241928.0
2023-01-07 08:10:51,484 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 25.83608627319336
2023-01-07 08:10:51,484 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,485 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,485 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,485 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 109.00654602050781
2023-01-07 08:10:51,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,485 > [DEBUG] 0 :: before allreduce fusion buffer :: -24954398.0
2023-01-07 08:10:51,486 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 68.20001220703125
2023-01-07 08:10:51,486 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,486 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,486 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,486 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 109.00654602050781
2023-01-07 08:10:51,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,486 > [DEBUG] 0 :: before allreduce fusion buffer :: -13170592.0
2023-01-07 08:10:51,488 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 109.00654602050781
2023-01-07 08:10:51,488 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,488 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,488 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,488 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 67.79949951171875
2023-01-07 08:10:51,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,488 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,488 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,489 > [DEBUG] 0 :: before allreduce fusion buffer :: 7.61849882851758e+20
2023-01-07 08:10:51,490 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 67.79949951171875
2023-01-07 08:10:51,490 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,490 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,490 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,490 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 223.13758850097656
2023-01-07 08:10:51,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,491 > [DEBUG] 0 :: before allreduce fusion buffer :: 75377.9765625
2023-01-07 08:10:51,492 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 142.03079223632812
2023-01-07 08:10:51,492 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,492 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,492 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,492 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 299.7996826171875
2023-01-07 08:10:51,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,492 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,492 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.4116152256020615e+22
2023-01-07 08:10:51,494 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 299.7996826171875
2023-01-07 08:10:51,494 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,494 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,494 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,494 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 145.75357055664062
2023-01-07 08:10:51,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,494 > [DEBUG] 0 :: before allreduce fusion buffer :: -4294284.5
2023-01-07 08:10:51,495 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 11.390154838562012
2023-01-07 08:10:51,495 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,495 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,495 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,495 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 145.75357055664062
2023-01-07 08:10:51,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,496 > [DEBUG] 0 :: before allreduce fusion buffer :: 1066679.0
2023-01-07 08:10:51,497 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 266.0744934082031
2023-01-07 08:10:51,497 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,497 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,497 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,497 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 145.75357055664062
2023-01-07 08:10:51,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,497 > [DEBUG] 0 :: before allreduce fusion buffer :: -1696526.0
2023-01-07 08:10:51,498 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 204.80160522460938
2023-01-07 08:10:51,498 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,498 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,498 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,499 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 67.80000305175781
2023-01-07 08:10:51,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,499 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,499 > [DEBUG] 0 :: before allreduce fusion buffer :: -2016087.375
2023-01-07 08:10:51,500 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 67.80000305175781
2023-01-07 08:10:51,500 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,500 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,500 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,501 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 145.75357055664062
2023-01-07 08:10:51,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,501 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,501 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,501 > [DEBUG] 0 :: before allreduce fusion buffer :: -1272672.5
2023-01-07 08:10:51,502 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 145.75357055664062
2023-01-07 08:10:51,502 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,502 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,502 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,503 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 67.80000305175781
2023-01-07 08:10:51,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,503 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,503 > [DEBUG] 0 :: before allreduce fusion buffer :: -73774.0625
2023-01-07 08:10:51,505 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 67.80000305175781
2023-01-07 08:10:51,505 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,505 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,505 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,505 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 223.13758850097656
2023-01-07 08:10:51,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,505 > [DEBUG] 0 :: before allreduce fusion buffer :: -560266.75
2023-01-07 08:10:51,506 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 108.8009033203125
2023-01-07 08:10:51,506 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,506 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,506 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,506 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -4.50378942489624
2023-01-07 08:10:51,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,507 > [DEBUG] 0 :: before allreduce fusion buffer :: 255583.9375
2023-01-07 08:10:51,508 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 268.452392578125
2023-01-07 08:10:51,508 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,508 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,508 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,508 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: -4.50378942489624
2023-01-07 08:10:51,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,508 > [DEBUG] 0 :: before allreduce fusion buffer :: -495924.46875
2023-01-07 08:10:51,510 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: -4.50378942489624
2023-01-07 08:10:51,510 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,510 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,510 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,510 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 223.13758850097656
2023-01-07 08:10:51,510 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,510 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,510 > [DEBUG] 0 :: before allreduce fusion buffer :: -220302.53125
2023-01-07 08:10:51,511 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 66.34883880615234
2023-01-07 08:10:51,511 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,511 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,511 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,511 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 223.13758850097656
2023-01-07 08:10:51,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,512 > [DEBUG] 0 :: before allreduce fusion buffer :: -310111.03125
2023-01-07 08:10:51,513 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 223.13758850097656
2023-01-07 08:10:51,513 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,513 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,513 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,513 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 66.79997253417969
2023-01-07 08:10:51,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,513 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,514 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,514 > [DEBUG] 0 :: before allreduce fusion buffer :: -625302.125
2023-01-07 08:10:51,516 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 66.79997253417969
2023-01-07 08:10:51,516 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,516 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,516 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,516 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 524.4674072265625
2023-01-07 08:10:51,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,516 > [DEBUG] 0 :: before allreduce fusion buffer :: -135227.96875
2023-01-07 08:10:51,517 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 90.57467651367188
2023-01-07 08:10:51,517 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,517 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,517 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,517 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 399.4329833984375
2023-01-07 08:10:51,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,518 > [DEBUG] 0 :: before allreduce fusion buffer :: -331274.1875
2023-01-07 08:10:51,519 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 260.8096618652344
2023-01-07 08:10:51,519 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,519 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,519 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,519 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 524.4674072265625
2023-01-07 08:10:51,519 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,519 > [DEBUG] 0 :: before allreduce fusion buffer :: -77560.7734375
2023-01-07 08:10:51,520 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 399.4329833984375
2023-01-07 08:10:51,521 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,521 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,521 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,521 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 524.4674072265625
2023-01-07 08:10:51,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,521 > [DEBUG] 0 :: before allreduce fusion buffer :: -50696.04296875
2023-01-07 08:10:51,522 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 137.96746826171875
2023-01-07 08:10:51,522 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,522 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,522 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,522 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 524.4674072265625
2023-01-07 08:10:51,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,522 > [DEBUG] 0 :: before allreduce fusion buffer :: -96280.828125
2023-01-07 08:10:51,524 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 524.4674072265625
2023-01-07 08:10:51,524 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,524 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,524 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,524 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 139.59999084472656
2023-01-07 08:10:51,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,524 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,525 > [DEBUG] 0 :: before allreduce fusion buffer :: -19731.837890625
2023-01-07 08:10:51,526 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 139.59999084472656
2023-01-07 08:10:51,526 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,526 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,526 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,526 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 642.934326171875
2023-01-07 08:10:51,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,526 > [DEBUG] 0 :: before allreduce fusion buffer :: -1128.4794921875
2023-01-07 08:10:51,528 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 642.934326171875
2023-01-07 08:10:51,528 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,528 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,528 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,528 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 572.6002197265625
2023-01-07 08:10:51,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,528 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,528 > [DEBUG] 0 :: before allreduce fusion buffer :: 1840.056640625
2023-01-07 08:10:51,530 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 572.6002197265625
2023-01-07 08:10:51,530 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,530 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,530 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,530 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -27.13916015625
2023-01-07 08:10:51,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,530 > [DEBUG] 0 :: before allreduce fusion buffer :: -7923.5693359375
2023-01-07 08:10:51,531 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -27.13916015625
2023-01-07 08:10:51,531 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,531 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,531 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,532 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 75.69377136230469
2023-01-07 08:10:51,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,532 > [DEBUG] 0 :: before allreduce fusion buffer :: 6220.01953125
2023-01-07 08:10:51,533 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 533.032470703125
2023-01-07 08:10:51,533 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,533 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,533 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,533 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: 75.69377136230469
2023-01-07 08:10:51,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,533 > [DEBUG] 0 :: before allreduce fusion buffer :: -3278.41357421875
2023-01-07 08:10:51,535 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: 75.69377136230469
2023-01-07 08:10:51,535 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,535 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,535 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,535 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 145.00022888183594
2023-01-07 08:10:51,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,535 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,535 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,535 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,535 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.4228515625
2023-01-07 08:10:51,537 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 145.00022888183594
2023-01-07 08:10:51,537 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,537 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,537 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,537 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 179.61817932128906
2023-01-07 08:10:51,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,537 > [DEBUG] 0 :: before allreduce fusion buffer :: -12817.7509765625
2023-01-07 08:10:51,539 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 179.61817932128906
2023-01-07 08:10:51,539 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,539 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,539 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,539 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 125.60037231445312
2023-01-07 08:10:51,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,539 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,539 > [DEBUG] 0 :: before allreduce fusion buffer :: 621.9716796875
2023-01-07 08:10:51,541 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 125.60037231445312
2023-01-07 08:10:51,541 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,541 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,541 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,541 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 182.20472717285156
2023-01-07 08:10:51,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,541 > [DEBUG] 0 :: before allreduce fusion buffer :: 740.5662841796875
2023-01-07 08:10:51,542 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 182.20472717285156
2023-01-07 08:10:51,542 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,543 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,543 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,543 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 161.16221618652344
2023-01-07 08:10:51,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 3585.25048828125
2023-01-07 08:10:51,544 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 545.7401123046875
2023-01-07 08:10:51,544 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,544 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,544 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,544 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 161.16221618652344
2023-01-07 08:10:51,544 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,544 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,544 > [DEBUG] 0 :: before allreduce fusion buffer :: 2360.290771484375
2023-01-07 08:10:51,546 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 161.16221618652344
2023-01-07 08:10:51,546 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,546 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,546 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,546 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 139.79998779296875
2023-01-07 08:10:51,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,546 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 2751.328857421875
2023-01-07 08:10:51,548 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 139.79998779296875
2023-01-07 08:10:51,548 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,548 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,548 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,548 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: 51.241024017333984
2023-01-07 08:10:51,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 1105.7020263671875
2023-01-07 08:10:51,550 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: 51.241024017333984
2023-01-07 08:10:51,550 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,550 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,550 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,550 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 139.79998779296875
2023-01-07 08:10:51,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,550 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,550 > [DEBUG] 0 :: before allreduce fusion buffer :: 68.31817626953125
2023-01-07 08:10:51,552 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 139.79998779296875
2023-01-07 08:10:51,552 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,552 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,552 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,552 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: 190.45086669921875
2023-01-07 08:10:51,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,552 > [DEBUG] 0 :: before allreduce fusion buffer :: 183.41708374023438
2023-01-07 08:10:51,553 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: 190.45086669921875
2023-01-07 08:10:51,553 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,554 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,554 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,554 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 572.7999877929688
2023-01-07 08:10:51,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,554 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,554 > [DEBUG] 0 :: before allreduce fusion buffer :: 29.703643798828125
2023-01-07 08:10:51,555 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 572.7999877929688
2023-01-07 08:10:51,555 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,555 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,556 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,556 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -65.04515075683594
2023-01-07 08:10:51,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,556 > [DEBUG] 0 :: before allreduce fusion buffer :: -265.879638671875
2023-01-07 08:10:51,557 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -65.04515075683594
2023-01-07 08:10:51,557 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,557 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,557 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,558 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 139.79998779296875
2023-01-07 08:10:51,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,558 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,558 > [DEBUG] 0 :: before allreduce fusion buffer :: -176.41073608398438
2023-01-07 08:10:51,559 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 139.79998779296875
2023-01-07 08:10:51,559 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,559 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,559 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,560 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: 17.907245635986328
2023-01-07 08:10:51,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,560 > [DEBUG] 0 :: before allreduce fusion buffer :: -95.04662322998047
2023-01-07 08:10:51,562 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 17.907245635986328
2023-01-07 08:10:51,562 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,562 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,562 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,562 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 142.79977416992188
2023-01-07 08:10:51,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,562 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,562 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.494894027709961
2023-01-07 08:10:51,564 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 142.79977416992188
2023-01-07 08:10:51,564 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,564 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,564 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,564 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 132.98699951171875
2023-01-07 08:10:51,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,564 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,564 > [DEBUG] 0 :: before allreduce fusion buffer :: 13.629737854003906
2023-01-07 08:10:51,565 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 132.98699951171875
2023-01-07 08:10:51,565 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,565 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,566 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 507.7975158691406
2023-01-07 08:10:51,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,566 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,566 > [DEBUG] 0 :: before allreduce fusion buffer :: 82.33700561523438
2023-01-07 08:10:51,567 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 507.7975158691406
2023-01-07 08:10:51,567 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,567 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,567 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 7.941385269165039
2023-01-07 08:10:51,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 41.13780212402344
2023-01-07 08:10:51,569 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 7.941385269165039
2023-01-07 08:10:51,569 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,569 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,569 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,570 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 282.9999694824219
2023-01-07 08:10:51,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,570 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,570 > [DEBUG] 0 :: before allreduce fusion buffer :: 11.438969612121582
2023-01-07 08:10:51,571 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 282.9999694824219
2023-01-07 08:10:51,571 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,571 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,571 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,572 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -24182.564453125
2023-01-07 08:10:51,572 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,572 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,572 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.393631458282471
2023-01-07 08:10:51,573 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -24182.564453125
2023-01-07 08:10:51,573 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,573 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,573 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,574 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -57.53635025024414
2023-01-07 08:10:51,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,574 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,574 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,575 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 285.46484375
2023-01-07 08:10:51,575 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,575 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,575 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,575 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -57.53635025024414
2023-01-07 08:10:51,575 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,575 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,575 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,578 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -57.53635025024414
2023-01-07 08:10:51,578 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,578 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,578 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,578 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -781.09423828125
2023-01-07 08:10:51,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,578 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,579 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1054.1341552734375
2023-01-07 08:10:51,579 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,579 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,579 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,579 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -781.09423828125
2023-01-07 08:10:51,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,580 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,581 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -781.09423828125
2023-01-07 08:10:51,581 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,581 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,581 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,581 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1074.197998046875
2023-01-07 08:10:51,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,582 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,582 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1090.33837890625
2023-01-07 08:10:51,582 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,582 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,583 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,583 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1074.197998046875
2023-01-07 08:10:51,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,583 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,584 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1074.197998046875
2023-01-07 08:10:51,584 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,584 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,585 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,585 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 284.1999816894531
2023-01-07 08:10:51,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,585 > [DEBUG] 0 :: check shard size is equal to param_size
2023-01-07 08:10:51,585 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,585 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,586 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 284.1999816894531
2023-01-07 08:10:51,586 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,586 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,587 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,587 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -1637.793701171875
2023-01-07 08:10:51,587 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,587 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,588 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -1637.793701171875
2023-01-07 08:10:51,588 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,588 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,588 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,589 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -198.943115234375
2023-01-07 08:10:51,589 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,589 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,589 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,590 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 293.8736572265625
2023-01-07 08:10:51,590 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,590 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,590 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,590 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -198.943115234375
2023-01-07 08:10:51,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,590 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,592 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -198.943115234375
2023-01-07 08:10:51,592 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,592 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,592 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,592 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 453.51177978515625
2023-01-07 08:10:51,592 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,592 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,592 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,593 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1092.740234375
2023-01-07 08:10:51,593 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,593 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,593 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,593 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 453.51177978515625
2023-01-07 08:10:51,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,594 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,595 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 453.51177978515625
2023-01-07 08:10:51,595 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,595 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,595 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,595 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 369.05975341796875
2023-01-07 08:10:51,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,596 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,596 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 295.8645935058594
2023-01-07 08:10:51,597 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,597 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,597 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,597 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 369.05975341796875
2023-01-07 08:10:51,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,597 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,598 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 369.05975341796875
2023-01-07 08:10:51,598 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,598 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,599 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,599 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 60.665367126464844
2023-01-07 08:10:51,599 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,599 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,599 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,600 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 297.8648681640625
2023-01-07 08:10:51,600 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,600 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,600 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,600 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 60.665367126464844
2023-01-07 08:10:51,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,600 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,602 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: 60.665367126464844
2023-01-07 08:10:51,602 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,602 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,602 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,602 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -120.3961181640625
2023-01-07 08:10:51,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,602 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,603 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1079.5303955078125
2023-01-07 08:10:51,603 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,603 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,603 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,603 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -120.3961181640625
2023-01-07 08:10:51,603 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,603 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,604 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,605 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: -120.3961181640625
2023-01-07 08:10:51,605 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,605 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,605 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,605 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 217.4132537841797
2023-01-07 08:10:51,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,606 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,606 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 299.46435546875
2023-01-07 08:10:51,607 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,607 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,607 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,607 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: 217.4132537841797
2023-01-07 08:10:51,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,607 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,607 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,608 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: 217.4132537841797
2023-01-07 08:10:51,608 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,609 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,609 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,609 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 132.26031494140625
2023-01-07 08:10:51,609 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,609 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,609 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,610 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 300.4649658203125
2023-01-07 08:10:51,610 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,610 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,610 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,610 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 132.26031494140625
2023-01-07 08:10:51,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,610 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,612 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 132.26031494140625
2023-01-07 08:10:51,612 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,612 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,612 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,612 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -187.8086700439453
2023-01-07 08:10:51,612 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,612 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,613 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1107.64404296875
2023-01-07 08:10:51,613 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,613 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,613 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,613 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -187.8086700439453
2023-01-07 08:10:51,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,614 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,615 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -187.8086700439453
2023-01-07 08:10:51,615 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,615 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,615 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,615 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -591.25048828125
2023-01-07 08:10:51,615 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,615 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,616 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,617 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 300.6653137207031
2023-01-07 08:10:51,617 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,617 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,617 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,617 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -591.25048828125
2023-01-07 08:10:51,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,617 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,618 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -591.25048828125
2023-01-07 08:10:51,618 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,619 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,619 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,619 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -2921.3408203125
2023-01-07 08:10:51,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,619 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,620 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 298.6894836425781
2023-01-07 08:10:51,620 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,620 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,620 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,620 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -2921.3408203125
2023-01-07 08:10:51,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,620 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,622 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -2921.3408203125
2023-01-07 08:10:51,622 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,622 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,622 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,622 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -20961.09375
2023-01-07 08:10:51,622 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,622 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,622 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,623 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1090.23388671875
2023-01-07 08:10:51,623 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,623 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,623 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,623 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -20961.09375
2023-01-07 08:10:51,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,624 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,624 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,625 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -20961.09375
2023-01-07 08:10:51,625 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,625 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,625 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,625 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -8860.009765625
2023-01-07 08:10:51,625 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,625 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,626 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,627 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 301.6650390625
2023-01-07 08:10:51,627 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,627 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,627 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,627 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -8860.009765625
2023-01-07 08:10:51,627 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,627 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,627 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,628 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -8860.009765625
2023-01-07 08:10:51,629 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,629 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,629 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,629 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23603.53515625
2023-01-07 08:10:51,629 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,629 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,629 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,630 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 302.2651062011719
2023-01-07 08:10:51,630 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,630 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,630 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,630 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -23603.53515625
2023-01-07 08:10:51,630 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,630 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,630 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,632 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -23603.53515625
2023-01-07 08:10:51,632 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,632 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,632 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,632 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50290.2890625
2023-01-07 08:10:51,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,632 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,633 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1093.4283447265625
2023-01-07 08:10:51,633 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,633 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,633 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,633 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -50290.2890625
2023-01-07 08:10:51,634 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,634 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,635 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -50290.2890625
2023-01-07 08:10:51,635 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,635 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,635 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,636 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -42300.2421875
2023-01-07 08:10:51,636 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,636 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,636 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,637 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 598.7507934570312
2023-01-07 08:10:51,637 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,637 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,637 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,637 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -42300.2421875
2023-01-07 08:10:51,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,637 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,637 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,639 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -42300.2421875
2023-01-07 08:10:51,639 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,639 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,639 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,639 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -342.00634765625
2023-01-07 08:10:51,639 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,639 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,639 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,640 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 503.17486572265625
2023-01-07 08:10:51,640 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,640 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,640 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,640 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -342.00634765625
2023-01-07 08:10:51,641 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,641 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,641 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,642 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -342.00634765625
2023-01-07 08:10:51,642 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,642 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,642 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,642 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -123174.40625
2023-01-07 08:10:51,642 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,643 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,643 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,644 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2143.1767578125
2023-01-07 08:10:51,644 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,644 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,644 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,644 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -123174.40625
2023-01-07 08:10:51,644 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,644 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,644 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,645 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -123174.40625
2023-01-07 08:10:51,645 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,645 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,645 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,646 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26590.96484375
2023-01-07 08:10:51,646 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,646 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,646 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,647 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2149.49755859375
2023-01-07 08:10:51,647 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,647 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,647 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,647 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -26590.96484375
2023-01-07 08:10:51,647 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,647 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,647 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,649 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -26590.96484375
2023-01-07 08:10:51,649 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,649 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,649 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,649 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -187.0867919921875
2023-01-07 08:10:51,649 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,649 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,649 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,650 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 601.0185546875
2023-01-07 08:10:51,650 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,650 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,650 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,650 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -187.0867919921875
2023-01-07 08:10:51,650 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,650 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,651 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,652 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -187.0867919921875
2023-01-07 08:10:51,652 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,652 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,652 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,652 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -33949.125
2023-01-07 08:10:51,652 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,652 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,653 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,653 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 600.7584228515625
2023-01-07 08:10:51,653 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,654 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,654 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,654 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -33949.125
2023-01-07 08:10:51,654 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,654 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,654 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,655 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -33949.125
2023-01-07 08:10:51,655 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,655 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,656 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,656 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102736.203125
2023-01-07 08:10:51,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,656 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,657 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2157.388671875
2023-01-07 08:10:51,657 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,657 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,657 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,657 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -102736.203125
2023-01-07 08:10:51,657 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,657 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,657 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,659 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -102736.203125
2023-01-07 08:10:51,659 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,659 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,659 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,659 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -12217.1162109375
2023-01-07 08:10:51,659 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,659 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,659 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,660 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 598.7711181640625
2023-01-07 08:10:51,660 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,660 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,660 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,660 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -12217.1162109375
2023-01-07 08:10:51,660 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,661 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,661 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,662 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -12217.1162109375
2023-01-07 08:10:51,662 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,662 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,662 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,662 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 32.964447021484375
2023-01-07 08:10:51,662 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,662 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,663 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,664 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 609.6134033203125
2023-01-07 08:10:51,664 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,664 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,664 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,664 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: 32.964447021484375
2023-01-07 08:10:51,664 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,664 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,664 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,665 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: 32.964447021484375
2023-01-07 08:10:51,666 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,666 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,666 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,666 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -148918.703125
2023-01-07 08:10:51,666 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,666 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,666 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,667 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2469.27197265625
2023-01-07 08:10:51,667 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,667 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,667 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,667 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -148918.703125
2023-01-07 08:10:51,667 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,667 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,667 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:51,669 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -148918.703125
2023-01-07 08:10:51,669 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:51,669 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:51,669 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:51,670 > [DEBUG] 0 :: 21.567890167236328
2023-01-07 08:10:51,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,672 > [DEBUG] 0 :: before allreduce fusion buffer :: -29676183486464.0
2023-01-07 08:10:51,673 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,673 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,674 > [DEBUG] 0 :: before allreduce fusion buffer :: -377548.03125
2023-01-07 08:10:51,676 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,676 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,676 > [DEBUG] 0 :: before allreduce fusion buffer :: 15893714.0
2023-01-07 08:10:51,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,678 > [DEBUG] 0 :: before allreduce fusion buffer :: -789577.5625
2023-01-07 08:10:51,679 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,679 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,680 > [DEBUG] 0 :: before allreduce fusion buffer :: -106293603860480.0
2023-01-07 08:10:51,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,681 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,681 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,681 > [DEBUG] 0 :: before allreduce fusion buffer :: -212587241275392.0
2023-01-07 08:10:51,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,683 > [DEBUG] 0 :: before allreduce fusion buffer :: -425174482550784.0
2023-01-07 08:10:51,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,685 > [DEBUG] 0 :: before allreduce fusion buffer :: -2124746.0
2023-01-07 08:10:51,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,686 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,686 > [DEBUG] 0 :: before allreduce fusion buffer :: 113344864.0
2023-01-07 08:10:51,687 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,687 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,687 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,687 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,688 > [DEBUG] 0 :: before allreduce fusion buffer :: -850348965101568.0
2023-01-07 08:10:51,689 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,689 > [DEBUG] 0 :: before allreduce fusion buffer :: -1700698198638592.0
2023-01-07 08:10:51,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,691 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,691 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,691 > [DEBUG] 0 :: before allreduce fusion buffer :: -3401396397277184.0
2023-01-07 08:10:51,692 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,692 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,693 > [DEBUG] 0 :: before allreduce fusion buffer :: -6802793331425280.0
2023-01-07 08:10:51,693 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,693 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,694 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,694 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,694 > [DEBUG] 0 :: before allreduce fusion buffer :: -9441706.0
2023-01-07 08:10:51,695 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,695 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,696 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.3605585589108736e+16
2023-01-07 08:10:51,697 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,697 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,697 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,697 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,697 > [DEBUG] 0 :: before allreduce fusion buffer :: -16914718.0
2023-01-07 08:10:51,698 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,699 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,699 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2056728040374272e+16
2023-01-07 08:10:51,700 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,700 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,700 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,700 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,700 > [DEBUG] 0 :: before allreduce fusion buffer :: -416693.5625
2023-01-07 08:10:51,702 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,702 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,702 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.5154435621650432e+16
2023-01-07 08:10:51,703 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,703 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,703 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,703 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,703 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.5154560175702016e+16
2023-01-07 08:10:51,705 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,705 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,705 > [DEBUG] 0 :: before allreduce fusion buffer :: -316055.25
2023-01-07 08:10:51,706 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,706 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,706 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,706 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,706 > [DEBUG] 0 :: before allreduce fusion buffer :: 526253.5
2023-01-07 08:10:51,708 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,708 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,708 > [DEBUG] 0 :: before allreduce fusion buffer :: 26184038.0
2023-01-07 08:10:51,709 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,709 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,709 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,710 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,710 > [DEBUG] 0 :: before allreduce fusion buffer :: 39412788.0
2023-01-07 08:10:51,711 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,711 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,711 > [DEBUG] 0 :: before allreduce fusion buffer :: 59795324.0
2023-01-07 08:10:51,712 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,712 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,713 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,713 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,713 > [DEBUG] 0 :: before allreduce fusion buffer :: 105491728.0
2023-01-07 08:10:51,714 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,714 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,714 > [DEBUG] 0 :: before allreduce fusion buffer :: 245387712.0
2023-01-07 08:10:51,715 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,715 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,716 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,716 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,716 > [DEBUG] 0 :: before allreduce fusion buffer :: 145538272.0
2023-01-07 08:10:51,717 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,717 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,718 > [DEBUG] 0 :: before allreduce fusion buffer :: 861737088.0
2023-01-07 08:10:51,718 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,718 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,719 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,719 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,719 > [DEBUG] 0 :: before allreduce fusion buffer :: 34814152.0
2023-01-07 08:10:51,720 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,720 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,721 > [DEBUG] 0 :: before allreduce fusion buffer :: 1606317056.0
2023-01-07 08:10:51,721 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,721 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,722 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,722 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,722 > [DEBUG] 0 :: before allreduce fusion buffer :: 1905825536.0
2023-01-07 08:10:51,723 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,723 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,724 > [DEBUG] 0 :: before allreduce fusion buffer :: 1956851328.0
2023-01-07 08:10:51,724 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,724 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,725 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,725 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,725 > [DEBUG] 0 :: before allreduce fusion buffer :: 701533888.0
2023-01-07 08:10:51,726 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,726 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,727 > [DEBUG] 0 :: before allreduce fusion buffer :: 5164951040.0
2023-01-07 08:10:51,727 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,727 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,728 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,728 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,728 > [DEBUG] 0 :: before allreduce fusion buffer :: 11662480384.0
2023-01-07 08:10:51,729 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,729 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,730 > [DEBUG] 0 :: before allreduce fusion buffer :: 21132656640.0
2023-01-07 08:10:51,730 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,731 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,731 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,731 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,731 > [DEBUG] 0 :: before allreduce fusion buffer :: 43047510016.0
2023-01-07 08:10:51,732 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,732 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,733 > [DEBUG] 0 :: before allreduce fusion buffer :: 84411711488.0
2023-01-07 08:10:51,733 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,733 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,734 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,734 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,734 > [DEBUG] 0 :: before allreduce fusion buffer :: 48092672000.0
2023-01-07 08:10:51,735 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,735 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,736 > [DEBUG] 0 :: before allreduce fusion buffer :: 274516606976.0
2023-01-07 08:10:51,736 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,737 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,737 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,737 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,737 > [DEBUG] 0 :: before allreduce fusion buffer :: 310446358528.0
2023-01-07 08:10:51,738 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,738 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,739 > [DEBUG] 0 :: before allreduce fusion buffer :: 595159547904.0
2023-01-07 08:10:51,739 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,740 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,740 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,740 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,740 > [DEBUG] 0 :: before allreduce fusion buffer :: -313573248.0
2023-01-07 08:10:51,741 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,741 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,742 > [DEBUG] 0 :: before allreduce fusion buffer :: 1251517923328.0
2023-01-07 08:10:51,742 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,743 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,743 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,743 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,743 > [DEBUG] 0 :: before allreduce fusion buffer :: 161703395328.0
2023-01-07 08:10:51,744 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,744 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,745 > [DEBUG] 0 :: before allreduce fusion buffer :: 2150219644928.0
2023-01-07 08:10:51,746 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,746 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,746 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,746 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,746 > [DEBUG] 0 :: before allreduce fusion buffer :: 4302075068416.0
2023-01-07 08:10:51,748 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,748 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,748 > [DEBUG] 0 :: before allreduce fusion buffer :: 8379770077184.0
2023-01-07 08:10:51,749 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,749 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,749 > [DEBUG] 0 :: before allreduce fusion buffer :: 17676634161152.0
2023-01-07 08:10:51,750 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,750 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,751 > [DEBUG] 0 :: before allreduce fusion buffer :: 35336331722752.0
2023-01-07 08:10:51,751 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,751 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,752 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,752 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,752 > [DEBUG] 0 :: before allreduce fusion buffer :: 1266398789632.0
2023-01-07 08:10:51,753 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,753 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,754 > [DEBUG] 0 :: before allreduce fusion buffer :: -3067223998464.0
2023-01-07 08:10:51,754 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,754 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,755 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,755 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,755 > [DEBUG] 0 :: before allreduce fusion buffer :: 2532853153792.0
2023-01-07 08:10:51,756 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,756 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,757 > [DEBUG] 0 :: before allreduce fusion buffer :: 31025268785152.0
2023-01-07 08:10:51,757 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,757 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,758 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,758 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,758 > [DEBUG] 0 :: before allreduce fusion buffer :: 121350274416640.0
2023-01-07 08:10:51,865 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,865 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,866 > [DEBUG] 0 :: before allreduce fusion buffer :: 42594251833344.0
2023-01-07 08:10:51,867 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,867 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,867 > [DEBUG] 0 :: before allreduce fusion buffer :: 228503836426240.0
2023-01-07 08:10:51,868 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,868 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,868 > [DEBUG] 0 :: before allreduce fusion buffer :: 213272657657856.0
2023-01-07 08:10:51,869 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,869 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,869 > [DEBUG] 0 :: before allreduce fusion buffer :: 452175968862208.0
2023-01-07 08:10:51,871 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,871 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,871 > [DEBUG] 0 :: before allreduce fusion buffer :: 485169236541440.0
2023-01-07 08:10:51,872 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,872 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,872 > [DEBUG] 0 :: before allreduce fusion buffer :: 1389522315116544.0
2023-01-07 08:10:51,873 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,873 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,873 > [DEBUG] 0 :: before allreduce fusion buffer :: 636475901214720.0
2023-01-07 08:10:51,874 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,874 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,874 > [DEBUG] 0 :: before allreduce fusion buffer :: 1715762662211584.0
2023-01-07 08:10:51,875 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,875 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,876 > [DEBUG] 0 :: before allreduce fusion buffer :: 3398310731710464.0
2023-01-07 08:10:51,877 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,877 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,877 > [DEBUG] 0 :: before allreduce fusion buffer :: 6829834445520896.0
2023-01-07 08:10:51,878 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:51,878 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:51,878 > [DEBUG] 0 :: before allreduce fusion buffer :: 9306468280958976.0
2023-01-07 08:10:52,049 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,049 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,049 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0111725529399296e+16
2023-01-07 08:10:52,050 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,050 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,050 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.022255341063373e+16
2023-01-07 08:10:52,051 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,051 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,052 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.044599158453043e+16
2023-01-07 08:10:52,053 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,053 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,053 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.044510682126746e+16
2023-01-07 08:10:52,054 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,054 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,054 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,054 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,054 > [DEBUG] 0 :: before allreduce fusion buffer :: 889302810624.0
2023-01-07 08:10:52,233 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,233 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,234 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.608902136425349e+17
2023-01-07 08:10:52,234 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,234 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,235 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.217813206382674e+17
2023-01-07 08:10:52,236 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,236 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,236 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.435608545701396e+17
2023-01-07 08:10:52,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,349 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,350 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2871232209687675e+18
2023-01-07 08:10:52,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,351 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.2871217091402793e+18
2023-01-07 08:10:52,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,353 > [DEBUG] 0 :: before allreduce fusion buffer :: 1294528806912.0
2023-01-07 08:10:52,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,355 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.755415933730161e+18
2023-01-07 08:10:52,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.951954958558429e+18
2023-01-07 08:10:52,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,358 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.190390441955872e+19
2023-01-07 08:10:52,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,359 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.380781323716395e+19
2023-01-07 08:10:52,360 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.761561767823488e+19
2023-01-07 08:10:52,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 1936215244800.0
2023-01-07 08:10:52,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,363 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.761561767823488e+19
2023-01-07 08:10:52,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,365 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.247469310922442e+21
2023-01-07 08:10:52,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,366 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,367 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,369 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,369 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.276571931327223e+23
2023-01-07 08:10:52,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,370 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.8186139691897215e+23
2023-01-07 08:10:52,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,372 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,372 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.243915557861328
2023-01-07 08:10:52,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,373 > [DEBUG] 0 :: before allreduce fusion buffer :: 655199005835264.0
2023-01-07 08:10:52,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,375 > [DEBUG] 0 :: before allreduce fusion buffer :: 17.197118759155273
2023-01-07 08:10:52,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,376 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,376 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,376 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3306038463758336e+16
2023-01-07 08:10:52,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,377 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.0806121826171875
2023-01-07 08:10:52,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,378 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,379 > [DEBUG] 0 :: before allreduce fusion buffer :: 95.4291000366211
2023-01-07 08:10:52,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,380 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.783918380737305
2023-01-07 08:10:52,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,382 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.6334461565350707e+18
2023-01-07 08:10:52,384 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,384 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,384 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.075538635253906
2023-01-07 08:10:52,385 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,385 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,385 > [DEBUG] 0 :: before allreduce fusion buffer :: 106.11341094970703
2023-01-07 08:10:52,386 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,386 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,386 > [DEBUG] 0 :: before allreduce fusion buffer :: -24.170438766479492
2023-01-07 08:10:52,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,387 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,387 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,387 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.9176368713378906
2023-01-07 08:10:52,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,389 > [DEBUG] 0 :: before allreduce fusion buffer :: -47.681396484375
2023-01-07 08:10:52,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,390 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.03285980224609375
2023-01-07 08:10:52,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,392 > [DEBUG] 0 :: before allreduce fusion buffer :: 82.41902160644531
2023-01-07 08:10:52,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,393 > [DEBUG] 0 :: before allreduce fusion buffer :: 151.01181030273438
2023-01-07 08:10:52,396 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:10:52,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,397 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,397 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,403 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,403 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,404 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,406 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,406 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,406 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,406 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,406 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,407 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.8296608629697324e+26
2023-01-07 08:10:52,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,411 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,411 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,411 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.863728690375786e+27
2023-01-07 08:10:52,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,412 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,412 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,413 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.34475361662399e+26
2023-01-07 08:10:52,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,414 > [DEBUG] 0 :: before allreduce fusion buffer :: -3669340616392704.0
2023-01-07 08:10:52,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,415 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.668950723324798e+27
2023-01-07 08:10:52,415 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: -25.074748992919922
2023-01-07 08:10:52,415 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,415 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,416 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,416 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 68.54412841796875
2023-01-07 08:10:52,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,416 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.193046569824219
2023-01-07 08:10:52,417 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 68.54412841796875
2023-01-07 08:10:52,417 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,417 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,417 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,418 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 27.015689849853516
2023-01-07 08:10:52,418 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,418 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,418 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,418 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,418 > [DEBUG] 0 :: before allreduce fusion buffer :: -61.351539611816406
2023-01-07 08:10:52,420 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 27.015689849853516
2023-01-07 08:10:52,420 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,420 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,420 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,420 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 26.900775909423828
2023-01-07 08:10:52,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,420 > [DEBUG] 0 :: before allreduce fusion buffer :: 27845462.0
2023-01-07 08:10:52,421 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 68.20001220703125
2023-01-07 08:10:52,421 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,421 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,421 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,421 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: 26.900775909423828
2023-01-07 08:10:52,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,421 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,422 > [DEBUG] 0 :: before allreduce fusion buffer :: 22.279434204101562
2023-01-07 08:10:52,423 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: 26.900775909423828
2023-01-07 08:10:52,423 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,423 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,423 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,423 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 68.54364013671875
2023-01-07 08:10:52,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,423 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,423 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,424 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,424 > [DEBUG] 0 :: before allreduce fusion buffer :: -4201410048.0
2023-01-07 08:10:52,425 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 68.54364013671875
2023-01-07 08:10:52,425 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,425 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,425 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,426 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 156.79742431640625
2023-01-07 08:10:52,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,426 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.91499137878418
2023-01-07 08:10:52,427 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 93.22845458984375
2023-01-07 08:10:52,427 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,427 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,427 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,427 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 297.86492919921875
2023-01-07 08:10:52,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,427 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,427 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,428 > [DEBUG] 0 :: before allreduce fusion buffer :: -70.13628387451172
2023-01-07 08:10:52,429 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 297.86492919921875
2023-01-07 08:10:52,429 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,429 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,429 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,429 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 60.98604965209961
2023-01-07 08:10:52,429 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,430 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,430 > [DEBUG] 0 :: before allreduce fusion buffer :: -93.2393798828125
2023-01-07 08:10:52,430 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 46.36910629272461
2023-01-07 08:10:52,431 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,431 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,431 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,431 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 60.98604965209961
2023-01-07 08:10:52,431 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,431 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,431 > [DEBUG] 0 :: before allreduce fusion buffer :: -16.68262481689453
2023-01-07 08:10:52,432 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 266.0744934082031
2023-01-07 08:10:52,432 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,432 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,432 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,432 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 60.98604965209961
2023-01-07 08:10:52,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,432 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,433 > [DEBUG] 0 :: before allreduce fusion buffer :: -150.0166015625
2023-01-07 08:10:52,434 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 172.95498657226562
2023-01-07 08:10:52,434 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,434 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,434 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,434 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 67.94882202148438
2023-01-07 08:10:52,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,434 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,434 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,434 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,434 > [DEBUG] 0 :: before allreduce fusion buffer :: -106.29803466796875
2023-01-07 08:10:52,435 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 67.94882202148438
2023-01-07 08:10:52,435 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,436 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,436 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,436 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: 60.98604965209961
2023-01-07 08:10:52,436 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,436 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,436 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,436 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,436 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.10863626003265381
2023-01-07 08:10:52,437 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: 60.98604965209961
2023-01-07 08:10:52,438 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,438 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,438 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,438 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 67.9488296508789
2023-01-07 08:10:52,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,438 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,438 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,438 > [DEBUG] 0 :: before allreduce fusion buffer :: -20.664260864257812
2023-01-07 08:10:52,440 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 67.9488296508789
2023-01-07 08:10:52,440 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,440 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,440 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,440 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 156.79742431640625
2023-01-07 08:10:52,440 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,440 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,440 > [DEBUG] 0 :: before allreduce fusion buffer :: 30.673446655273438
2023-01-07 08:10:52,441 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 74.71560668945312
2023-01-07 08:10:52,441 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,441 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,441 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,442 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 3.393340587615967
2023-01-07 08:10:52,442 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,442 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,442 > [DEBUG] 0 :: before allreduce fusion buffer :: 172.95269775390625
2023-01-07 08:10:52,443 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 268.452392578125
2023-01-07 08:10:52,443 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,443 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,443 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,443 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 3.393340587615967
2023-01-07 08:10:52,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,443 > [DEBUG] 0 :: before allreduce fusion buffer :: 18.831371307373047
2023-01-07 08:10:52,445 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 3.393340587615967
2023-01-07 08:10:52,445 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,445 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,445 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,445 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 156.79742431640625
2023-01-07 08:10:52,445 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,445 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,445 > [DEBUG] 0 :: before allreduce fusion buffer :: -43.53339385986328
2023-01-07 08:10:52,446 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 66.34883880615234
2023-01-07 08:10:52,446 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,446 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,446 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,446 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 156.79742431640625
2023-01-07 08:10:52,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,447 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,447 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.7982821464538574
2023-01-07 08:10:52,448 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 156.79742431640625
2023-01-07 08:10:52,448 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,448 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,448 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,448 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 67.09762573242188
2023-01-07 08:10:52,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,448 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,448 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,449 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.0222301483154297
2023-01-07 08:10:52,450 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 67.09762573242188
2023-01-07 08:10:52,450 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,451 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,451 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,451 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 380.5870666503906
2023-01-07 08:10:52,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,451 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,452 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 75.73173522949219
2023-01-07 08:10:52,452 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,452 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,452 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,452 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 435.49334716796875
2023-01-07 08:10:52,452 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,452 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,453 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,454 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 260.8096618652344
2023-01-07 08:10:52,454 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,454 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,454 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,454 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 380.5870666503906
2023-01-07 08:10:52,454 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,454 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,454 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,455 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 435.49334716796875
2023-01-07 08:10:52,455 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,455 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,455 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,456 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 380.5870666503906
2023-01-07 08:10:52,456 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,456 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,456 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,457 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 137.96746826171875
2023-01-07 08:10:52,457 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,457 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,457 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,457 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 380.5870666503906
2023-01-07 08:10:52,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,457 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,459 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 380.5870666503906
2023-01-07 08:10:52,459 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,459 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,459 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,459 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 139.59999084472656
2023-01-07 08:10:52,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,459 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,459 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,459 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,461 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 139.59999084472656
2023-01-07 08:10:52,461 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,461 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,461 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,461 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 745.3551635742188
2023-01-07 08:10:52,461 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,461 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,461 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,462 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 745.3551635742188
2023-01-07 08:10:52,462 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,462 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,463 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,463 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 572.1536865234375
2023-01-07 08:10:52,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,463 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,463 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,463 > [DEBUG] 0 :: before allreduce fusion buffer :: 41507.55859375
2023-01-07 08:10:52,464 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 572.1536865234375
2023-01-07 08:10:52,464 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,464 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,464 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,465 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 7.2041168212890625
2023-01-07 08:10:52,465 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,465 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,465 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,466 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 7.2041168212890625
2023-01-07 08:10:52,466 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,466 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,466 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,466 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -14.408748626708984
2023-01-07 08:10:52,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,467 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,467 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 533.032470703125
2023-01-07 08:10:52,467 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,467 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,468 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,468 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -14.408748626708984
2023-01-07 08:10:52,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,469 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -14.408748626708984
2023-01-07 08:10:52,469 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,469 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,469 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,470 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 145.00022888183594
2023-01-07 08:10:52,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,470 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,470 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,470 > [DEBUG] 0 :: before allreduce fusion buffer :: 13794293.0
2023-01-07 08:10:52,471 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 145.00022888183594
2023-01-07 08:10:52,471 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,471 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,471 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,471 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 120.40299987792969
2023-01-07 08:10:52,472 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,472 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,472 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,473 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 120.40299987792969
2023-01-07 08:10:52,473 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,473 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,473 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,473 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 125.60037231445312
2023-01-07 08:10:52,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,474 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,474 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,474 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,475 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 125.60037231445312
2023-01-07 08:10:52,475 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,475 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,475 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,475 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 279.73321533203125
2023-01-07 08:10:52,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,476 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,477 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 279.73321533203125
2023-01-07 08:10:52,477 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,477 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,477 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,477 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 270.5721130371094
2023-01-07 08:10:52,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,477 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,478 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 545.133056640625
2023-01-07 08:10:52,478 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,478 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,478 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,478 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 270.5721130371094
2023-01-07 08:10:52,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,479 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,480 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 270.5721130371094
2023-01-07 08:10:52,480 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,480 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,480 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,480 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 147.59573364257812
2023-01-07 08:10:52,480 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,480 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,481 > [DEBUG] 0 :: before allreduce fusion buffer :: -19281.61328125
2023-01-07 08:10:52,482 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 147.59573364257812
2023-01-07 08:10:52,482 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,482 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,482 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,482 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: -95.82027435302734
2023-01-07 08:10:52,482 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,482 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,483 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,484 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -95.82027435302734
2023-01-07 08:10:52,484 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,484 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,484 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,484 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 147.6061553955078
2023-01-07 08:10:52,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,484 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,484 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,485 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,486 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 147.6061553955078
2023-01-07 08:10:52,486 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,486 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,486 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,486 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: 310.3248596191406
2023-01-07 08:10:52,486 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,486 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,486 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,488 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: 310.3248596191406
2023-01-07 08:10:52,488 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,488 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,488 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,488 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 613.5357666015625
2023-01-07 08:10:52,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,488 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,488 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,488 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,490 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 613.5357666015625
2023-01-07 08:10:52,490 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,490 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,490 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,490 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: -48.29625701904297
2023-01-07 08:10:52,490 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,490 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,490 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,492 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: -48.29625701904297
2023-01-07 08:10:52,492 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,492 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,492 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,492 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 147.7027587890625
2023-01-07 08:10:52,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,492 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,492 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,492 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,494 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 147.7027587890625
2023-01-07 08:10:52,494 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,494 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,494 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,494 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: 12.816650390625
2023-01-07 08:10:52,494 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,494 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,494 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,496 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 12.816650390625
2023-01-07 08:10:52,496 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,496 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,496 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,496 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 142.83160400390625
2023-01-07 08:10:52,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,496 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,496 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,496 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,498 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 142.83160400390625
2023-01-07 08:10:52,498 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,498 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,498 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,498 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 199.5485382080078
2023-01-07 08:10:52,498 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,498 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,499 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,500 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 199.5485382080078
2023-01-07 08:10:52,500 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,500 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,500 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,500 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 514.2662353515625
2023-01-07 08:10:52,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,501 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,502 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 514.2662353515625
2023-01-07 08:10:52,502 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,502 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,502 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,502 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 80.4475326538086
2023-01-07 08:10:52,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,502 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,504 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 80.4475326538086
2023-01-07 08:10:52,504 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,504 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,504 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,504 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 283.9898986816406
2023-01-07 08:10:52,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,504 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,504 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,504 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,504 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,506 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 283.9898986816406
2023-01-07 08:10:52,506 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,506 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,506 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,506 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -33455.55078125
2023-01-07 08:10:52,506 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,506 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,506 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,508 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -33455.55078125
2023-01-07 08:10:52,508 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,508 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,508 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,508 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -358.19970703125
2023-01-07 08:10:52,508 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,508 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,508 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,509 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 283.9692687988281
2023-01-07 08:10:52,509 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,509 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,509 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,509 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -358.19970703125
2023-01-07 08:10:52,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,510 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,511 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -358.19970703125
2023-01-07 08:10:52,511 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,511 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,511 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,511 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1148.833984375
2023-01-07 08:10:52,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,511 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,512 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,512 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1045.73583984375
2023-01-07 08:10:52,512 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,512 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,512 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,513 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1148.833984375
2023-01-07 08:10:52,513 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,513 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,513 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,514 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -1148.833984375
2023-01-07 08:10:52,514 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,514 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,514 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,514 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1457.971923828125
2023-01-07 08:10:52,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,515 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,515 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1081.940185546875
2023-01-07 08:10:52,516 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,516 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,516 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,516 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1457.971923828125
2023-01-07 08:10:52,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,516 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,517 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1457.971923828125
2023-01-07 08:10:52,518 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,518 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,518 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,518 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 285.23944091796875
2023-01-07 08:10:52,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,518 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,518 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,518 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,519 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 285.23944091796875
2023-01-07 08:10:52,519 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,520 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,520 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,520 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -2503.4326171875
2023-01-07 08:10:52,520 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,520 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,520 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,521 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -2503.4326171875
2023-01-07 08:10:52,521 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,521 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,521 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,522 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -196.36611938476562
2023-01-07 08:10:52,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,522 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,523 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 292.3780517578125
2023-01-07 08:10:52,523 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,523 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,523 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,523 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -196.36611938476562
2023-01-07 08:10:52,523 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,523 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,523 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,525 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -196.36611938476562
2023-01-07 08:10:52,525 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,525 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,525 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,525 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 570.9168701171875
2023-01-07 08:10:52,525 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,525 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,525 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,526 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1084.342041015625
2023-01-07 08:10:52,526 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,526 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,526 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,526 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 570.9168701171875
2023-01-07 08:10:52,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,527 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,528 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 570.9168701171875
2023-01-07 08:10:52,528 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,528 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,528 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,528 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 332.0378723144531
2023-01-07 08:10:52,528 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,528 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,529 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,529 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 294.3690185546875
2023-01-07 08:10:52,529 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,529 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,530 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,530 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 332.0378723144531
2023-01-07 08:10:52,530 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,530 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,530 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,531 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 332.0378723144531
2023-01-07 08:10:52,531 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,531 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,531 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,532 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 368.4935302734375
2023-01-07 08:10:52,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,532 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,533 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 296.3692932128906
2023-01-07 08:10:52,533 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,533 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,533 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,533 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 368.4935302734375
2023-01-07 08:10:52,533 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,533 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,533 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,535 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: 368.4935302734375
2023-01-07 08:10:52,535 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,535 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,535 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,535 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -35.17192077636719
2023-01-07 08:10:52,535 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,535 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,535 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,536 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1071.132080078125
2023-01-07 08:10:52,536 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,536 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,536 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,536 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: -35.17192077636719
2023-01-07 08:10:52,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,537 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,538 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: -35.17192077636719
2023-01-07 08:10:52,538 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,538 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,538 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,538 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -122.28982543945312
2023-01-07 08:10:52,538 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,538 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,539 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,539 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 297.96881103515625
2023-01-07 08:10:52,539 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,539 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,539 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,540 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -122.28982543945312
2023-01-07 08:10:52,540 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,540 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,540 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,541 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: -122.28982543945312
2023-01-07 08:10:52,541 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,541 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,541 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,542 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 27.66333770751953
2023-01-07 08:10:52,542 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,542 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,542 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,543 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 298.9693908691406
2023-01-07 08:10:52,543 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,543 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,543 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,543 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: 27.66333770751953
2023-01-07 08:10:52,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,545 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: 27.66333770751953
2023-01-07 08:10:52,545 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,545 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,545 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,545 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -456.2446594238281
2023-01-07 08:10:52,545 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,545 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,545 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,546 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1113.394775390625
2023-01-07 08:10:52,546 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,546 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,546 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,546 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -456.2446594238281
2023-01-07 08:10:52,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,547 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,548 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -456.2446594238281
2023-01-07 08:10:52,548 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,548 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,548 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,548 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -1155.65966796875
2023-01-07 08:10:52,548 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,548 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,549 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,549 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 299.16973876953125
2023-01-07 08:10:52,549 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,549 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,549 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,550 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -1155.65966796875
2023-01-07 08:10:52,550 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,550 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,550 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,551 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -1155.65966796875
2023-01-07 08:10:52,551 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,551 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,551 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,552 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -4972.9931640625
2023-01-07 08:10:52,552 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,552 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,552 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,553 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 294.8940124511719
2023-01-07 08:10:52,553 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,553 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,553 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,553 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -4972.9931640625
2023-01-07 08:10:52,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,553 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,555 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -4972.9931640625
2023-01-07 08:10:52,555 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,555 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,555 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,555 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -35076.80859375
2023-01-07 08:10:52,555 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,555 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,555 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,556 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1082.06494140625
2023-01-07 08:10:52,556 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,556 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,556 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,556 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -35076.80859375
2023-01-07 08:10:52,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,557 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,558 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -35076.80859375
2023-01-07 08:10:52,558 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,558 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,558 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,558 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -14991.857421875
2023-01-07 08:10:52,558 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,559 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,559 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 300.1695251464844
2023-01-07 08:10:52,559 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,559 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,560 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,560 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -14991.857421875
2023-01-07 08:10:52,560 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,560 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,561 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -14991.857421875
2023-01-07 08:10:52,561 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,562 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,562 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,562 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -39560.59375
2023-01-07 08:10:52,562 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,562 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,562 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,563 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 300.76959228515625
2023-01-07 08:10:52,563 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,563 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,563 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,563 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -39560.59375
2023-01-07 08:10:52,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,563 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,563 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,565 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -39560.59375
2023-01-07 08:10:52,565 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,565 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,565 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,565 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -84063.484375
2023-01-07 08:10:52,565 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,565 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,565 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,566 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1085.259765625
2023-01-07 08:10:52,566 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,566 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,566 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -84063.484375
2023-01-07 08:10:52,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,567 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,567 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,568 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -84063.484375
2023-01-07 08:10:52,568 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,568 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,568 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -70903.9609375
2023-01-07 08:10:52,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,569 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,569 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 598.880126953125
2023-01-07 08:10:52,570 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,570 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,570 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,570 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -70903.9609375
2023-01-07 08:10:52,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,570 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,571 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -70903.9609375
2023-01-07 08:10:52,571 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,572 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,572 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,572 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -580.1268310546875
2023-01-07 08:10:52,572 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,572 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,572 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,574 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 496.0686950683594
2023-01-07 08:10:52,574 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,574 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,574 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,574 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -580.1268310546875
2023-01-07 08:10:52,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,574 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,574 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,576 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -580.1268310546875
2023-01-07 08:10:52,576 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,576 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,576 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,576 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -205744.78125
2023-01-07 08:10:52,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,577 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,577 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,578 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2152.323486328125
2023-01-07 08:10:52,578 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,578 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,578 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,578 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -205744.78125
2023-01-07 08:10:52,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,578 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,579 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -205744.78125
2023-01-07 08:10:52,579 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,579 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,579 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,580 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -44476.703125
2023-01-07 08:10:52,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,580 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,581 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2154.676025390625
2023-01-07 08:10:52,581 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,581 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,581 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,581 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -44476.703125
2023-01-07 08:10:52,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,581 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,583 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -44476.703125
2023-01-07 08:10:52,583 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,583 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,583 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,583 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -506.0019226074219
2023-01-07 08:10:52,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,583 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,584 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 600.098388671875
2023-01-07 08:10:52,584 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,584 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,584 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,584 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -506.0019226074219
2023-01-07 08:10:52,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,585 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,585 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,586 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -506.0019226074219
2023-01-07 08:10:52,586 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,586 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,586 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,586 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -56784.6015625
2023-01-07 08:10:52,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,587 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,587 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,588 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 599.9537963867188
2023-01-07 08:10:52,588 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,588 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,588 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,588 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -56784.6015625
2023-01-07 08:10:52,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,588 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,588 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,590 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -56784.6015625
2023-01-07 08:10:52,590 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,590 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,590 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,590 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -171655.9375
2023-01-07 08:10:52,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,590 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,591 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2162.83349609375
2023-01-07 08:10:52,591 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,591 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,591 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,591 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -171655.9375
2023-01-07 08:10:52,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,592 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,593 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -171655.9375
2023-01-07 08:10:52,593 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,593 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,593 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,593 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -20564.43359375
2023-01-07 08:10:52,593 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,593 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,594 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,594 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 597.0371704101562
2023-01-07 08:10:52,594 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,594 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,594 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,595 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -20564.43359375
2023-01-07 08:10:52,595 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,595 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,595 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,596 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -20564.43359375
2023-01-07 08:10:52,596 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,596 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,596 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,597 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -272.03228759765625
2023-01-07 08:10:52,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,597 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,598 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 616.42626953125
2023-01-07 08:10:52,598 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,598 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,598 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,598 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -272.03228759765625
2023-01-07 08:10:52,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,598 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,600 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: -272.03228759765625
2023-01-07 08:10:52,600 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,600 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,600 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,600 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -249309.4375
2023-01-07 08:10:52,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,600 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,601 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2483.99560546875
2023-01-07 08:10:52,601 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,601 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,601 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,601 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -249309.4375
2023-01-07 08:10:52,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,602 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:52,603 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -249309.4375
2023-01-07 08:10:52,603 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:52,603 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:52,604 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:52,604 > [DEBUG] 0 :: 61.32720184326172
2023-01-07 08:10:52,606 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,607 > [DEBUG] 0 :: before allreduce fusion buffer :: -2100705280.0
2023-01-07 08:10:52,607 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,608 > [DEBUG] 0 :: before allreduce fusion buffer :: -228718208.0
2023-01-07 08:10:52,610 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,610 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,610 > [DEBUG] 0 :: before allreduce fusion buffer :: 37.82002639770508
2023-01-07 08:10:52,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,611 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,611 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,611 > [DEBUG] 0 :: before allreduce fusion buffer :: -457475584.0
2023-01-07 08:10:52,613 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,613 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,613 > [DEBUG] 0 :: before allreduce fusion buffer :: 1548.212158203125
2023-01-07 08:10:52,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,614 > [DEBUG] 0 :: before allreduce fusion buffer :: -457434752.0
2023-01-07 08:10:52,616 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,616 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,616 > [DEBUG] 0 :: before allreduce fusion buffer :: 3024.09228515625
2023-01-07 08:10:52,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,617 > [DEBUG] 0 :: before allreduce fusion buffer :: -457436544.0
2023-01-07 08:10:52,619 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,619 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,619 > [DEBUG] 0 :: before allreduce fusion buffer :: 220.21714782714844
2023-01-07 08:10:52,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,620 > [DEBUG] 0 :: before allreduce fusion buffer :: -478959872.0
2023-01-07 08:10:52,622 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,622 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,622 > [DEBUG] 0 :: before allreduce fusion buffer :: -23.827436447143555
2023-01-07 08:10:52,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,623 > [DEBUG] 0 :: before allreduce fusion buffer :: -957833472.0
2023-01-07 08:10:52,625 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,625 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,625 > [DEBUG] 0 :: before allreduce fusion buffer :: 20.12158203125
2023-01-07 08:10:52,626 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,626 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,626 > [DEBUG] 0 :: before allreduce fusion buffer :: -1915744768.0
2023-01-07 08:10:52,628 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,628 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,628 > [DEBUG] 0 :: before allreduce fusion buffer :: 337.6068115234375
2023-01-07 08:10:52,629 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,629 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,629 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,629 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,630 > [DEBUG] 0 :: before allreduce fusion buffer :: -1915665408.0
2023-01-07 08:10:52,631 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,631 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,631 > [DEBUG] 0 :: before allreduce fusion buffer :: -551.450927734375
2023-01-07 08:10:52,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,633 > [DEBUG] 0 :: before allreduce fusion buffer :: -1915832320.0
2023-01-07 08:10:52,634 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,634 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,634 > [DEBUG] 0 :: before allreduce fusion buffer :: -3189.99560546875
2023-01-07 08:10:52,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,635 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,636 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,636 > [DEBUG] 0 :: before allreduce fusion buffer :: -3075.80810546875
2023-01-07 08:10:52,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,637 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,638 > [DEBUG] 0 :: before allreduce fusion buffer :: -7360.2333984375
2023-01-07 08:10:52,638 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,638 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,639 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,639 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,639 > [DEBUG] 0 :: before allreduce fusion buffer :: -6211.03125
2023-01-07 08:10:52,640 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,640 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,641 > [DEBUG] 0 :: before allreduce fusion buffer :: -661.3764038085938
2023-01-07 08:10:52,641 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,641 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,642 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,642 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,642 > [DEBUG] 0 :: before allreduce fusion buffer :: -13238.9833984375
2023-01-07 08:10:52,644 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,644 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,644 > [DEBUG] 0 :: before allreduce fusion buffer :: -1166.8797607421875
2023-01-07 08:10:52,645 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,645 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,645 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,645 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,645 > [DEBUG] 0 :: before allreduce fusion buffer :: 80.90632629394531
2023-01-07 08:10:52,647 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,647 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,647 > [DEBUG] 0 :: before allreduce fusion buffer :: -12762.26171875
2023-01-07 08:10:52,648 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,648 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,648 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,648 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,648 > [DEBUG] 0 :: before allreduce fusion buffer :: -27422.5078125
2023-01-07 08:10:52,650 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,650 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,650 > [DEBUG] 0 :: before allreduce fusion buffer :: -3961.904541015625
2023-01-07 08:10:52,651 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,651 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,651 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,651 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,651 > [DEBUG] 0 :: before allreduce fusion buffer :: -32903.2734375
2023-01-07 08:10:52,653 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,653 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,653 > [DEBUG] 0 :: before allreduce fusion buffer :: -17.291364669799805
2023-01-07 08:10:52,654 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,654 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,654 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,654 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,654 > [DEBUG] 0 :: before allreduce fusion buffer :: -40290.7265625
2023-01-07 08:10:52,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,656 > [DEBUG] 0 :: before allreduce fusion buffer :: -76006.234375
2023-01-07 08:10:52,657 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,657 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,657 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,657 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,657 > [DEBUG] 0 :: before allreduce fusion buffer :: -81847.671875
2023-01-07 08:10:52,659 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,659 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,659 > [DEBUG] 0 :: before allreduce fusion buffer :: -152.30654907226562
2023-01-07 08:10:52,660 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,660 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,660 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,660 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,660 > [DEBUG] 0 :: before allreduce fusion buffer :: -82515.1015625
2023-01-07 08:10:52,662 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,662 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,662 > [DEBUG] 0 :: before allreduce fusion buffer :: -674.1561279296875
2023-01-07 08:10:52,663 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,663 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,663 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,663 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,663 > [DEBUG] 0 :: before allreduce fusion buffer :: -109956.0
2023-01-07 08:10:52,665 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,665 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,665 > [DEBUG] 0 :: before allreduce fusion buffer :: -110632.2265625
2023-01-07 08:10:52,666 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,666 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,666 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,666 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,666 > [DEBUG] 0 :: before allreduce fusion buffer :: -6942.80322265625
2023-01-07 08:10:52,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,668 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,668 > [DEBUG] 0 :: before allreduce fusion buffer :: -2308.2041015625
2023-01-07 08:10:52,669 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,669 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,669 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,669 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,669 > [DEBUG] 0 :: before allreduce fusion buffer :: -232658.6875
2023-01-07 08:10:52,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,671 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,671 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.47931724786758423
2023-01-07 08:10:52,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,672 > [DEBUG] 0 :: before allreduce fusion buffer :: -178585.15625
2023-01-07 08:10:52,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,674 > [DEBUG] 0 :: before allreduce fusion buffer :: -130923.2421875
2023-01-07 08:10:52,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,675 > [DEBUG] 0 :: before allreduce fusion buffer :: -467477.4375
2023-01-07 08:10:52,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,677 > [DEBUG] 0 :: before allreduce fusion buffer :: -37778.53125
2023-01-07 08:10:52,678 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,678 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,678 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,678 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,679 > [DEBUG] 0 :: before allreduce fusion buffer :: -567199.375
2023-01-07 08:10:52,680 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,680 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,681 > [DEBUG] 0 :: before allreduce fusion buffer :: -77541.203125
2023-01-07 08:10:52,681 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,682 > [DEBUG] 0 :: before allreduce fusion buffer :: -583396.0
2023-01-07 08:10:52,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,683 > [DEBUG] 0 :: before allreduce fusion buffer :: -302179.21875
2023-01-07 08:10:52,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,684 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,684 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,684 > [DEBUG] 0 :: before allreduce fusion buffer :: 20973.27734375
2023-01-07 08:10:52,686 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,686 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,686 > [DEBUG] 0 :: before allreduce fusion buffer :: -80834.2265625
2023-01-07 08:10:52,687 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,687 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,687 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,687 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,687 > [DEBUG] 0 :: before allreduce fusion buffer :: 138443.859375
2023-01-07 08:10:52,689 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,689 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,689 > [DEBUG] 0 :: before allreduce fusion buffer :: -182419.859375
2023-01-07 08:10:52,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,690 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,690 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,690 > [DEBUG] 0 :: before allreduce fusion buffer :: -18403.50390625
2023-01-07 08:10:52,856 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,856 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,857 > [DEBUG] 0 :: before allreduce fusion buffer :: -385604.0625
2023-01-07 08:10:52,858 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,858 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,858 > [DEBUG] 0 :: before allreduce fusion buffer :: -784680.125
2023-01-07 08:10:52,859 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,859 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,859 > [DEBUG] 0 :: before allreduce fusion buffer :: -1569366.0
2023-01-07 08:10:52,860 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,860 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,861 > [DEBUG] 0 :: before allreduce fusion buffer :: -1569387.625
2023-01-07 08:10:52,862 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,862 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,862 > [DEBUG] 0 :: before allreduce fusion buffer :: -3138726.0
2023-01-07 08:10:52,863 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,863 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,863 > [DEBUG] 0 :: before allreduce fusion buffer :: -6277449.0
2023-01-07 08:10:52,864 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,864 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,864 > [DEBUG] 0 :: before allreduce fusion buffer :: -12554905.0
2023-01-07 08:10:52,865 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,865 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,865 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3825647830963135
2023-01-07 08:10:52,866 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,866 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,867 > [DEBUG] 0 :: before allreduce fusion buffer :: -25109808.0
2023-01-07 08:10:52,867 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,868 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,868 > [DEBUG] 0 :: before allreduce fusion buffer :: -24678744.0
2023-01-07 08:10:52,869 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:52,869 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:52,869 > [DEBUG] 0 :: before allreduce fusion buffer :: -50685712.0
2023-01-07 08:10:53,038 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,038 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,038 > [DEBUG] 0 :: before allreduce fusion buffer :: -101371440.0
2023-01-07 08:10:53,040 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,040 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,040 > [DEBUG] 0 :: before allreduce fusion buffer :: -202742848.0
2023-01-07 08:10:53,041 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,041 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,041 > [DEBUG] 0 :: before allreduce fusion buffer :: -405485696.0
2023-01-07 08:10:53,042 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,042 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,042 > [DEBUG] 0 :: before allreduce fusion buffer :: -786304960.0
2023-01-07 08:10:53,043 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,043 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,043 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,043 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,044 > [DEBUG] 0 :: before allreduce fusion buffer :: -1586404224.0
2023-01-07 08:10:53,223 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,224 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,224 > [DEBUG] 0 :: before allreduce fusion buffer :: -3208347136.0
2023-01-07 08:10:53,225 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,225 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,225 > [DEBUG] 0 :: before allreduce fusion buffer :: -3165843456.0
2023-01-07 08:10:53,226 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,227 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,227 > [DEBUG] 0 :: before allreduce fusion buffer :: -6331686912.0
2023-01-07 08:10:53,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,341 > [DEBUG] 0 :: before allreduce fusion buffer :: -6331686912.0
2023-01-07 08:10:53,342 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,342 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,342 > [DEBUG] 0 :: before allreduce fusion buffer :: -12663373824.0
2023-01-07 08:10:53,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,343 > [DEBUG] 0 :: before allreduce fusion buffer :: -25382273024.0
2023-01-07 08:10:53,345 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,345 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,345 > [DEBUG] 0 :: before allreduce fusion buffer :: 483133760.0
2023-01-07 08:10:53,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,346 > [DEBUG] 0 :: before allreduce fusion buffer :: -24643762176.0
2023-01-07 08:10:53,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,347 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,348 > [DEBUG] 0 :: before allreduce fusion buffer :: -49287524352.0
2023-01-07 08:10:53,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,349 > [DEBUG] 0 :: before allreduce fusion buffer :: -47810117632.0
2023-01-07 08:10:53,350 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,350 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,350 > [DEBUG] 0 :: before allreduce fusion buffer :: -95620235264.0
2023-01-07 08:10:53,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,351 > [DEBUG] 0 :: before allreduce fusion buffer :: -102682918912.0
2023-01-07 08:10:53,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,353 > [DEBUG] 0 :: before allreduce fusion buffer :: -191240470528.0
2023-01-07 08:10:53,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,354 > [DEBUG] 0 :: before allreduce fusion buffer :: -422432112640.0
2023-01-07 08:10:53,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,356 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,357 > [DEBUG] 0 :: before allreduce fusion buffer :: -11805971709952.0
2023-01-07 08:10:53,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,358 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5641377568244934
2023-01-07 08:10:53,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,359 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,360 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 316075180032.0
2023-01-07 08:10:53,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,361 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.43091338872909546
2023-01-07 08:10:53,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,363 > [DEBUG] 0 :: before allreduce fusion buffer :: -10.415984153747559
2023-01-07 08:10:53,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,364 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.2459867000579834
2023-01-07 08:10:53,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,365 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,365 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,366 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.6457319259643555
2023-01-07 08:10:53,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,367 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.6819324493408203
2023-01-07 08:10:53,368 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,368 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,368 > [DEBUG] 0 :: before allreduce fusion buffer :: -14.409605979919434
2023-01-07 08:10:53,369 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,369 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,370 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.6161904335021973
2023-01-07 08:10:53,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,371 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,371 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,371 > [DEBUG] 0 :: before allreduce fusion buffer :: -47.362770080566406
2023-01-07 08:10:53,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,373 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.4417463541030884
2023-01-07 08:10:53,374 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,374 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,374 > [DEBUG] 0 :: before allreduce fusion buffer :: -46836523008.0
2023-01-07 08:10:53,375 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,375 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,376 > [DEBUG] 0 :: before allreduce fusion buffer :: -11.359981536865234
2023-01-07 08:10:53,376 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,377 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,377 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,377 > [DEBUG] 0 :: before allreduce fusion buffer :: -27.308277130126953
2023-01-07 08:10:53,378 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,378 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,379 > [DEBUG] 0 :: before allreduce fusion buffer :: -9.442811965942383
2023-01-07 08:10:53,379 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,379 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,380 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,380 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,380 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.7711687088012695
2023-01-07 08:10:53,381 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,381 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,382 > [DEBUG] 0 :: before allreduce fusion buffer :: -13.67049789428711
2023-01-07 08:10:53,382 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,382 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,383 > [DEBUG] 0 :: before allreduce fusion buffer :: -373100.28125
2023-01-07 08:10:53,387 > [DEBUG] 0 :: communication is scheduled in BWTOFW
2023-01-07 08:10:53,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,388 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,388 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,389 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,389 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,390 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,390 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,391 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,391 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,391 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,392 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,392 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,393 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,393 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,394 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,394 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,395 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,395 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,396 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,396 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,396 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.440273261016803e+19
2023-01-07 08:10:53,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,398 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,398 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,399 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,399 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,400 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,400 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,400 > [DEBUG] 0 :: before allreduce fusion buffer :: -214539706564608.0
2023-01-07 08:10:53,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,401 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,401 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,402 > [DEBUG] 0 :: before allreduce fusion buffer :: -52433215488.0
2023-01-07 08:10:53,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,402 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,402 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,403 > [DEBUG] 0 :: before allreduce fusion buffer :: -858055411499008.0
2023-01-07 08:10:53,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,403 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,403 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,404 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,404 > [DEBUG] 0 :: before allreduce fusion buffer :: -858443032297472.0
2023-01-07 08:10:53,404 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 sum :: 8.399063110351562
2023-01-07 08:10:53,404 > [DEBUG] 0 :: param conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,404 > [DEBUG] 0 :: param_name :: conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,405 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,405 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  bn1._dp_wrapped_module.flat_param_0 value:: 69.11934661865234
2023-01-07 08:10:53,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,405 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,405 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,405 > [DEBUG] 0 :: before allreduce fusion buffer :: -138.04933166503906
2023-01-07 08:10:53,406 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 sum :: 69.11934661865234
2023-01-07 08:10:53,406 > [DEBUG] 0 :: param bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,406 > [DEBUG] 0 :: param_name :: bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,406 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,407 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv1._dp_wrapped_module.flat_param_0 value:: 27.339523315429688
2023-01-07 08:10:53,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,407 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,407 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,407 > [DEBUG] 0 :: before allreduce fusion buffer :: -3431960189861888.0
2023-01-07 08:10:53,409 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 sum :: 27.339523315429688
2023-01-07 08:10:53,409 > [DEBUG] 0 :: param layer1.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,409 > [DEBUG] 0 :: param_name :: layer1.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,409 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,409 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -36.147300720214844
2023-01-07 08:10:53,409 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,409 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,409 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.136761665344238
2023-01-07 08:10:53,410 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 sum :: 68.20001220703125
2023-01-07 08:10:53,410 > [DEBUG] 0 :: param layer1.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,410 > [DEBUG] 0 :: param_name :: layer1.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,410 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,410 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.conv2._dp_wrapped_module.flat_param_0 value:: -36.147300720214844
2023-01-07 08:10:53,410 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,410 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,411 > [DEBUG] 0 :: before allreduce fusion buffer :: -21.233924865722656
2023-01-07 08:10:53,413 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 sum :: -36.147300720214844
2023-01-07 08:10:53,413 > [DEBUG] 0 :: param layer1.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,413 > [DEBUG] 0 :: param_name :: layer1.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,413 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,413 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn2._dp_wrapped_module.flat_param_0 value:: 69.11885070800781
2023-01-07 08:10:53,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,413 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,413 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,414 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,414 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,414 > [DEBUG] 0 :: before allreduce fusion buffer :: 8467328270336.0
2023-01-07 08:10:53,416 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 sum :: 69.11885070800781
2023-01-07 08:10:53,416 > [DEBUG] 0 :: param layer1.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,416 > [DEBUG] 0 :: param_name :: layer1.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,416 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,416 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 121.55289459228516
2023-01-07 08:10:53,416 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,416 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,416 > [DEBUG] 0 :: before allreduce fusion buffer :: 5.725072860717773
2023-01-07 08:10:53,417 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 sum :: 55.48986053466797
2023-01-07 08:10:53,417 > [DEBUG] 0 :: param layer1.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,417 > [DEBUG] 0 :: param_name :: layer1.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,417 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,417 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.0.bn3._dp_wrapped_module.flat_param_0 value:: 296.3693542480469
2023-01-07 08:10:53,417 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,417 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,418 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,418 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,418 > [DEBUG] 0 :: before allreduce fusion buffer :: -14.12237548828125
2023-01-07 08:10:53,419 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 sum :: 296.3693542480469
2023-01-07 08:10:53,419 > [DEBUG] 0 :: param layer1.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,419 > [DEBUG] 0 :: param_name :: layer1.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,419 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,420 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.1096439361572266
2023-01-07 08:10:53,420 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,420 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,420 > [DEBUG] 0 :: before allreduce fusion buffer :: -2071.300537109375
2023-01-07 08:10:53,421 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 75.524169921875
2023-01-07 08:10:53,421 > [DEBUG] 0 :: param layer1.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,421 > [DEBUG] 0 :: param_name :: layer1.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,421 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,421 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.1096439361572266
2023-01-07 08:10:53,421 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,421 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,421 > [DEBUG] 0 :: before allreduce fusion buffer :: 44.94581604003906
2023-01-07 08:10:53,422 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 266.13201904296875
2023-01-07 08:10:53,422 > [DEBUG] 0 :: param layer1.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,422 > [DEBUG] 0 :: param_name :: layer1.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,422 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,422 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.1096439361572266
2023-01-07 08:10:53,422 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,422 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,423 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.3466386795043945
2023-01-07 08:10:53,424 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 sum :: 148.47726440429688
2023-01-07 08:10:53,424 > [DEBUG] 0 :: param layer1.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,424 > [DEBUG] 0 :: param_name :: layer1.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,424 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,424 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn1._dp_wrapped_module.flat_param_0 value:: 68.06387329101562
2023-01-07 08:10:53,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,424 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,424 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,424 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,424 > [DEBUG] 0 :: before allreduce fusion buffer :: -28.459186553955078
2023-01-07 08:10:53,426 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 sum :: 68.06387329101562
2023-01-07 08:10:53,426 > [DEBUG] 0 :: param layer1.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,426 > [DEBUG] 0 :: param_name :: layer1.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,426 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,426 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.conv2._dp_wrapped_module.flat_param_0 value:: -3.1096439361572266
2023-01-07 08:10:53,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,426 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,426 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,426 > [DEBUG] 0 :: before allreduce fusion buffer :: 4740.88818359375
2023-01-07 08:10:53,428 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 sum :: -3.1096439361572266
2023-01-07 08:10:53,428 > [DEBUG] 0 :: param layer1.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,428 > [DEBUG] 0 :: param_name :: layer1.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,428 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,428 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.1.bn2._dp_wrapped_module.flat_param_0 value:: 68.06387329101562
2023-01-07 08:10:53,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,428 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,428 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,428 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.231021881103516
2023-01-07 08:10:53,430 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 sum :: 68.06387329101562
2023-01-07 08:10:53,430 > [DEBUG] 0 :: param layer1.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,430 > [DEBUG] 0 :: param_name :: layer1.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,430 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,430 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 121.55289459228516
2023-01-07 08:10:53,430 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,430 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,430 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.594670295715332
2023-01-07 08:10:53,431 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 sum :: 51.59657669067383
2023-01-07 08:10:53,432 > [DEBUG] 0 :: param layer1.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,432 > [DEBUG] 0 :: param_name :: layer1.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,432 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,432 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 11.430530548095703
2023-01-07 08:10:53,432 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,432 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,432 > [DEBUG] 0 :: before allreduce fusion buffer :: -207901851648.0
2023-01-07 08:10:53,433 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 sum :: 268.79754638671875
2023-01-07 08:10:53,433 > [DEBUG] 0 :: param layer1.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,433 > [DEBUG] 0 :: param_name :: layer1.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,433 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,433 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv1._dp_wrapped_module.flat_param_0 value:: 11.430530548095703
2023-01-07 08:10:53,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,433 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,433 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,434 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.942533493041992
2023-01-07 08:10:53,435 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 sum :: 11.430530548095703
2023-01-07 08:10:53,435 > [DEBUG] 0 :: param layer1.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,435 > [DEBUG] 0 :: param_name :: layer1.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,435 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,435 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 121.55289459228516
2023-01-07 08:10:53,435 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,435 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,436 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.0346217155456543
2023-01-07 08:10:53,436 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 sum :: 66.46388244628906
2023-01-07 08:10:53,437 > [DEBUG] 0 :: param layer1.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,437 > [DEBUG] 0 :: param_name :: layer1.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,437 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,437 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.conv2._dp_wrapped_module.flat_param_0 value:: 121.55289459228516
2023-01-07 08:10:53,437 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,437 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,437 > [DEBUG] 0 :: before allreduce fusion buffer :: 187.93496704101562
2023-01-07 08:10:53,438 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 sum :: 121.55289459228516
2023-01-07 08:10:53,438 > [DEBUG] 0 :: param layer1.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,438 > [DEBUG] 0 :: param_name :: layer1.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,438 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,439 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer1.2.bn2._dp_wrapped_module.flat_param_0 value:: 67.32772064208984
2023-01-07 08:10:53,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,439 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,439 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,439 > [DEBUG] 0 :: before allreduce fusion buffer :: 410048224.0
2023-01-07 08:10:53,441 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 sum :: 67.32772064208984
2023-01-07 08:10:53,441 > [DEBUG] 0 :: param layer1.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,441 > [DEBUG] 0 :: param_name :: layer1.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,441 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,441 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 364.98394775390625
2023-01-07 08:10:53,441 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,441 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,441 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,442 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 sum :: 64.86288452148438
2023-01-07 08:10:53,442 > [DEBUG] 0 :: param layer1.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,442 > [DEBUG] 0 :: param_name :: layer1.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,442 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,443 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv1._dp_wrapped_module.flat_param_0 value:: 462.31707763671875
2023-01-07 08:10:53,443 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,443 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,443 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,444 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 sum :: 260.6824035644531
2023-01-07 08:10:53,444 > [DEBUG] 0 :: param layer1.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,444 > [DEBUG] 0 :: param_name :: layer1.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,444 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,444 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 364.98394775390625
2023-01-07 08:10:53,444 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,444 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,445 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,446 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 sum :: 462.31707763671875
2023-01-07 08:10:53,446 > [DEBUG] 0 :: param layer2.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,446 > [DEBUG] 0 :: param_name :: layer2.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,446 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,446 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 364.98394775390625
2023-01-07 08:10:53,446 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,446 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,446 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,447 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 sum :: 135.6686553955078
2023-01-07 08:10:53,447 > [DEBUG] 0 :: param layer2.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,447 > [DEBUG] 0 :: param_name :: layer2.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,447 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,447 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv2._dp_wrapped_module.flat_param_0 value:: 364.98394775390625
2023-01-07 08:10:53,447 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,447 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,448 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,449 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 sum :: 364.98394775390625
2023-01-07 08:10:53,449 > [DEBUG] 0 :: param layer2.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,449 > [DEBUG] 0 :: param_name :: layer2.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,449 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,449 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn2._dp_wrapped_module.flat_param_0 value:: 139.60000610351562
2023-01-07 08:10:53,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,449 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,449 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,450 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,450 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,451 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 sum :: 139.60000610351562
2023-01-07 08:10:53,451 > [DEBUG] 0 :: param layer2.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,451 > [DEBUG] 0 :: param_name :: layer2.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,451 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,451 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.conv3._dp_wrapped_module.flat_param_0 value:: 819.700439453125
2023-01-07 08:10:53,451 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,451 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,451 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,453 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 sum :: 819.700439453125
2023-01-07 08:10:53,453 > [DEBUG] 0 :: param layer2.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,453 > [DEBUG] 0 :: param_name :: layer2.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,453 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,453 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.bn3._dp_wrapped_module.flat_param_0 value:: 571.80859375
2023-01-07 08:10:53,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,453 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,453 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,454 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,455 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 sum :: 571.80859375
2023-01-07 08:10:53,455 > [DEBUG] 0 :: param layer2.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,455 > [DEBUG] 0 :: param_name :: layer2.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,455 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,455 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.0.downsample.0._dp_wrapped_module.flat_param_0 value:: 75.12689971923828
2023-01-07 08:10:53,455 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,455 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,455 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,456 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: 75.12689971923828
2023-01-07 08:10:53,456 > [DEBUG] 0 :: param layer2.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,456 > [DEBUG] 0 :: param_name :: layer2.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,457 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,457 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -106.2437744140625
2023-01-07 08:10:53,457 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,457 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,457 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,458 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 532.47802734375
2023-01-07 08:10:53,458 > [DEBUG] 0 :: param layer2.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,458 > [DEBUG] 0 :: param_name :: layer2.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,458 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,458 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv1._dp_wrapped_module.flat_param_0 value:: -106.2437744140625
2023-01-07 08:10:53,458 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,458 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,458 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,460 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 sum :: -106.2437744140625
2023-01-07 08:10:53,460 > [DEBUG] 0 :: param layer2.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,460 > [DEBUG] 0 :: param_name :: layer2.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,460 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,460 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn1._dp_wrapped_module.flat_param_0 value:: 145.00022888183594
2023-01-07 08:10:53,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,460 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,460 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,460 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,462 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 sum :: 145.00022888183594
2023-01-07 08:10:53,462 > [DEBUG] 0 :: param layer2.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,462 > [DEBUG] 0 :: param_name :: layer2.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,462 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,462 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv2._dp_wrapped_module.flat_param_0 value:: 102.90418243408203
2023-01-07 08:10:53,462 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,462 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,462 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,464 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 sum :: 102.90418243408203
2023-01-07 08:10:53,464 > [DEBUG] 0 :: param layer2.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,464 > [DEBUG] 0 :: param_name :: layer2.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,464 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,464 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.bn2._dp_wrapped_module.flat_param_0 value:: 125.60037231445312
2023-01-07 08:10:53,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,464 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,464 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,464 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,466 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 sum :: 125.60037231445312
2023-01-07 08:10:53,466 > [DEBUG] 0 :: param layer2.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,466 > [DEBUG] 0 :: param_name :: layer2.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,466 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,466 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.1.conv3._dp_wrapped_module.flat_param_0 value:: 316.4154052734375
2023-01-07 08:10:53,466 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,466 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,466 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,467 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 sum :: 316.4154052734375
2023-01-07 08:10:53,467 > [DEBUG] 0 :: param layer2.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,467 > [DEBUG] 0 :: param_name :: layer2.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,468 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,468 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 416.5829772949219
2023-01-07 08:10:53,468 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,468 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,468 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,469 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 sum :: 544.6357421875
2023-01-07 08:10:53,469 > [DEBUG] 0 :: param layer2.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,469 > [DEBUG] 0 :: param_name :: layer2.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,469 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,469 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv1._dp_wrapped_module.flat_param_0 value:: 416.5829772949219
2023-01-07 08:10:53,469 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,469 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,469 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,471 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 sum :: 416.5829772949219
2023-01-07 08:10:53,471 > [DEBUG] 0 :: param layer2.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,471 > [DEBUG] 0 :: param_name :: layer2.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,471 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,471 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn1._dp_wrapped_module.flat_param_0 value:: 153.6795654296875
2023-01-07 08:10:53,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,471 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,471 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,471 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,473 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 sum :: 153.6795654296875
2023-01-07 08:10:53,473 > [DEBUG] 0 :: param layer2.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,473 > [DEBUG] 0 :: param_name :: layer2.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,473 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,473 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv2._dp_wrapped_module.flat_param_0 value:: -212.29449462890625
2023-01-07 08:10:53,473 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,473 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,473 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,474 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 sum :: -212.29449462890625
2023-01-07 08:10:53,475 > [DEBUG] 0 :: param layer2.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,475 > [DEBUG] 0 :: param_name :: layer2.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,475 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,475 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn2._dp_wrapped_module.flat_param_0 value:: 153.69784545898438
2023-01-07 08:10:53,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,475 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,475 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,475 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,476 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 sum :: 153.69784545898438
2023-01-07 08:10:53,477 > [DEBUG] 0 :: param layer2.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,477 > [DEBUG] 0 :: param_name :: layer2.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,477 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,477 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.conv3._dp_wrapped_module.flat_param_0 value:: 399.79974365234375
2023-01-07 08:10:53,477 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,477 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,477 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,478 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 sum :: 399.79974365234375
2023-01-07 08:10:53,478 > [DEBUG] 0 :: param layer2.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,478 > [DEBUG] 0 :: param_name :: layer2.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,478 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,479 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.2.bn3._dp_wrapped_module.flat_param_0 value:: 644.9771118164062
2023-01-07 08:10:53,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,479 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,479 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,479 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,481 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 sum :: 644.9771118164062
2023-01-07 08:10:53,481 > [DEBUG] 0 :: param layer2.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,481 > [DEBUG] 0 :: param_name :: layer2.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,481 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,481 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv1._dp_wrapped_module.flat_param_0 value:: 32.8604736328125
2023-01-07 08:10:53,481 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,481 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,481 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,482 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 sum :: 32.8604736328125
2023-01-07 08:10:53,483 > [DEBUG] 0 :: param layer2.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,483 > [DEBUG] 0 :: param_name :: layer2.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,483 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,483 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn1._dp_wrapped_module.flat_param_0 value:: 153.78640747070312
2023-01-07 08:10:53,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,483 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,483 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,483 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,484 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 sum :: 153.78640747070312
2023-01-07 08:10:53,485 > [DEBUG] 0 :: param layer2.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,485 > [DEBUG] 0 :: param_name :: layer2.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,485 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,485 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv2._dp_wrapped_module.flat_param_0 value:: 33.13457107543945
2023-01-07 08:10:53,485 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,485 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,485 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,487 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 sum :: 33.13457107543945
2023-01-07 08:10:53,487 > [DEBUG] 0 :: param layer2.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,487 > [DEBUG] 0 :: param_name :: layer2.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,487 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,487 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn2._dp_wrapped_module.flat_param_0 value:: 141.82550048828125
2023-01-07 08:10:53,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,487 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,487 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,488 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,489 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 sum :: 141.82550048828125
2023-01-07 08:10:53,489 > [DEBUG] 0 :: param layer2.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,489 > [DEBUG] 0 :: param_name :: layer2.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,489 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,489 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.conv3._dp_wrapped_module.flat_param_0 value:: 260.775146484375
2023-01-07 08:10:53,489 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,489 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,489 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,491 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 sum :: 260.775146484375
2023-01-07 08:10:53,491 > [DEBUG] 0 :: param layer2.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,491 > [DEBUG] 0 :: param_name :: layer2.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,491 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,491 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer2.3.bn3._dp_wrapped_module.flat_param_0 value:: 519.2098999023438
2023-01-07 08:10:53,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,491 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,491 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,491 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,493 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 sum :: 519.2098999023438
2023-01-07 08:10:53,493 > [DEBUG] 0 :: param layer2.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,493 > [DEBUG] 0 :: param_name :: layer2.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,493 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,493 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv1._dp_wrapped_module.flat_param_0 value:: 467.8331298828125
2023-01-07 08:10:53,493 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,493 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,493 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,494 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 sum :: 467.8331298828125
2023-01-07 08:10:53,495 > [DEBUG] 0 :: param layer3.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,495 > [DEBUG] 0 :: param_name :: layer3.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,495 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,495 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.bn1._dp_wrapped_module.flat_param_0 value:: 284.40362548828125
2023-01-07 08:10:53,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,495 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,495 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,495 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,496 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 sum :: 284.40362548828125
2023-01-07 08:10:53,497 > [DEBUG] 0 :: param layer3.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,497 > [DEBUG] 0 :: param_name :: layer3.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,497 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,497 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv2._dp_wrapped_module.flat_param_0 value:: -40192.25390625
2023-01-07 08:10:53,497 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,497 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,497 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,498 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 sum :: -40192.25390625
2023-01-07 08:10:53,498 > [DEBUG] 0 :: param layer3.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,498 > [DEBUG] 0 :: param_name :: layer3.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,499 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,499 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -768.7770385742188
2023-01-07 08:10:53,499 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,499 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,499 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,500 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 sum :: 282.7441711425781
2023-01-07 08:10:53,500 > [DEBUG] 0 :: param layer3.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,500 > [DEBUG] 0 :: param_name :: layer3.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,500 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,500 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.conv3._dp_wrapped_module.flat_param_0 value:: -768.7770385742188
2023-01-07 08:10:53,500 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,500 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,500 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,502 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 sum :: -768.7770385742188
2023-01-07 08:10:53,502 > [DEBUG] 0 :: param layer3.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,502 > [DEBUG] 0 :: param_name :: layer3.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,502 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,502 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1510.34765625
2023-01-07 08:10:53,502 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,502 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,502 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,503 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 sum :: 1038.856689453125
2023-01-07 08:10:53,503 > [DEBUG] 0 :: param layer3.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,503 > [DEBUG] 0 :: param_name :: layer3.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,503 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,503 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -1510.34765625
2023-01-07 08:10:53,503 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,503 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,504 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,505 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -1510.34765625
2023-01-07 08:10:53,505 > [DEBUG] 0 :: param layer3.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,505 > [DEBUG] 0 :: param_name :: layer3.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,505 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,505 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1692.724853515625
2023-01-07 08:10:53,505 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,505 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,505 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,506 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 1075.06103515625
2023-01-07 08:10:53,506 > [DEBUG] 0 :: param layer3.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,506 > [DEBUG] 0 :: param_name :: layer3.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,506 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,507 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv1._dp_wrapped_module.flat_param_0 value:: -1692.724853515625
2023-01-07 08:10:53,507 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,507 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,507 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,508 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 sum :: -1692.724853515625
2023-01-07 08:10:53,508 > [DEBUG] 0 :: param layer3.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,508 > [DEBUG] 0 :: param_name :: layer3.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,508 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,508 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.bn1._dp_wrapped_module.flat_param_0 value:: 286.0472717285156
2023-01-07 08:10:53,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,509 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,509 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,509 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,510 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 sum :: 286.0472717285156
2023-01-07 08:10:53,510 > [DEBUG] 0 :: param layer3.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,510 > [DEBUG] 0 :: param_name :: layer3.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,510 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,510 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv2._dp_wrapped_module.flat_param_0 value:: -3212.95751953125
2023-01-07 08:10:53,511 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,511 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,511 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,512 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 sum :: -3212.95751953125
2023-01-07 08:10:53,512 > [DEBUG] 0 :: param layer3.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,512 > [DEBUG] 0 :: param_name :: layer3.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,512 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,512 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -317.4832458496094
2023-01-07 08:10:53,512 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,512 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,513 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,513 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 sum :: 291.15301513671875
2023-01-07 08:10:53,514 > [DEBUG] 0 :: param layer3.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,514 > [DEBUG] 0 :: param_name :: layer3.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,514 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,514 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.1.conv3._dp_wrapped_module.flat_param_0 value:: -317.4832458496094
2023-01-07 08:10:53,514 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,514 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,514 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,515 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 sum :: -317.4832458496094
2023-01-07 08:10:53,515 > [DEBUG] 0 :: param layer3.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,516 > [DEBUG] 0 :: param_name :: layer3.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,516 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,516 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 412.44287109375
2023-01-07 08:10:53,516 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,516 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,516 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,517 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 sum :: 1077.462646484375
2023-01-07 08:10:53,517 > [DEBUG] 0 :: param layer3.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,517 > [DEBUG] 0 :: param_name :: layer3.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,517 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,517 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv1._dp_wrapped_module.flat_param_0 value:: 412.44287109375
2023-01-07 08:10:53,517 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,517 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,517 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,519 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 sum :: 412.44287109375
2023-01-07 08:10:53,519 > [DEBUG] 0 :: param layer3.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,519 > [DEBUG] 0 :: param_name :: layer3.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,519 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,519 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 312.74273681640625
2023-01-07 08:10:53,519 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,519 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,519 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,520 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 sum :: 293.1439208984375
2023-01-07 08:10:53,520 > [DEBUG] 0 :: param layer3.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,520 > [DEBUG] 0 :: param_name :: layer3.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,520 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,520 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv2._dp_wrapped_module.flat_param_0 value:: 312.74273681640625
2023-01-07 08:10:53,521 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,521 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,521 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,522 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 sum :: 312.74273681640625
2023-01-07 08:10:53,522 > [DEBUG] 0 :: param layer3.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,522 > [DEBUG] 0 :: param_name :: layer3.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,522 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,522 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 592.6246337890625
2023-01-07 08:10:53,522 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,522 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,523 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,523 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 sum :: 295.14422607421875
2023-01-07 08:10:53,524 > [DEBUG] 0 :: param layer3.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,524 > [DEBUG] 0 :: param_name :: layer3.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,524 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,524 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.2.conv3._dp_wrapped_module.flat_param_0 value:: 592.6246337890625
2023-01-07 08:10:53,524 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,524 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,524 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,525 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 sum :: 592.6246337890625
2023-01-07 08:10:53,525 > [DEBUG] 0 :: param layer3.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,526 > [DEBUG] 0 :: param_name :: layer3.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,526 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,526 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 25.67688751220703
2023-01-07 08:10:53,526 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,526 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,526 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,527 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 sum :: 1064.2529296875
2023-01-07 08:10:53,527 > [DEBUG] 0 :: param layer3.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,527 > [DEBUG] 0 :: param_name :: layer3.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,527 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,527 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv1._dp_wrapped_module.flat_param_0 value:: 25.67688751220703
2023-01-07 08:10:53,527 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,527 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,527 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,529 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 sum :: 25.67688751220703
2023-01-07 08:10:53,529 > [DEBUG] 0 :: param layer3.3.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,529 > [DEBUG] 0 :: param_name :: layer3.3.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,529 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,529 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -375.514404296875
2023-01-07 08:10:53,529 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,529 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,529 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,530 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 sum :: 296.74371337890625
2023-01-07 08:10:53,530 > [DEBUG] 0 :: param layer3.3.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,530 > [DEBUG] 0 :: param_name :: layer3.3.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,530 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,530 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv2._dp_wrapped_module.flat_param_0 value:: -375.514404296875
2023-01-07 08:10:53,531 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,531 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,531 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,532 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 sum :: -375.514404296875
2023-01-07 08:10:53,532 > [DEBUG] 0 :: param layer3.3.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,532 > [DEBUG] 0 :: param_name :: layer3.3.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,532 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,532 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -56.612998962402344
2023-01-07 08:10:53,532 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,532 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,533 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,533 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 sum :: 297.74432373046875
2023-01-07 08:10:53,534 > [DEBUG] 0 :: param layer3.3.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,534 > [DEBUG] 0 :: param_name :: layer3.3.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,534 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,534 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.3.conv3._dp_wrapped_module.flat_param_0 value:: -56.612998962402344
2023-01-07 08:10:53,534 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,534 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,534 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,535 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 sum :: -56.612998962402344
2023-01-07 08:10:53,535 > [DEBUG] 0 :: param layer3.3.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,536 > [DEBUG] 0 :: param_name :: layer3.3.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,536 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,536 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -663.664306640625
2023-01-07 08:10:53,536 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,536 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,536 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,537 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 sum :: 1118.1116943359375
2023-01-07 08:10:53,537 > [DEBUG] 0 :: param layer3.3.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,537 > [DEBUG] 0 :: param_name :: layer3.3.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,537 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,537 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv1._dp_wrapped_module.flat_param_0 value:: -663.664306640625
2023-01-07 08:10:53,537 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,537 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,537 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,539 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 sum :: -663.664306640625
2023-01-07 08:10:53,539 > [DEBUG] 0 :: param layer3.4.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,539 > [DEBUG] 0 :: param_name :: layer3.4.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,539 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,539 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -1595.307373046875
2023-01-07 08:10:53,539 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,539 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,539 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,540 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 sum :: 297.9446716308594
2023-01-07 08:10:53,540 > [DEBUG] 0 :: param layer3.4.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,540 > [DEBUG] 0 :: param_name :: layer3.4.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,540 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,541 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv2._dp_wrapped_module.flat_param_0 value:: -1595.307373046875
2023-01-07 08:10:53,541 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,541 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,541 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,542 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 sum :: -1595.307373046875
2023-01-07 08:10:53,542 > [DEBUG] 0 :: param layer3.4.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,542 > [DEBUG] 0 :: param_name :: layer3.4.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,542 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,542 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -6558.41162109375
2023-01-07 08:10:53,543 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,543 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,543 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,544 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 sum :: 291.7757568359375
2023-01-07 08:10:53,544 > [DEBUG] 0 :: param layer3.4.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,544 > [DEBUG] 0 :: param_name :: layer3.4.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,544 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,544 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.4.conv3._dp_wrapped_module.flat_param_0 value:: -6558.41162109375
2023-01-07 08:10:53,544 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,544 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,544 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,546 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 sum :: -6558.41162109375
2023-01-07 08:10:53,546 > [DEBUG] 0 :: param layer3.4.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,546 > [DEBUG] 0 :: param_name :: layer3.4.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,546 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,546 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -45991.78125
2023-01-07 08:10:53,546 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,546 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,546 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,547 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 sum :: 1075.37353515625
2023-01-07 08:10:53,547 > [DEBUG] 0 :: param layer3.4.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,547 > [DEBUG] 0 :: param_name :: layer3.4.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,547 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,547 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv1._dp_wrapped_module.flat_param_0 value:: -45991.78125
2023-01-07 08:10:53,547 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,547 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,548 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,549 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 sum :: -45991.78125
2023-01-07 08:10:53,549 > [DEBUG] 0 :: param layer3.5.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,549 > [DEBUG] 0 :: param_name :: layer3.5.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,549 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,549 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -19735.46484375
2023-01-07 08:10:53,549 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,549 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,549 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,550 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 sum :: 298.9444580078125
2023-01-07 08:10:53,550 > [DEBUG] 0 :: param layer3.5.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,550 > [DEBUG] 0 :: param_name :: layer3.5.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,550 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,551 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv2._dp_wrapped_module.flat_param_0 value:: -19735.46484375
2023-01-07 08:10:53,551 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,551 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,551 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,552 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 sum :: -19735.46484375
2023-01-07 08:10:53,552 > [DEBUG] 0 :: param layer3.5.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,552 > [DEBUG] 0 :: param_name :: layer3.5.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,553 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,553 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -51895.3671875
2023-01-07 08:10:53,553 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,553 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,553 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,554 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 sum :: 299.54449462890625
2023-01-07 08:10:53,554 > [DEBUG] 0 :: param layer3.5.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,554 > [DEBUG] 0 :: param_name :: layer3.5.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,554 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,554 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer3.5.conv3._dp_wrapped_module.flat_param_0 value:: -51895.3671875
2023-01-07 08:10:53,554 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,554 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,554 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,556 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 sum :: -51895.3671875
2023-01-07 08:10:53,556 > [DEBUG] 0 :: param layer3.5.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,556 > [DEBUG] 0 :: param_name :: layer3.5.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,556 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,556 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -110173.0078125
2023-01-07 08:10:53,556 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,556 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,556 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,557 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 sum :: 1078.568603515625
2023-01-07 08:10:53,557 > [DEBUG] 0 :: param layer3.5.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,557 > [DEBUG] 0 :: param_name :: layer3.5.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,557 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,557 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv1._dp_wrapped_module.flat_param_0 value:: -110173.0078125
2023-01-07 08:10:53,557 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,558 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,558 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,559 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 sum :: -110173.0078125
2023-01-07 08:10:53,559 > [DEBUG] 0 :: param layer4.0.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,559 > [DEBUG] 0 :: param_name :: layer4.0.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,559 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,559 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -93018.65625
2023-01-07 08:10:53,559 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,560 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,560 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,560 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 sum :: 598.9859619140625
2023-01-07 08:10:53,561 > [DEBUG] 0 :: param layer4.0.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,561 > [DEBUG] 0 :: param_name :: layer4.0.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,561 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,561 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv2._dp_wrapped_module.flat_param_0 value:: -93018.65625
2023-01-07 08:10:53,561 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,561 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,561 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,562 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 sum :: -93018.65625
2023-01-07 08:10:53,562 > [DEBUG] 0 :: param layer4.0.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,563 > [DEBUG] 0 :: param_name :: layer4.0.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,563 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,563 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -756.5370483398438
2023-01-07 08:10:53,563 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,563 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,563 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,564 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 sum :: 490.21649169921875
2023-01-07 08:10:53,564 > [DEBUG] 0 :: param layer4.0.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,564 > [DEBUG] 0 :: param_name :: layer4.0.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,564 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,564 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.conv3._dp_wrapped_module.flat_param_0 value:: -756.5370483398438
2023-01-07 08:10:53,564 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,564 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,564 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,566 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 sum :: -756.5370483398438
2023-01-07 08:10:53,566 > [DEBUG] 0 :: param layer4.0.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,566 > [DEBUG] 0 :: param_name :: layer4.0.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,566 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,566 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -269569.375
2023-01-07 08:10:53,566 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,566 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,567 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,567 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 sum :: 2160.2099609375
2023-01-07 08:10:53,567 > [DEBUG] 0 :: param layer4.0.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,568 > [DEBUG] 0 :: param_name :: layer4.0.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,568 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,568 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.0.downsample.0._dp_wrapped_module.flat_param_0 value:: -269569.375
2023-01-07 08:10:53,568 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,568 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,568 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,569 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 sum :: -269569.375
2023-01-07 08:10:53,569 > [DEBUG] 0 :: param layer4.0.downsample.0._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,569 > [DEBUG] 0 :: param_name :: layer4.0.downsample.0._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,569 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,569 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -58275.9765625
2023-01-07 08:10:53,570 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,570 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,570 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,571 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 sum :: 2158.96240234375
2023-01-07 08:10:53,571 > [DEBUG] 0 :: param layer4.0.downsample.1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,571 > [DEBUG] 0 :: param_name :: layer4.0.downsample.1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,571 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,571 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv1._dp_wrapped_module.flat_param_0 value:: -58275.9765625
2023-01-07 08:10:53,571 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,571 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,571 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,573 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 sum :: -58275.9765625
2023-01-07 08:10:53,573 > [DEBUG] 0 :: param layer4.1.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,573 > [DEBUG] 0 :: param_name :: layer4.1.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,573 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,573 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -751.629150390625
2023-01-07 08:10:53,573 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,573 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,573 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,574 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 sum :: 599.333984375
2023-01-07 08:10:53,574 > [DEBUG] 0 :: param layer4.1.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,574 > [DEBUG] 0 :: param_name :: layer4.1.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,574 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,574 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv2._dp_wrapped_module.flat_param_0 value:: -751.629150390625
2023-01-07 08:10:53,574 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,574 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,575 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,576 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 sum :: -751.629150390625
2023-01-07 08:10:53,576 > [DEBUG] 0 :: param layer4.1.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,576 > [DEBUG] 0 :: param_name :: layer4.1.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,576 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,576 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -74435.171875
2023-01-07 08:10:53,576 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,576 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,576 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,577 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 sum :: 599.295166015625
2023-01-07 08:10:53,577 > [DEBUG] 0 :: param layer4.1.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,577 > [DEBUG] 0 :: param_name :: layer4.1.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,578 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,578 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.1.conv3._dp_wrapped_module.flat_param_0 value:: -74435.171875
2023-01-07 08:10:53,578 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,578 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,578 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,579 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 sum :: -74435.171875
2023-01-07 08:10:53,579 > [DEBUG] 0 :: param layer4.1.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,579 > [DEBUG] 0 :: param_name :: layer4.1.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,579 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,580 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -224922.125
2023-01-07 08:10:53,580 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,580 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,580 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,581 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 sum :: 2166.796630859375
2023-01-07 08:10:53,581 > [DEBUG] 0 :: param layer4.1.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,581 > [DEBUG] 0 :: param_name :: layer4.1.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,581 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,581 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv1._dp_wrapped_module.flat_param_0 value:: -224922.125
2023-01-07 08:10:53,581 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,581 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,581 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,583 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 sum :: -224922.125
2023-01-07 08:10:53,583 > [DEBUG] 0 :: param layer4.2.conv1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,583 > [DEBUG] 0 :: param_name :: layer4.2.conv1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,583 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,583 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -27011.623046875
2023-01-07 08:10:53,583 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,583 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,583 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,584 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 sum :: 595.60400390625
2023-01-07 08:10:53,584 > [DEBUG] 0 :: param layer4.2.bn1._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,584 > [DEBUG] 0 :: param_name :: layer4.2.bn1._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,584 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,584 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv2._dp_wrapped_module.flat_param_0 value:: -27011.623046875
2023-01-07 08:10:53,584 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,584 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,585 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,586 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 sum :: -27011.623046875
2023-01-07 08:10:53,586 > [DEBUG] 0 :: param layer4.2.conv2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,586 > [DEBUG] 0 :: param_name :: layer4.2.conv2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,586 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,586 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -535.077880859375
2023-01-07 08:10:53,586 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,586 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,587 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,587 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 sum :: 622.0064697265625
2023-01-07 08:10:53,588 > [DEBUG] 0 :: param layer4.2.bn2._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,588 > [DEBUG] 0 :: param_name :: layer4.2.bn2._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,588 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,588 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  layer4.2.conv3._dp_wrapped_module.flat_param_0 value:: -535.077880859375
2023-01-07 08:10:53,588 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,588 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,588 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,589 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 sum :: -535.077880859375
2023-01-07 08:10:53,589 > [DEBUG] 0 :: param layer4.2.conv3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,590 > [DEBUG] 0 :: param_name :: layer4.2.conv3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,590 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,590 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -326947.8125
2023-01-07 08:10:53,590 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,590 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,590 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,591 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 sum :: 2495.435546875
2023-01-07 08:10:53,591 > [DEBUG] 0 :: param layer4.2.bn3._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,591 > [DEBUG] 0 :: param_name :: layer4.2.bn3._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,591 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,591 > [DEBUG] 0 :: param variable tracking model? rank :: 0 param name ::  fc._dp_wrapped_module.flat_param_0 value:: -326947.8125
2023-01-07 08:10:53,591 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,591 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,591 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:53,593 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 sum :: -326947.8125
2023-01-07 08:10:53,593 > [DEBUG] 0 :: param fc._dp_wrapped_module.flat_param_0 is fully commnicated
2023-01-07 08:10:53,593 > [DEBUG] 0 :: param_name :: fc._dp_wrapped_module.flat_param_0 communicated param num : 0
2023-01-07 08:10:53,593 > [DEBUG] 0 :: ########### task is assigned to module############
2023-01-07 08:10:53,594 > [DEBUG] 0 :: 139.4436798095703
2023-01-07 08:10:53,596 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,596 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,596 > [DEBUG] 0 :: before allreduce fusion buffer :: 4233664135168.0
2023-01-07 08:10:53,597 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,597 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,598 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,598 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,598 > [DEBUG] 0 :: before allreduce fusion buffer :: 204378.0625
2023-01-07 08:10:53,600 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,600 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,600 > [DEBUG] 0 :: before allreduce fusion buffer :: 38.72346115112305
2023-01-07 08:10:53,601 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,601 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,602 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,602 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,602 > [DEBUG] 0 :: before allreduce fusion buffer :: 8467289997312.0
2023-01-07 08:10:53,604 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,604 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,604 > [DEBUG] 0 :: before allreduce fusion buffer :: 16934581043200.0
2023-01-07 08:10:53,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,605 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,605 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,606 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,606 > [DEBUG] 0 :: before allreduce fusion buffer :: 16934583140352.0
2023-01-07 08:10:53,608 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,608 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,608 > [DEBUG] 0 :: before allreduce fusion buffer :: 33869162086400.0
2023-01-07 08:10:53,609 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,609 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,609 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,609 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,609 > [DEBUG] 0 :: before allreduce fusion buffer :: 1637550.25
2023-01-07 08:10:53,611 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,611 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,611 > [DEBUG] 0 :: before allreduce fusion buffer :: -1020.9879150390625
2023-01-07 08:10:53,612 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,612 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,612 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,612 > [DEBUG] 0 :: before allreduce fusion buffer :: -1211856.75
2023-01-07 08:10:53,614 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,614 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,614 > [DEBUG] 0 :: before allreduce fusion buffer :: -603481216.0
2023-01-07 08:10:53,615 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,615 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,615 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,615 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,615 > [DEBUG] 0 :: before allreduce fusion buffer :: -601864576.0
2023-01-07 08:10:53,617 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,617 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,617 > [DEBUG] 0 :: before allreduce fusion buffer :: -1207137536.0
2023-01-07 08:10:53,618 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,618 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,618 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,618 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,618 > [DEBUG] 0 :: before allreduce fusion buffer :: -2049403.125
2023-01-07 08:10:53,620 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,620 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,620 > [DEBUG] 0 :: before allreduce fusion buffer :: -2414361600.0
2023-01-07 08:10:53,621 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,621 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,621 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,621 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,621 > [DEBUG] 0 :: before allreduce fusion buffer :: 2456452.0
2023-01-07 08:10:53,623 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,623 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,623 > [DEBUG] 0 :: before allreduce fusion buffer :: 42570.48046875
2023-01-07 08:10:53,624 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,624 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,624 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,624 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,624 > [DEBUG] 0 :: before allreduce fusion buffer :: -9661915136.0
2023-01-07 08:10:53,626 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,626 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,626 > [DEBUG] 0 :: before allreduce fusion buffer :: -19311730688.0
2023-01-07 08:10:53,627 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,627 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,627 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,627 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,628 > [DEBUG] 0 :: before allreduce fusion buffer :: -38618546176.0
2023-01-07 08:10:53,630 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,630 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,631 > [DEBUG] 0 :: before allreduce fusion buffer :: -38623461376.0
2023-01-07 08:10:53,631 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,632 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,632 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,632 > [DEBUG] 0 :: before allreduce fusion buffer :: -77235609600.0
2023-01-07 08:10:53,633 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,633 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,634 > [DEBUG] 0 :: before allreduce fusion buffer :: -291.035888671875
2023-01-07 08:10:53,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,635 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,635 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,635 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,635 > [DEBUG] 0 :: before allreduce fusion buffer :: -103950925824.0
2023-01-07 08:10:53,637 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,637 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,637 > [DEBUG] 0 :: before allreduce fusion buffer :: -102.98548126220703
2023-01-07 08:10:53,638 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,638 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,638 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,638 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,639 > [DEBUG] 0 :: before allreduce fusion buffer :: -103947976704.0
2023-01-07 08:10:53,640 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,640 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,640 > [DEBUG] 0 :: before allreduce fusion buffer :: -207921496064.0
2023-01-07 08:10:53,641 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,641 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,641 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,641 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,642 > [DEBUG] 0 :: before allreduce fusion buffer :: -415817465856.0
2023-01-07 08:10:53,643 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,643 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,643 > [DEBUG] 0 :: before allreduce fusion buffer :: -552.63427734375
2023-01-07 08:10:53,644 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,644 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,644 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,644 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,645 > [DEBUG] 0 :: before allreduce fusion buffer :: -415766183936.0
2023-01-07 08:10:53,646 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,646 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,646 > [DEBUG] 0 :: before allreduce fusion buffer :: 95.05695343017578
2023-01-07 08:10:53,647 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,647 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,647 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,647 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,648 > [DEBUG] 0 :: before allreduce fusion buffer :: -831682904064.0
2023-01-07 08:10:53,649 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,649 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,649 > [DEBUG] 0 :: before allreduce fusion buffer :: -1663673040896.0
2023-01-07 08:10:53,650 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,650 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,650 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,650 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,651 > [DEBUG] 0 :: before allreduce fusion buffer :: -3327192465408.0
2023-01-07 08:10:53,652 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,652 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,652 > [DEBUG] 0 :: before allreduce fusion buffer :: 435.6410827636719
2023-01-07 08:10:53,653 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,653 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,653 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,653 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,654 > [DEBUG] 0 :: before allreduce fusion buffer :: -3327243845632.0
2023-01-07 08:10:53,655 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,655 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,655 > [DEBUG] 0 :: before allreduce fusion buffer :: 718.3514404296875
2023-01-07 08:10:53,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,656 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,656 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,657 > [DEBUG] 0 :: before allreduce fusion buffer :: -3327040946176.0
2023-01-07 08:10:53,658 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,658 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,658 > [DEBUG] 0 :: before allreduce fusion buffer :: -6654692163584.0
2023-01-07 08:10:53,659 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,659 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,659 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,659 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,660 > [DEBUG] 0 :: before allreduce fusion buffer :: -6654081892352.0
2023-01-07 08:10:53,661 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,661 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,661 > [DEBUG] 0 :: before allreduce fusion buffer :: -2243.35595703125
2023-01-07 08:10:53,662 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,662 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,662 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,662 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,663 > [DEBUG] 0 :: before allreduce fusion buffer :: -6654081892352.0
2023-01-07 08:10:53,664 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,664 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,664 > [DEBUG] 0 :: before allreduce fusion buffer :: -4481.71923828125
2023-01-07 08:10:53,665 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,665 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,665 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,665 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,666 > [DEBUG] 0 :: before allreduce fusion buffer :: -13308165881856.0
2023-01-07 08:10:53,667 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,667 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,667 > [DEBUG] 0 :: before allreduce fusion buffer :: -26618768654336.0
2023-01-07 08:10:53,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,668 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,668 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,669 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,669 > [DEBUG] 0 :: before allreduce fusion buffer :: -53235104612352.0
2023-01-07 08:10:53,670 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,670 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,670 > [DEBUG] 0 :: before allreduce fusion buffer :: 7124.3642578125
2023-01-07 08:10:53,671 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,671 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,672 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,672 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,672 > [DEBUG] 0 :: before allreduce fusion buffer :: 5658457088.0
2023-01-07 08:10:53,674 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,674 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,674 > [DEBUG] 0 :: before allreduce fusion buffer :: 28517.42578125
2023-01-07 08:10:53,675 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,675 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,675 > [DEBUG] 0 :: before allreduce fusion buffer :: 11317132288.0
2023-01-07 08:10:53,676 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,676 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,676 > [DEBUG] 0 :: before allreduce fusion buffer :: 114070.921875
2023-01-07 08:10:53,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,677 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,677 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,678 > [DEBUG] 0 :: before allreduce fusion buffer :: 15711405056.0
2023-01-07 08:10:53,679 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,679 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,679 > [DEBUG] 0 :: before allreduce fusion buffer :: -4552.81640625
2023-01-07 08:10:53,680 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,680 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,680 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,680 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,681 > [DEBUG] 0 :: before allreduce fusion buffer :: 15711485952.0
2023-01-07 08:10:53,682 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,682 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,682 > [DEBUG] 0 :: before allreduce fusion buffer :: -18213.84375
2023-01-07 08:10:53,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,683 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,683 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,684 > [DEBUG] 0 :: before allreduce fusion buffer :: 15711436800.0
2023-01-07 08:10:53,847 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,847 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,847 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.01462106965482235
2023-01-07 08:10:53,848 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,848 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,848 > [DEBUG] 0 :: before allreduce fusion buffer :: 31423172608.0
2023-01-07 08:10:53,850 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,850 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,850 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.308821439743042
2023-01-07 08:10:53,851 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,851 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,851 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.6200881004333496
2023-01-07 08:10:53,852 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,852 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,852 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.8098516464233398
2023-01-07 08:10:53,853 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,853 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,853 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.6412500143051147
2023-01-07 08:10:53,854 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,854 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,855 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.044790834188461304
2023-01-07 08:10:53,856 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,856 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,856 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.2083821296691895
2023-01-07 08:10:53,857 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,857 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,857 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.02142071723938
2023-01-07 08:10:53,858 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,858 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,858 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.134300708770752
2023-01-07 08:10:53,859 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:53,859 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:53,860 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.19536982476711273
2023-01-07 08:10:54,029 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,029 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,030 > [DEBUG] 0 :: before allreduce fusion buffer :: -5.023709297180176
2023-01-07 08:10:54,031 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,031 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,031 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.032967861741781235
2023-01-07 08:10:54,032 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,032 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,032 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.2190804481506348
2023-01-07 08:10:54,033 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,033 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,034 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.305758476257324
2023-01-07 08:10:54,034 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,034 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,035 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,035 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,035 > [DEBUG] 0 :: before allreduce fusion buffer :: -4.3546671867370605
2023-01-07 08:10:54,214 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,214 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,214 > [DEBUG] 0 :: before allreduce fusion buffer :: 2.222177505493164
2023-01-07 08:10:54,215 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,215 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,215 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.813596725463867
2023-01-07 08:10:54,217 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,217 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,217 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.896149754524231
2023-01-07 08:10:54,330 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,330 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,330 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.7929033041000366
2023-01-07 08:10:54,332 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,332 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,332 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.38051846623420715
2023-01-07 08:10:54,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,333 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,333 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,333 > [DEBUG] 0 :: before allreduce fusion buffer :: 6.386589050292969
2023-01-07 08:10:54,335 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,335 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,335 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.5073328018188477
2023-01-07 08:10:54,336 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,336 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,336 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.0515401363372803
2023-01-07 08:10:54,337 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,337 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,337 > [DEBUG] 0 :: before allreduce fusion buffer :: -1.9153177738189697
2023-01-07 08:10:54,338 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,338 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,338 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.39455896615982056
2023-01-07 08:10:54,340 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,340 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,340 > [DEBUG] 0 :: before allreduce fusion buffer :: -3.483870029449463
2023-01-07 08:10:54,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,341 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,341 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,341 > [DEBUG] 0 :: before allreduce fusion buffer :: 1.3429327011108398
2023-01-07 08:10:54,343 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,343 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,343 > [DEBUG] 0 :: before allreduce fusion buffer :: 8.791234970092773
2023-01-07 08:10:54,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,344 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,344 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,344 > [DEBUG] 0 :: before allreduce fusion buffer :: -46013.87109375
2023-01-07 08:10:54,346 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,346 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,346 > [DEBUG] 0 :: before allreduce fusion buffer :: -2633853.25
2023-01-07 08:10:54,347 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,347 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,347 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.0
2023-01-07 08:10:54,348 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,348 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,349 > [DEBUG] 0 :: before allreduce fusion buffer :: 15.602964401245117
2023-01-07 08:10:54,349 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,350 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,350 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,350 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,350 > [DEBUG] 0 :: before allreduce fusion buffer :: 0.5310105085372925
2023-01-07 08:10:54,351 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,351 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,352 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.910891532897949
2023-01-07 08:10:54,352 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,353 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,353 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,353 > [DEBUG] 0 :: before allreduce fusion buffer :: 58.41462326049805
2023-01-07 08:10:54,354 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,354 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,355 > [DEBUG] 0 :: before allreduce fusion buffer :: -0.5245000123977661
2023-01-07 08:10:54,355 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,355 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,356 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,356 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,356 > [DEBUG] 0 :: before allreduce fusion buffer :: -6373015552.0
2023-01-07 08:10:54,357 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,357 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,357 > [DEBUG] 0 :: before allreduce fusion buffer :: -6.301095962524414
2023-01-07 08:10:54,358 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,358 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,358 > [DEBUG] 0 :: before allreduce fusion buffer :: -7.943743705749512
2023-01-07 08:10:54,359 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,359 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,360 > [DEBUG] 0 :: before allreduce fusion buffer :: 3.9766178131103516
2023-01-07 08:10:54,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,361 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,361 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,362 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,362 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,362 > [DEBUG] 0 :: before allreduce fusion buffer :: -1083354.75
2023-01-07 08:10:54,363 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,363 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,364 > [DEBUG] 0 :: before allreduce fusion buffer :: 4.669113636016846
2023-01-07 08:10:54,364 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,364 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,365 > [DEBUG] 0 :: before allreduce fusion buffer :: -104.79806518554688
2023-01-07 08:10:54,366 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,366 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,366 > [DEBUG] 0 :: before allreduce fusion buffer :: -39645312.0
2023-01-07 08:10:54,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,367 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,367 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,367 > [DEBUG] 0 :: before allreduce fusion buffer :: -15.734989166259766
2023-01-07 08:10:54,369 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,369 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,369 > [DEBUG] 0 :: before allreduce fusion buffer :: 10.962148666381836
2023-01-07 08:10:54,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,370 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,370 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,370 > [DEBUG] 0 :: before allreduce fusion buffer :: 18464068.0
2023-01-07 08:10:54,372 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,372 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,372 > [DEBUG] 0 :: before allreduce fusion buffer :: 4415867404156928.0
2023-01-07 08:10:54,373 > [DEBUG] 0 :: do all reduce async
2023-01-07 08:10:54,373 > [DEBUG] 0 :: same parameter is in the dictionary
2023-01-07 08:10:54,373 > [DEBUG] 0 :: before allreduce fusion buffer :: -2.388056755065918
