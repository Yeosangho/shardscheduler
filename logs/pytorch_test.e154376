[00;33m 	'cuda/11.3' does not supports the {CUDA_MPI}. [0m
[00;34m 	{CUDA_MPI} is only supported in cuda 11.4 version. [0m
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "main_gpt2_with_health_checker.py", line 484, in <module>
    trainer = Trainer(world_size, rank, bucket_size, count, adaptive_shard_ratio, health_check_scheduler_thread, health_check_main_proc, health_check_thread_ready, trial_info, thread) 
  File "main_gpt2_with_health_checker.py", line 313, in __init__
    make_schedule_from_json(params_list, self._schedule_comm_init, self._scheduled_comms, self._locks, self.adaptive_sdp_modules)
  File "/scratch/hpc72a03/shardscheduler/test_cases.py", line 792, in make_schedule_from_json
    task_dict[comp_type][comp_param].append(task)
KeyError: '_dp_wrapped_module._fpw_module.transformer.ln_f._dp_wrapped_module.flat_param_0'
Traceback (most recent call last):
  File "main_gpt2_with_health_checker.py", line 484, in <module>
    trainer = Trainer(world_size, rank, bucket_size, count, adaptive_shard_ratio, health_check_scheduler_thread, health_check_main_proc, health_check_thread_ready, trial_info, thread) 
  File "main_gpt2_with_health_checker.py", line 313, in __init__
    make_schedule_from_json(params_list, self._schedule_comm_init, self._scheduled_comms, self._locks, self.adaptive_sdp_modules)
  File "/scratch/hpc72a03/shardscheduler/test_cases.py", line 792, in make_schedule_from_json
    task_dict[comp_type][comp_param].append(task)
KeyError: '_dp_wrapped_module._fpw_module.transformer.ln_f._dp_wrapped_module.flat_param_0'
Traceback (most recent call last):
  File "main_gpt2_with_health_checker.py", line 484, in <module>
    trainer = Trainer(world_size, rank, bucket_size, count, adaptive_shard_ratio, health_check_scheduler_thread, health_check_main_proc, health_check_thread_ready, trial_info, thread) 
  File "main_gpt2_with_health_checker.py", line 313, in __init__
    make_schedule_from_json(params_list, self._schedule_comm_init, self._scheduled_comms, self._locks, self.adaptive_sdp_modules)
  File "/scratch/hpc72a03/shardscheduler/test_cases.py", line 792, in make_schedule_from_json
    task_dict[comp_type][comp_param].append(task)
KeyError: '_dp_wrapped_module._fpw_module.transformer.ln_f._dp_wrapped_module.flat_param_0'
Traceback (most recent call last):
  File "main_gpt2_with_health_checker.py", line 484, in <module>
    trainer = Trainer(world_size, rank, bucket_size, count, adaptive_shard_ratio, health_check_scheduler_thread, health_check_main_proc, health_check_thread_ready, trial_info, thread) 
  File "main_gpt2_with_health_checker.py", line 313, in __init__
    make_schedule_from_json(params_list, self._schedule_comm_init, self._scheduled_comms, self._locks, self.adaptive_sdp_modules)
  File "/scratch/hpc72a03/shardscheduler/test_cases.py", line 792, in make_schedule_from_json
    task_dict[comp_type][comp_param].append(task)
KeyError: '_dp_wrapped_module._fpw_module.transformer.ln_f._dp_wrapped_module.flat_param_0'
srun: error: gpu10: tasks 0-2: Exited with exit code 1
srun: error: gpu10: task 3: Exited with exit code 1
